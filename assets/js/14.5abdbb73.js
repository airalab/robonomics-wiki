(window["webpackJsonp"] = window["webpackJsonp"] || []).push([[14],{

/***/ "A2fM":
/*!**********************************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=custom&index=0&blockType=static-query ***!
  \**********************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_babel_loader_lib_index_js_ref_14_0_node_modules_gridsome_lib_plugins_vue_components_lib_loaders_static_query_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/babel-loader/lib??ref--14-0!../../node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=custom&index=0&blockType=static-query */ \"r2nM\");\n/* empty/unused harmony star reexport */ /* harmony default export */ __webpack_exports__[\"default\"] = (_node_modules_babel_loader_lib_index_js_ref_14_0_node_modules_gridsome_lib_plugins_vue_components_lib_loaders_static_query_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_0__[\"default\"]); \n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "BO/4":
/*!************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=script&lang=js& ***!
  \************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/babel-loader/lib??ref--1-1!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=script&lang=js& */ \"uifM\");\n/* empty/unused harmony star reexport */ /* harmony default export */ __webpack_exports__[\"default\"] = (_node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_0__[\"default\"]); \n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "JaYo":
/*!*************************************************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=style&index=0&id=64c7a3b8&prod&scoped=true&lang=css& ***!
  \*************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_2_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_2_oneOf_1_2_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/mini-css-extract-plugin/dist/loader.js!../../node_modules/css-loader/dist/cjs.js??ref--2-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src??ref--2-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=style&index=0&id=64c7a3b8&prod&scoped=true&lang=css& */ \"shUY\");\n/* harmony import */ var _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_2_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_2_oneOf_1_2_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_2_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_2_oneOf_1_2_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_0__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_2_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_2_oneOf_1_2_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_0__) if([\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_2_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_2_oneOf_1_2_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_0__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "RKrg":
/*!*****************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/cache-loader/dist/cjs.js?{"cacheDirectory":"node_modules/.cache/gridsome","cacheIdentifier":"d818ecc8-vue-loader-template"}!./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/vue-loader/lib/loaders/templateLoader.js??ref--6!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=template&id=64c7a3b8&scoped=true& ***!
  \*****************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: render, staticRenderFns */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"render\", function() { return render; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"staticRenderFns\", function() { return staticRenderFns; });\nvar render = function render() {\n  var _vm = this,\n    _c = _vm._self._c;\n  return _c('div', {\n    staticClass: \"search-container\",\n    class: _vm.toggleClasses,\n    attrs: {\n      \"tabindex\": \"0\"\n    },\n    on: {\n      \"focusin\": _vm.focusIn,\n      \"focusout\": _vm.focusOut\n    }\n  }, [_c('input', {\n    directives: [{\n      name: \"model\",\n      rawName: \"v-model\",\n      value: _vm.search,\n      expression: \"search\"\n    }],\n    attrs: {\n      \"type\": \"search\",\n      \"aria-label\": \"Search\",\n      \"placeholder\": \"Search\"\n    },\n    domProps: {\n      \"value\": _vm.search\n    },\n    on: {\n      \"input\": function ($event) {\n        if ($event.target.composing) return;\n        _vm.search = $event.target.value;\n      }\n    }\n  }), _vm.searchResults.length > 0 ? _c('div', {\n    staticClass: \"searchresults\",\n    attrs: {\n      \"role\": \"listbox\"\n    }\n  }, [_c('div', {\n    staticClass: \"layout__content\"\n  }, [_c('div', {\n    staticClass: \"search-msg-count\",\n    attrs: {\n      \"aria-hidden\": \"true\"\n    }\n  }, [_vm._v(\"Found results: \" + _vm._s(_vm.searchResults.length))]), _c('nav', _vm._l(_vm.searchResults, function (post) {\n    return _c('g-link', {\n      key: post.node.id,\n      attrs: {\n        \"to\": post.node.path\n      },\n      on: {\n        \"focusout\": _vm.SearchLinksNextFocus\n      }\n    }, [_vm._v(_vm._s(post.node.title))]);\n  }), 1)])]) : _vm._e()]);\n};\nvar staticRenderFns = [];\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/cache-loader/dist/cjs.js?%7B%22cacheDirectory%22:%22node_modules/.cache/gridsome%22,%22cacheIdentifier%22:%22d818ecc8-vue-loader-template%22%7D!./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/vue-loader/lib/loaders/templateLoader.js??ref--6!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "ope7":
/*!******************************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=template&id=64c7a3b8&scoped=true& ***!
  \******************************************************************************/
/*! exports provided: render, staticRenderFns */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_d818ecc8_vue_loader_template_node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_vue_loader_lib_loaders_templateLoader_js_ref_6_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/cache-loader/dist/cjs.js?{\"cacheDirectory\":\"node_modules/.cache/gridsome\",\"cacheIdentifier\":\"d818ecc8-vue-loader-template\"}!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/babel-loader/lib??ref--1-1!../../node_modules/vue-loader/lib/loaders/templateLoader.js??ref--6!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=template&id=64c7a3b8&scoped=true& */ \"RKrg\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"render\", function() { return _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_d818ecc8_vue_loader_template_node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_vue_loader_lib_loaders_templateLoader_js_ref_6_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__[\"render\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"staticRenderFns\", function() { return _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_d818ecc8_vue_loader_template_node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_vue_loader_lib_loaders_templateLoader_js_ref_6_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__[\"staticRenderFns\"]; });\n\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "r2nM":
/*!****************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/babel-loader/lib??ref--14-0!./node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=custom&index=0&blockType=static-query ***!
  \****************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var vue__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! vue */ \"Kw5r\");\n\nconst {\n  computed\n} = vue__WEBPACK_IMPORTED_MODULE_0__[\"default\"].config.optionMergeStrategies;\nconst data = {\n  \"allDocPage\": {\n    \"edges\": [{\n      \"node\": {\n        \"id\": \"d0d990f6331e4d4af06321360f4bd757\",\n        \"title\": \"Zigbee Adapter with Zigbee2MQTT for Pre-installed Image or Home Assistant Docker or Core\",\n        \"path\": \"/docs/zigbee-to-mqtt/\",\n        \"content\": \"\\n**In this article you will set up your Zigbee adapter for Robonomics pre-installed image or Home Assistant Docker or Home Assistant Core.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/zigbee2mqtt.png\\\" />\\n\\n**If you have the [JetHome USB JetStick Z2](https://jethome.ru/z2/?sl=en) (which has all of the necessary firmware), you can simply proceed with these instructions. However, if you have another adapter, the first thing you need to do is to flash it with Zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).**\\n\\n\\n## Software Install\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\n  If you use pre-installed image from Robonomics, this software already installed to your Raspberry Pi. Go to [\\\"Configuration and Run\\\"](/docs/zigbee-to-mqtt#config-and-run) section.\\n\\n</robo-wiki-note>\\n\\nSet up Node.js runtime environment repository and install it with required dependencies:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -\\nsudo apt-get install -y nodejs git make g++ gcc\\n```\\n\\n</code-helper>\\n\\nVerify that the correct versions of Node.js (v14.X, V16.x, V17.x or V18.X) and package manager npm (6.X, 7.X or 8.X) automatically installed with Node.js, have been installed:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nnode --version\\nnpm --version\\n```\\n\\n</code-helper>\\n\\nCreate a directory for Zigbee2MQTT and set your user as owner of it:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo mkdir /opt/zigbee2mqtt\\nsudo chown -R ${USER}: /opt/zigbee2mqtt\\n```\\n\\n</code-helper>\\n\\nClone Zigbee2MQTT repository:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\ngit clone --depth 1 --branch 1.28.2 https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\n```\\n\\n</code-helper>\\n\\nInstall dependencies (as user pi). Note that the npm ci could produce some warning which can be ignored.\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-title :type=\\\"2\\\" anchor=\\\"config-and-run\\\">\\nConfiguration and Run\\n</robo-wiki-title>\\n\\nConnect the Zigbee adapter to Raspberry Pi.\\n\\n<robo-wiki-picture src=\\\"home-assistant/connect-stick.gif\\\" />\\n\\nThen you need to find the location of the adapter. For this run the next command:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```bash\\nls -l /dev/serial/by-id\\n```\\n\\n</code-helper>\\n\\nOutput should look like:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n\\n```shell\\n$ ls -l /dev/serial/by-id\\ntotal 0\\nlrwxrwxrwx 1 root root 13 Oct 10 01:44 usb-Silicon_Labs_CP2102_USB_to_UART_Bridge_Controller_0001-if00-port0 -> ../../ttyUSB0\\n\\n```\\n\\n</code-helper>\\n\\nIn this example device connection directory is `ttyUSB0`.\\n\\nBefore starting Zigbee2MQTT you need to edit the `configuration.yaml` file. This file contains the configuration which will be used by Zigbee2MQTT:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\n\\n</code-helper>\\n\\nThe basic configuration needs a few adjustments. Change the following statements:\\n - `homeassistant:` to `true`. It will automatically connect sensors to Home Assistant.\\n - uncomment `user` and `password`statements under `mqtt` and enter your username and password (as a string, with quotes) from MQTT Broker.\\n - change port in `serial`-> `port` to `/dev/DEVICE_CONNECTION_DIRECTORY>`. In this example — `/dev/ttyUSB0`.\\n\\nAdjusted configuration file should look like:\\n\\n<code-helper copy>\\n\\n```shell\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: true\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n  # MQTT server authentication, uncomment if required:\\n  user: <YOUR_USERNAME>\\n  password: <YOUR_PASSWORD>\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/<YOUR_PORT> # /dev/ttyUSB0 for example\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\n  If you already have an active Zigbee adapter or gateway in your home, and you are now configuring another adapter, then they will conflict with each other. To solve this problem you need to change the channel on the new device. For this add the following strings to the end of configuration file:\\n\\n</robo-wiki-note>\\n\\n<code-helper copy>\\n\\n```shell\\nadvanced:\\n  # Optional: ZigBee channel, changing requires re-pairing of all devices. (Note: use a ZLL channel: 11, 15, 20, or 25 to avoid Problems)\\n  # (default: 11)\\n  channel: 15\\n```\\n\\n</code-helper>\\n\\nNow you can start Zigbee2MQTT:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n\\n</code-helper>\\n\\nIf started successfully, you will see something like:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nBuilding Zigbee2MQTT... (initial build), finished\\nZigbee2MQTT:info  2022-07-29 14:36:36: Logging to console and directory: '/opt/zigbee2mqtt/data/log/2022-07-29.14-36-36' filename: log.txt\\nZigbee2MQTT:info  2022-07-29 14:36:36: Starting Zigbee2MQTT version 1.26.0 (commit #bc4ffc0)\\nZigbee2MQTT:info  2022-07-29 14:36:36: Starting zigbee-herdsman (0.14.40)\\nZigbee2MQTT:info  2022-07-29 14:36:49: zigbee-herdsman started (resumed)\\nZigbee2MQTT:info  2022-07-29 14:36:49: Coordinator firmware version: '{\\\"meta\\\":{\\\"maintrel\\\":1,\\\"majorrel\\\":2,\\\"minorrel\\\":7,\\\"product\\\":1,\\\"revision\\\":20211219,\\\"transportrev\\\":2},\\\"type\\\":\\\"zStack3x0\\\"}'\\nZigbee2MQTT:info  2022-07-29 14:36:49: Currently 0 devices are joined:\\nZigbee2MQTT:warn  2022-07-29 14:36:49: `permit_join` set to  `true` in configuration.yaml.\\nZigbee2MQTT:warn  2022-07-29 14:36:49: Allowing new devices to join.\\nZigbee2MQTT:warn  2022-07-29 14:36:49: Set `permit_join` to `false` once you joined all devices.\\nZigbee2MQTT:info  2022-07-29 14:36:49: Zigbee: allowing new devices to join.\\nZigbee2MQTT:info  2022-07-29 14:36:49: Connecting to MQTT server at mqtt://localhost\\nZigbee2MQTT:info  2022-07-29 14:36:49: Connected to MQTT server\\nZigbee2MQTT:info  2022-07-29 14:36:49: MQTT publish: topic 'zigbee2mqtt/bridge/state', payload 'online'\\nZigbee2MQTT:info  2022-07-29 14:36:49: MQTT publish: topic 'zigbee2mqtt/bridge/config', payload '{\\\"commit\\\":\\\"bc4ffc0\\\",\\\"coordinator\\\":{\\\"meta\\\":{\\\"maintrel\\\":1,\\\"majorrel\\\":2,\\\"minorrel\\\":7,\\\"product\\\":1,\\\"revision\\\":20211219,\\\"transportrev\\\":2},\\\"type\\\":\\\"zStack3x0\\\"},\\\"log_level\\\":\\\"info\\\",\\\"network\\\":{\\\"channel\\\":11,\\\"extendedPanID\\\":\\\"0x00124b0020cd133d\\\",\\\"panID\\\":6754},\\\"permit_join\\\":true,\\\"version\\\":\\\"1.26.0\\\"}'\\nZigbee2MQTT:info  2022-07-29 14:36:49: MQTT publish: topic 'zigbee2mqtt/bridge/state', payload 'online\\n```\\n\\n</code-helper>\\n\\n## Pairing Device\\n\\nIt's time to connect your smart device. The most common way to switch a device to connect mode is to hold its power button or switch them on/off 5 times. Make sure Zigbee2MQTT is running.\\n\\n<robo-wiki-picture src=\\\"home-assistant/switch-device.gif\\\" />\\n\\nWhen the device connects, you should see a message like:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```\\nZigbee2MQTT:info  2022-07-29 14:44:39: Successfully interviewed '0x00158d0003eeeacf', device has successfully been paired\\n```\\n</code-helper>\\n\\nRemember the ID of the sensor: in this example `0x00158d0003eeeacf`.\\n\\nNow you should see this sensor with ID in your Home Assistant WebUI. Go to `Settings` -> `Devices & Services` -> `Devices`:\\n\\n<robo-wiki-picture src=\\\"home-assistant/mqtt-devices.jpg\\\" />\\n\\nAfter adding all the sensors, you can stop the program with `Ctrl+C`.\\n\\n<robo-wiki-note type=\\\"note\\\"> \\n\\n  If you don’t want to add any more devices, you can open the configuration file again and set `permit_join:` to `false`.\\n  \\n</robo-wiki-note>\\n\\nTo make the Zigbee2MQTT run after reboot, make a service. Create the file:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\n\\n</code-helper>\\n\\nAdd the following to this file:\\n\\n<code-helper copy>\\n\\n```shell\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\nStandardError=inherit\\nRestart=always\\nUser=<YOUR_USER_HERE>\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"note\\\">\\n\\nIf you don't know your username, use `whoami` command.\\n\\n</robo-wiki-note>\\n\\nSave file and verify that the configuration works:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo systemctl start zigbee2mqtt\\nsystemctl status zigbee2mqtt.service\\n```\\n\\n</code-helper>\\n\\nOutput should look like:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\n</code-helper>\\n\\nEnable the service to start Zigbee2MQTT automatically on boot:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n</code-helper>\\n\\nNow you can go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\\n\\n## Related videos\\n\\nhttps://youtu.be/gWhs7Ftx5h4\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"e4107983ffd13da7cd43fd92628d8166\",\n        \"title\": \"Zigbee Adapter with Zigbee2MQTT Addon for Home Assistant OS\",\n        \"path\": \"/docs/zigbee-to-mqtt-hassos/\",\n        \"content\": \"\\n**In this article you will set up your Zigbee adapter for Home Assistant OS.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/zigbee2mqtt.png\\\" />\\n\\n**If you have the [JetHome USB JetStick Z2](https://jethome.ru/z2/?sl=en) (which has all of the necessary firmware), you can simply proceed with these instructions. However, if you have another adapter, the first thing you need to do is to flash it with Zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).**\\n\\n## Zigbee2MQTT Addon Install\\n\\n1. Go to the Add-on store, click ⋮ on the upper right corner and choose `Repositories`. Paste there the following link and press `ADD`:\\n```\\nhttps://github.com/zigbee2mqtt/hassio-zigbee2mqtt\\n```\\n2. Close the repository manager and refresh the page. Find `Zigbee2MQTT` addon and `INSTAL` it (do not confuse with Zigbee2MQTT Edge).\\n\\n## Configuration and Run\\n\\n1. Connect the Zigbee adapter to Raspberry Pi.\\n\\n<robo-wiki-picture src=\\\"home-assistant/connect-stick.gif\\\" />\\n\\n2. Find the location of the adapter. For this open SSH Add-on and run the following command:\\n\\n<code-helper copy additionalLine=\\\"Home Assistant Command Line\\\">\\n\\n```bash\\nha hardware info\\n```\\n\\n</code-helper>\\n\\nIn output find the strings like this:\\n\\n<code-helper additionalLine=\\\"Home Assistant Command Line\\\">\\n\\n```bash\\n- attributes:\\n    DEVLINKS: /dev/serial/by-id/usb-Silicon_Labs_CP2102_USB_to_UART_Bridge_Controller_0001-if00-port0\\n       /dev/serial/by-path/platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.1:1.0-port0\\n    DEVNAME: /dev/ttyUSB0\\n    DEVPATH: /devices/platform/scb/fd500000.pcie/pci0000:00/0000:00:00.0/0000:01:00.0/usb1/1-1/1-1.1/1-1.1:1.0/ttyUSB0/tty/ttyUSB0\\n    ID_BUS: usb\\n    ID_MODEL: CP2102_USB_to_UART_Bridge_Controller\\n    ID_MODEL_ENC: CP2102\\\\x20USB\\\\x20to\\\\x20UART\\\\x20Bridge\\\\x20Controller\\n    ID_MODEL_ID: ea60\\n    ID_PATH: platform-fd500000.pcie-pci-0000:01:00.0-usb-0:1.1:1.0\\n    ID_PATH_TAG: platform-fd500000_pcie-pci-0000_01_00_0-usb-0_1_1_1_0\\n    ID_REVISION: \\\"0100\\\"\\n    ID_SERIAL: Silicon_Labs_CP2102_USB_to_UART_Bridge_Controller_0001\\n    ID_SERIAL_SHORT: \\\"0001\\\"\\n    ID_TYPE: generic\\n    ID_USB_DRIVER: cp210x\\n    ID_USB_INTERFACE_NUM: \\\"00\\\"\\n    ID_USB_INTERFACES: ':ff0000:'\\n    ID_VENDOR: Silicon_Labs\\n    ID_VENDOR_ENC: Silicon\\\\x20Labs\\n    ID_VENDOR_ID: 10c4\\n    MAJOR: \\\"188\\\"\\n    MINOR: \\\"0\\\"\\n    SUBSYSTEM: tty\\n    TAGS: ':systemd:'\\n    USEC_INITIALIZED: \\\"10937474053\\\"\\nby_id: /dev/serial/by-id/usb-Silicon_Labs_CP2102_USB_to_UART_Bridge_Controller_0001-if00-port0\\nchildren: []\\ndev_path: /dev/ttyUSB0\\nname: ttyUSB0\\nsubsystem: tty\\nsysfs: /sys/devices/platform/scb/fd500000.pcie/pci0000:00/0000:00:00.0/0000:01:00.0/usb1/1-1/1-1.1/1-1.1:1.0/ttyUSB0/tty/ttyUSB0\\n```\\n\\n</code-helper>\\n\\nIn this example device connection directory is `/dev/ttyUSB0`.\\n\\n3. Before starting Zigbee2MQTT you need to configure it. Click on `Configuration` in the Zigbee2MQTT addon. The basic options needs a few adjustments, change the following statements:\\n\\n<robo-wiki-picture src=\\\"home-assistant/hassos-zigbee2mqtt-config.png\\\" />\\n\\n- In `serial` field add the device connection directory:\\n\\n<code-helper copy>\\n\\n```yaml\\nport: /dev/ttyUSB0\\n```\\n\\n</code-helper>\\n\\n- Leave `mqtt` field **empty when using the Mosquitto** broker addon, otherwise add in your MQTT details in the [proper format](https://www.zigbee2mqtt.io/guide/configuration/mqtt.html#server-connection).\\n\\n4. Start the addon by going to `Info` and click `START`.\\n\\n5. Wait till Zigbee2MQTT starts and press `OPEN WEB UI` to verify Zigbee2MQTT started correctly.\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\n  If you already have an active Zigbee adapter or gateway in your home, and you are now configuring another adapter, then they will conflict with each other. To solve this problem you need to change the channel on the new device.\\n\\n  To do that you need to open Zigbee2MQTT Web UI, go to `Settings` → `Advanced` and change `ZigBee channel` field.\\n\\n  You also will need to delete `coordinator_backup.json` to refresh channel on the adapter. To do this, open the SSH Add-on and find location of the zigbee2mqtt config and after that, restart Zigbee2MQTT addon:\\n\\n</robo-wiki-note>\\n\\n<code-helper additionalLine=\\\"Home Assistant Command Line\\\">\\n\\n```bash\\ncd config/zigbee2mqtt\\nrm coordinator_backup.json\\n```\\n\\n</code-helper>\\n\\n## Pairing Device\\n\\n1. Open Zigbee2MQTT Web UI and click on the `Permit join` button.\\n\\n2. The most common way to switch a device to connect mode is to hold its power button or switch them on/off 5 times.\\n\\n<robo-wiki-picture src=\\\"home-assistant/switch-device.gif\\\" />\\n\\n3. When the device connects, you should see the it in the Zigbee2MQTT Web UI.\\n\\n<robo-wiki-picture src=\\\"home-assistant/zigbee-2-mqtt-addon-ui.png\\\" />\\n\\n4. Now you should see the device with the same IEEE Address in your Home Assistant Web UI. Go to `Settings` -> `Devices & Services` -> `Devices`.\\n\\nNow you can go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"54f1b0e2741eed380c3c65400dc18416\",\n        \"title\": \"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\n        \"path\": \"/docs/xcm-robobank/\",\n        \"content\": \"\\n\\nThe main goal of this project is the simplification of parachain runtime development, when cross-chain messages are used. \\nIt allows the development of runtime code with integration tests with high degree of repeatability and simple usage.\\nIt automates building, construction of pre-set network configuration (i.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and run messaging tests, sending messages, using call to runtime, all constructed and composed in Python.\\n\\nXCM Testsuite is used for testing the production cycle of Robobank - the set of Substrate pallets, which allow robots to register on external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside the Robonomics network with all required infrastructure, but at the same time, offer their services on any other parachain.\\n\\nAn example video is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe main steps in the demo scenario are:\\n- launch relay chain and two parachains in a pack of 6 processes\\n- setup XCM message channels between parachains\\n- register a robot in both parachains\\n- create an order for this robot in the client parachain (reserving payment for the completion of order)\\n- send XCM message to the Robonomics parachain\\n- creating the \\\"mirrored\\\" order record on the Robonomics parachain\\n- robot accepts the order on the Robonomics parachain\\n- send XCM message about the order acceptance back to the client parachain\\n- accept the order on the client parachain (reserving a penalty fee for lack-of-order-completion until the order deadline)\\n- robot completes the order on the Robonomics parachain\\n- send XCM message about the order completion to the client parachain\\n- settle all payments (client payment is transfered to the robot, as well as the unutilized penalty fee)\\n- close the order1\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nIt contains code of the runtime pallets being tested.\\nAs in original node code of the parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] The first build can take a lot of time, up to several hours on suboptimal machines.\\n\\n[NOTE] The script works with the FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains.\\n\\n[NOTE] By default the script re-creates the same environment every launch, by removing all previous states. This behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param.\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc.)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for the relay chain and also for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (i.e. 4 validators of running a stable Rococo revision)\\n    - collators for parachain-100 (i.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (i.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing you to study any chain using frontend apps (explorer, DApp)\\n - keep printing all the output data of all chains to console\\n\\n[WARNING] After launching, wait until the network is up, make sure that block finalization has started, and that the parachains are registered. These processes should require approximately 5 min (50 blocks x 6 sec).\\n\\n## Checking that initial setup works \\n\\nUse the standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, and consensus started off, we can proceed to run our test cases (in a new terminal).\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates a `Balance.transfer` message in `parachain-100` and passes it to the relay chain.\\nWhen the relay chain receives the message it will transfer 15 tokens from `para 100` account to the Charlie acount.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates a `Balance.transfer` message in `parachain-100` and passes it to the `sibling 200` one.\\nBefore that, it endows the`subl 100` account with 1000 tokens and  establish a communication channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running the `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace the balances and authorities parameters with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit the code. The above command will rebuild the project and update the collator node before starting.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent versions of the software. To do this, change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"5cdb6b93b647d5c775d185a65b49fddc\",\n        \"title\": \"How To Use Blueprints\",\n        \"path\": \"/docs/use-blueprints/\",\n        \"content\": \"\\nIn this article you will know how to add automation blueprints to your Home Assistant and configure it.\\n\\n## Blueprint Automations\\n\\nSome blueprints are already installed. Automations based on such blueprints only need to be configured. In web interface you can find pre-installed blueprints in `Settings/Automations & Scenes`. Open `Blueprints` and find the blueprint you want to use. In this example `Motion-activated Light` will be used. \\n\\n<robo-wiki-picture src=\\\"home-assistant/blueprint-settings.jpg\\\" alt=\\\"Blueprint Settings\\\" />\\n\\nClick on `Create Automation` to open the automation editor. Give a name, choose a blueprint to use (`Motion-activated Light` in our case). After that you need to choose motion sensor and lamp. When configuration is finished, click `Save`.\\n\\n<robo-wiki-picture src=\\\"home-assistant/automation-configure.jpg\\\" alt=\\\"Automation Configuration\\\" />\\n\\nIf you want to make changes, you can find it by going to `Settings/Automations & Scenes` and then `Automations`. \\n\\n<robo-wiki-picture src=\\\"home-assistant/automations-all.jpg\\\" alt=\\\"Automations List\\\" />\\n\\n## Importing Blueprints\\n\\nHome Assistant can import blueprints from the Home Assistant forums, GitHub and GitHub gists. List of all Blueprints are located on [Blueprints Exchange](https://community.home-assistant.io/c/blueprints-exchange/53). After you chose, go to `Settings/Automations & Scenes` and open `Blueprints`. Click on `Import Blueprint` and insert URL of the chosen blueprint. Then click on `PREVIEW BLUEPRINT`. In this case we will use [Low battery level detection & notification for all battery sensors](https://community.home-assistant.io/t/low-battery-level-detection-notification-for-all-battery-sensors/258664). \\n\\n<robo-wiki-picture src=\\\"home-assistant/importing-blueprint.jpg\\\" alt=\\\"Importing Blueprint\\\" /> \\n\\nThis will load the blueprint and show a preview in the import dialog. You can change the name and finish the import. Click on `Create Automation` to open the automation editor. Here you can configure automation's parameters and add actions to get notifications.\\n\\n<robo-wiki-picture src=\\\"home-assistant/configure-battery-blueprint.jpg\\\" alt=\\\"Configure Battery Blueprint\\\" /> \"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"913698afe42043885b786cf78193aa9a\",\n        \"title\": \"How to Send Launch with Subscription\",\n        \"path\": \"/docs/subscription-launch/\",\n        \"content\": \"\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Parachain\\\">\\n\\n  Pay attention that this tutorial demonstrates using a subscription on Robonomics Kusama parachain. You can also perform\\n  all the same steps on your [local node](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\nIf your address has an active subscription, then any devices set up with that account's secret can send extrinsics with no fee. \\nLet's try to send the `launch` command.\\n\\nGo to the `Developer/Extrinsics` page, then choose your account (the one from device list) and select `rws -> call(subscriptionId, call)`. \\nThen in `subscriptionId` field paste the subscription's owner address (the one who bid the auction) and in the next field\\nchoose `launch -> launch(robot, param)`. In the `robot` field type the address you want to send `launch` transaction \\nto and insert the command (for launch command description refer [here](/docs/launch)). Then submit transaction:\\n\\n![launch](./images/rws/launch.png)\\n\\n\\nNow go to the `Network/Explorer` page, and in the `Recent Events` area you will see two events that you created; `rws.NewCall` and `launch.NewLaunch`:\\n\\n![events](./images/rws/events.png)\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"e12edf7195df63e5a7c77ee7f4827afa\",\n        \"title\": \"Subscription Activate\",\n        \"path\": \"/docs/sub-activate/\",\n        \"content\": \"\\nIn this article you will create Robonomics parachain accounts and buy IoT subscription. \\n\\n<robo-wiki-picture src=\\\"home-assistant/sub_activate.png\\\" />\\n\\n\\nTo control Home Assistant with Robonomics, you need 2 accounts on the Robonomics parachain. For one of the accounts (`sub_owner`), you will buy a Robonomics subscription. Second account (`sub_controller`) will control all Home Assistant processes (such as telemetry) and will give access to other users. These accounts will provide security for your Home Assistant. \\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"WARNING\\\">\\n\\nBoth accounts must be created with **ed25519** encryption. Because of this, you need to create an account using the Polkadot-JS UI and select the required encryption. \\n\\nThis feature is disabled by default on the Polkadot-JS UI. To enable it, navigate to `Settings` -> `General` -> `account options` and select `Allow local in-browser account storage` in the drop-down menu `in-browser account creation`.\\n\\n</robo-wiki-note>\\n\\n## Create Owner and Controller Accounts\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmQiJYPYajUJXENX2PzSJMSKGSshyWyPNqugSYxP5eCNvm', type:'mp4'}]\\\" />\\n\\n1. Go to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check the top left corner to ensure that you are connected to Robonomics Parachain.**\\n\\n2. Go to `Accounts` -> `Accounts` and press `Add account` button. You will see the popup menu with account seed. It has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). \\n\\n3. Open `Advanced creation options`, change the crypto type of creating account to `Edwards - ed25519` and press `Next`.\\n\\n\\n4. Save the mnemonic seed phrase securely and press `Next`.\\n\\n5. In the next menu, you need to set the account name and password. Give it a name `sub_owner` for convenience. Press `Next`.\\n\\n6. On the last window click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n7. Repeat these steps for an account with the name `sub_controller`.\\n\\n\\n## Add Accounts to Polkadot.js\\n\\nFor convenience, you should use the [Polkadot.js extension](https://polkadot.js.org/extension/) and add these newly created accounts to it. For an ed25519 account you can do that only with a backup JSON file. You can use the files saved when you created the accounts.\\n\\nYou can get these files again by creating a backup file of the account. Press on three dots on your account, choose `Create a backup file for this account` and type in your password.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmRd7gztUjWkLF4W2XuJwy5aXBwzNV2aPCU6CQQLvUpSNj', type:'mp4'}]\\\" />\\n\\n1. Open an extension and press `+` button on the top right, then choose `Restore account from backup JSON file`.\\n\\n2. In an opened window upload the JSON file, enter the password and press `Restore`.\\n\\n3. Make sure the Robonomics network is selected for accounts in the Polkadot.js extension. On on Polkadot / Substrate Portal go to `Setting` -> `Metadata` and click on the `Update metadata` button. \\n\\n4. Confirm the metadata update in the popup. Now the extension will show the label of the network for which the address is used.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmT5sTNP9t8gpbD4RJJw6ETwG4wiziiChAh2uHHBk9Zsyd', type:'mp4'}]\\\" />\\n\\n## Activate Robonomics Subscription \\n\\n<robo-wiki-note type=\\\"okay\\\">\\n\\nFor this step, you must have a sufficient amount of XRT tokens (minimum 2-3 XRTs) in your `sub_owner` account.\\n\\n</robo-wiki-note>\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmXrFCajmJgkRDSbshGD3QehjnoyS6jafEPSjHdYkoBHum', type:'mp4'}]\\\" />\\n\\n1. Go to Robonomics dapp to the [subscription page](https://dapp.robonomics.network/#/subscription) and press connect account on the right sidebar.\\n\\n2. In the following popup menu connect Polkadot.js extension. You will see your account address with balance.\\n\\n3. Before purchasing, check that you chose the `sub_owner` account. Press the address profile icon, you should see the `sub_owner` account under the `Check owner account` field.\\n\\n4. Finally, press the `SUBMIT` button and enter the password for your account. After that wait until the activation process is completed. You will see the state of your subscription after a while.\\n\\n\\n## Add Accounts to Subscription\\n\\nNow you need to add a `sub_controller` account to the **access list**. \\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmV1gkwtcXsWv54ov9tuXfcHg7nqs1foM8cRwts4sqnqtX', type:'mp4'}]\\\" />\\n\\n1. Open extension and click on the icon near the account name. It will copy the account address.\\n\\n\\n2. Paste this address to the `Robonomics parachain address` field in the **Manage access** part. Give it a name and press the `+` button. \\n\\n3. Repeat steps 1 and 2 for `sub_owner` account.\\n\\n3. Press `Save`. Enter your `sub_owner` password in the popup window and wait until the activation process is completed.\\n\\nAfter that, go to the article [\\\"Robonomics Integration Setup\\\"](/docs/robonomics-hass-integration/) article.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"a652f42d33dee5a1791a1924f14ed797\",\n        \"title\": \"Get Smart Home Telemetry\",\n        \"path\": \"/docs/smart-home-telemetry/\",\n        \"content\": \"\\n**In this article, you will use the Robonomics service, which queries the telemetry of smart home devices.**\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/Qmao9RoWcKo2qs4PAGtm5gqHzyAHJcpDqNLgciU35FJeVm', type:'mp4'}]\\\" />\\n\\n1. Go to dapp and choose [SmartHome Telemetry](https://dapp.robonomics.network/#/smarthome-telemetry) service.\\n\\n2. In the controller field enter the `SUB_CONTROLLER` address. Insert the seed phrase to encrypt data.\\n\\n3. In the `Get telemetry` block choose a timestamp from the drop-down list and press the `DOWNLOAD TELEMETRY` button.\\n\\n4. Telemetry downloading could take some time. After finishing, you will see the information from your devices and sensors.\\n\\n\\n<!---\\n## Launch devices\\n\\nGo back and  choose service [\\\"SmartHome Telemetry\\\"](https://dapp.robonomics.network/#/services). You will forward to DApp website. In first login give permission to website to use polkadot{.js} extension. You will see next:\\n\\n<robo-wiki-picture src=\\\"home-assistant/telemetry-start.jpg\\\" />\\n\\nFind address of your `user` account and press blue button:\\n\\n<robo-wiki-picture src=\\\"home-assistant/datalog-start.jpg\\\" />\\n\\nAnd you will see popup \\\"Launch\\\" window:\\n\\n<robo-wiki-picture src=\\\"home-assistant/launch-window.jpg\\\" />\\n\\nLaunch command calls HomeAssistant service, first two fields are **service name** - \\\"Platform\\\" and **service function** - \\\"Name\\\". Let's find them.\\n\\nFor this go to your Home Assistant interface in browser -> `Developer tools` -> `SERVICES` and turn on `YAML mode`.\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha-services.jpg\\\" />\\n\\nFind a service you need using a search field or choose from a drop-down list there.\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha-light.jpg\\\" />\\n\\nLet's find a `light` service. You will see available functions(`turn_on`, `turn_off`, `toggle`). Choose `turn_on` function.\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha-light-on.jpg\\\" />\\n\\nOn the picture you see **service name** - `light` and **service function** - `turn_on`. Write these statements to popup window of DApp.\\n\\n<robo-wiki-picture src=\\\"home-assistant/light-window.jpg\\\" />\\n\\nNext you need to find the sensor ID. For this go to `Overview` on the HA page. Find sensor, which you want to turn on(in this example it is the light) and press on it. \\n\\n<robo-wiki-picture src=\\\"home-assistant/light-name.jpg\\\" />\\n\\nYou will see a popup window and with a \\\"settings\\\" button on it the top-right corner. Press on it. The popup window will change. In the new window you will find required `entity_id`:\\n\\n<robo-wiki-picture src=\\\"home-assistant/entity-ha.jpg\\\" />\\n\\nCopy it and paste to field in our dapp:\\n\\n<robo-wiki-picture src=\\\"home-assistant/dapp-entity.jpg\\\" />\\n\\nFinally, press `SEND` button and sign transaction with your password. Wait until transaction is in block and check your light. It should be turned on (sometimes it takes a bit more time).\\n\\nCongratulations, You have fully installed and set up Your Home Assistant with Robonomics!\\n-->\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"c4a05afab713f91f79eaaa2e497d4553\",\n        \"title\": \"Robonomics SLS Gateway\",\n        \"path\": \"/docs/sls-gateway/\",\n        \"content\": \"\\n**In this article you will set up Robonomics SLS Gateway. You will install the required software for the gateway, configure it and connect it to Home Assistant.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/sls_gateway.png\\\" />\\n\\n## Firmware\\n\\nFirst you need to install microcontroller firmware of the gateway. Prepare the gateway by setting switches `1` and `3` at the bottom part of SLS Gateway to `ON`, others must be `OFF`.\\n\\n<robo-wiki-picture src=\\\"home-assistant/sls-gateway-13.gif\\\" />\\n\\nConnect gateway to your Raspberry Pi via USB type-C port on the gateway.\\n\\n<robo-wiki-picture src=\\\"home-assistant/sls-rpi.gif\\\" />\\n\\nClone the repository with firmware to your Raspberry Pi:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\ngit clone https://github.com/airalab/robonomics-hass-utils.git\\n```\\n\\n</code-helper>\\n\\nGo to `robonomics-hass-utils/esp_firmware/linux`. To flash the SLS gateway you need to run `Clear` and `Flash_16mb` scripts.\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\ncd robonomics-hass-utils/esp_firmware/linux\\nsudo chmod +x Clear.sh\\nsudo chmod +x Flash_16mb.sh\\n./Clear.sh\\n./Flash_16mb.sh\\n```\\n\\n</code-helper>\\n\\n### Troubleshooting\\n\\nIf you are experiencing problems updating the gateway firmware, you need to take additional steps:\\n\\n1. Make sure you have the pySerial module installed:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\npip install pyserial\\n```\\n</code-helper>\\n\\n2. Give your user access rights to the USB port and reboot computer:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsudo usermod -a -G dialout $USER\\nsudo reboot\\n```\\n</code-helper>\\n\\n3. In some cases, it is necessary to change the bandwidth setting in the script to update the firmware. Open the `Flash_16mb.sh` script with the `nano` editor and change the baud parameter from `921600` to a smaller value (for example, `115200`).\\n\\n## Configuration\\n\\n1. Disconnect SLS Gateway from rhe computer. Set the switches on the back of the gateway to the proper position. Switches `5` (RX Zigbee to ESP) and `6` (TX Zigbee to ESP) must be in the `ON` position, the others must be `OFF`. \\n\\n<robo-wiki-picture src=\\\"home-assistant/sls-gateway-56.gif\\\" />\\n\\n2. Connect the type-C power cable. The indicator light in the center should turn green.\\n\\n<robo-wiki-picture src=\\\"home-assistant/sls-gateway-connect.gif\\\" />\\n\\n3. On the first startup, the gateway will start sharing Wi-Fi with the SSID `zgw****`. Connect to this network. Keep in mind that the signal may be quite weak, so it is better to keep the SLS gateway closer to your computer. \\n\\n<robo-wiki-picture src=\\\"home-assistant/sls-gateway-wifi.gif\\\" />\\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). \\n\\n5. You will see `Wi-Fi Settings` page. Select your Wi-Fi and enter the password. Press `Apply` button. The gateway will restart and connect to your Wi-Fi network. \\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmSht6roENzrV6oqsQ1a5gp6GVCz54EDZdPAP8XVh9SCwH', type:'mp4'}]\\\" />\\n\\n6. Find the local IP of the SLS gateway to access the web interface. To find it you can use [Fing mobile app](https://www.fing.com/products) or [nmap CLI tool](https://vitux.com/find-devices-connected-to-your-network-with-nmap/). The gateway name should look like this: `zgw****`. Open the web interface of the gateway by pasting the gateway IP into a browser.\\n\\n7. Go to `Setting` -> `Hardware` and make sure that the settings look like on the image. Correct the settings if necessary and click `Save` button:\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmeSksMxU9xkvvK7f81WDAYULiMFokK7P7KDVYEjv2MHjn', type:'mp4'}]\\\" />\\n\\nThe table with required values:\\n\\n| Field                    | Value              |\\n|--------------------------|:-------------------|\\n| Zigbee module            | TI                 |\\n| Zigbee UART RX           | 22                 |\\n| Zigbee UART TX           | 23                 |\\n| Zigbee RST Pin           | 18                 |\\n| Zigbee BSL Pin           | 19                 |\\n| Service Button Pin       | 33 (pullUP - true) |\\n| Number addressable leds  | 0                  |\\n| Led Red (or addr)        | 21                 |\\n| Led Green                | 5                  |\\n| Led Blue                 | 27                 |\\n| I2C SDA                  | 255                |\\n| I2C SCL                  | 255                |\\n\\n8. Then reboot the gateway. Choose `Actions` -> `Reboot system` at the right top corner.\\n\\n9. Make sure that the gateway works properly in the Zigbee info window. DeviceState should be `OK`.\\n\\n10. Configure automatically adding devices to Home Assistant. Go to `Zigbee` -> `Config` then choose `Home Assistant MQTT Discovery` and `Clear States`. Save changes and again **reboot** SLS gateway.\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\nIf you already have an active SLS gateway in your home, and you are now configuring another one, then they will conflict with each other. To solve this problem you need to change the channel on the new device. To do this, go to `Zigbee` -> `Config` and change the channel to another one (e.g. channel 15).\\n\\n</robo-wiki-note>\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmVZMB1xQeB6ZLfSR6aUrN6cRSF296s8CMJt7E2jBJ5MjZ', type:'mp4'}]\\\" />\\n\\n## Pairing SLS to MQTT\\n\\nAfter configuring the SLS Gateway, you need to connect SLS Gateway to Home Assistant. Open SLS Gateway web interface and go to `Settings/Link` -> `MQTT Setup`:\\n\\n\\nAdd your broker address (address of the Raspberry Pi with Home Assistant in local network, you can find it with [Fing mobile app](https://www.fing.com/products) or [nmap CLI tool](https://vitux.com/find-devices-connected-to-your-network-with-nmap/)), port (default is `1883`) your broker username and password (which you have created earlier) and the topic name (you can choose any). Also, the Raspberry Pi IP address must be static. Click on `Enable` and `Retain states`.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmdNKDqwwy87VQEDDVsX5kpaDQm9wKKPEJUNJnhnjx6e5y', type:'mp4'}]\\\" />\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\n## Connect Devices\\n\\nConnect your devices by going to `Zigbee` -> `Join`. Put your sensors in pairing mode, the most common way to switch a device to connect mode is to hold its power button or switch them on/off for 5 times. Press the `Enable Join` button to start searching Zigbee devices. You will see active sensors.\\n\\n<robo-wiki-picture src=\\\"home-assistant/switch-device.gif\\\" />\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/Qmdq3PBNY88QbYYqakwSLG2vn3mVUom3w3wsSWfTd1pzJA', type:'mp4'}]\\\" />\\n\\n\\nNow you can go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"4862ab749c8f7064a610e983e34b8ee1\",\n        \"title\": \"Decentralized Sensors Network\",\n        \"path\": \"/docs/sensors-network-introduction/\",\n        \"content\": \"\\nThe articles about Decentralized Sensors Network was transferred to Robonomics Academy: https://robonomics.academy/en/online-courses/sensors-connectivity-course/\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"6b4a1d174b284fa9ef26fded1023fc79\",\n        \"title\": \"Securely connect cloud AI to the factory floor\",\n        \"path\": \"/docs/securely-connect-cloud-ai-to-the-factory-floor/\",\n        \"content\": \"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n<!-- ![](./images/google-play-store.gif) -->\\n<!-- <img src=\\\"./images/google-play-store.gif\\\" /> -->\\n<robo-wiki-picture src=\\\"google-play-store.gif\\\" />\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n<!-- ![](./images/Veracity_Protocol_Transaction.gif) -->\\n<!-- <img src=\\\"./images/Veracity_Protocol_Transaction.gif\\\" /> -->\\n<robo-wiki-picture src=\\\"Veracity_Protocol_Transaction.gif\\\" />\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n<!-- ![](./images/Veracity_Protocol_Launch.gif) -->\\n<!-- <img src=\\\"./images/Veracity_Protocol_Launch.gif\\\" /> -->\\n<robo-wiki-picture src=\\\"Veracity_Protocol_Launch.gif\\\" />\\n\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"9d28d8429441488738c3be3032aebbb6\",\n        \"title\": \"How to Run Robonomics Dev Node\",\n        \"path\": \"/docs/run-dev-node/\",\n        \"content\": \"\\n**For testing your applications on Robonomics you may want to run it in the dev mode. This article shows step-by-step\\ninstructions how to get your own local testing instance of Robonomics.**\\n\\n\\n## Get Node Binary\\n\\n1. First, you need a binary file, download the archive with it from the latest [release](https://github.com/airalab/robonomics/releases).\\n\\n2. Navigate to the archive folder, unpack the binary and change permissions:\\n\\n```bash\\ntar xf robonomics-2.4.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n## Run\\n\\nRun the node with:\\n\\n```bash\\n./robonomics --dev\\n```\\nYou will see the following output:\\n\\n![robonomics](./images/dev-node/robonomics.png)\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"From Scratch\\\">\\n\\n  If you want to purge existing blocks you may do this with removing RocksDB at `/tmp/substrate******/chains/dev/db/full`.\\n  Replace `******` with a corresponding identifier displayed in logs on launch.\\n\\n  If you want to start the node from scratch every time use `--tmp` flag.\\n\\n</robo-wiki-note>\\n\\n## Connect\\n\\nNow you can connect to your local node through the [Polkadot Portal](https://polkadot.js.org/apps/#/explorer).\\n\\nChange the network to `Local Node` in the upper left corner and press `Switch`.\\n\\n![switch](./images/dev-node/portal.png)\\n\\nWelcome to the local instance of Robonomics!\\n\\n![local_node](./images/dev-node/dev-portal.png)\\n\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"30f4215c9d7d0ade3a7831b264a2abe3\",\n        \"title\": \"Robonomics Smart Home Overview\",\n        \"path\": \"/docs/robonomics-smart-home-overview/\",\n        \"content\": \"<robo-wiki-video loop controls :videos=\\\"[{src: 'https://crustipfs.art/ipfs/QmdZKkPJCa9GEN43iUBX81jfrFTDxcn7J6wWURrwNVwcKx', type:'webm'}, {src: 'https://crustipfs.art/ipfs/QmStCDsEHCYwVYvnDdmZBMnobPmrgZx3iJLm65b8XNzKQa', type:'mp4'}]\\\" />\\n\\n## Why Robonomics\\n\\nFor your smart home, the modern IoT market provides a wide range of solutions. But you are usually tied to centralized cloud providers or expensive proprietary gateways. As a result, you as a user are always dependent on the hardware and infrastructure vendor to run your smart system. At the same time, your smart home cannot be truly smart without cloud statistics and analytics.\\n\\n**We see two main problems with current smart homes:**\\n\\n1. You have no control over what data you share with the vendor or third party.\\n2. Your smart home is vulnerable to shutdowns of centralized cloud servers. \\n\\n<robo-wiki-picture src=\\\"home-assistant/ha-problems.png\\\" />\\n\\nTo solve both problems, we suggest you to try Robonomics, our **secure**, **serverless** and **futuristic** decentralized cloud.\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha-robonomics.png\\\" />\\n\\n## What you need for installation\\n\\n  <robo-wiki-grid-element-wrapper textAlign=\\\"center\\\" :columns=\\\"4\\\">\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_1.png\\\" /> \\n      <p><a href=\\\"https://www.home-assistant.io/\\\">Home Assistant</a> as control system software</p> \\n    </robo-wiki-grid-element>\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_2.png\\\" /> \\n      <p>Raspberry Pi 4 (at least 2 GB RAM)</p>  \\n    </robo-wiki-grid-element>\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_3.png\\\" /> \\n      <p>SD card (minimum 32 GB)</p>  \\n    </robo-wiki-grid-element>\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_4.png\\\" /> \\n      <p>SD adapter</p>\\n    </robo-wiki-grid-element>\\n  </robo-wiki-grid-element-wrapper>\\n\\n  <robo-wiki-grid-element-wrapper :columns=\\\"2\\\" textAlign=\\\"center\\\">\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_5.png\\\" />\\n      <p>Zigbee smart devices (any from <a href=\\\"https://slsys.io/action/supported_devices.html\\\">supported devices</a>)</p>\\n    </robo-wiki-grid-element>\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_6.png\\\" /> \\n      <p>Zigbee adapter <a href=\\\"https://jethome.ru/z2/\\\">JetHome USB JetStick Z2</a> (or one of <a href=\\\"https://www.zigbee2mqtt.io/information/supported_adapters.html\\\">supported</a>) or \\n      <a href=\\\"https://easyeda.com/ludovich88/robonomics_sls_gateway_v01\\\">Robonomics SLS Gateway</a></p>\\n    </robo-wiki-grid-element/>\\n  </robo-wiki-grid-element-wrapper>\\n\\n## How to install Home Assistant with Robonomics \\n\\n* [Pre-installed image](/docs/hass-image-install/) — This method implies setting up a whole new OS on your Raspberry Pi.\\n* [Home Assistant OS](/docs/hass-os-upgrade/) — The method is suitable for integrating Robonomics with an existing Home Assistant OS.\\n* [Home Assistant Docker for Unix-like OS](/docs/hass-docker-upgrade/) — The method is suitable for integrating Robonomics with an existing Home Assistant Docker for Unix-like OS.\\n* [Home Assistant Core](/docs/hass-core-upgrade/) — The method is suitable for integrating Robonomics with an existing Home Assistant Core.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"517fd4db2d5dacbe91f138fdd1ce214d\",\n        \"title\": \"Robonomics + Prometheus + Grafana\",\n        \"path\": \"/docs/robonomics-prometheus-grafana/\",\n        \"content\": \"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](./images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](./images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](./images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](./images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](./images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](./images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](./images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](./images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](./images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"e12c829cdc7ea4bd0ca4b05f3cc6919a\",\n        \"title\": \"Robonomics integration setup\",\n        \"path\": \"/docs/robonomics-hass-integration/\",\n        \"content\": \"\\n**In this article, you will add Robonomics to Home Assistant. This allows Home Assistant to record datalogs with encrypted data to Robonomics Parachain and listen for launch commands from the parachain to control smart devices. Integration uses IPFS to store data and send IPFS hashes to datalog or launch functions.**\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmQp66J943zbF6iFdkKQpBikSbm9jV9La25bivKd7cz6fD', type:'mp4'}]\\\" />\\n\\n1. In the web interface of Home Assistant go to `Settings` -> `Device & Services` and press `ADD INTEGRATION`. Search for `Robonomics`.\\n\\n2. Click on Robonomics and fill in the configuration: \\n\\n- Add seed from the `SUB_CONTROLLER` account to controller account seed.\\n- Add the public address of the `SUB_OWNER` account to the subscription owner address.\\n- Set the interval of data sending (by default it is 10 minutes).\\n- (Optional) You can add credentials for pinning service Pinata to spread your data wider over the IPFS network.\\n\\n3. Press `SUBMIT` after finishing the configuration. If you filled in everything correctly, you will see the success window.\\n\\nCongratulations! You have fully installed and configured Home Assistant with Robonomics integration. Now go to [**\\\"Use\\\"**](/docs/global-administration) section to start working with your upgraded smart home.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"a98df1be40f5c33942e2f0ab0a3482ce\",\n        \"title\": \"Robonomics on Ethereum\",\n        \"path\": \"/docs/robonomics-ethereum/\",\n        \"content\": \"\\nAll information about robonomics on ethereum moved to GitHub repository. All necessary information could be [found here.](https://github.com/airalab/Robonomics_on_Ethereum_Wiki)\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"b87e1eda8f18ba09ebef9efa3b638b1b\",\n        \"title\": \"Robonomics Coffee\",\n        \"path\": \"/docs/robonomics-coffee/\",\n        \"content\": \"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](./images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](./images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](./images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](./images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](./images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](./images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](./images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](./images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](./images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](./images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](./images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](./images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](./images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"2a669f5338ceb2a3e5f8d74959d53372\",\n        \"title\": \"Python interface and Robonomics IO\",\n        \"path\": \"/docs/rinterface/\",\n        \"content\": \"\\n**Some extrinsics implemented in Robonomics pallets are hard to be submitted from the Polkadot app. More that, there is \\na need to interact with this functionality using programming languages. For this purpose a simple Python tool was developed\\ncalled [robonomics-interface](https://github.com/Multi-Agent-io/robonomics-interface). It's a wrapper over polkascan-maintained \\n[py-substrate-interface](https://github.com/polkascan/py-substrate-interface). Below is a brief description of this package\\nand some useful links and examples. Also, CLI tools is discussed.**\\n\\n## robonomics-interface\\n\\nAvailable on [PyPi](https://pypi.org/project/robonomics-interface/) package is ready to download and set up.\\nThere is a detailed docstring-generated [documentation](https://multi-agent-io.github.io/robonomics-interface/) available as well.\\n\\nAll in all, this is a tool for developers who wish to interact with Robonomics blockchain via programming tools. Almost \\nall the Python projects of Robonomics team which interact with the parachain use this interface.\\n\\n### Installation\\n\\nThe installation process requires user to have at least Python 3.8 installed. Neither `x86`, nor `arm7`, nor `arm8`\\narchitectures require compilation process. All the wheels are built and published by dependencies maintainers.\\n\\n`pip` is used as an installation tool:\\n\\n```bash\\n$ pip3 install robonomics_interface\\n```\\n\\n### Sample use\\n\\nThe main idea is to create an `Account` instance and then use it to create pallet-dedicated instances.\\n\\n\\n```python\\nfrom robonomicsinterface import Account, Datalog\\naccount = Account()\\ndatalog_ = Datalog(account)\\ndatalog_.get_item(addr=\\\"4G1V6yyvrkd3Z57H1giUky8RTRX3SZieRvuDpQzK4knNRy5R\\\",index=2)\\n\\n>>> (1657226418528, 'blah')\\n```\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Local node\\\">\\n\\n  It is also possible to use custom endpoints (e.g. local node for testing):\\n\\n  ```python\\n  account = Account(remote_ws=\\\"ws://127.0.0.1:9944\\\")\\n  ```\\n\\n</robo-wiki-note>\\n\\nExtrinsics are also possible to submit:\\n\\n```python\\nfrom robonomicsinterface import Account, Datalog\\naccount = Account(seed=\\\"one two three four five six seven eight nine ten eleven twelve\\\")\\ndatalog_ = Datalog(account)\\ndatalog_.record(\\\"Hello, Robonomics!\\\")\\n\\n>>> 0xb2f742b6164ffc14b75a21188b37287c2416e6617635805e0a77db12773f6068  # this is an extrinsic hash\\n```\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Docs\\\">\\n\\n  As have been said, more examples are available on the [documentation](https://multi-agent-io.github.io/robonomics-interface/) page.\\n\\n</robo-wiki-note>\\n\\n## CLI tool\\n\\n`robonomics-interface` also contains a Python `click` CLI tools to use for purposes of prototyping and quick tests. It is installed\\nwith the package and available in the Terminal:\\n\\n```bash\\n$ robomomics_interface --help\\n\\n#Usage: robonomics_interface [OPTIONS] COMMAND [ARGS]...\\n#\\n#Options:\\n#  --help  Show this message and exit.\\n#\\n#Commands:\\n#  read   Subscribe to datalog/launch events in the chain\\n#  write  Send various extrinsics (launch commands or record datalogs)\\n```\\n\\nYou may try to use it with local node. Pipeline philosophy is adopted:\\n\\n```bash\\n$ echo \\\"Hello, Robonomics!\\\" | robonomics_interface write datalog -s \\\"//Alice\\\" --remote_ws \\\"ws://127.0.0.1:9944\\\"\\n\\n#0x22dbac7d25d2ee67c7d985f074163f674c8c9b4c554e545ca4c7186307e9023c  # this is an extrinsic hash\\n```\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"f60e2642a26264299ba111d9f49a07d5\",\n        \"title\": \"Robonomics Smart Home\",\n        \"path\": \"/docs/notifications/\",\n        \"content\": \"\\nYou can receive notifications on your smartphone with [notify](https://notify.events/). Girstly register there and on `Control Panel` creae new channel:\\n\\n![control_panel](./images/home-assistant/not_control_panel.png)\\n\\nAdd title and press `Save`:\\n\\n![channel](./images/home-assistant/not_create_chanell.png)\\n\\nThen press `Add Source` and choose `Home Assistant` in `IoT and Smart Home` tab:\\n\\n![source](./images/home-assistant/not_add_source.png)\\n\\nWrite title and press `Next`:\\n\\n![source_next](./images/home-assistant/not_add_source_next.png)\\n\\nThere you will see the token which you need to add to your configuration file for home Assistant. Save it somewhere and press `Done`:\\n\\n![token](./images/home-assistant/not_token.png)\\n\\nthen press `Subscribe` to add subscribers:\\n\\n![subscribe](./images/home-assistant/not_subscribe.png)\\n\\nChoose whatever subscriber you want and follow the instructions.\\n\\nNow you need to edit configuration on your compuer with Home Assistant. Under `homeassistant` user open `configuration.yaml` file:\\n\\n```bash\\nsudo -u homeassistant -H -s\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add theese lines:\\n\\n```yaml\\nnotify_events:\\n    token: <your token from notify>\\n```\\nAlso add new automation after `automation:` line:\\n```yaml\\n- alias: notifications\\n  trigger:\\n  - entity_id: binary_sensor.contact_sensor_contact\\n    platform: state\\n    from: 'off'\\n    to: 'on'\\n  action:\\n  - service: notify.notify\\n    data:\\n      message: Door was changed to {{ states(\\\"binary_sensor.contact_sensor_contact\\\") }}\\n```\\nThis automation will send message `Door was changed to on/off` after sensor wit entity id `binary_sensor.contact_sensor_contact` change state from `off` to `on`.\\n\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"f4fefa486a8bb39f30fb22f9b7b1916e\",\n        \"title\": \"MQTT Integration Setup\",\n        \"path\": \"/docs/mqtt-integration/\",\n        \"content\": \"\\n**In this article you will add MQTT integration to Home Assistant.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/mqtt_integration.png\\\" />\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmYm9qNfpGdePRHRvmahY2DgHXRfAWNN6CasEY4tFRBARr', type:'mp4'}]\\\" />\\n\\n1. Open Home Assistant web interface and go to `Settings` -> `Devices & Services`.\\n\\n2. Press `ADD INTEGRATION` at the right bottom corner. In the opened window find `MQTT`:\\n\\n3. Select MQTT and enter:\\n\\n- Broker address — `localhost`\\n- Port — `1883`\\n- Username & password — your credentials which you created earlier for Mosquitto Broker.\\n\\n4. After that, press `SUBMIT`.\\n\\nNow, you can proceed to add devices. Depending on the hardware you have, choose one of the options:\\n\\n**Option 1 (with zigbee2MQTT for Home Assistant OS)**\\n* For Zigbee adapter and Home Assistant OS [go here](/docs/zigbee-to-mqtt-hassos/). Ideal for [JetHome USB JetStick Z2](https://jethome.ru/z2/?sl=en) or similar [supported adapters](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\n**Option 2 (with zigbee2MQTT for for pre-installed image or Home Assistant Docker or Core)**\\n* For Zigbee adapter with other options of the Home Assistant installation [go here](/docs/zigbee-to-mqtt/). Ideal for [JetHome USB JetStick Z2](https://jethome.ru/z2/?sl=en) or similar [supported adapters](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\n**Option 3 (with SLS Gateway)**\\n* For Robonomics SLS Gateway regardless of the Home Assistant installation options [go here](/docs/sls-gateway/). Open SLS gateway specs your can [find here](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01).\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"79320e46512bd93a4330d352a706f686\",\n        \"title\": \"MQTT Broker for Pre-installed Image or Home Assistant Docker or Core\",\n        \"path\": \"/docs/mqtt-image-docker-core/\",\n        \"content\": \"\\n**This article describes how to install MQTT broker for Robonomics pre-installed image or for Home Assistant Docker or Core.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/mqtt_broker_core.png\\\" />\\n\\nThere is a quick installation option with a pre-written script, that installs the [Mosquitto](https://mosquitto.org/) MQTT broker. Connect to your Raspberry Pi and run:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\ncurl -O https://raw.githubusercontent.com/airalab/robonomics-hass-utils/main/raspberry_pi/mqtt-install.sh\\nbash mqtt-install.sh\\n```\\n</code-helper>\\n\\nYou will be asked to enter `USERNAME` and `PASSWORD` for the broker. After finishing, the broker will be running as a `systemd` service.\\n\\n## Next step\\n\\nAfter that, go to the [MQTT Integration Setup](/docs/mqtt-integration/) article.\\n\\n## Related videos\\n\\nhttps://youtu.be/n4PX25aB1JU\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"ca898d96cb5130c89cfb4a201cc95d6d\",\n        \"title\": \"MQTT Broker for Home Assistant OS\",\n        \"path\": \"/docs/mqtt-hassos/\",\n        \"content\": \"\\n**This article describes how to install MQTT broker to Home Assistant OS.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/mqtt_broker_os.png\\\" />\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmaoaTBu3KqwC8NKRSopmF3KQ5BYL8skEfYJjXypcJNdNL', type:'mp4'}]\\\" />\\n\\n1. We will use [Mosquitto](https://mosquitto.org/) MQTT broker. In the Add-on Store find the `Mosquitto broker` add-on, press on it and press `INSTALL`. \\n\\n2. After installation go to `Configuration` tab and add `USERNAME` and `PASSWORD` for the broker in `Logins` section in the following format:\\n\\n<code-helper copy additionalLine=\\\"Mosquitto Broker Options\\\">\\n\\n```\\n- username: 'USERNAME'\\n  password: 'PASSWORD'\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n  \\n  Make sure you save your credentials securely, you will need them in the next steps.\\n  \\n</robo-wiki-note>\\n\\n3. Save the configuration and go to the `Info` tab to start the add-on.\\n\\nContinue MQTT setup with the [**MQTT Integration Setup**](/docs/mqtt-integration) article.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"3cee4bdd78b62d9dbaf0d6715e60335c\",\n        \"title\": \"Liability\",\n        \"path\": \"/docs/liability/\",\n        \"content\": \"\\n**To turn robots into economic agents one needs a contract tool for this. Meet Liability - Robonomics pallet implementing\\ncontracts between parachain accounts!**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Dev Node\\\">\\n\\n  Please pay attention that this tutorial is demonstrated on a local instance of Robonomics Node. Set up yours with [these instructions](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\n## Theory Overview\\n\\nBack on the Ethereum there was quite a complicated structure of liability interaction. You can get acquainted with it \\n[here](/docs/robonomics-how-it-works). Nowadays things are a bit easier with Kusama!\\n\\n### Negotiations\\n\\nTo sign a contract the two sides need to negotiate first. This may be done several ways, including \\n[IPFS PubSub ](https://blog.ipfs.tech/25-pubsub/) or Robonomics PubSub. A sample of Python code using Robonomics PubSub is \\npresented [here](https://multi-agent-io.github.io/robonomics-interface/usage.html#pubsub). \\n\\nOffer and demand are messages containing two main characteristics of a contract: **job description** and **price**. Message\\nformat is to be designed by user for each specific application. It is not that important in the negotiations process to follow\\na strict format rule. The possible flow is presented in the picture below.\\n\\n<robo-wiki-picture src=\\\"liability/negotiations.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"PubSub\\\">\\n\\n  Note that PubSub is an open protocol, so no sensible data should be transferred. For this you should use other protocols.\\n\\n</robo-wiki-note>\\n\\n\\n### Signatures\\n\\nWhen negotiations are successfully over, each side needs to sign its so-called agreement named a signature. This is a \\nmessage containing job description and price **in a specific format** signed with a private key of the account. There is a \\n[Python tool](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.Liability.sign_liability) for that as well.\\n - Job description is called **technics**. This is a launch-like 32 bytes long string which may be an encoded IPFS CID.\\n - Price is called **economics**. This is an XRT decimal - Weiner. 1 Weiner = 10**-9 XRT.\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"32 bytes\\\">\\n\\n  One may obtain an [IPFS](https://ipfs.tech/) CID formatted in a proper way with the [Python library](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.utils.ipfs_qm_hash_to_32_bytes).\\n  When using the `sign_liability` function, no need to transform the hash, it will be done automatically.\\n\\n</robo-wiki-note>\\n\\nFollowing the coffee example:\\n\\n1. The task is a JSON\\n```json\\n{\\\"task\\\": \\\"make_espresso\\\", \\\"description\\\": \\\"Make one cup of espresso\\\"}\\n```\\n2. Its IPFS CID is `QmP17mWKtQtq2Gq6qZAggPRrho3sVjQGBpXZ8KZiQ57FDi`\\n3. So the **technics** (transformed CID) is `0x09daaa8055722a6894951b1273e807f8a46628efeec46805f0228ace230bd5a9` \\n4. **Economics** is `1.5 XRT`.\\n\\nWhen signed, it's time to create a liability! This may be done by one of the sides (either promisee or promisor) or by a \\n3rd-party account of a so-called provider.\\n\\n## Create Liability\\n\\n### Preparations\\n\\nAs have been mentioned earlier, at least two sides are involved in the process. For this example, let's use three and make\\na separated provider for this. Assume that the negotiations took place somehow already.\\n\\n### 1. Create three accounts and add funds to them\\n\\n<robo-wiki-picture src=\\\"liability/balances.jpg\\\" />\\n\\nHere we have supplied the provider with 100 XRT to sign liability extrinsics, promisee was given 2 XRT to pay for the work.\\nPromisor wasn't granted any funds (except for an existential deposit of at least 1 mXRT).\\n\\n### 1. Navigate to Developer -> Extrinsics\\n\\n<robo-wiki-picture src=\\\"liability/extrinsics.jpg\\\" />\\n\\n### 2. Choose liability -> create from the dropdown list of possible extrinsics\\n\\nAlso choose an account you want to submit the extrinsic with. Fill in all the parameters.\\n\\n<robo-wiki-picture src=\\\"liability/create.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Signatures\\\">\\n\\n  Since provider is used here, no need to know seeds of the participants. Only their signatures needed.\\n\\n</robo-wiki-note>\\n\\n### 3. Submit transaction\\n\\n<robo-wiki-picture src=\\\"liability/submit.jpg\\\" />\\n\\n### 4. Review your liability in the events\\n\\nFor this, navigate to `Network -> Explorer` and find a list of events on the right. Click a triangle icon to expand.\\n\\n<robo-wiki-picture src=\\\"liability/new-liability.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Hash\\\">\\n\\n  The hash may be transformed to an IPFS CID with the same \\n  [Python tool](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.utils.ipfs_32_bytes_to_qm_hash).\\n\\n</robo-wiki-note>\\n\\n### 5. Storage exploring\\n\\nYou may also explore some characteristics of the liabilities in storage module `liability`.\\n\\n<robo-wiki-picture src=\\\"liability/storage-liability.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Next Index\\\">\\n\\n  The `Next Index` storage function shows the latest liability index +1, so even though it's `1`, liability `0` is explored.\\n\\n</robo-wiki-note>\\n\\n## Reports\\n\\nImage that a coffee has been made and now the coffee machine needs to report it somehow. That's where liability reports\\ncome into scene. As a proof of labour the account adds another IPFS CID as a report content when finalizing the existing\\nliability. This again requires a signature of the promisor.\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Report signature\\\">\\n\\n  Message signed contains of the existing liability index and the report IPFS CID encoded in 32 bytes representation. Once again,\\n  the [Python tool](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.Liability.sign_report) can help to sign the report.\\n\\n</robo-wiki-note>\\n\\nKeeping with the coffee machine example:\\n\\n1. Report is a JSON\\n```json\\n{\\\"report\\\": \\\"Coffee made! Time to execute - 80 seconds.\\\"}\\n```\\n2. Its IPFS CID is `QmeXCrBuv6cw825JJfSWqNVv28AyjJZW9KReN9wcLQjfCm`\\n3. So the **payload** (transformed CID) is `0xf06f2394f55537a5f37d63fd72bfbef50e9f60ea9e0e34224e455afae27a97a2` \\n4. **Index** is `0` it's the existing liability index.\\n\\n### 1. Navigate to extrinsics, liability -> finalize(report)\\n\\nFill in the parameters and submit extrinsic. Again, this may be done by a 3rd-party account. \\n\\n<robo-wiki-picture src=\\\"liability/report.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Existential deposit\\\">\\n\\n  Pay attention that the promisor account should not be \\\"dead\\\" - it should have the existential deposit of at least 1 mXRT.\\n\\n</robo-wiki-note>\\n\\nSign and submit the report. When done, you can explore it in the events.\\n\\n<robo-wiki-picture src=\\\"liability/new-report.jpg\\\" />\\n\\n### 2. Explore reports\\n\\nYou can also observe the report in the storage. Go to `Developer -> Storage` and choose `liability` from the dropdown list.\\n\\n<robo-wiki-picture src=\\\"liability/storage-report.jpg\\\" />\\n\\n### 3. Check balances\\n\\nOn the picture it's shown that now the promisor has got the \\\"salary\\\". Economical relationship happened!\\n\\n<robo-wiki-picture src=\\\"liability/balances-2.jpg\\\" />\\n\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Verifying\\\">\\n\\n  As for now there is no way to verify the job is done, so as soon as the promisor reports, the tokens are transferred to its account.\\n  The verify feature is to be added in the future.\\n\\n</robo-wiki-note>\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"f52ebfe9b47062f648d7a7f3cb033f45\",\n        \"title\": \"Launch\",\n        \"path\": \"/docs/launch/\",\n        \"content\": \"\\n**Another basic feature of Robonomics parachain is the Launch pallet. It allows you to send commands to the accounts/any \\nentities behind them. These commands include parameter to specify the task to be executed.**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Dev Node\\\">\\n\\n  Please pay attention that this and following tutorials are demonstrated on a local instance of Robonomics Node. Set\\n up yours with [these instructions](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\n## 1. Navigate to Developer -> Extrinsics\\n\\n<robo-wiki-picture src=\\\"launch/extrinsics.jpg\\\" />\\n\\n## 2. Choose launch -> launch from the dropdown list of possible extrinsics\\n\\nAlso choose an account you want to submit the extrinsic with. Fill in the target address and the parameter field.\\n\\n<robo-wiki-picture src=\\\"launch/launch.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"32 bytes\\\">\\n\\n  Launch supports 32 bytes long strings as commands ([source](https://polkascan.github.io/py-scale-codec/types.html#scalecodec.types.H256)),\\n  so there is a room to improvise here:\\n  - For basic commands like toggling you may use \\\"0x0000000000000000000000000000000000000000000000000000000000000001\\\" or\\n  \\\"0x0000000000000000000000000000000000000000000000000000000000000000\\\".\\n  - For advanced commands including json-like you may use [IPFS](https://ipfs.tech/) CID formatted in a \\n  [proper way](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.utils.ipfs_qm_hash_to_32_bytes).\\n\\n</robo-wiki-note>\\n\\n## 3. Submit transaction\\n\\n<robo-wiki-picture src=\\\"launch/submit.jpg\\\" />\\n\\n## 4. Review your launch in the events\\n\\nFor this, navigate to *Network -> Explorer* and find a list of events on the right. Click a triangle icon to expand.\\n\\n<robo-wiki-picture src=\\\"launch/event.jpg\\\" />\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"63a149194297b1a03eb2f1210b92a68e\",\n        \"title\": \"How to Update Robonomics Collator Node Version\",\n        \"path\": \"/docs/how-to-update-collator-node-version/\",\n        \"content\": \"\\nIt is recommended to have read the following articles prior to reading this post: [\\\"How to Build Collator Node\\\"](/docs/how-to-build-collator-node) & [\\\"How to Launch the Robonomics Collator\\\"](/docs/how-to-launch-the-robonomics-collator).\\n\\nThis article contains the commands required to update a Robonomics collator node (running on Ubuntu), and also gives an example afterwards.\\n\\n## **Required Commands**\\n\\n0. Before you begin, it is recommended that you are logged in as `root`, if not, then I would recommend that you use:\\n\\n<code-helper copy>\\n\\n```shell\\nsudo su -\\n```\\n\\n</code-helper>\\n\\n1. Stop the Robonomics service:\\n\\n<code-helper copy>\\n\\n```shell\\nsystemctl stop robonomics.service\\n```\\n\\n</code-helper>\\n\\n2. Remove previous version of Robonomics (make sure you are in the correct directory):\\n\\n<code-helper copy>\\n\\n```shell\\nrm -f robonomics.X.X.X-ubuntu-x86_64.tar.gz\\n```\\n\\n</code-helper>\\n\\n3. Get the [latest release](https://github.com/airalab/robonomics/releases) version of Robonomics:\\n\\n<code-helper copy>\\n\\n```shell\\nwget https://github.com/airalab/robonomics/releases/vX.X.X/.....\\n```\\n</code-helper>\\n\\n\\n4. Extract the file:\\n\\n<code-helper copy>\\n\\n```shell\\ntar -xf robonomics-X.X.X-x86_64-unknown-linux.gnu.tar.gz\\n```\\n</code-helper>\\n\\n5. Move the file:\\n\\n<code-helper copy>\\n\\n```shell\\nmv robonomics /usr/local/bin/\\n```\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"note\\\">\\n\\nYou need to move this file to the correct directory which you installed the Robonomics node)\\n\\n</robo-wiki-note>\\n\\n6. Start Robonomics:\\n\\n<code-helper copy>\\n\\n```shell\\nsystemctl start robonomics.service\\n```\\n</code-helper>\\n\\nExample for upgrading collator node to Robonomics v1.8.4:\\n\\n<code-helper>\\n\\n```shell\\nsudo su -\\ncd /home/admin\\nsystemctl stop robonomics.service\\nrm -f robonomics-1.7.3-x86_64-unknown-linux-gnu.tar.gz\\nwget https://github.com/airalab/robonomics/releases/download/v1.8.4/robonomics-1.8.4-x86_64-unknown-linux-gnu.tar.gz\\ntar -xf robonomics-1.8.4-x86_64-unknown-linux-gnu.tar.gz\\nmv robonomics /usr/local/bin/\\nsystemctl start robonomics.service\\n\\n```\\n</code-helper>\\n\\n## **Changing Kusama Relay Chain Database with No Base Path Set**\\n\\nThere are times where certain snapshots of the Kusama Relay Chain cause your node to have errors. This will often cause your node to stop working. Example error caused by a corrupt Relay Chain database:\\n\\n<code-helper>\\n\\n```shell\\nDec 08 19:14:31 ns3159483 robonomics[1019836]: 2022-12-08 19:14:31 [Relaychain] GRANDPA voter error: could not complete a round on disk: Database\\nDec 08 19:14:31 ns3159483 robonomics[1019836]: 2022-12-08 19:14:31 [Relaychain] Essential task `grandpa-voter` failed. Shutting down service.\\nDec 08 19:14:32 ns3159483 robonomics[1019836]: Error: Service(Other(\\\"Essential task failed.\\\"))\\nDec 08 19:14:32 ns3159483 systemd[1]: robonomics.service: Main process exited, code=exited, status=1/FAILURE\\nDec 08 19:14:32 ns3159483 systemd[1]: robonomics.service: Failed with result 'exit-code'.\\nec 08 19:14:33 ns3159483 robonomics[1022922]: Error: Service(Client(Backend(\\\"Invalid argument: Column families not opened: col12, col11, col10, col9, col8, col7, col6, col5, col4, col3, col2, col1, col0\\\")))\\nDec 08 19:14:33 ns3159483 systemd[1]: robonomics.service: Main process exited, code=exited, status=1/FAILURE\\nDec 08 19:14:33 ns3159483 systemd[1]: robonomics.service: Failed with result 'exit-code'.\\n```\\n</code-helper>\\n\\nIn order to fix this error, you should remove your existing Kusama Relay Chain database (likely RocksDb) and replace it with another Db such as ParityDb. Execute the following commands:\\n\\n1. Find the directory of Robonomics node and check the files:\\n\\n<code-helper>\\n\\n```shell\\ncd /home/robonomics/\\nls -a\\n```\\n</code-helper>\\n\\n2. Confirm that you see the polkadot directory, and then navigate to the chains directory:\\n\\n<code-helper>\\n\\n```shell\\ncd /polkadot/chains/\\nls -a\\n```\\n</code-helper>\\n\\n3. Delete the `ksmcc3` directory:\\n\\n<code-helper copy>\\n\\n```shell\\nrm -r ksmcc3\\n```\\n</code-helper>\\n\\n4. Make a new `ksmcc3` directory.\\n\\n<code-helper>\\n\\n```shell\\nmkdir ksmcc3\\nchown -R robonomics:robonomics ksmcc3\\ncd ksmcc3\\n```\\n\\n</code-helper>\\n\\n5. Now you need to download a new snapshot. This example uses a heavily pruned relay chain snapshot, but you can swap it for any snapshot you prefer.\\n\\n<code-helper copy>\\n\\n```shell\\nwget wget https://snaps.sik.rocks/ksm_pruned.tar.gz\\n```\\n\\n</code-helper>\\n\\n6. Whilst the snapshot is downloading, open a new session and edit your service file:\\n\\n\\n<code-helper copy>\\n\\n```shell\\nsudo nano /etc/systemd/system/robonomics.service\\n```\\n\\n</code-helper>\\n\\nModify lines within the service file which relate to the database and pruning:\\n\\n<code-helper copy>\\n\\n```shell\\n  --database=paritydb \\\\\\n  --state-pruning=100 \\\\\\n  --blocks-pruning=100 \\\\\\n  --execution=Wasm\\n```\\n\\n</code-helper>\\n\\n  \\nUse `Ctrl + S` and then `Ctrl + X` to save and exit the service file.\\n\\n7. Now you need to reload your daemon.\\n\\n<code-helper copy>\\n\\n```shell\\nsystemctl daemon-reload\\n```\\n</code-helper>\\n\\n\\n8. By this time, in your other session, hopefully the new Db has downloaded, so extract the file:\\n\\n<code-helper copy>\\n\\n```shell\\ntar -xvzf ksm_pruned.tar.gz\\n```\\n\\n</code-helper>\\n\\n9. After the unpacking is completed, execute the following:\\n\\n<code-helper copy>\\n\\n\\n```shell\\nchown -R robonomics:robonomics paritydb\\n```\\n\\n</code-helper>\\n\\n10. Now you can start the service, monitor it for any errors, and check that it is peering on both the relay chain and the parachain:\\n\\n\\n<code-helper copy>\\n\\n\\n```shell\\nsystemctl start robonomics && journalctl -fu robonomics\\n```\\n</code-helper>\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"716e3992e88ea98e13db8c7022696a41\",\n        \"title\": \"How to launch the Robonomics collator\",\n        \"path\": \"/docs/how-to-launch-the-robonomics-collator/\",\n        \"content\": \"\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Note\\\">\\n  In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n</robo-wiki-note>\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is primarily maintained by the initial developers, but anyone can support the project. Every additional full node of the blockchain helps it to become more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it can be [built from source](/docs/how-to-build-collator-node/).\\n\\n## What is a collator\\n\\nA Collator is part of the Robonomics parachain. This type of node creates new blocks for the Robonomics chain.\\n\\n>Collators maintain parachains by collecting parachain transactions from users and producing state transition proofs for Relay Chain validators. In other words, collators maintain parachains by aggregating parachain transactions into parachain block candidates and producing state transition proofs for validators based on those blocks.\\n\\nYou can learn more about collators on the related [Polkadot wiki page](https://wiki.polkadot.network/docs/learn-collator)\\n\\nIn the Robonomics parachain every collator gets rewards of (**0.000380520 XRT**) for every block that the collator builds (rewards occur when blocks are sealed to the chain). \\nAlso the collator that builds the block gets **50% of transactions fees** contained within the block they create.\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nHowever, it is recommended that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need to include *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can easily launch a collator directly in the command line to check for errors.\\nAfter doing this it is strongly recommended to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](./images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      --execution=Wasm \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --execution=Wasm \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](./images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service \\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with: `journalctl -u robonomics.service -f` \\n\\nOnce the Robonomics collator is launched it will begin to sync with the Kusama Relay Chain, this can take a considerable amount of time, depending on your network speed and system specifications, so we recommend to download a Kusama snapshot. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the Robonomics service. You can find more info about snapshots and usage instructions on the following page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](./images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](./images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\\n## Troubleshooting\\n### Error: \\\"State Database error: Too many sibling blocks inserted\\\"\\nFor fix this error you can just launch your collator in archive mode: \\n\\n1) First, need to stop the Robonomics service: \\n    \\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    \\n\\n2) Then add the parameter `--state-pruning=archive` to the parachain part of the service file. Example of the edited service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n    --parachain-id=2048 \\\\\\n    --name=\\\"%NODE_NAME%\\\" \\\\\\n    --validator \\\\\\n    --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n    --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n    --base-path=\\\"%BASE_PATH%\\\" \\\\\\n    --state-cache-size=0 \\\\\\n    --execution=Wasm \\\\\\n    --state-pruning=archive \\\\\\n    -- \\\\\\n    --database=RocksDb \\\\\\n    --unsafe-pruning \\\\\\n    --execution=Wasm \\\\\\n    --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n\\n3) Reload the systemd manager configuration:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl daemon-reload\\n    ```\\n\\n4) Remove the exists parachain database:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/chains/robonomics/db/\\n    ```\\n\\n5) Start the robonomics service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n    After that need to wait for the synchronization of the parahain database.\\n\\n### Error: \\\"cannot create module: compilation settings are not compatible with the native host\\\"\\nThis error related to the virtualization parameters. Need to use \\\"host-model\\\" type of the emulated processor. You can set up this on the virtualisation host.\\n\\nBut, if you catch this error on any hosting, you need to ask the technical support about this problem only.\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"657264036c99df16b9de979bb6c7a850\",\n        \"title\": \"How to build collator node from source\",\n        \"path\": \"/docs/how-to-build-collator-node/\",\n        \"content\": \"\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Note\\\">\\n  In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n</robo-wiki-note>\\n\\n## What is a collator\\n\\nCollator is part of the Robonomics parachain. This nodes type creates new blocks for chain.\\n\\n>Collators maintain parachains by collecting parachain transactions from users and producing state transition proofs for Relay Chain validators. In other words, collators maintain parachains by aggregating parachain transactions into parachain block candidates and producing state transition proofs for validators based on those blocks.\\n\\nYou can learn more about collator on the related [Polkadot wiki page](https://wiki.polkadot.network/docs/learn-collator)\\n\\nIn the Robonomics parachain every collator get rewards (**0.000380520 XRT**) for every block it built, if this block was sealed to the chain. \\nAlso collator get **50% transactions fees** from this block.\\n\\n## Building process\\n\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](./images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v2.6.0:\\n\\n```\\n  rustup install nightly-2022-08-05\\n```\\n![Install nightly](./images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2022-08-05\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2022-08-05\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v2.6.0 robonomics-node\\n```\\n![Start build Robonomics](./images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](./images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"b6ca48a552d45fad1f2e74721af685f8\",\n        \"title\": \"Upgrade Your Home Assistant OS\",\n        \"path\": \"/docs/hass-os-upgrade/\",\n        \"content\": \"\\n**This article contains instructions to upgrade your existing Home Assistant OS with Robonomics integration.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/homeassistant_os.png\\\" />\\n\\n## Install IPFS Add-on\\n\\n\\nRobonomics Integration stores the data using local IPFS daemon, so you need to install it first. \\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmdAmUHW9bpTU6sUwBYu4ai4DVJ6nZ5xerjM9exvooGKGq', type:'mp4'}]\\\" />\\n\\n1. There is an [IPFS Add-on for Home Assistant](https://github.com/airalab/ipfs-addon). To install it go to `Settings` -> `Add-ons` and press the `ADD-ON STORE` button in the lower right corner.\\n\\n2. Press on three dots in the upper right corner and choose `Repositories`. Add there the following link:\\n\\n<code-helper copy>\\n\\n```\\nhttps://github.com/airalab/ipfs-addon\\n```\\n\\n</code-helper>\\n\\n3. Press `ADD` button.\\n\\n4. Close the repository manager and refresh the page. Now in the end of the page you can see IPFS Daemon Add-on.\\n\\n5. Open the addon and press `INSTALL`. After installation press `START`.\\n\\n## Install HACS\\n\\n[Home Assistant Community Store (HACS)](https://hacs.xyz/) allows you to install custom integrations.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmYJFpxrww9PRvcAUhdgKufeDbyUFoBZTREZHPgV452kzs', type:'mp4'}]\\\" />\\n\\n1. Before start, you need to install add-on for connecting to the Home Assistant device with SSH. In Add-on Store search `ssh`. We recommend to install `SSH & Web Terminal` add-on.\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Warning\\\">\\n\\n  If the SSH addon is not found, try enabling Advanced Mode in your user profile settings. To do this, click on the profile icon in the lower left corner, and find the Advanced Mode option.\\n\\n</robo-wiki-note>\\n\\n2. Choose the add-on and press `INSTALL`. After installation is finished, go to `Configuration` tab and add `password` or `authorized_keys`. Don't forget to save this part of configuration.\\n\\n3. In the `Info` tab press `START`. If you want to see the addon in the sidebar, don't forget to enable `Show in sidebar`.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmcijfJ45fmW9omB67xWyPKvHhZuwLMTTQ7DBqnyxHUXR1', type:'mp4'}]\\\" />\\n\\n4. Open SSH Add-on and run the following command:\\n\\n<code-helper copy additionalLine=\\\"Home Assistant Command Line\\\">\\n\\n```bash\\nwget -O - https://get.hacs.xyz | bash -\\n```\\n\\n</code-helper>\\n\\n5. Restart Home Assistant (you can do it in `Settings`->`System`). \\n\\n6. Now HACS Integration will be available to add in the `Integrations` menu. Go to `Settings`->`Devices & Services`, press `Add Integration` and find HACS.\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Warning\\\">\\n\\n  To use HACS you need a Github Account.\\n\\n</robo-wiki-note>\\n\\n7. Click on it and follow the installation instructions. \\n\\n## Install Robonomics Integration\\n\\nNow you can install Robonomics Integration using HACS.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/Qmb19UEQwwHfNroCaH8NMFhPV2dc52vSC8i4ATJsqVYiZf', type:'mp4'}]\\\" />\\n\\n1. Open HACS from a sidebar menu and go to `Integrations`. Press on three dots in the upper right corner and choose `Custom Repositories`. In the opened window paste the following link:\\n\\n<code-helper copy>\\n\\n```\\nhttps://github.com/airalab/homeassistant-robonomics-integration\\n```\\n\\n</code-helper>\\n\\n2. After that, choose `Integration` category and press `ADD`. \\n\\n3. In `Custom Repositories` click on Robonomics and press the `Download` button in the lower right corner. After downloading, restart Home Assistant.\\n\\nNow you have two options:\\n\\n- If you have not yet used MQTT integration to connect smart devices via Zigbee adapter, go to the [**MQTT Broker for Home Assistant OS**](/docs/mqtt-hassos) article.\\n- Otherwise, go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"2ec95dfc8a5c62f4f21381867d9f4e2b\",\n        \"title\": \"Home Assistant Initialization\",\n        \"path\": \"/docs/hass-init/\",\n        \"content\": \"\\n**After installing Home Assistant, it needs to be initialized.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha_init.png\\\" />\\n\\nYou are starting with the creation of the owner account of Home Assistant. This account is an administrator and can make any changes. Open web browser and go to `http://%RASPBERRY_IP_ADDRESS%:8123`. You can find the IP address of Raspberry Pi using [Fing mobile app](https://www.fing.com/products) or [nmap CLI tool](https://vitux.com/find-devices-connected-to-your-network-with-nmap/).\\n\\n<robo-wiki-note type=\\\"note\\\">Raspberry Pi address may change in time, due router settings.</robo-wiki-note>\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmYd1Mh2VHVyF3WgvFsN3NFkozXscnCVmEV2YG86UKtK3C', type:'mp4'}]\\\" />\\n\\n1. At the first page, enter a name, username, password and click on the `CREATE ACCOUNT` button.\\n\\n2. On the next screen, enter a name for your home and set your location and unit system. Click `DETECT` to find your location and set your time zone and unit system based on that location. If you don't want to send your location, you can set these values manually.\\n\\n3. After that, Home Assistant will show any devices that it has discovered on your network. Don’t worry if you see fewer items than what is shown below; you can always manually add devices later. For now, just click `FINISH` and you will be on the main Home Assistant screen.\\n\\n4. Finally, you will see the Home Assistant web interface, which will show all of your devices. \\n\\n## Next step\\n\\nNext you need to setup MQTT Broker using one of the options:\\n\\n**Option 1 (Home Assistant OS)**\\n* If you are upgrading your **Home Assistant OS**, [go here](/docs/mqtt-hassos/).\\n\\n**Option 2 (Pre-installed image or Home Assistant Docker or Home Assistant Core)**\\n* If you are using **pre-installed image** or upgrading your **Home Assistant Docker** or **Core**, [go here](/docs/mqtt-image-docker-core/).\\n\\n## Related videos\\n\\nhttps://youtu.be/n4PX25aB1JU\\n\\n## Troubleshooting\\n\\n1. If you forget your login or password for local user, [check this article](https://www.home-assistant.io/docs/locked_out/) to restore your credentials. If you forget a password to Home Assistant from your Robonomics account, [check the Dapp.](https://dapp.robonomics.network/#/home-assistant)\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"db3dac72fca3d30e742c18c575345724\",\n        \"title\": \"Pre-installed Image For Raspberry Pi\",\n        \"path\": \"/docs/hass-image-install/\",\n        \"content\": \"\\n<robo-wiki-video loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmXjFaTd81dLrMgADtENmSqbS2uJuLJUgQUrmDu2CsSuAq', type:'mp4'}]\\\" />\\n\\n**Welcome to the guide on installing Home Assistant with Robonomics integration on a Raspberry Pi. Home Assistant is an open-source home automation system that provides a centralized hub for controlling smart devices in your home network. By integrating with Robonomics, a decentralized cloud service, you can enhance the functionality and security of your smart home. In this article, we will provide step-by-step instructions on how to install Home Assistant with Robonomics on a Raspberry Pi, giving you the ability to automate and control various aspects of your home using a secure and decentralized solution. Let's get started!**\\n\\n<robo-wiki-picture src=\\\"home-assistant/pre_installed_image.png\\\" />\\n\\n## 1. Downloading the Image\\n\\nTo simplify the installation process, a pre-made image can be used. It contains Home Assistant Core with Robonomics integration and IPFS. Options for downloading:\\n\\n### GitHub Release\\n\\nDownload it from the latest [GitHub releases.](https://github.com/airalab/Robonomics-HomeAssistant-image/releases)\\n\\n### IPFS get\\n\\nAlternatively, you can download it using IPFS. [Install IPFS](https://docs.ipfs.tech/install/command-line/), initialize and start the daemon:\\n\\n<code-helper additionalLine=\\\"your_username@your_hostname\\\">\\n\\n```shell\\nipfs init\\nipfs daemon\\n```\\n</code-helper>\\n\\nOpen the new terminal and download the image:\\n\\n<code-helper additionalLine=\\\"your_username@your_hostname\\\">\\n\\n```shell\\nipfs get QmbuaMeXG51RS6uSzVN2C2oXeJ8vsgJ1JQKnQHgshyporE -o rpi.img.xz\\n```\\n</code-helper>\\n\\n\\n## 2. Configuring the Image\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card.\\n\\n<robo-wiki-picture src=\\\"home-assistant/insert-sd-card.gif\\\" alt=\\\"insert SD card\\\" />\\n\\n\\nRun the Raspberry Pi Imager program. Choose required image as the operating system and ensure to select your SD card from the storage dropdown menu. In settings provide your Wi-Fi, password, choose your country from drop-down list and then `Write!` image. \\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmVgex7Aw9sH97kDbbwaHkbcHZRu8xWruh5a7hfnMstNrV', type:'mp4'}]\\\" />\\n\\nYou can find country codes [here](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes).\\n\\n## 3. First Boot\\n\\n**Safely eject the SD card**, insert it into the Raspberry Pi and connect the power cable to your device. It should connect to your Wi-Fi network. \\n\\n<robo-wiki-picture src=\\\"home-assistant/first-start.gif\\\" alt=\\\"first boot\\\" />\\n\\nOnce your Raspberry Pi is connected, the red LED will light up and the green LED will flash for some time. Wait up to 5 minutes for the Raspberry Pi to boot up and register on the network. \\n\\nNow find the IP address of Raspberry Pi. To find it you can use [Fing mobile app](https://www.fing.com/products) or \\n[nmap CLI tool](https://vitux.com/find-devices-connected-to-your-network-with-nmap/). Find the `robots-home` (optional name could be `Home(homeassistant)`) \\nname of the host machine in the IP list. \\n\\nIn this example the address is `192.168.43.56`. \\n\\nConnect to Raspberry Pi with `ssh` command: \\n\\n<code-helper additionalLine=\\\"your_username@your_hostname\\\">\\n\\n```bash\\nssh smart@192.168.43.56\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"note\\\"> \\n\\nUser is `smart`, password is `robot`. \\n\\n</robo-wiki-note>\\n\\n## Next step\\n\\nNow you have a Raspberry Pi with firmware installed, go to the [Home Assistant Init](/docs/hass-init/) article.\\n\\n<!-- ## Related videos\\n\\nhttps://youtu.be/qW4sjUaShWA -->\\n\\n## Troubleshooting\\n\\n1. To change Wi-Fi setting later, use command `sudo raspi-config`. Find more information about this command on [the official site.](https://www.raspberrypi.com/documentation/computers/configuration.html)\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"0ad36878de5a3cd70a33383e3be423ef\",\n        \"title\": \"Upgrade Your Home Assistant Docker for Unix-like OS\",\n        \"path\": \"/docs/hass-docker-upgrade/\",\n        \"content\": \"\\n**This article contains instructions to upgrade your existing Home Assistant Docker (on a Unix-like OS) with the Robonomics integration.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha_docker.png\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"DISCLAIMER\\\">\\n\\n  1. It is assumed that default Docker images and container of Home Assistant named <u>homeassistant</u> are used.\\n  2. IPFS will be installed and run as a <u>systemd</u> service on the host machine.\\n  3. It is assumed that you have [Python3.9](https://www.python.org/downloads/) or higher installed.\\n\\n</robo-wiki-note>\\n\\n## Install\\n\\nDownload the installation script and run it in the terminal:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nwget https://raw.githubusercontent.com/airalab/robonomics-hass-utils/main/raspberry_pi/install_integration_docker.sh\\nbash install_integration_docker.sh\\n```\\n\\n</code-helper>\\n\\nYou will see the following output:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\n<...>\\nadded /dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw\\n<...>\\nIPFS daemon installed and launched, use ipfs-daemon.service to manage.\\n<...>\\nExecuting subversion-1.14.2-r1.pre-install\\nExecuting busybox-1.35.0-r17.trigger\\nOK: 157 MiB in 165 packages\\n<...>\\nA    robonomics/utils.py\\nChecked out revision 120.\\nIntegration downloaded!\\n```\\n\\n</code-helper>\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Error: `custom_components` exists\\\">\\n\\n  You may see an error like `mkdir: can't create directory 'custom_components': File exists`. This means that you have already have this folder with some custom components installed. Just ignore this message.\\n\\n</robo-wiki-note>\\n\\nRestart the container:\\n\\n<robo-wiki-tabs>\\n  <robo-wiki-tab title=\\\"Docker\\\">\\n    <code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n    <pre>docker restart homeassistant</pre>\\n    </code-helper>\\n  </robo-wiki-tab>\\n  <robo-wiki-tab title=\\\"Docker Compose\\\">\\n    <code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n    <pre>docker compose restart</pre>\\n    </code-helper>\\n  </robo-wiki-tab>\\n</robo-wiki-tabs>\\n\\n\\n## Verify\\n\\nCheck that the IPFS service is up and running:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsystemctl status ipfs-daemon.service \\n```\\n\\n</code-helper>\\n\\nYou will see the following output:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n\\n```\\n● ipfs-daemon.service - IPFS Daemon Service\\n     Loaded: loaded (/etc/systemd/system/ipfs-daemon.service; enabled; preset: enabled)\\n     Active: active (running) since Thu 2022-11-03 11:30:39 UTC; 14min ago\\n   Main PID: 4400 (ipfs)\\n      Tasks: 12 (limit: 4416)\\n     Memory: 141.9M\\n        CPU: 3min 5.031s\\n     CGroup: /system.slice/ipfs-daemon.service\\n             └─4400 /usr/local/bin/ipfs daemon\\n```\\n\\n</code-helper>\\n\\nNow you have two options:\\n\\n- If you have not yet used MQTT integration to connect smart devices via Zigbee adapter, go to the [**MQTT Broker for Pre-installed Image, Home Assistant Docker and Core**](/docs/mqtt-image-docker-core) article.\\n- Otherwise, go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"20e7142749e4cac34392eed3b6408f14\",\n        \"title\": \"Upgrade Your Home Assistant Core\",\n        \"path\": \"/docs/hass-core-upgrade/\",\n        \"content\": \"\\n**This article contains instructions to upgrade your existing Home Assistant Core with the Robonomics integration.**\\n\\n<robo-wiki-picture src=\\\"home-assistant/ha_core.png\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"DISCLAIMER\\\">\\n\\n  1. It is assumed that the installation of your Home Assistant Core was completed in accordance to the [official instructions](https://www.home-assistant.io/installation/raspberrypi#install-home-assistant-core) and there is a <u>homeassistant</u> user and the `venv` environment. If it is not the case, follow instructions below, **but edit the script accordingly**.\\n  2. IPFS will be installed and run as a <u>systemd</u> service on the host machine.\\n  3. It is assumed that you have [Python3.9](https://www.python.org/downloads/) or higher installed.\\n\\n</robo-wiki-note>\\n\\n## Install\\n\\nDownload the installation script and run it in the terminal:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n  \\n```shell\\nwget https://raw.githubusercontent.com/airalab/robonomics-hass-utils/main/raspberry_pi/install_integration_core.sh\\nbash install_integration_core.sh\\n```\\n\\n</code-helper>\\n\\nYou will see the following output:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n\\n```shell\\n<...>\\nhttps://raw.githubusercontent.com/airalab/robonomics-hass-utils/main/raspberry_pi/install_ipfs_arc_dependent.sh\\n<...>\\nIPFS daemon installed and launched, use ipfs-daemon.service to manage.\\n<...>\\nA    robonomics/utils.py\\nChecked out revision 125.\\nIntegration downloaded!\\n```\\n\\n</code-helper>\\n\\nDuring the process, you will be asked to confirm the restart of several services. Navigating with `tab`, select the `yes` option.\\n  \\n<robo-wiki-note type=\\\"note\\\" title=\\\"Error: `custom_components` exists\\\">\\n\\n  You may see an error like `mkdir: can't create directory 'custom_components': File exists`. This means that you have already have this folder with some custom components installed. Just ignore this message.\\n\\n</robo-wiki-note>\\n  \\nAfter finishing, restart your Home Assistant.\\n\\n## Verify\\n\\nCheck that the IPFS service is up and running:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```shell\\nsystemctl status ipfs-daemon.service \\n```\\n\\n</code-helper>\\n\\nYou will see the following output:\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\">\\n\\n```\\n● ipfs-daemon.service - IPFS Daemon Service\\n     Loaded: loaded (/etc/systemd/system/ipfs-daemon.service; enabled; preset: enabled)\\n     Active: active (running) since Thu 2022-11-03 11:30:39 UTC; 14min ago\\n   Main PID: 4400 (ipfs)\\n      Tasks: 12 (limit: 4416)\\n     Memory: 141.9M\\n        CPU: 3min 5.031s\\n     CGroup: /system.slice/ipfs-daemon.service\\n             └─4400 /usr/local/bin/ipfs daemon\\n```\\n\\n</code-helper>\\n\\nNow you have two options:\\n\\n- If you have not yet used MQTT integration to connect smart devices via Zigbee adapter, go to the [**MQTT Broker for Pre-installed Image, Home Assistant Docker and Core**](/docs/mqtt-image-docker-core) article.\\n- Otherwise, go to the [**IoT Subscription**](/docs/sub-activate) section and start activating the Robonomics subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"93b43322b6850bffa4b180dea301ab0d\",\n        \"title\": \"Glossary\",\n        \"path\": \"/docs/glossary/\",\n        \"content\": \"\\n## A\\n\\n### Account (on Blockchain)\\na conjunction of a public-private keypair, the public part of which is the user's public address, and the private part is the secret key for accessing the control of this address.\\n\\n\\n### Auction (of Parachains)\\nmechanism of leasing slots for parachains in the Polkadot and Kusama ecosystems; a parachain have win a candle auction to get a slot.\\n\\n### Autonomous Agent\\na computational system that receives sensory data from its environment and decides how to respond to external stimuli in order to achieve its goals.\\n\\n### AIRA\\nor Autonomous Intelligent Robot Agent — a software, developed by Robonomics team in 2015, that implements the standard of economic human-machine and machine-machine interaction through an intellectual liability contract.\\n\\n\\n## B\\n\\n### Blockchain\\nin a broad sense, a distributed network that uses cryptography to allow a group of participants to trustlessly come to consensus on the changing state of a system.\\n\\n### Blockchain Explorer\\nan application that allows to explore the different blocks, transactions and addresses on a blockchain (e.g. Etherscan, Subscan).\\n\\n### Blueprint (Hass)\\na pre-made automation logic that can be easily added to a Home Assistant instance.\\n\\n### Bridge\\na technology and methods by which two economically sovereign and technologically diverse chains to communicate with each other. \\n\\n\\n## C\\n\\n### Coase (XRT)\\nor Cs — a millionth share of one XRT token, 1 XRT = 1 000 000 Cs; named after Ronald Coase, a British economist, one of the founders of institutional economics, a laureate of the Nobel Memorial Prize in Economic Sciences. \\n\\n### Collator\\na node that maintains a parachain by collecting parachain transactions and producing state transition proofs for the validators.\\n\\n### Consensus\\na process in which nodes of a blockchain network reach agreement about the present state of the data in the network (e.g. Proof-of-Work, Proof-of-Stake).\\n\\n### Crowdloan\\na crowdfunding campaign of collecting tokens to make a bid on the slots auction in the Polkadot / Kusama ecosystem.\\n\\n### Cybernetics\\nthe study of control and communication in the animal and the machine, according definition of N. Wiener.\\n\\n### Cyber-Physical System\\nor CPS — a strong unification and mutual integration of multiple computational, networking, and physical processes.\\n\\n\\n## D\\n\\n### DAO\\na collectively-owned, blockchain-governed organization, in which resource management is carried out in accordance with a pre-agreed and formalized set of rules, the enforcement of which is performed automatically.\\n\\n### Datalog (Function)\\na Robonomics parachain function, that stores device data on the blockchain.\\n\\n### Dapp\\nor decentralized application — an application that runs as part of a distributed network and provides access its functions in a user-friendly way.\\n\\n### Decentralized Cloud\\na cloud computing service based on a decentralized peer-to-peer network that users can join either to use services or to provide their resources such as for computing, networking, storage, etc.\\n\\n### Digital Twin\\na digital version of real equipment that copies its technical characteristics and historical data.\\n\\n\\n## E\\n\\n### Edge-system\\nan IoT device that acts as a link between locally accessible embedded systems and the global network, typically supporting communication protocols and transmitting telemetry and control signals.\\n\\n### Embedded System\\nan IoT device with limited computing and communication resources that provides basic functions (sensors, actuators, buttons) at the lowest level, usually without user interfaces.\\n\\n### Ethereum\\na decentralized open-source blockchain system that works as a platform for numerous other cryptocurrencies, as well as for the execution of decentralized smart contracts.\\n\\n### Ethereum Upgrade\\npreviously known as Ethereum 2.0 or Eth2 — a upgrades of Ethereum protocol that should make the network more scalable, secure and sustainable; for these purposes, it is proposed to change the consensus to Proof-of-Stake and add a sharding mechanism to increase network capacity.\\n\\n### Exodus\\nprocess of transfer XRT tokens from Ethereum network to the Robonomics parachain.\\n\\n### Extrinsic\\na function on the Polkadot and Kusama network, that can trigger network state transitions from outside of the state.\\n\\n\\n## G\\n\\n### Glushkov (XRT)\\nor Gk — a thousandth of one XRT token, 1 XRT = 1 000 Gk; named after Victor Glushkov, a Soviet mathematician, one of the founders of information technology and cybernetics in the Soviet Union.\\n\\n\\n## H\\n\\n### Home Assistant\\nor Hass — an open source control system software, designed to be a central hub for smart devices. \\n\\n### HRMP\\nor Horizontal Relay-routed Message Passing — a secure message passing between parachains, that stores all messages in the Relay Chain storage before sending it to parachains. \\n\\n### HMI\\nor Human-Machine Interface — a user interface or dashboard that connects the user to a machine, system, or device.\\n\\n\\n## I\\n\\n### Industry 4.0\\nor the Fourth Industrial Revolution — the ongoing automation of traditional manufacturing and industrial practices, using modern smart technology.\\n\\n### IPFS\\nor InterPlanetary File System — a peer-to-peer software for storing and sharing data in a distributed file system.\\n\\n### IoT\\nor Internet of Things — a connection to a global network of billions of devices, capable of collecting data and integrated into the environment.\\n\\n### IoT Gateway\\nan edge-system, that aggregates and transmits data from IoT devices to network and vice versa; often these devices are a more complex version of the WiFi router.\\n\\n### IoT Provider\\nan external service that provides IoT users with remote access to data and analytics, as well as control of smart devices over the Internet.\\n\\n### IoT Subscription\\nRobonomics parachain feature, that allows to use the all functions of the parachain for a certain period without fee.\\n\\n\\n## K\\n\\n### KSM\\na native token for Kusama network.\\n\\n### Kusama\\nthe \\\"canary network\\\" for Polkadot that consists of an early-release, unaudited version of the Polkadot software.\\n\\n\\n## L\\n\\n### Launch (Function)\\na Robonomics parachain function that starts or stops a device by sending a command through the blockchain.\\n\\n### Lease Period\\nan amount of time that a parachain can connect to the Relay Chain.\\n\\n### Libp2p\\nan open-source library for creating encrypted peer-to-peer networks.\\n\\n### Lights-out Factory\\nor Smart Factory — a factory that is fully automated and requires no human presence on-site.\\n\\n### Lighthouse\\na smart contract, in the robot economy concept, which performs a transaction when the Provider establishes a market match between the Promisor and the Promisee.\\n\\n### Liability\\na smart contract, made by cyber-physical systems with each other or with humans, to execute a task for payment.\\n\\n### Liability Market\\na platform, in the robot economy concept, in charge of matching offers and demands among the nodes of the system.\\n\\n\\n## M\\n\\n### MQTT\\nor Message Queuing Telemetry Transport — a publish-subscribe protocol designed for low-bandwidth, high latency, unreliable networks for operating high volumes of IoT devices messages.\\n\\n### MQTT Broker\\na service that receives all the messages from the MQTT clients and then routes the messages to the appropriate subscribing clients.\\n\\n\\n## N\\n\\n### NFT\\nor Non-Fungible Token — a token that cannot be interchangeable and indistinguishable from other tokens which allow the tokenization of unique items and provide exclusive ownership for those tokens.\\n\\n### Node (of Robonomics)\\na Substrate-based or Ethereum-based blockchain module with Robonomics extensions for connecting to Robonomics Network.\\n\\n\\n## O\\n\\n### On-chain Governance\\na process of determining what changes to the network are permissible, such as modifications to code or movement of funds, that exists in the network itself and can directly changes it.\\n\\n\\n## P\\n\\n### Pallet\\na Substrate module written in Rust that bundles specific logic or algorithm for runtime of Substrate-based blockchain. \\n\\n### Parachain\\na custom, application-specific data structure (usually, a blockchain) that is integrated to the Relay Chain and can be validated by the validators.\\n\\n### Parathread\\na parachain without a slot that can temporarily participate (on a block by block basis with a fee) in the Relay Chain security.\\n\\n### Polkadot\\na heterogeneous, multi-chain network allowing various blockchains of different characteristics to perform arbitrary, cross-chain communication under shared security.\\n\\n### Polkadot/Substrate Portal\\na basic Substrate UI for interacting with a Polkadot, Kusama and others Substrate network.\\n\\n### Proposal (on Polkadot / Kusama)\\na potential function call to be voted on in a Polkadot, Kusama or parachains referendum. \\n\\n### Proof-of-Work\\na consensus mechanism in which, in order to reach agreement, network participants are required to perform computational work.\\n\\n### Proof-of-Stake\\na consensus mechanism in which, in order to reach agreement, network participants are required to stake capital of the associated cryptocurrency that acts as collateral.\\n\\n### Promisee\\na node that places an order for execution of a task in the robot economy concept.\\n\\n### Promisor\\na node that agrees to execute a task for payment in the robot economy concept.\\n\\n### Provider (Robonomics)\\na node, in the robot economy concept, that monitors the messages of the Liability Market and matches an offer and a demand for a small fee. \\n\\n\\n## R\\n\\n### Referendum (on Polkadot / Kusama)\\na part of on-chain governance, vote on whether or not a proposal should be accepted by the network users. \\n\\n### Relay Chain\\nthe main chain that coordinates consensus of Polkadot / Kusama and communication between parachains.\\n\\n### Robofirm\\nan organization in which the entire business process cycle is fully automated and does not require human participation.\\n\\n### Rococo\\nthe testnet for testing parachains on Kusama\\n\\n### robonomics-interface\\na Python library which specializes in interfacing with Robonomics to convenient programming.\\n\\n### Robonomics on Ethereum\\na version of Robonomics Network running on top of Ethereum, released in 2018.\\n\\n### Robot Economy\\nan economic system in which devices act as independent agents capable of performing key economic activities previously unique to humans.\\n\\n### Robot-as-a-Service\\nor RaaS — a business model where companies rent their robotics equipment to clients and customers for short-term or long-term use.\\n\\n### ROS\\nor Robot Operating System — a framework for robot software development, that provides services designed for a heterogeneous computer cluster such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management.\\n\\n### ROS 2\\nan updated and rebuilt version of Robot Operating System with new features, such as support for multi-robot and small embedded systems, and integration with real-time.\\n\\n### ROS 2 Middleware\\nor RMW — a protocol that provides standard ROS 2 features such as discovery, serialization, and transportation; ROS 2 supports multiple middleware implementations that can chosen to best suit for project requirements.\\n\\n### RWS\\nor Robonomics Web Services — decentralized infrastructure services for robotics and IoT that lets connect devices easily and interact with user applications, cloud services, and other devices securely; it has its own token also called RWS, witch gives lifetime IoT subscription in Robonomics parachain.\\n\\n### Runtime\\na state transition function of a blockchain which defines a valid algorithm for determining the state of the next block given the previous state.\\n\\n\\n## S\\n\\n### Seed Phrase\\na human-readable private key created as a sequence of random words and required to get access to blockchain address and its tokens.\\n\\n### Shared Security\\nthe security model of Polkadot / Kusama whereby all chains are equally secured by placing proofs of the validity of parachain blocks into the Relay Chain such that a potential attacker would need to attack the entire system.\\n\\n### SLS Gateway\\nan open source IoT gateway for Zigbee devices based on the ESP32 microcontroller developed by Smart Logic System.\\n\\n### Slot (of Parachain)\\na scarce resource in Polkadot / Kusama ecosystem, that allows parachain to be connected to the Relay Chain without fee for each block.\\n\\n### Smart Leasing\\na Robot-as-a-Service model variant, in which rent is paid not by time, but for specific operations and their number.\\n\\n### Smart Contract\\na program or algorithm stored on a blockchain that run automatically when predetermined conditions are met.\\n\\n### SSH\\nor Secure Shell — a network protocol for operating network services securely over an unsecured network, that uses public-key cryptography to authenticate the remote computer. \\n\\n### Staking\\nthe part of the Proof-of-Stake consensus, an act of bonding tokens by depositing them as collateral for a chance to produce a valid block and obtain a reward.\\n\\n### Substrate\\na modular framework for building blockchains like Polkadot and Kusama.\\n\\n\\n## T\\n\\n### Treasury\\na pot of funds collected through a portion of block production rewards, transaction fees, staking, etc., that can be spent by making a spending proposal; if the Treasury ends a spend period without spending all of its funds, it suffers a burn of a percentage of the funds.\\n\\n### Transaction Costs\\nthe cost of collecting and processing information due to the bounded rationality of economic agents and complexity of the processes.\\n\\n\\n## V\\n\\n### Validator\\na node that secures the Relay Chain by staking its tokens, validating proofs from collators on parachains and voting on consensus along with other validators.\\n\\n\\n## W\\n\\n### Web3\\nan idea for a new iteration of the Web which incorporates concepts such as decentralization, blockchain technologies, and token-based economics.\\n\\n### Wiener (XRT)\\nor Wn — a billionth share of one XRT token, 1 XRT = 1 000 000 000 Wn; named after Norbert Wiener, an American mathematician, one of the founders of cybernetics and the theory of artificial intelligence.\\n\\n\\n## X\\n\\n### XCM\\nor Cross-Consensus Message Format — a format of messaging between different blockchain systems in Polkadot / Kusama.\\n\\n\\n### XRT\\na native token for Robonomics Network, that exists independently on the Ethereum and Kusama networks.\\n\\n\\n## Y\\n\\n### Yggdrasil\\nan overlay network implementation of a fully end-to-end encrypted routing scheme for mesh networks.\\n\\n\\n## Z\\n\\n### Zigbee\\na wireless communication protocol, very commonly used for connecting smart devices because of low power consumption, easability and flexibility of configuration, and support of self-organizing and self-recovering network topology.\\n\\n### Zigbee Adapter\\na device that transfers data between the Zigbee network and another network (i.e. Wi-Fi) for controlling Zigbee devices.\\n\\n### Zigbee2MQTT\\na software that allows connecting Zigbee to MQTT networks by translating messages from the one network to another. \"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"20fd80c63512e4dec1cc55d947b53805\",\n        \"title\": \"Global Administration\",\n        \"path\": \"/docs/global-administration/\",\n        \"content\": \"\\n**This article will show you how to set up a new user to your Home Assistant.**\\n\\n## Adding Users to Subscription\\n\\nYou cannot use previously created accounts because `SUB_OWNER` and `SUB_CONTROLLER` provide security, and the first user you created when you first started Home Assistant does not have a Robonomics Parachain account.\\n\\n1. Create an account on Robonomics parachain, as you did in the [previous article](/docs/sub-activate/).\\n\\n2. Using `SUB_OWNER` account add new user account to the subscription in the [dapp](https://dapp.robonomics.network/#/subscription/devices). Now there should be three addresses in the access list: `SUB_OWNER`, `SUB_CONTROLLER` and `USER`.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmSxzram7CF4SXpVgEyv98XetjYsxNFQY2GY4PfyhJak7H', type:'mp4'}]\\\" />\\n\\n\\n## Granting Access to User\\n\\n1. Go to the dapp service called [Home Assistant Account](https://dapp.robonomics.network/#/home-assistant). Choose the account you've just created at the right sidebar (check that you have chosen the intended account by pressing the profile icon).\\n\\n2. Enter the `USER` seed in the required field. Add `SUB_OWNER` and `SUB_CONTROLLER` addresses in the administrator credits fields. If everything is correct, you will see verification status `VERIFIED`.\\n\\n3. Create a password for a new user which you have just registered and then confirm the transaction, that will now be without fee due to the subscription. Later you can restore the password in the Restore tab.\\n\\n4. After the registration process, log in to Home Assistant with your user address as login and a newly-created password.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.live/ipfs/QmW2TXuwCYXzgcRfEUx4imZU5ZerEzkuD5P53u9g2WnxDh', type:'mp4'}]\\\" />\\n\\nNow you can use the dapp to control your home through Robonomics, check [**\\\"Get Smart Home Telemetry\\\"**](/docs/smart-home-telemetry/) article.\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"39fcfe0df696631025ff0176e29d8413\",\n        \"title\": \"Getting Started\",\n        \"path\": \"/docs/\",\n        \"content\": \"\\n## What is Robonomics\\n\\nRobonomics platform provides tools for working with the robot economy network. Robonomics allow designers of smart cities and industry 4.0 zones to build trust among the [autonomous robots services](/docs/glossary#cyber-physical-system), provide [direct user access via dapp](/docs/glossary#dapp) for ordering products from autonomous factories and services of urban sensor networks. This in turn will allow us to put in place a decentralized system that globally monitors the activities of cyber physical systems.\\n\\nThe following chart describes what place Robonomics takes in the scenario:\\n\\n<robo-wiki-picture src=\\\"robonomics_network_basic_scheme.jpg\\\" alt=\\\"Robonomics Network scenario\\\" />\\n\\n<!-- ![Robonomics Chart](./images/robonomics_network_basic_scheme.jpg \\\"Robonomics Network scenario\\\") -->\\n\\nFind more in [Building dApps on Robonomics deck](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf)\\n\\n## Robonomics Network quick start\\n**For newcomer's convenience core Robonomics developers came up with a [6 lessons learning curve](/docs/wschool2021-intro/)!**\\n\\nYou'll explore the serverless IoT architecture! Robonomics Web Services (RWS) is the basic infrastructural service for Robotics and IoT on top of Polkadot && IPFS.\\n\\nCourse graduates can launch a local relay chain and control a ROS-compatible device through cross-chain transaction.\\n\\n**[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.**\\n\\n### Benefits for Robonomics Academy graduates\\n- Intership for best students   Become a Robonomics team member and contribute to the development of the chosen product.\\n- Active community && regular events   Become a part of the learner's community, discuss your use-cases with industry experts. Team-up and participate in hackathons!\\n- Certificate of completion   Add a certificate for completing the course on building DAPPs for IoT to your portfolio.\\n- Assistance in admission to the ITMO university. Whether you are a bachelor or master, you'll get assistance in your admission to the university.\\n- Funding && acceleration opportunities: 1)Apply for up to $50.000 Academia - support grant; 2)Participate in Robonomics builders acceleration program supported by Web3 Foundation; 3)Deploy your stand-alone DAPP on top of Robonomics; 4)Monetize it && get marketing support from Robonomics team.\\n\\n\\n## What the documentation contains\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"5b98aab4f8a8c988596942ab2372f6b3\",\n        \"title\": \"How to Buy a Subscription\",\n        \"path\": \"/docs/get-subscription/\",\n        \"content\": \"\\n**Paying commissions for transactions in blockchain is annoying. Imagine an IoT device which sends telemetry every 5-10 \\nminutes. This will make you pay quite a lot through month. One of the key features of Robonomics Network is RWS - Robonomics\\nWeb Service subscription. Pay monthly and forget about transaction cost! For theoretical background refer to \\n[this](https://blog.aira.life/rws-overview-part-2-heterogeneous-tokenomics-afc209cc855) article.**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Parachain\\\">\\n\\n  Pay attention that this tutorial demonstrates buying a subscription on Robonomics Kusama parachain. You can also perform\\n  all the same steps on your [local node](/docs/run-dev-node).\\n\\n  One more thing before start. This is a \\\"hard\\\" way of buying a subscription. There is a conventional way to do this through\\n  [Robonomics DApp](https://dapp.robonomics.network/#/).\\n\\n</robo-wiki-note>\\n\\n## Bid an Auction\\n\\nThe subscriptions in Robonomics are sold with an auction model. To get one, you need to bid an auction and win it (no worries, it's fast).\\n\\nIn `Developer/Chain state` you can see available auctions. \\nChoose `rws` and `auctionQueue` and press `+` button, you will see IDs of available auctions:\\n\\n![queue](./images/rws/queue.png)\\n\\nYou can see an information about any subscription with `rws` `auction` and ID of auction (the auction's ID in the picture is 79):\\n\\n![auction](./images/rws/auction.png)\\n\\nIn the information about the auction you can see `winner` field, at the moment it is `null` so nobody has this subscription\\nand you can get it. For that go to `Developer/Extrinsic`, choose your account and `rws -> bid`. Also set auction ID (79) and \\nthe amount of units to bid (more than 1000000000 Wn):\\n\\n![bid](./images/rws/bid.png)\\n\\nSubmit the transaction and check the information about the auction with ID 79 (in `Chain state` choose `rws -> auction` and ID 79):\\n\\n![win](./images/rws/auc_win.png)\\n\\nNow in `winner` field you will see your account address, it means that this account has the subscription 79. An auction\\nstarts with the first bid and lasts a few blocks, so if somebody bids more tokens than you in the next few blocks this one \\nwill be the winner and will take the subscription.\\n\\nNow you can add devices. Devices are accounts that are able to use this subscription and submit extrinsics with no fee.\\nTo test it create a new account with no tokens and add it to devices. \\n\\nTo add devices choose `rws -> setDevices` in `Developer/Extrinsic`. Then press `Add Item` button and choose recently\\ncreated account with no tokens:\\n\\n![set_devices](./images/rws/set_devices.png)\\n\\nSubmit the transaction. Now you can check the list of devices in `Chain state` with `rws -> devices`. There you will\\nsee the address of your account without tokens. Choose the account that has bought the subscription and press `+`:\\n\\n![devices](./images/rws/devices.png)\\n\\nNow you can try to [send launch](/docs/subscription-launch) extrinsic using the subscription.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"b5688171357b9dbae6d3e956d31f2752\",\n        \"title\": \"Gaka-Chu setup and software Installation\",\n        \"path\": \"/docs/gaka-chu/\",\n        \"content\": \"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](./images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](./images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"c269f813cf2d134fcc3ab427be966032\",\n        \"title\": \"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\n        \"path\": \"/docs/freertos-mqtt/\",\n        \"content\": \"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](./images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](./images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](./images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](./images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](./images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"a73c1d9b67f1a4c53f7c4a53cec2c8f8\",\n        \"title\": \"Supported Hardware\",\n        \"path\": \"/docs/feecc-system-supporthardware/\",\n        \"content\": \"\\n## List of supported hardware by systems\\n\\n### Feecc Engineer Workbench\\n\\nThe choice of equipment for the \\\"Feecc Engineer Workbench\\\" is determined by the financial capabilities of the company\\noperating the system and the specifics of the chosen architecture.\\n\\nFigures 1 and 2 show the Feecc Engineer Workplace architecture with decentralized and centralized system organization\\ntopology in a corporate environment.\\n![architec1](/docs/images/feecc-system-architecture/picture1.png)\\n\\n<p align=\\\"center\\\">\\nPicture 1 - Feecc Engineer Workbench architecture with decentralized system organization topology in a corporate environment.\\n</p>\\n\\n![architec2](/docs/images/feecc-system-architecture/picture2.png)\\n\\n<p align=\\\"center\\\">\\nPicture 2 - Feecc Engineer Workbench architecture with centralized system organization topology in a corporate environment.\\n</p>\\n\\n> **It is worth noting that these are not all the architectures described, and there are more economical options: one\\nprinter per group of desks, a monitor without touch screen input or no monitor at all. But RFID and barcode scanners, a\\nsingle board or desktop computer, and a camera on each desk are mandatory.**\\n\\n#### **RFID scanner**\\n\\n> A USB RFID scanner is needed to authorize engineers in the field with their internal badges. Incoming information is\\n> processed using the [feecc-hid-reader-daemon](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon).\\n\\nRequired technical specifications:\\n\\n- Operating frequency - 125kHz.\\n\\n*You can buy\\nit [here](https://aliexpress.ru/item/1005003579675742.html?spm=a2g2w.productlist.0.0.190ad16cWCptVr&sku_id=12000026804509353)\\n.*\\n\\n#### **Barcode scanner**\\n\\n> The USB barcode scanner is necessary for identifying products by barcodes, sending commands to services and for the\\n> correct assignment of certificates. It is also used to read QR codes to identify certificates. The incoming information\\n> is also processed with the [feecc-hid-reader-daemon](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon).\\n\\nRequired technical specifications:\\n\\n- Reading in two dimensions (desirable, but not required).\\n\\n*You can buy\\nit [here](https://aliexpress.ru/item/32902727438.html?spm=a2g2w.productlist.0.0.263d68c5fTwi8J&sku_id=10000009784771593)\\n.*\\n\\n#### **Work computer**\\n\\n> A small single-board computer. It processes signals from external devices (barcode scanner, RFID scanner), sends\\n> requests for printing images on the printer, starting and stopping video recording, sending data to IPFS and the\\n> Robonomics platform. It runs the following\\n> services: [feecc-workbench-frontend](https://github.com/Multi-Agent-io/feecc-workbench-frontend)\\n> , [feecc-workbench-daemon](https://github.com/Multi-Agent-io/feecc-workbench-daemon)\\n> , [feecc-hid-reader-daemon](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon). An Internet connection via Wi-Fi\\n> or LAN is required.\\n\\nIt is worth specifying that any computer can be used instead of a single-payer computer with a monitor. The operating\\nsystem [GNU/LINUX](https://www.gnu.org/) must be installed on it natively or through a virtual machine.\\n\\nMinimum technical specifications:\\n\\n- Raspberry Pi4 4 GB RAM, it is possible to use an analogue.\\n\\n*You can buy it [here](https://www.cytron.io/p-raspberry-pi-4-model-b-4gb).*\\n\\n#### **Touch screen**\\n\\n> The monitor is used by the employee to enter and view information about the current production step. It also displays\\n> hints for the engineer on the current stage.\\n\\nRequired technical specifications:\\n\\n- Touch screen (desirable but not necessary. Other input devices can be used).\\n\\n*You can buy it [here](https://www.asus.com/Displays-Desktops/Monitors/Touch/VT168H/).*\\n\\n#### **Label printer**\\n\\n> The label printer is used to print QR codes and bar codes for further placement of labels on the product for\\n> identification and verification purposes. Interaction with the printer is carried out with the help of\\n> the [feecc-print-server](https://github.com/Multi-Agent-io/feecc-print-server).\\n\\nRequired technical specifications:\\n\\n- This option uses Brother model QL-800 printers.\\n\\n*You can buy it [here](https://www.brother-usa.com/products/ql800).*\\n\\n#### **IP Camera**\\n\\n> IP camera for capturing production processes for inclusion in the product certificate. Located above the assembly area\\n> of the product. Interaction with the camera is performed using\\n> the [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman) service.\\n\\nRequired technical specifications:\\n\\n- PoE power supply.\\n- RTSP data transfer protocol.\\n- This option uses Hikvision HiWatch DS-i200d\\n\\n*You can buy\\nit [here](https://www.hi-watch.eu/en-us/product/1986/ip-camera/bullet-camera/2-0-mp-ir-network-bullet-camera).*\\n\\n> **The latest version [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman) supports WEB cameras, so pay\\nattention to this detail when choosing equipment.**\\n\\n<robo-wiki-note type=\\\"warning\\\">\\nThe equipment shown below is used for several tables at once.\\n</robo-wiki-note>\\n\\n#### **Router or switch that supports PoE 802.3af**\\n\\n> Router or switch with PoE 802.3af support for powering IP cameras and connecting them to\\n> the [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman) service.\\n\\nRequired technical specifications:\\n\\n- PoE power on the output ports.\\n- This variant used MikroTik hEX PoE - one for 3-4 workplaces + power supply.\\n\\n*You can buy it with the following links: [router](https://mikrotik.com/product/RB960PGS)\\nand [power adapter](https://mikrotik.com/product/48POW).*\\n\\n#### **Optional, Fixed Server**\\n\\n> A more powerful server than the single board computers. It can\\n> run [feecc-ipfs-gateway](https://github.com/Multi-Agent-io/feecc-ipfs-gateway)\\n> , [feecc-print-server](https://github.com/Multi-Agent-io/feecc-print-server)\\n> , [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman). Can be located in place of one of the computers\\n> of the engineers' workplaces. The connection to the Internet is LAN.\\n\\nRequired technical specifications:\\n\\n- Intel® Xeon® E-2200 processor or equivalent\\n- RAM from 8 Gb\\n- Hard drive from 1 Tb\\n- LAN network interface from 1 Gbit/s\\n\\n*You can buy it [here](https://www.dell.com/en-us/shop/cty/pdp/spd/poweredge-r240/pe_r240_tm_vi_vp_sb).*\\n\\n### Feecc Analytics\\n\\nThe only hardware required for the module to work is a local or remote server (virtual machine) on which the \\\"Feecc\\nAnalytics\\\" web application will run. Each authorized employee can access the web application from his/her computer with\\na username and password.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"224645458e32c5b5f7ab257f1de74a85\",\n        \"title\": \"Быстрый старт\",\n        \"path\": \"/docs/feecc-system-quickstart/\",\n        \"content\": \"\\n## Описание\\n\\nВ данном разделе описываются методы тестового развертывания \\\"Feecc Рабочее Место Инженера\\\" для тестирования и оценки\\nсистемы в производственной среде. В качестве инструмента развертывания системы \\\"Feecc Рабочее Место Инженера\\\"\\nиспользуется инструмент Docker Compose.\\n\\n### Предварительные настройки\\n\\n#### Установка Docker Engine\\n\\n1. Обновите систему и установите служебные пакеты для установки Docker:\\n\\n   Для Debian-based систем:\\n\\n    ```bash\\n    sudo apt update -y\\n    sudo apt upgrade -y\\n    sudo apt dist-upgrade -y\\n    sudo apt autoremove -y\\n    sudo apt-get install \\\\\\n        ca-certificates \\\\\\n        curl \\\\\\n        gnupg \\\\\\n        lsb-release \\\\\\n        git  \\n    ```\\n\\n2. Удалите старую версию Docker если она была\\n\\n   Для Debian-based систем:\\n\\n    ```bash\\n    sudo apt-get remove docker docker-engine docker.io containerd runc\\n    ```\\n\\n3. Добавьте официальный GPG ключ Docker и настройте список репозиториев\\n\\n   Для Debian-based систем:\\n\\n    ```bash\\n    sudo mkdir -p /etc/apt/keyrings\\n    curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\\n\\n    echo \\\\\\n    \\\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\\\\n    $(lsb_release -cs) stable\\\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\\n    ```\\n\\n4. Установите Docker Engine\\n\\n   Для Debian-based систем:\\n\\n   ```bash\\n    sudo apt-get update\\n    sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\\n   ```\\n\\nВ данный комплект поставки Docker Engine уже входит Docker Compose, по этому дополнительных манипуляций с Docker\\nпроводить не нужно.\\n\\n#### Подготовка базы данных MongoDB\\n\\nДля оперативного хранения и доступа к данным в \\\"Feecc Рабочее Место Инженера\\\" используется база данных MongoDB. В ходе\\nподготовки к развертыванию \\\"Feecc Рабочее Место Инженера\\\" вы можете выбрать любой подходящий вам метод развертывания\\nMongoDB, как на своей инфраструктуре так и на облачной, мы приложили несколько ссылок чтобы вам было удобнее\\nориентироваться:\\n\\n- [Установка MongoDB на свой сервер](https://www.mongodb.com/try/download/community)\\n- [Бесплатный MongoDB кластер в Atlas](https://www.mongodb.com/atlas)\\n- [Аренда MongoDB кластера в Digital Ocean](https://www.digitalocean.com/products/managed-databases-mongodb)\\n\\nМы в свою очередь на первом этапе рекомендуем\\nвоспользоваться [бесплатным MongoDB кластером в Atlas](https://www.mongodb.com/atlas), данная платформа является крайне\\nудобной и гибкой в рабочих задачах. Ниже будет инструкция как воспользоваться MongoDB Atlas в связке с \\\"Feecc Рабочее\\nМесто Инженера\\\"\\n\\n1. Вам необходимо зарегистрироваться в [MongoDB Atlas](https://www.mongodb.com/atlas), указать свою почту, логин и\\n   пароль.\\n2. Вам необходимо создать свой первый бесплатный MongoDB кластер нажав на кнопку \\\"Create\\\" в разделе \\\"Database\\\" как на\\n   картинке ниже ![mongodb-step1](/docs/images/feecc-system-quickstart/mongodb-step1.png)\\n3. В разделе \\\"Создание своего MongoDB кластера\\\" вы можете выбрать бесплатный режим \\\"Shared\\\", а также провайдера услуги и\\n   месторасположение MongoDB кластера как на рисунке\\n   ниже ![mongodb-step2](/docs/images/feecc-system-quickstart/mongodb-step2.png)\\n4. После того как ваш первый MongoDB кластер был создан вы должны нажать на кнопку \\\"Connect\\\" для уточнения информации по\\n   методу подключения к MongoDB кластеру как на рисунке\\n   ниже ![mongodb-step3](/docs/images/feecc-system-quickstart/mongodb-step3.png)\\n5. В разделе методы подключения выберете \\\"Connect your application\\\" как на рисунке\\n   ниже ![mongodb-step4](/docs/images/feecc-system-quickstart/mongodb-step4.png)\\n6. В разделе \\\"Select your driver and version\\\" вам нужно выбрать Python и любую последнюю версию от 3.10 как на рисунке\\n   ниже ![mongodb-step5](/docs/images/feecc-system-quickstart/mongodb-step5.png)\\n\\nВ результате всех манипуляций у вас будет строка в которой будет храниться информация о методе подключения к вашему\\nMongoDB кластеру, где вместо черного прямоугольника будет ваш логин, а вместо поля `<password>` вам необходимо будет\\nвписать ваш пароль, в формате `mongodb+srv://yourlogin:yourpassword@......` эта строка будет использоваться в качестве\\nзначения переменной `MONGODB_URI` в .env файле при развертывании системы.\\n\\n#### Создание аккаунта в Pinata.cloud\\n\\nДля обеспечения быстрой доступности файлов из IPFS в обычной сети связи используется сервис Pinata.cloud. Чтобы завести\\nаккаунт, вам необходимо пройти по [ссылке](https://app.pinata.cloud/register) и завести собственный аккаунт, это\\nбесплатно. Вам необходимо сохранить логин и пароль, а также дополнительные данные API так как в дальнейшем они будут\\nиспользоваться в \\\"Feecc Рабочее Место Инженера\\\" в переменных `PINATA_API`, `PINATA_SECRET_API` .\\n\\n#### Создание аккаунта в YOURLS\\n\\nДля обеспечения работы сокращателя ссылок вы можете развернуть как свой сервис [YOURLS](https://yourls.org/), так и\\nвременно воспользоваться нашим сервисом YOURLS по ссылке [utl.today](https://yourls.org/)\\nВам необходимо сохранить логин и пароль, а также ссылку на ваш YOURLS сервис, так как в дальнейшем эти данные будут\\nиспользоваться в \\\"Feecc Рабочее Место Инженера\\\" в переменных `YOURLS_SERVER`, `YOURLS_USERNAME`, `YOURLS_PASSWORD`\\n\\n**ВАЖНО, использование тестового аккаунта [utl.today](https://yourls.org/) в реальном производстве строго запрещено, его\\nможно использовать только для тестов**\\n**Тестовый аккаунт YOURLS**\\n`YOURLS_SERVER`:`url.today`\\n`YOURLS_USERNAME`:`demouser`\\n`YOURLS_PASSWORD`:`Jhvw*s4ndnEc6ttm`\\n\\n#### Создание аккаунта Robonomics parachain в экосистеме Polkadot\\n\\nДля создания аккаунта Robonomics parachain в экосистеме Polkadot воспользуйтесь инструкцией\\nпо [ссылке](https://wiki.robonomics.network/docs/en/create-account-in-dapp/#1-using-polkadotjs-browser-extension). Вам\\nнеобходимо сохранить ключевые фразы аккаунта так как в дальнейшем они будут использованы в\\nпеременной `ROBONOMICS_ACCOUNT_SEED`.\\n\\n### Развертывание Feecc Рабочее Место Инженера\\n\\nДля быстрого запуска Feecc Рабочее Место Инженера вы можете воспользоваться\\nрепозиторием [feecc-demo](https://github.com/Multi-Agent-io/feecc-demo) в котором мы собрали несколько docker-compose и\\nслужебных файлов для развертывания Feecc Рабочее Место Инженера с использованием рекомендованного оборудования, а \\nтакже в режиме эмуляции рекомендованного оборудования.\\n\\n#### Развертывание Feecc Рабочее Место Инженера с использованием рекомендованного оборудования\\n\\nДля развертывания Feecc Рабочее Место Инженера с использованием рекомендованного оборудования вам необходимо выполнить\\nследующие условия:\\n\\n1. Подключите все устройства к компьютеру/серверу на котором будет запущен Feecc Рабочее Место Инженера\\n\\n    - Принтер этикеток к компьютеру/серверу используя USB\\n    - Сканер штрихкодов и RFID сканер используя USB\\n    - IP камера через PoE маршрутизатор/коммутатор\\n    - **Опционально** Сенсорный экран используя USB и HDMI/VGA\\n\\n2. Склонируйте репозиторий [feecc-demo](https://github.com/Multi-Agent-io/feecc-demo)\\n\\n   ```bash\\n   git clone https://github.com/Multi-Agent-io/feecc-demo.git\\n   ```\\n\\n3. Установите mongosh для управления вашей базой данных MongoDB.\\n\\n   ```bash\\n   sudo apt-get install gnupg\\n   wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\\n   echo \\\"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse\\\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\\n   sudo apt-get update\\n   sudo apt-get install -y mongodb-mongosh\\n   ```\\n\\n4. Перейдите в папку проекта и в папке проекта перейдите в раздел \\\"feecc-quickstart-supporthardware\\\"\\n\\n   ```bash\\n   cd ./feecc-demo/feecc-quickstart-supporthardware\\n   ```\\n\\n   Импортируйте размеченную базу данных с коллекциями для MongoDB\\n\\n   ```bash\\n   mongoimport --uri=\\\"mongodb+srv://....yourcluster....\\\" --file=./\\n   ```\\n   Добавьте в размеченную базу данных ID вашей RFID карты, ФИО и права доступа пользователя\\n\\n   ```bash\\n   mongosh \\\"mongodb+srv://....yourcluster.... --apiVersion 1 --username yourusername\\\"\\n   ```\\n\\n5. В разделе \\\"feecc-quickstart-supporthardware\\\" откройте файл .env любым файловым редактором и внесите информацию о\\n   переменных. Пример заполнения переменных указан в .env файле.\\n\\n6. Авторизуйтесь в Digital Ocean Container Registry который предоставляет\\n   компания [Multi-Agent Systems](http://multi-agent.io) для скачивания готовых контейнеров необходимых для\\n   развертывание Feecc Рабочее Место Инженера и запустите docker-compose\\n\\n   ```bash\\n   docker login -u dop_v1_6debfd8d476d14847bf81aecc74dfcda1fb63a503ba2d61d66eaa113cc272596 -p dop_v1_6debfd8d476d14847bf81aecc74dfcda1fb63a503ba2d61d66eaa113cc272596 registry.digitalocean.com\\n   sudo docker-compose up -d --build --env-file=./.env\\n   ```\\n\\n7. Дождитесь окончания развертывания и проверьте работу системы \\\"Feecc Рабочее Место Инженера\\\" перейдя по ссылке в\\n   браузере [http://localhost:3000/](http://localhost:3000/) и попытайтесь авторизоваться используя личную RFID карту\\n   которую вы указали ранее.\\n\\n#### Развертывание Feecc Рабочее Место Инженера в режиме эмуляции рекомендованного оборудования\\n\\nДля развертывания Feecc Рабочее Место Инженера в режиме эмуляции рекомендованного оборудования необходимо выполнить\\nследующие условия:\\n\\n1. Склонируйте репозиторий [feecc-demo](https://github.com/Multi-Agent-io/feecc-demo)\\n\\n   ```bash\\n   git clone https://github.com/Multi-Agent-io/feecc-demo.git\\n   ```\\n\\n2. Перейдите в папку проекта и в папке проекта перейдите в раздел \\\"feecc-quickstart-supporthardware\\\"\\n\\n   ```bash\\n   cd ./feecc-demo/feecc-quickstart-supporthardware\\n   ```\\n\\n3. Авторизуйтесь в Digital Ocean Container Registry который предоставляет\\n   компания [Multi-Agent Systems](http://multi-agent.io) для скачивания готовых контейнеров необходимых для\\n   развертывание Feecc Рабочее Место Инженера и запустите docker-compose\\n\\n   ```bash\\n   docker login -u dop_v1_6debfd8d476d14847bf81aecc74dfcda1fb63a503ba2d61d66eaa113cc272596 -p dop_v1_6debfd8d476d14847bf81aecc74dfcda1fb63a503ba2d61d66eaa113cc272596 registry.digitalocean.com\\n   sudo docker-compose up -d --build --env-file=./.env\\n   ```\\n\\n4. Дождитесь окончания развертывания и проверьте работу системы \\\"Feecc Рабочее Место Инженера\\\" перейдя по ссылке в\\n   браузере [http://localhost:3000/](http://localhost:3000/) и проверьте работу системы в соответствии с\\n   инструкцией [feecc-demo](https://github.com/Multi-Agent-io/feecc-demo)\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"4359cdcc9093670eb8f850a72bcb1829\",\n        \"title\": \"Overview\",\n        \"path\": \"/docs/feecc-system-overview/\",\n        \"content\": \"\\nFeecc is a platform developed by [Multi-Agent Systems](http://multi-agent.io) that allows companies to create and\\ncustomize their own quality control systems for products or services according to business objectives\\n\\n## Main Idea\\n\\nUsing web3 technology and a set of flexible software modules, the Feecc platform allows you to organize the production\\nprocess of any type of product, audit employee access to the workplace and retrieve all workflow data. Information is\\nstored in an unchanged and secure distributed IPFS storage, data hashes are saved in the Robonomics network datalog with\\naccess for the quality control department via Feecc Analytics. With Feecc, a company can not only digitize its processes\\nand get rid of paperwork and lawsuits, but also attract the attention of new customers to the product, increasing trust\\nin it.\\n\\nThe platform is a set of software for controlling the production process and collecting information for subsequent\\nanalysis by the QCD or other participants. Globally, the scheme of platform integration into the business process can be\\nrepresented as follows:\\n![business_schema](/docs/images/feecc-system-overview/business_schema_eng.jpg)\\n\\n## Platform Opportunities\\n\\n### Reliable and secure data storage\\n\\nFeecc uses a secure data storage based on a content-addressable architecture and a distributed registry to ensure the\\nreliability and validity of collected workflow data.\\n\\n### A clear link between the employee and the product\\n\\nFeecc monitors all phases of the workflow with video recording, data logging from peripheral devices and employee access\\nauthorization. The platform supports any sequential workflow, including long-term or interrupted operations.\\n\\n### Digital product certificate\\n\\nAll digital traces of the workflow are summarized in a single product certificate with a unique identifier which is then\\nattached as a QR code to the product. Feecc can add custom process parameters to the certificate and automate its\\ncreation even for composite parts.\\n\\n### Extensive support for peripheral devices\\n\\nFeecc supports standard digital I/O interfaces for connecting various devices (video cameras, scanners, printers, etc.).\\n\\n## Video Demonstration of the Feecc Engineer Workplace\\n\\nhttps://www.youtube.com/watch?v=WhtOJtGjAok\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"cd2d649b383f15526c308c388430795f\",\n        \"title\": \"Feecc Аналитика для разработчиков\",\n        \"path\": \"/docs/feecc-system-dev-feecc-analytics/\",\n        \"content\": \"\\nВ этом руководстве поговорим о разработке сервисов на базе бекенда Feecc Analytics\\n\\n> Предполагается, что вы уже разобрались с запуском бекенда системы Feecc Аналитика. Если еще нет, обратитесь\\n> к [этому руководству](/docs/en/feecc-system-deploy-feecc-analytics.md)\\n\\n## Основная информация\\n\\nПроект написан на языке Python (фреймворк FastAPI). В качестве дополнительной базы данных используется MongoDB, для\\nнеизменяемости и валидации данных IPFS и Robonomics Datalog\\n\\nХотите внести свой вклад? PR соответствующие\\nвсем [guidelines](https://github.com/Multi-Agent-io/contribution-guidelines) приветствуются.\\n\\n## Основные эндпоинты (по группам)\\n\\nТут описаны исключительно эндпоинты (и группы эндпоинтов), содержащие необычное поведение. Для ознакомления с\\nостальными, обратитесь к Swagger по адресу бекенда добавив к нему `/docs`.\\n\\n### Работа с сертификатами: /api/v1/passports\\n\\n#### GET /\\n\\nЭндпоинт для получения списка сертификатов выпущенных изделий\\n\\nАргументы:\\n\\n- `page` - номер страницы\\n- `items` - количество элементов на странице\\n- `sort_by_date` - сортировка по дате выпуска (`asc`/`desc`)\\n- `status` - статус сертификата (`production`, `built`, `revision`, `approved`, `finalized`)\\n- `name` - строка для фильтрации по названию изделия, short_url, uuid\\n- `date` - строка для фильтрации по дате выпуска (в формате datetime)\\n- `types` - строка для фильтрации по типу изделия. Возможна фильтрация по множественным типам, но в\\n  формате: `\\\"[type1,type2,type3...typeN]\\\"`\\n\\nПолучаемые данные:\\n\\n- `status_code` - статус запроса\\n- `detail` - детали ответа\\n- `count` - общее количество сертификатов, соответствующих параметрам фильтрации\\n- `data` - список сертификатов в формате:\\n\\n  ```json\\n  {\\n    schema_id: str,\\n    uuid: str,\\n    internal_id: str,\\n    passport_short_url: str/null,\\n    passport_ipfs_cid: str/null,\\n    is_in_db: bool/null,\\n    featured_in_int_id: str/null,\\n    biography: Array/null,\\n    components_internal_ids: Array<str>/null,\\n    model: str/null,\\n    date: datetime,\\n    type: str/null,\\n    parential_unit: str/null,\\n    serial_number: str/null,\\n    status: str/null,\\n    txn_hash: str/null\\n  }\\n  ```\\n\\n#### GET /types\\n\\nПолучение списка всех типов изделий\\n\\nПолучаемые данные:\\n\\n- `status_code` - статус запроса\\n- `detail` - детали ответа\\n- `types` - список всех типов изделий\\n\\n#### POST /\\n\\nЭндпоинт для создания нового сертификата\\n\\nАргументы:\\n\\n- `passport` - сертификат в формате\\n\\n  ```json\\n  {\\n    schema_id: str,\\n    uuid: str,\\n    internal_id: str,\\n    passport_short_url: str/null,\\n    passport_ipfs_cid: str/null,\\n    is_in_db: bool/null,\\n    featured_in_int_id: str/null,\\n    biography: Array/null,\\n    components_internal_ids: Array<str>/null,\\n    model: str/null,\\n    date: datetime,\\n    type: str/null,\\n    parential_unit: str/null,\\n    serial_number: str/null,\\n    status: str/null,\\n    txn_hash: str/null\\n  }\\n  ```\\n\\n#### DELETE /{internal_id}\\n\\nУдаление сертификата из системы по внутреннему номеру\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата в формате EAN13\\n\\n#### GET /{internal_id}\\n\\nПолучение данных сертификата из системы по внутреннему номеру\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата в формате EAN13\\n\\nПолучаемые данные:\\n\\n- `status_code` - статус запроса\\n- `detail` - детали ответа\\n- `passport` - данные сертификата в формате:\\n\\n  ```json\\n  {\\n    schema_id: str,\\n    uuid: str,\\n    internal_id: str,\\n    passport_short_url: str/null,\\n    passport_ipfs_cid: str/null,\\n    is_in_db: bool/null,\\n    featured_in_int_id: str/null,\\n    biography: Array/null,\\n    components_internal_ids: Array<str>/null,\\n    model: str/null,\\n    date: datetime,\\n    type: str/null,\\n    parential_unit: str/null,\\n    serial_number: str/null,\\n    status: str/null,\\n    txn_hash: str/null\\n  }\\n  ```\\n\\n#### POST /{internal_id}/serial\\n\\nОбновление серийного номера и статуса сертификата по внутреннему номеру\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата в формате EAN13\\n- `serial_number` - серийный номер\\n\\n#### POST /{internal_id}/revision\\n\\nEndpoint для отправки текущего сертификата на доработку по выбранным производственным этапам.\\nБудут созданы пустые копии этих этапов. Статус сертификата изменится на \\\"revision\\\".\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата в формате EAN13\\n- `stages_ids` - array id каждого этапа, который нуждается в доработке\\n\\n#### POST /{internal_id}/revision/cancel\\n\\nEndpoint для отмены доработки для выбранных этапов.\\nЕсли это единственный этап, отправленный на доработку, текущий сертификат изменит свой статус на \\\"built\\\", в противном\\nслучае статус не поменяется\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата в формате EAN13\\n- `stage_id` - id этапа, доработку которого нужно отменить\\n\\n### Работа с ОТК: /api/v1/tcd\\n\\n#### GET /protocols\\n\\nЭндпоинт для получения списка протоколов ОТК\\n\\nАргументы:\\n\\n- `page` - номер страницы\\n- `items` - количество элементов на странице\\n- `sort_by_date` - сортировка по дате выпуска (`asc`/`desc`)\\n- `status` - статус протокола (\\\"Первая стадия испытаний пройдена\\\", \\\"Вторая стадия испытаний пройдена\\\", \\\"Протокол\\n  утверждён\\\")\\n- `name` - строка для фильтрации по названию протокола или серийному номеру (той части, которая находится в системе)\\n- `date` - строка для фильтрации по дате создания (в формате datetime)\\n\\n#### GET /protocols/types\\n\\nЭндпоинт для получения списка возможных статусов протоколов\\n\\nПолучаемые данные:\\n\\n- `status_code` - статус запроса\\n- `detail` - детали ответа\\n- `data` - список всех статусов\\n\\n#### GET /protocols/pending\\n\\nЭндпоинт для получения номеров протоколов, которые нуждаются в утверждении (протоколы, выпущенные более 2-х дней назад и\\nне имеющие статуса \\\"протокол утвержден\\\")\\n\\nПолучаемые данные:\\n\\n- `status_code` - статус запроса\\n- `detail` - детали ответа\\n- `count` - количество протоколов, нуждающихся в утверждении\\n- `pending` - список id всех протоколов, нуждающихся в утверждении\\n\\n#### POST /protocols/{internal_id}/approve\\n\\nЭндпоинт для утверждения протокола (если устройство точно прошло ВСЕ проверки), отправки сертификата в ipfs и robonomics\\ndatalog (если включена опция `USE_DATALOG` и указан путь до `Feecc IPFS Gateway`)\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата (не протокола)\\n\\n#### DELETE /protocols/{internal_id}\\n\\nЭндпоинт для удаления протокола. Если вы хотите изменить уже утвержденный протокол, необходимо удалить старый\\n\\nАргументы:\\n\\n- `internal_id` - внутренний номер сертификата\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"f0098e2309306f502abdd4b0ac8f4478\",\n        \"title\": \"Развертывание \\\"Feecc Рабочее Место Инженера\\\" (РМИ или Workbench)\",\n        \"path\": \"/docs/feecc-system-deploy-feecc-wb/\",\n        \"content\": \"\\n## Общая информация:\\n\\nРабота системы \\\"Feecc Рабочее Место Инженера\\\" (далее Feecc РМИ) зависит от работы сервисов feecc-workbench-frontend (\\nФронтенд), feecc-workbench-daemon (Daemon), feecc-ipfs-gateway (IPFS Gateway), feecc-print-server (Print Server),\\nfeecc-cameraman (Cameraman), feecc-hid-reader-daemon (HID Daemon).\\n\\nЧтобы узнать больше о сервисах, обратитесь в раздел [Обзор архитектуры](/docs/feecc-system-architecture).\\n\\n## Запуск HID Daemon\\n\\n> Инструкция может устареть, обратитесь к инструкции\\n> в [репозитории](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon#readme)\\n\\n1. Склонируйте репозиторий\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-hid-reader-daemon`\\n\\n2. Обновите систему и установите необходимые пакеты:\\n\\n   Для Debian-based систем:\\n\\n    ```bash\\n    sudo apt update -y\\n    sudo apt upgrade -y\\n    sudo apt dist-upgrade -y\\n    sudo apt autoremove -y\\n    sudo apt install -y htop python3 python3-dev python3-pip gcc\\n    ```\\n\\n3. Запустите Daemon\\n\\n    ```bash\\n    sudo mv EventToInternet /etc/systemd/system/\\n    sudo chown -R root:root /etc/systemd/system/EventToInternet\\n    cd /etc/systemd/system/EventToInternet\\n    ```\\n\\n4. Установите пакеты (обязательно с `sudo`)\\n\\n    ```bash\\n    sudo python3 -m pip install -r requirements.txt\\n    sudo bash install.sh\\n    ```\\n\\n* Для удаления:\\n\\n    ```bash\\n    sudo bash /etc/systemd/system/EventToInternet/uninstall.sh\\n    sudo rm -rf /etc/systemd/system/EventToInternet*\\n    ```\\n\\n## Запуск Workbench Daemon\\n\\n> Инструкция может устареть, обратитесь к инструкции\\n> в [репозитории](https://github.com/Multi-Agent-io/feecc-workbench-daemon#readme)\\n\\n1. Склонируйте репозиторий\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-workbench-daemon && cd feecc-workbench-daemon`\\n\\n2. Проведите конфигурацию, открыв docker-compose.yml любым текстовым редактором\\n\\n   Измените переменные окружения. Значения каждого параметра:\\n\\n    ```\\n    \\n    MONGODB_URI (Required): MongoDB connection URI\\n    ROBONOMICS_ENABLE_DATALOG (Optional): enable datalog posting or not (bool)\\n    ROBONOMICS_ACCOUNT_SEED (Optional): Your Robonomics network account seed phrase\\n    ROBONOMICS_SUBSTRATE_NODE_URL (Optional): Robonomics network node URI\\n    YOURLS_SERVER (Required): Your Your Yourls server URL\\n    YOURLS_USERNAME (Required): Yourls server username\\n    YOURLS_PASSWORD (Required): Yourls server password\\n    IPFS_GATEWAY_ENABLE (Optional): Whether to enable IPFS posting or not\\n    IPFS_GATEWAY_IPFS_SERVER_URI (Optional): Your IPFS gateway deployment URI\\n    PRINTER_ENABLE (Optional): Whether to enable printing or not\\n    PRINTER_PRINT_SERVER_URI (Optional): Your Print-server deployment URI\\n    PRINTER_SKIP_ACK (Optional): Whether to wait for the task acknowledgement (slow) or not\\n    PRINTER_PRINT_BARCODE (Optional): Whether to print barcodes or not\\n    PRINTER_PRINT_QR (Optional): Whether to print QR codes or not\\n    PRINTER_PRINT_QR_ONLY_FOR_COMPOSITE (Optional): Whether to enable QR code printing for non-composite units or note or not\\n    PRINTER_QR_ADD_LOGOS (Optional): Whether to add logos to the QR code or not\\n    PRINTER_PRINT_SECURITY_TAG (Optional): Whether to enable printing security tags or not\\n    PRINTER_SECURITY_TAG_ADD_TIMESTAMP (Optional): Whether to enable timestamps on security tags or not\\n    CAMERA_ENABLE (Optional): Whether to enable Cameraman or not\\n    CAMERA_CAMERAMAN_URI (Optional): Your Cameraman deployment URI\\n    CAMERA_CAMERA_NO (Optional): Camera number\\n    WORKBENCH_NUMBER (Required): Workbench number\\n    HID_DEVICES_RFID_READER (Optional): RFID reader device name\\n    HID_DEVICES_BARCODE_READER (Optional): Barcode reader device name\\n    LOG_ECS_ENABLE (Optional): Emit file logs in the ECS format (defaults to \\\"disabled\\\")\\n    ```\\n\\n3. Запустите Workbench daemon:\\n\\n   `sudo docker-compose up -d --build`\\n\\n4. Проверьте работоспособность:\\n\\n   Перейдите на `127.0.0.1:5000/docs` и убедитесь, что Swagger отдает данные о REST API\\n\\n## Запуск IPFS Gateway\\n\\n1. Склонируйте репозитории\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-ipfs-gateway.git`\\n\\n2. Измените параметры\\n\\n    ```bash\\n    cd feecc-ipfs-gateway\\n    vim docker-compose.yml\\n    ```\\n\\n   Значение параметров:\\n\\n    ```\\n      MONGODB_URI: ''  # Your MongoDB connection URI ending with /db-name\\n      PRODUCTION_ENVIRONMENT: no  # Leave \\\"no\\\" if you want testing credentials to work\\n      LOCAL_IPFS_ENABLED: yes  # Whether to enable local IPFS node publishing or not.\\n      PINATA_ENABLED: yes  # Whether to upload files to Pinata.cloud or not\\n      PINATA_API: ''  # Pinata.cloud credentials. Leave empty if you don't need it\\n      PINATA_SECRET_API: ''  # Pinata.cloud credentials. Leave empty if you don't need it\\n      ROBONOMICS_ENABLE_DATALOG: no  # Whether to post CIDs to Robonomics network datalog or not\\n      ROBONOMICS_ACCOUNT_SEED: ''  # Robonomics network account seed\\n      ROBONOMICS_SUBSTRATE_NODE_URL: ''  # Robonomics node URL in case you want to use non-default node\\n      PY_IPFS_HTTP_CLIENT_DEFAULT_ADDR: '/dns/ipfsnode/tcp/5001/http'  # Node address, don't change\\n      AUTH_MODE: \\\"workbench\\\" # Auth mode. Available options are \\\"analytics\\\", \\\"workbench\\\" and \\\"noauth\\\"\\n    ```\\n\\n3. Запустите контейнер\\n\\n   `sudo docker-compose up --build`\\n\\n4. Проверьте работоспособность\\n\\n   Проверьте развертывание, перейдя по адресу http://127.0.0.1:8082/docs в браузере. Вы должны увидеть страницу\\n   SwaggerUI.\\n\\n## Запуск Print server\\n\\n1. Склонируйте репозиторий\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-print-server.git`\\n\\n2. Измените параметры\\n\\n    ```bash\\n    cd feecc-print-server\\n    vim docker-compose.yml\\n    ```\\n\\n   Значения параметров:\\n\\n    ```\\n    MONGODB_URI - Your MongoDB connection URI ending with /db-name\\n    PRODUCTION_ENVIRONMENT - Leave null if you want testing credentials to work, otherwise set it to true\\n    PAPER_WIDTH - Paper width in mm\\n    PRINTER_MODEL - Label printer model name\\n    RED - Whether the black and red paper is loaded or not (boolean, null for false)\\n    ```\\n\\n3. Запустите контейнер\\n\\n   `sudo docker-compose up --build`\\n\\n4. Проверьте работоспособность\\n\\n   Проверьте развертывание, перейдя по адресу http://127.0.0.1:8083/docs в браузере. Вы должны увидеть страницу\\n   SwaggerUI.\\n\\n## Запуск Cameraman\\n\\n1. Склонируйте репозитории\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-cameraman.git`\\n\\n2. Измените параметры\\n\\n    ```bash\\n    cd feecc-cameraman\\n    vim docker-compose.yml\\n    ```\\n\\n   Значение параметров:\\n\\n    ```\\n    MONGODB_URI - Your MongoDB connection URI ending with /db-name\\n    PRODUCTION_ENVIRONMENT - Leave null if you want testing credentials to work, otherwise set it to true\\n    FFMPEG_COMMAND - ffmpeg command used for capturing the video stream\\n    CAMERAS_CONFIG - A JSON-like string for camera configuration. This string represents a JSON list of strings, each one describing an RTSP stream (\\\"-\\\" separated stream number and RTSP stream URI). Example: '[\\\"1-rtsp://login:password@192.168.88.239:554/Streaming/Channels/101\\\"]'\\n    ```\\n\\n3. Запустите контейнер\\n\\n   `sudo docker-compose up --build`\\n\\n4. Проверьте работоспособность\\n\\n   Проверьте развертывание, перейдя по адресу http://127.0.0.1:8081/docs в браузере. Вы должны увидеть страницу\\n   SwaggerUI.\\n\\n## Запуск фронтенда\\n\\n1. Склонируйте репозитории\\n\\n   `git clone https://github.com/Multi-Agent-io/feecc-workbench-frontend.git`\\n\\n2. Измените параметры\\n\\n   `vim configs/config.json`\\n\\n   Значение параметров:\\n\\n    ```json\\n    { \\n       \\\"socket\\\": адрес Workbench Daemon,\\n       \\\"interface_language\\\": Язык интерфейса (\\\"ru\\\"/\\\"en\\\"),\\n       \\\"dev_show_reducers\\\": Режим разработчика,\\n       \\\"pulling_period\\\": Периодичность получения обновлений с бекенда в мс,\\n       \\\"use_devtools\\\": использование devtools,\\n       \\\"show_test_schemas\\\": показывать ли тестовые схемы\\n    }\\n    ```\\n\\n3. Запустите контейнер\\n\\n   `docker-compose up --build -d`\\n\\n4. Проверьте работоспособность\\n\\n   Откройте в браузере страницу `localhost:3000`. Должна открыться страница авторизации.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"c849d25dcdfa753f7da1af2eba2c8c1e\",\n        \"title\": \"Deployment of Feecc Analytics\",\n        \"path\": \"/docs/feecc-system-deploy-feecc-analytics/\",\n        \"content\": \"\\nIn this guide, we will talk about the deployment of Feecc Analytics.\\n\\nYou will need `git` and `docker-compose` (v3 or higher) installed in order to run\\n\\n## Analytics backend startup\\n\\n### Clone source code\\n\\nRun:\\n\\n```\\ngit clone https://github.com/Multi-Agent-io/feecc-analytics-backend\\n```\\n\\nTo access dev version (beta) change branch to `development`\\n\\n### Configuration\\n\\nEdit your `.env` file with any text editor.\\n\\n`.env` options:\\n\\n* `MONGO_CONNECTION_URL` - URL MongoDB (in form of `mongodb://<username:password>@<host>:<port>/<defaultauthdb>`)\\n\\n* `MONGO_DATABASE_NAME` - name of mongodb database which will be used for reading/writing data\\n\\n* `SECRET_KEY` - secret key for hash/dehash\\n\\n* `IPFS_GATEWAY_HOST` - URL of IPFS Gateway\\n\\n* `USE_DATALOG` - Will analytics send data to Robonomics Datalog (True/False)\\n\\n* `ROBONOMICS_SEED` - Seed-phrase of the Robonomics wallet on the **Kusama** network\\n\\n### Application startup\\n\\nRun `docker-compose up --build` to start an application\\n\\nIf some parameters were not filled (or filled incorrectly) the system will generate an error, in this case check the\\ncorrectness of filling the `.env`\\n\\n### Check deployment\\n\\nTo check startup, go to `localhost:5002/docs`.\\n\\nIf all done correctly, you will see a page (generated by Swagger) with all Feecc Analytics REST API endpoints. Now you\\nare ready to launch the frontend.\\n\\n## Analytics frontend startup\\n\\n### Clone source code\\n\\nRun:\\n\\n```\\ngit clone https://github.com/Multi-Agent-io/feecc-analytics-frontend\\n```\\n\\nTo access dev version (beta) change branch to `dev`\\n\\n### Configuration\\n\\nEdit `src/config.json` file with any text editor\\n\\nOptions:\\n\\n* `base_url` - URL of Feecc Analytics Backend (in form of `хх.хх.хх.хх:port`)\\n\\n### Application startup\\n\\nTo start run:\\n\\n```\\ndocker-compose up --build\\n```\\n\\n### Check deployment\\n\\nTo check if it works, go to `localhost:8081/docs`.\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"bd17fe781d806b8214eba4eb6b15a0cf\",\n        \"title\": \"System Architecture\",\n        \"path\": \"/docs/feecc-system-architecture/\",\n        \"content\": \"\\n## Architecture Description\\n\\nThe Feecc platform consists of several services, such as:\\n\\n### Feecc Analytics\\n\\n- [feecc-analytics-frontend](https://github.com/Multi-Agent-io/feecc-analytics-frontend)\\n- [feecc-analytics-backend](https://github.com/Multi-Agent-io/feecc-analytics-backend)\\n\\n### Feecc Engineer Workbench\\n\\n- [feecc-workbench-frontend](https://github.com/Multi-Agent-io/feecc-workbench-frontend)\\n- [feecc-workbench-daemon](https://github.com/Multi-Agent-io/feecc-workbench-daemon)\\n\\n### Feecc Validator\\n\\n- [feecc-validator-frontend](https://github.com/Multi-Agent-io/feecc-validator-frontend)\\n- [feecc-validator-backend](https://github.com/Multi-Agent-io/feecc-validator-backend)\\n\\n### Feecc other services\\n\\n- [feecc-ipfs-gateway](https://github.com/Multi-Agent-io/feecc-ipfs-gateway)\\n- [feecc-print-server](https://github.com/Multi-Agent-io/feecc-print-server)\\n- [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman)\\n- [feecc-hid-reader-daemon](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon)\\n\\nEach service is responsible for some kind of functionality required for deployment in an enterprise environment.\\n\\n### Feecc Engineer Workbench\\n\\nThe main task of the Feecc Engineer Workbench is to organize the workspace of the assembly engineer. Depending on the\\ntask the engineer may need the following devices:\\n\\n- IP or Web camera to organize video recording of the production process.\\n- RFID reader for identification in the system by personal RFID card.\\n- Barcode reader for scanning product labels.\\n- Label printer for labeling the manufactured products.\\n- Digital sensors collecting data from various devices/stations\\n\\nFeecc The Engineer's workplace usually consists of the following containers:\\n\\n- Installation is mandatory on the computer from which the product is assembled:\\n\\n    - [feecc-workbench-frontend](https://github.com/Multi-Agent-io/feecc-workbench-frontend)\\n    - [feecc-workbench-daemon](https://github.com/Multi-Agent-io/feecc-workbench-daemon)\\n    - [feecc-hid-reader-daemon](https://github.com/Multi-Agent-io/feecc-hid-reader-daemon)\\n\\n- Installation can be carried out both on the computer from which the product is assembled, and on a server or other\\n  device in the local network:\\n\\n    - [feecc-ipfs-gateway](https://github.com/Multi-Agent-io/feecc-ipfs-gateway)\\n    - [feecc-print-server](https://github.com/Multi-Agent-io/feecc-print-server)\\n    - [feecc-cameraman](https://github.com/Multi-Agent-io/feecc-cameraman)\\n\\nFigures 1 and 2 show the Feecc Engineer Workplace architecture with decentralized and centralized system organization\\ntopology in a corporate environment.\\n![architec1](/docs/images/feecc-system-architecture/picture1.png)\\n\\n<p align=\\\"center\\\">\\nPicture 1 - Feecc Engineer Workbench architecture with decentralized system organization topology in a corporate environment.\\n</p>\\n\\n![architec2](/docs/images/feecc-system-architecture/picture2.png)\\n\\n<p align=\\\"center\\\">\\nPicture 2 - Feecc Engineer Workbench architecture with centralized system organization topology in a corporate environment.\\n</p>\\n\\nThe choice of topology and the deployment of different combinations depends on a company's existing data network,\\ninstalled computers, reliability requirements, centralization or decentralization, and much more. All microservice\\napplications support the exchange of data over an IP network among themselves.\\n\\n### Feecc Analytics\\n\\nThe main task of Feecc Analytics is to organize the process of traceability of finished products and their pre-sales\\ninspection in the product quality control department.\\n\\nFeecc Analytics depends on the following containers:\\n\\n- [feecc-analytics-frontend](https://github.com/Multi-Agent-io/feecc-analytics-frontend)\\n- [feecc-analytics-backend](https://github.com/Multi-Agent-io/feecc-analytics-backend)\\n\\nAnd it is usually deployed on a single server with a globally routable IP to access Feecc Analytics from the outside,\\nbut can also be deployed locally.\\n\\n### Feecc Validator\\n\\nThe main task of the Feecc Validator is to compare data from different data stores in order to validate the integrity of\\nthe digital product certificate.\\n\\nFeecc Validator depends on the following containers:\\n\\n- [feecc-validator-frontend](https://github.com/Multi-Agent-io/feecc-validator-frontend)\\n- [feecc-validator-backend](https://github.com/Multi-Agent-io/feecc-validator-backend)\\n\\nAnd it is usually deployed on a single server with a globally routable IP to access the Feecc Validator from the\\noutside, but can also be deployed locally. \"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"33630dbe7de4a91f0f48f309c640672a\",\n        \"title\": \"How to Edit Wiki\",\n        \"path\": \"/docs/edit-wiki/\",\n        \"content\": \"\\n**Robonomics Wiki is open source. Any corrections are welcome: fixing errors, typos, some unclear or outdated information, translation into any language. You'll need a [GitHub](https://github.com/) account.**\\n\\n\\n## How to edit\\n\\nIf you need to edit docs of Robonomics Wiki, please, follow these steps\\n\\nMake sure, you have [Node.js](https://nodejs.org/en/download/package-manager/) and [Gridsome](https://gridsome.org/docs/#1-install-gridsome-cli-tool) installed.\\n\\n### 1. Clone repo\\n\\nAt first, you need to clone the wiki repository:\\n\\n```\\ngit clone https://github.com/airalab/robonomics-wiki.git\\n```\\n\\nGo to the directory of the repository and run the following commands:\\n\\n`using npm`\\n```\\ncd robonomics-wiki\\nnpm install \\n```\\n\\n`using yarn`\\n```\\ncd robonomics-wiki\\nyarn install\\n```\\n\\n### 2. Serve locally (develop, develop-m1)\\n\\nThen deploy the project locally: \\n\\n```\\ngridsome develop\\n```\\n\\n> If you have the error `node: --openssl-legacy-provider is not allowed in NODE_OPTIONS`, run the following command:\\n```\\ngridsome develop-m1\\n```\\n\\n### 3. Make PR\\n\\n[Make pull request](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) to [wiki repo](https://github.com/airalab/robonomics-wiki)\\n\\n## Components\\n\\n### Asciinema\\nRobonomics Wiki has support for Asciinema. To insert Asciinema, please, follow these instructions:\\n* Import component after frontmatter block `import Asciinema from '~/components/Asciinema.vue'`\\n* Insert as separate paragraph `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, where is vid is ID of specific asciicast\\n\\n> You can get the widget script for a specific asciicast by clicking on “Embed” link on asciicast page.\\n> It looks like this:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Asciinema docs](https://asciinema.org/docs/embedding)\\n\\nIn the example above vid is 14.\\n\\n### Code\\n\\nYou can add helpful extras to your code: \\n\\n`code with copy button`\\n\\n```c\\n<code-helper copy>\\n  YOUR CODE HERE\\n</code-helper>\\n```\\n\\nor\\n\\n`code with additional line`\\n\\n```c\\n<code-helper additionalLine=\\\"this line will be added above your code :)\\\">\\n  YOUR CODE HERE\\n</code-helper>\\n```\\n\\n**Properties for code-helper**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'copy', code: true}, {name: 'Boolean', code: true}, {name: false, code: true}, {name: false, code: true}, {name: 'add a copy button for your code'}]}, { id: 1, items: [{ name: 'additional line', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: `additional line for you code that will be displayed above`}]}]\\\" />\\n\\n<code-helper copy>\\n\\n```bash\\n$ ls -l /dev/serial/by-id\\n```\\n\\n</code-helper>\\n\\n<code-helper copy additionalLine=\\\"your@helper\\\">\\n\\n```bash\\n$ ls -l /dev/serial/by-id\\n```\\n\\n</code-helper>\\n\\n\\n### Frontmatter\\nDocs in Robonomics Wiki contain frontmatter block. It must be at the top of the Markdown file, and must take the form of valid YAML set between triple-dashed lines. Between the triple-dashed lines, you can set or edit folowing options:\\n\\n```YAML\\n---\\ntitle: How to contribute # Title for the page, you do not need to duplicate it in text\\ncontributors: [positivecrash] # Main contributors (who actively curates this page). GitHub nickname required, without any additional symbols\\ntools:   \\n  - rust 1.62.0 \\n    https://blog.rust-lang.org/2022/06/30/Rust-1.62.0.html\\n  - Robonomics 1.4.0\\n  - baxter\\n    http://wiki.ros.org/melodic/Installation\\n    # Tools that were used for technology testing\\n---\\n```\\n\\n### Grid \\nHelps to add grid layout to elements:\\n\\n- Use grid wrapper component first: \\n\\n```c\\n<robo-wiki-grid-element-wrapper></robo-wiki-grid-element-wrapper>\\n```\\n\\n- And then use as many grid items components as you like inside wrapper:\\n\\n```c\\n  <robo-wiki-grid-element-wrapper :columns=\\\"2\\\" textAlign=\\\"center\\\">\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_5.png\\\" />\\n      <p>Zigbee smart devices (any from <a href=\\\"https://slsys.io/action/supported_devices.html\\\">supported devices</a>)</p>\\n    </robo-wiki-grid-element>\\n    <robo-wiki-grid-element>\\n      <robo-wiki-picture src=\\\"home-assistant/need_6.png\\\" /> \\n      <p>Zigbee adapter <a href=\\\"https://jethome.ru/z2/\\\">JetHome USB JetStick Z2</a> (or one of <a href=\\\"https://www.zigbee2mqtt.io/information/supported_adapters.html\\\">supported</a>) or \\n      <a href=\\\"https://easyeda.com/ludovich88/robonomics_sls_gateway_v01\\\">Robonomics SLS Gateway</a></p>\\n    </robo-wiki-grid-element/>\\n  </robo-wiki-grid-element-wrapper>\\n```\\n\\n**Properties for robo-wiki-grid-element-wrapper**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'columns', code: true}, {name: 'Number', code: true}, {name: false, code: true}, {name: 4, code: true}, {name: [{text: 'you can choose column number:'}, {text: `from`, codeText: ' 1 to 5'}]}]}, { id: 1, items: [{ name: 'align', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: [{text: 'align items on the block axis:'}, {text: `options:`, codeText: 'start, center, end'}]}]}, { id: 2, items: [{ name: 'justify', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: [{text: 'align items on the inline axis:'}, {text: `options:`, codeText: 'start, center, end'}]}]}, { id: 3, items: [{ name: 'textAlign', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: 'left', code: true}, {name: [{text: 'align text inside grid'}, {text: `options:`, codeText: 'left, center, right'}]}]}, ]\\\" />\\n\\n\\n<robo-wiki-grid-element-wrapper textAlign=\\\"center\\\">\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_1.png\\\" /> \\n    <p><a href=\\\"https://www.home-assistant.io/\\\">Home Assistant</a> as control system software</p> \\n  </robo-wiki-grid-element>\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_2.png\\\" /> \\n    <p>Raspberry Pi 4 (at least 2 GB RAM)</p>  \\n  </robo-wiki-grid-element>\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_3.png\\\" /> \\n    <p>SD card (minimum 16 GB)</p>  \\n  </robo-wiki-grid-element>\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_4.png\\\" /> \\n    <p>SD adapter</p>\\n  </robo-wiki-grid-element>\\n</robo-wiki-grid-element-wrapper>\\n\\n<robo-wiki-grid-element-wrapper :columns=\\\"2\\\" textAlign=\\\"center\\\">\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_5.png\\\" />\\n    <p>Zigbee smart devices (any from <a href=\\\"https://slsys.io/action/supported_devices.html\\\">supported devices</a>)</p>\\n  </robo-wiki-grid-element>\\n  <robo-wiki-grid-element>\\n    <robo-wiki-picture src=\\\"home-assistant/need_6.png\\\" /> \\n    <p>Zigbee adapter <a href=\\\"https://jethome.ru/z2/\\\">JetHome USB JetStick Z2</a> (or one of <a href=\\\"https://www.zigbee2mqtt.io/information/supported_adapters.html\\\">supported</a>) or \\n    <a href=\\\"https://easyeda.com/ludovich88/robonomics_sls_gateway_v01\\\">Robonomics SLS Gateway</a></p>\\n  </robo-wiki-grid-element/>\\n</robo-wiki-grid-element-wrapper>\\n\\n\\n### Images\\n\\n#### How to upload \\nUpload image in folder `/docs/images/url-of-your-doc`\\n* If image needs to be localized, insert all of them in one folder\\n* Use locale appendix in name of images if it's localized, e.g. `image_en.jpg`\\n* Make sure your image is web optimized and at the same time it looks good\\n\\n#### How to insert \\n\\nThere are two ways for inserting pictures in your documents:\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\nIt is recommended to insert pictures with built-in tag `<robo-wiki-picture>`, however you may also use standard way for Markdown files.\\n\\n</robo-wiki-note>\\n\\n`with caption`\\n\\n```c\\n<robo-wiki-picture link=\\\"/docs/community\\\" src=\\\"example_image.jpg\\\" caption=\\\"EXPLORE ROBONOMICS WIKI\\\" />\\n```\\n\\n`or without caption` \\n\\n```c\\n<robo-wiki-picture link=\\\"/docs/community\\\" src=\\\"example_image.jpg\\\" />\\n```\\n\\n`or simple image` \\n\\n```c\\n<robo-wiki-picture src=\\\"example_image.jpg\\\" />\\n```\\n\\n`or simple image with caption`\\n\\n```c\\n<robo-wiki-picture src=\\\"example_image.jpg\\\" caption=\\\"EXPLORE ROBONOMICS WIKI\\\" />\\n```\\n\\n`image with alt`\\n\\n```c\\n<robo-wiki-picture src=\\\"example_image.jpg\\\" caption=\\\"EXPLORE ROBONOMICS WIKI\\\" alt=\\\"this is alternative text for image\\\" />\\n```\\n**Properties for robo-wiki-picture:**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'src', code: true}, {name: 'String', code: true}, {name: true, code: true}, {name: null, code: false}, {name: [{text: `path to the image:`}, {text: `if you uploaded your image directly to the /docs/images/ use:`, codeText: 'url-of-your-doc'}, {text: `if you uploaded image in one of the folders than use:`, codeText:  `folder-name/url-of-your-doc`}]}]}, { id: 1, items: [{ name: 'link', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: `link to the needed page`}]}, {id: 2, items: [{ name: 'caption', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: `caption for the image`}]}]\\\" />\\n\\n### Notes & warnings\\nYou can add notes and give them specific types:\\n* warning (<span style=\\\"color:#f08432\\\">**orange color**</span>)\\n* okay (<span style=\\\"color:#3eaf7c\\\">**green color**</span>)\\n* note (<span style=\\\"color:#90a4b7\\\">**grey color**</span>)\\n\\n`note with title`\\n\\n```c\\n<robo-wiki-note type=\\\"okay\\\" title=\\\"Some information about robots\\\" />\\n```\\n\\n`note with content`\\n\\n```c\\n<robo-wiki-note type=\\\"okay\\\">Fascinating information about robonomics here only</robo-wiki-note>\\n```\\n\\n`note with title and content`\\n\\n```c\\n<robo-wiki-note type=\\\"okay\\\" title=\\\"Robonomics for you\\\">\\n  Fascinating information about robonomics here only\\n</robo-wiki-note>\\n```\\n\\n<robo-wiki-note type=\\\"okay\\\" title=\\\"Join Discord\\\">\\n\\n[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.\\n\\n</robo-wiki-note>\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Join Discord\\\">\\n\\n[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.\\n\\n</robo-wiki-note>\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Join Discord\\\">\\n\\n[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.\\n\\n</robo-wiki-note>\\n\\n**Properties for robo-wiki-note**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'type', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: 'note', code: false}, {name: [{text: `there are three types in total:`, codeText: 'note, warning, okay'}]}]}, { id: 1, items: [{ name: 'title', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: `adds title to your note`}]}]\\\" />\\n\\n### Tabs\\nYou can add tabs to the doc:\\n\\n- Use tabs wrapper component: \\n\\n```c\\n<robo-wiki-tabs></robo-wiki-tabs>\\n```\\n\\n- And then use as many tab items components as you like inside wrapper:\\n\\n```c\\n  <robo-wiki-tabs>\\n    <robo-wiki-tab title=\\\"Linux\\\">\\n      <pre>ip a</pre>\\n    </robo-wiki-tab>\\n    <robo-wiki-tab title=\\\"OSX\\\">\\n      ifconfig\\n    </robo-wiki-tab>\\n  </robo-wiki-tabs>\\n```\\n\\n\\n`horizontal tabs`\\n\\n```c\\n  <robo-wiki-tabs>\\n    <robo-wiki-tab title=\\\"Linux\\\">\\n      <pre>ip a</pre>\\n    </robo-wiki-tab>\\n    <robo-wiki-tab title=\\\"OSX\\\">\\n      ifconfig\\n    </robo-wiki-tab>\\n  </robo-wiki-tabs>\\n```\\n\\n`vertical tabs`\\n\\n```c\\n  <robo-wiki-tabs mode=\\\"vertical\\\">\\n    <robo-wiki-tab title=\\\"Linux\\\">\\n      <pre>ip a</pre>\\n    </robo-wiki-tab>\\n    <robo-wiki-tab title=\\\"OSX\\\">\\n      <pre>ifconfig</pre>\\n    </robo-wiki-tab>\\n  </robo-wiki-tabs>\\n```\\n\\n`tab item with border`\\n\\n```c\\n  <robo-wiki-tabs>\\n    <robo-wiki-tab title=\\\"Linux\\\">\\n      <pre>ip a</pre>\\n    </robo-wiki-tab>\\n    <robo-wiki-tab title=\\\"OSX\\\" border>\\n      ifconfig\\n    </robo-wiki-tab>\\n  </robo-wiki-tabs>\\n```\\n\\n**Properties for robo-wiki-tabs (wrapper)**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'mode', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: 'horizontal', code: false}, {name: [{text: 'you can choose tabs mode:'}, {text: ``, codeText: ' horizontal'}, {text: ``, codeText: 'vertical'}]}]}]\\\" />\\n\\n**Properties for robo-wiki-tab (item)**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'title', code: true}, {name: 'String', code: true}, {name: true, code: true}, {name: null, code: false}, {name: 'title for the tab'}]}, { id: 1, items: [{ name: 'border', code: true}, {name: 'Boolean', code: true}, {name: false, code: true}, {name: false, code: true}, {name: 'add border to the content wrapper'}]}]\\\" />\\n\\n\\n<robo-wiki-tabs>\\n  <robo-wiki-tab title=\\\"Linux\\\">\\n    <pre>ip a</pre>\\n  </robo-wiki-tab>\\n  <robo-wiki-tab title=\\\"OSX\\\" border >\\n      ifconfig \\n  </robo-wiki-tab>\\n</robo-wiki-tabs>\\n\\n\\n<robo-wiki-tabs mode=\\\"vertical\\\">\\n  <robo-wiki-tab title=\\\"Linux\\\">\\n    <pre>ip a</pre>\\n  </robo-wiki-tab>\\n  <robo-wiki-tab title=\\\"OSX\\\">\\n    <pre>ifconfig</pre>\\n  </robo-wiki-tab>\\n</robo-wiki-tabs>\\n\\n\\n### Title with anchors\\nYou can create custom titles with anchors and give them certain value\\n\\n`title with anchor`\\n\\n```c\\n<robo-wiki-title :type=\\\"2\\\" anchor=\\\"Some information about robots\\\"> \\n  Learn Robonomics :)\\n</robo-wiki-title>\\n```\\n\\nor\\n\\n`title without anchor`\\n\\n```c\\n<robo-wiki-title :type=\\\"5\\\"> \\n  Learn with us ;)\\n</robo-wiki-title>\\n```\\n\\n**Properties for robo-wiki-title**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'type', code: true}, {name: 'Number (from 2 to 6)', code: true}, {name: true, code: true}, {name: null, code: false}, {name: 'choose heading level'}]}, { id: 1, items: [{ name: 'anchor', code: true}, {name: 'String', code: true}, {name: false, code: true}, {name: null, code: false}, {name: `value for the anchor`}]}]\\\" />\\n\\n<robo-wiki-title :type=\\\"6\\\"> \\n I'm custom title :)\\n</robo-wiki-title>\\n\\n### Videos\\n\\nThere are two ways for inserting videos in your documents:\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\nIt is recommended to insert videos with built-in tag `<robo-wiki-video>`, however you may also use standard way for Markdown files.\\n\\n</robo-wiki-note>\\n\\n#### IPFS / Server\\nYou need to specify format of video\\n\\n```c\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.art/ipfs/QmdZKkPJCa9GEN43iUBX81jfrFTDxcn7J6wWURrwNVwcKx', type:'webm'}, {src: 'https://crustipfs.art/ipfs/QmStCDsEHCYwVYvnDdmZBMnobPmrgZx3iJLm65b8XNzKQa', type:'mp4'}]\\\" />\\n```\\n\\n#### Local\\n\\n```c\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: '/videos/add-ext.mp4', type:'mp4'}]\\\" />\\n```\\n\\n##### Properties\\n\\n- If you adding a file with the size of more than <span style=\\\"color:#af1c1c\\\">10MB</span>, please, upload it on server, not in repo.\\n\\n- You may use any properties for [HTML5 video tag](https://www.w3schools.com/tags/tag_video.asp).\\n\\n- Acceptable formats - mp4, webm, ogg.\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'videos', code: true}, {name: 'Array', code: true}, {name: true, code: true}, {name: null, code: false}, {name: [{text: `Array of objects [{src: 'path to video', type: 'type of video'}]`}]}]}]\\\" />\\n\\n\\n#### YouTube \\nYou can embed any YouTube video in doc by inserting share link as separate paragraph without any additional quotes or tags, e.g.: `https://youtu.be/kQaSwNYHJQ8`\\n\\nHowever, if you need an autoplay you must use special component: \\n\\n```c\\n<robo-wiki-youtube autoplay link=\\\"https://www.youtube.com/watch?v=5s4-S_z4VYE\\\" />\\n```\\n\\n**Properties for robo-wiki-youtube**\\n\\n<probs-table :items=\\\"[{ id: 0, items: [{ name: 'link', code: true}, {name: 'String', code: true}, {name: true, code: true}, {name: null, code: false}, {name: [{text: `link to youtube video`}]}]}, { id: 1, items: [{ name: 'autoplay', code: true}, {name: 'Boolean', code: true}, {name: false, code: true}, {name: false, code: true}, {name: [{text: `autoplays youtube video`}]}]}, { id: 2, items: [{ name: 'loop', code: true}, {name: 'Boolean', code: true}, {name: false, code: true}, {name: false, code: true}, {name: [{text: `loop youtube video`}]}]}]\\\" />\\n\\n\\n## How to edit sidebar navigation\\n\\nIf you need to edit sidebar navigation of Robonomics Wiki, please, follow these steps:\\n\\n* Edit file `/data/sidebar_docs.yaml`.\\n\\n* Decide where to place your doc\\n\\n* Use valid YAML for `/data/sidebar_docs.yaml` and rely on the existing file structure\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"4880febaad35269fd72b5b916dcc3c3b\",\n        \"title\": \"Get Notified When Door Opens\",\n        \"path\": \"/docs/door-notification/\",\n        \"content\": \"\\nIn this article you will install the Telegram bot notifier integration and configure an automation, which will send to your Telegram account notification when a door is open.\\n\\n## Telegram Bot Notifications\\n\\nFirst, you need to create a personal Telegram bot. For this go to the [special Telegram bot @BotFather](https://t.me/botfather) and follow instruction. \\nSave your token for accessing the HTTP API.\\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/bot-father.mp4\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\">\\n\\nKeep your token **secure** and store it **safely**, it can be used by anyone to control your bot \\n\\n</robo-wiki-note>\\n\\nNext step is find your ***User Chat ID***. For this use the next [GetIdsBot](https://t.me/getidsbot). \\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/get-id-bot.mp4\\\" />\\n\\nNow let's install \\\"Telegram broadcast\\\" integration. This integration will send messages to your Telegram.\\n\\nFor Robonomics pre-installed image, Home Assistant Docker or Home Assistant Core you have to edit `configuration.yaml`. Connect to your Raspberry Pi via `ssh`:\\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/open-config.mp4\\\" />\\n\\n<code-helper additionalLine=\\\"rasppi_username@rasppi_hostname\\\" >\\n\\n```shell\\nsudo -u homeassistant -H -s\\ncd\\ncd .homeassistant \\nnano configuration.yaml\\n```\\n\\n</code-helper >\\n\\nPaste next lines to the end of file. Insert your **bot API key** and **your User Chat ID**. Also create a name for your notify service:\\n\\n\\n<code-helper copy >\\n\\n```shell\\ntelegram_bot:\\n  - platform: broadcast\\n    api_key: <YOUR_API_KEY>\\n    allowed_chat_ids:\\n      -  <YOUR_USER_CHAT_ID> # 123456789  example id of a user\\n      \\nnotify:\\n  - platform: telegram\\n    name: <NOTIFIER_NAME>\\n    chat_id: <YOUR_USER_CHAT_ID>\\n```\\n\\n</code-helper >\\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/insert-config.mp4\\\" />\\n\\n**Save configuration and reload Home Assistant.**\\n\\n\\nAs result, in your Home Assistant service will be created service, which will send any message to the Telegram chat with you. \\nYou can check it in Developer Tools menu on Home Assistant web interface. \\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/telegram-result.mp4\\\" />\\n\\n##  Door Open Notification\\n\\nNow it's time to create automation. First, you import blueprint to your Home Assistant from this link:\\n\\n<code-helper copy>\\n\\n```shell\\nhttps://github.com/airalab/home-assistant-blueprints/blob/main/door-opened-notifications/door-notifications.yaml\\n```\\n\\n</code-helper >\\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/insert-blue.mp4\\\" />\\n\\nAnd create automation:\\n\\n<robo-wiki-video controls src=\\\"https://static.robonomics.network/wiki/create-automation.mp4\\\" />\\n\\nNow you will receive message from Telegram bot every time the door is open.\\n\\n<robo-wiki-note type=\\\"okay\\\">\\nYou can use this automation with any doors/windows in your home.\\n</robo-wiki-note>\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"d911b3cc8a9d53b95952a35cae02e42f\",\n        \"title\": \"Digital Twins\",\n        \"path\": \"/docs/digital-twins/\",\n        \"content\": \"  \\n**Imagine having a complicated device or system which has several modules to maintain and requires a few accounts to use.\\nTo keep all of them in one place or to encode some functionality with separate accounts or, for example, to set different datalog \\nsources for different information flows, Digital Twin module is to be used.**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Dev Node\\\">\\n\\n  Please pay attention that this and following tutorials are demonstrated on a local instance of Robonomics Node. Set\\n up yours with [these instructions](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\n## Theory overview\\nAny account can create and manage a Digital Twin. The Twin may be imagined as some sort of table with the following\\ncontents:\\n\\n| DT id  | Topic Name \\t| Source    \\t|\\n|--------|------------\\t|-----------\\t|\\n| 0      | 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1      | 0x00...001 \\t| 4GVi...Bn \\t|\\n| \\t      | 0x00...002 \\t| 4Hm...vLS \\t|\\n| \\t      | 0x00...... \\t| 4HQ...RQY \\t|\\n| n\\t  | 0xFF...FFF \\t| 4Hw...CyK \\t|\\n\\n\\n Where:\\n* **DT id** is unsigned integer unique Digital Twin index.\\n* **Topic name** is a hex `H256` or ASCII data of 32 bytes length, same as [`Launch`](/docs/launch) extrinsic parameter. \\nFor example: `0x1234....FF` or  `hello.parachain.robonomics.world`.\\n* **Source** - is some Account address.\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Topics\\\">\\n\\n  As have been discussed previously in Launch extrinsic overview, the `H256` may be represented as an encoded IPFS CID (see\\n  [Python tool](https://multi-agent-io.github.io/robonomics-interface/modules.html#robonomicsinterface.utils.ipfs_qm_hash_to_32_bytes) for that).\\n  Therefore, topics may be used as some data storage as well, say, a Twin's module description.\\n\\n</robo-wiki-note>\\n\\n\\n## Create Digital Twin\\n\\n### 1. Navigate to Developer -> Extrinsics\\n\\n<robo-wiki-picture src=\\\"digital-twin/extrinsics.jpg\\\" />\\n\\n### 2. Choose digitalTwin -> create from the dropdown list of possible extrinsics\\n\\n<robo-wiki-picture src=\\\"digital-twin/twin-create.jpg\\\" />\\n\\nSubmit the transaction. Here, no parameters needed to create a Twin. It will be granted an index and only the Digital\\nTwin owner is able to add/modify topics of the Twin from now on.\\n\\nTwin ID may be found on the Explorer overview page.\\n\\n<robo-wiki-picture src=\\\"digital-twin/create-log.jpg\\\" />\\n\\n## Add Topic\\n\\n### Choose digitalTwin -> setSource from the dropdown list of possible extrinsics\\n\\n<robo-wiki-picture src=\\\"digital-twin/set-topic.jpg\\\" />\\n\\n* `id` - Digital Twin ID, which has been obtained on the Explorer page.\\n* `topic` - previously discussed `H256` topic name. In this picture it's a string of 32 symbols.\\n* `source` - account address to be associated with the topic.\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Overwrite\\\">\\n\\n  Pay attention that the topic may be overwritten with another source address if needed.\\n\\n</robo-wiki-note>\\n\\nSign and submit the extrinsic.\\n\\n## Explore\\n\\nYou can find all information about existing Digital Twins in `Developer -> Chain state` storage module `digitalTwin`.\\n\\n- Total number of Twins - `total()`;\\n- Digital Twin owner - `owner(u32)`;\\n- Information about topics of a Digital Twin - `digitalTwin(u32)`.\\n\\n<robo-wiki-picture src=\\\"digital-twin/chain-state.jpg\\\" />\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"c288be24eabf36856bdd36e478c532aa\",\n        \"title\": \"Datalog\",\n        \"path\": \"/docs/datalog/\",\n        \"content\": \"\\n**Now that you have some funds on your account you can submit extrinsics. The first to try is a Datalog. It allows you \\nto store data in the blockchain persistently. Imagine a distributed and crypto-protected storage for your data and this is it!**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Dev Node\\\">\\n\\n  Please pay attention that this and following tutorials are demonstrated on a local instance of Robonomics Node. Set\\n up yours with [these instructions](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\n## 1. Navigate to Developer -> Extrinsics\\n\\n<robo-wiki-picture src=\\\"datalog/extrinsics.jpg\\\" />\\n\\n## 2. Choose datalog -> record from the dropdown list of possible extrinsics\\n\\nAlso choose an account you want to submit the extrinsic with. Fill in the record field.\\n\\n<robo-wiki-picture src=\\\"datalog/record.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Large amount of data\\\">\\n\\n  Datalog supports a string with a maximum of 512 bytes. To store large amount of data one may use [IPFS](https://ipfs.tech/).\\n\\n</robo-wiki-note>\\n\\n## 3. Submit transaction\\n\\nSign and submit the transaction with an account created previously using the extension or the DApp.\\n\\n<robo-wiki-picture src=\\\"datalog/submit.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Erase\\\">\\n\\n  You may also erase **ALL** of your records with *datalog -> erase* call.\\n\\n</robo-wiki-note>\\n\\n## 4. Review your datalog in the storage\\n\\nFor this, navigate to *Developer -> Chain state*, select *datalog -> datalogIndex*, specify your account and press the \\n\\\"+\\\" button to get the indexes of your account's records and then explore the one you need with *datalog -> datalogItem*.\\n\\n<robo-wiki-picture src=\\\"datalog/item.jpg\\\" />\\n\\n<robo-wiki-note type=\\\"note\\\" title=\\\"Explorer\\\">\\n\\n  All the events including datalog record may be seen in the events flow in the *Explorer*.\\n\\n</robo-wiki-note>\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"a4f9f7326687843b80644b49ecf5b648\",\n        \"title\": \"Create digital identity run by Ethereum\",\n        \"path\": \"/docs/create-digital-identity-run-by-ethereum/\",\n        \"content\": \"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](./images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](./images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](./images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](./images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](./images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](./images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"186ef2c734330a94116f16de215ff48a\",\n        \"title\": \"Create Account for Robonomics Parachain\",\n        \"path\": \"/docs/create-account-in-dapp/\",\n        \"content\": \"\\n**In order to interact and operate with Robonomics Parachain, developers and users need to create an account on the Polkadot / Substrate Portal. The account performs basic functions for the network: your public network address(the public key), the access control to the address and funds (the private key), sending transactions to the network, showing your tokens and their amount, etc. Below are two main ways to create an account for Robonomics Parachain.**\\n\\n## 1. Using Polkadot{.js} Browser Extension\\n\\nThe Polkadot Extension provides a mechanism to generate the account and interact with all Polkadot / Kusama projects including Robonomics Parachain. This is not the safest way to manage your account, but it is the most convenient in terms of security / usability balance.\\n\\n## 1.1. Install Browser Extension\\n\\nThe browser extension is available for [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) and [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=en) (plus Chromium-based browsers).\\n\\n![Browser Extension](./images/creating-an-account/1.1-polkadot-extension.png \\\"Browser Extension\\\")\\n\\n## 1.2. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. If this is the first time you entered the portal, it will request access to the browser extension, so allow access. \\n\\nOnce you've opened the app, take a look at the top left corner. The name of the network, its icon and the number of the last block are displayed there. Clicking on this area will open a list of all Polkadot / Kusama networks, including test networks and local nodes. You can switch between networks by selecting the required one and pressing the `Switch` button. **Make sure you are connected to Robonomics Parachain now**. \\n\\n![Robonomics Parachain app](./images/creating-an-account/1.2-robonomics-app.png \\\"Robonomics Parachain app\\\")\\n\\n## 1.3. Update Extension Metadata\\n\\nIt is very likely that the app will ask you to update the metadata for the extension to display the correct information about the chain you are connected to. Go to **Settings -> Metadata**, press `Update metadata` button and then, in the pop-up window, allow the extension to do it. \\n\\n![Updating metadata](./images/creating-an-account/1.3-metadata-update.png \\\"Updating metadata\\\")\\n\\n## 1.4. Create Account in Extension\\n\\nOpen the Polkadot{.js} browser extension. Click the big plus button or select `Create new account` from the small plus icon in the top right. You should see the following menu, with generated mnemonic seed in the form of twelve words and the address. \\n\\n![Account creation, step one](./images/creating-an-account/1.4-create-account-step-1.png \\\"Account creation, step one\\\")\\n\\nThe seed is your key to the account. Knowing the seed allows you (or anyone else who knows the seed) to get control on this account and even re-create it, if you forget the password. **It's very important to store it somewhere securely**, preferably on paper or other non-digital device, not in digital storage or on a computer. \\n\\nSave the seed and press `Next step`. You should see the following menu.\\n\\n![Account creation, step two](./images/creating-an-account/1.5-create-account-step-2.png \\\"Account creation, step two\\\")\\n\\n- *Network* allows you to choose which of the networks this account will be exclusively used for. You can use the same address on multiple networks, however, for privacy reasons, it is recommended that you create a new address for each network you use. \\nSelect the Robonomics network from the drop-down list. If you could not find the Robonomics network, then most likely you did not update the metadata, go back and do it.\\n\\n    - You will notice that the format of the address and the account icon will change — this is normal. Different network formats are merely other representations of the same public key. \\n\\n- *Name* is just account's name for your use only. It is not stored on the blockchain and will not be visible to other users. \\n\\n- *Password* is used to encrypt your account's information. You will need to re-enter it when signing transactions on the portal. Create one and remember it.\\n\\nAs a result, after creating an account, you will see it in the list of accounts in Polkadot{.js} extension. By clicking on three dots, you can rename the account, export it, remove it from the extension and change the network used for the account. \\n\\nAlso, the account will appear in the **Accounts -> Accounts** menu on the portal, where it will be noted that it was injected using the extension.\\n\\n![Successful account creation](./images/creating-an-account/1.6-account-injected.png \\\"Successful account creation\\\")\\n\\n\\n## 2. Directly on Robonomics Parachain App\\n\\nYou can use the user interface on the Polkadot / Substrate Portal to create an account. It could be used for development and tests. \\n\\n## 2.1. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check at the top left corner that you are connected to Robonomics Parachain**.  \\n\\nGo to **Accounts -> Accounts** and press `Add account` button. \\n\\n![Robonomics Parachain App](./images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Robonomics Parachain App\\\")\\n\\n## 2.2. Create Account\\n\\nYou should see the following popup menu with account seed. \\n\\n![Generating account seed](./images/creating-an-account/2.2-robonomics-app-seed.png \\\"Generating account seed\\\")\\n\\nIt has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). Save the seed phrase securely and press `Next`.\\n\\n> Also you can change the crypto type of creating account, for that open `Advanced creation options` and choose the type (`ed25519` on the picture).\\n\\n![ed25519 crypto type account](./images/creating-an-account/ed-account.jpg)\\n\\nIn the next menu, you need to set the account name and password, similar to the extension instructions described above.\\n\\n![Generating account name and password](./images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Generating account name and password\\\")\\n\\nClicking on the `Next` button will take you to the last window. Click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n![Successful account creation](./images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Successful account creation\\\")\\n\\n## 2.3 Add ed25519 account to Polkadot extension\\n\\nYou may need to add created account to Polkadot.js extension (for ed25519 account you can do that only with backup JSON file). For that you need to create backup file of the account. Press on three dots on your account and choose `Create a backup file for this account` and write your password.\\n\\n![Backup file](./images/creating-an-account/backup-file.jpg)\\n\\nThen open an extension and press `+` button on the top right, then choose `Restore account from backup JSON file`.\\n\\n![Restore backup in extension](./images/creating-an-account/extention-add-backup.jpg)\\n\\nIn opened window drop saved file, enter the password and press `Restore`.\\n\\n![Restore backup in extension 2](./images/creating-an-account/file-backup.jpg)\\n\\n## 3. Account Сreated Successfully \\n\\nNow you can fully operate with your fresh-created account. Send and receive tokens, messages, write datalog and more. Feel free to explore all the features of app. To copy your account's address simply click on its icon, address will be copied to clipboard. \\n\\nIf you would like to know more about Polkadot / Kusama accounts and additional ways to create them, more information can be found [here](https://wiki.polkadot.network/docs/learn-accounts) and [here](https://wiki.polkadot.network/docs/learn-account-generation).\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"04a1703849a87814837e1bb68ccf21cd\",\n        \"title\": \"How to Contribute to Robonomics Resources\",\n        \"path\": \"/docs/contributing/\",\n        \"content\": \"\\nRobonomics Network is an open-source project and we want to make it easy for anyone to contribute. You may create articles, suggest changes, improve documentation or run tests. If you want to contribute, please, open a new issue or create a pull request in the same repository.\\n\\n## Main Robonomics Repositories \\n\\n- [Robonomics Wiki](https://github.com/airalab/robonomics-wiki) — Main wiki project\\n- [Robonomics Main](https://github.com/airalab/robonomics.network) —  Official main website of Robonomics Network \\n- [Robonomics.cloud](https://github.com/airalab/robonomics.cloud) — Home for Robonomics Web Services\\n- [Robonomics Dapp](https://github.com/airalab/dapp.robonomics.network) — Official dapp\\n- [Robonomics Academy](https://github.com/airalab/robonomics.academy) — Official website of Robonomics Academy\\n\\n### Rules for Reporting\\n\\nWhen opening a new issue, do not forget about a few basic rules for reporting:\\n\\n1. Choose exact repository, that you want to submit an issue.\\n\\n2. If you are reporting bug, make sure the bug was not already reported.\\n\\n3. Be sure to include title and clear description, as much relevant information as possible.\\n\\n4. Please, prefix your issue with one of the following: `[BUG]`, `[PROPOSAL]`, `[QUESTION]`.\\n\\n\\n## Pull Requests\\n\\nAny Robonomics repository may be subject to pull requests or changes by contributors, where you believe you have something valuable to add or change. Please, do not forget about basic rules for contributors.\\n\\n### Rules for contributing\\n\\n1. Pull requests are preferred to issues, if you have some fixes, especially for small changes such as typos.\\n\\n2. Make sure the PR description clearly describes the problem and the solution. Include the relevant issue number if applicable.\\n\\n3. Please, do not fix whitespace, format code, or make a purely cosmetic patch.\\n\\n4. Please, attempt to adhere to the prevailing Markdown style, language, and layout.\\n\\n\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"2acc72053db6120411e8523fc919e1cb\",\n        \"title\": \"Offsetting Service\",\n        \"path\": \"/docs/carbon-footprint-service/\",\n        \"content\": \"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"3e25d2e757fc04687191665f6f6cdf41\",\n        \"title\": \"Connect sensor\",\n        \"path\": \"/docs/carbon-footprint-sensor/\",\n        \"content\": \"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"5c95cdeabd41575011fefb91cf8af3e8\",\n        \"title\": \"Backup Services\",\n        \"path\": \"/docs/backup-services/\",\n        \"content\": \"\\n**In this article, you will learn how to generate backups of your Home Assistant configuration and restore it when needed. To create backups, a service is called that generates a secure archive with configuration files. This service then adds the archive to IPFS and stores the resulting CID in Robonomics Digital Twin.**\\n## Creating Home Assistant Configuration's Backup\\n\\nCreating a backup allows you to easily restore your Home Assistant configuration in the event of a failure.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.art/ipfs/QmVo91dLaAYgFDM1vrL2PYfAffM6SGGC59ZERbfHR44tqW', type:'mp4'}]\\\" />\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"WARNING\\\">\\nIn order to restore your configuration, it is necessary to use a custom IPFS gateway such as Pinata. Without it, your backup will be stored solely on your local IPFS node, which may prevent you from restoring your Home Assistant configuration in the event of a local node failure.\\n</robo-wiki-note>\\n\\n1. In the web interface of Home Assistant go to `Developer Tools` -> `Services`. Search for `Robonomics: Save Backup to Robonomics` and press `CALL SERVICE`.\\n\\n2. Wait until you see the notification `Backup was updated in Robonomics` appear in `Notification`.\\n\\n## Restoring Home Assistant Configuration from Backup\\n\\nIn order to restore your configuration, you will need to install Home Assistant and Robonomics Integration.\\n\\n<robo-wiki-video autoplay loop controls :videos=\\\"[{src: 'https://crustipfs.art/ipfs/QmWmnmkXUcPXsAnQzwN3UEuki2GMYnQDx3vhgjEypCU8aR', type:'mp4'}]\\\" />\\n\\n1. Install [Home Assisntant with Robonomics](https://wiki.robonomics.network/docs/robonomics-smart-home-overview#how-to-install-home-assistant-with-robonomics) and confgire it, following the steps from the article.\\n\\n2.  [Set up Robonomics Integration](https://wiki.robonomics.network/docs/robonomics-hass-integration) using the same seeds you used previously. If you subscription has been finished, [activate it](https://wiki.robonomics.network/docs/sub-activate).\\n\\n3. In the web interface of Home Assistant go to `Developer Tools` -> `Services`. Search for `Robonomics: Restore from the Backup in Robonomics` and press `CALL SERVICE`. Navigate to the `Overview` page, to check the status of your backup, .\\n\\n4. Once Home Assistant has finished restarting, your configuration will be restored. If the status changes to `restored` but Home Assistant does not automatically restart, you need to manually restart it by navigating to `Settings` > `System` and clicking on the `RESTART` button in the upper right corner.\"\n      }\n    }, {\n      \"node\": {\n        \"id\": \"5f6a4ef1dcf293a2070803f07dbd2817\",\n        \"title\": \"Adding funds to your account on Robonomics Portal\",\n        \"path\": \"/docs/adding-funds-to-account-in-dapp/\",\n        \"content\": \"\\n**After successfully creating your accounts on Robonomics portal, it is time to add funds to them so that you would be able to initiate transactions.**\\n\\n<robo-wiki-note type=\\\"warning\\\" title=\\\"Dev Node\\\">\\n\\n  Please pay attention that this and following tutorials are demonstrated on a local instance of Robonomics Node. Set\\n up yours with [these instructions](/docs/run-dev-node).\\n\\n</robo-wiki-note>\\n\\n## 1. Navigate to Accounts section on Robonomics portal \\n\\n![Accounts](./images/creating-an-account/portal-top-left.jpg \\\"Accounts\\\")\\n\\n## 2. Choose the account you want to transfer funds from\\n\\nIn the development mode, there exist several accounts, with 10000 Units worth of funds each, that can be used to transfer funds to other accounts created in the development network. These accounts are indicated by wrench signs <img alt=\\\"wrench sign\\\" src=\\\"./images/adding-funds/wrench.png\\\" width=\\\"20\\\" /> next to them.\\n\\n![Accounts-for-sending](./images/adding-funds/accounts-for-sending.svg \\\"Accounts-for-sending\\\")\\n\\n- Click on the \\\"send\\\" button of the account you want to transfer funds from, for example BOB\\n\\n## 3. Choose the account you want to transfer funds into\\nAfter clicking on the \\\"send\\\" button, you would be prompted with the \\\"send funds window\\\". In the prompted window:\\n\\n- From the list of available accounts, choose the account you want to send funds into.\\n- Enter the number of Units you want to send.\\n- Press \\\"make transfer\\\"\\n\\n![Transfer-Funds](./images/adding-funds/send-funds.png \\\"Transfer-Funds\\\")\\n\\n## 4. Authorize the transaction\\n\\nAfter pressing \\\"make transfer\\\" in the previous stage, you would be prompted with \\\"authorize transaction window\\\".<br/>\\nReview the details of the transaction and finally click on \\\"sign and submit\\\" button.\\n\\n![sign-transaction](./images/adding-funds/sign-transaction.png \\\"sign-transaction\\\")\\nIn this example, we transferred 500 units of funds from \\\"BOB\\\" to \\\"EMPLOYER\\\". You can see that EMPLOYER's account, which initially did not have any funds, has 500 Units of fund now.\\n\\n![funds-added](./images/adding-funds/funds-added.svg \\\"funds-added\\\")\\n\\n**Make sure that you have enough funds in the accounts you want to use in the playground.**\"\n      }\n    }]\n  }\n};\n/* harmony default export */ __webpack_exports__[\"default\"] = (({\n  options\n}) => {\n  if (options.__staticData) {\n    options.__staticData.data = data;\n    return;\n  }\n  options.__staticData = vue__WEBPACK_IMPORTED_MODULE_0__[\"default\"].observable({\n    data\n  });\n  options.computed = computed({\n    $static: () => options.__staticData.data\n  }, options.computed);\n});\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/babel-loader/lib??ref--14-0!./node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "shUY":
/*!********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/mini-css-extract-plugin/dist/loader.js!./node_modules/css-loader/dist/cjs.js??ref--2-oneOf-1-1!./node_modules/vue-loader/lib/loaders/stylePostLoader.js!./node_modules/postcss-loader/src??ref--2-oneOf-1-2!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=style&index=0&id=64c7a3b8&prod&scoped=true&lang=css& ***!
  \********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// extracted by mini-css-extract-plugin\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/mini-css-extract-plugin/dist/loader.js!./node_modules/css-loader/dist/cjs.js??ref--2-oneOf-1-1!./node_modules/vue-loader/lib/loaders/stylePostLoader.js!./node_modules/postcss-loader/src??ref--2-oneOf-1-2!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "uifM":
/*!************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=script&lang=js& ***!
  \************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony default export */ __webpack_exports__[\"default\"] = ({\n  data() {\n    return {\n      isActive: false,\n      isFocused: false,\n      search: ''\n    };\n  },\n  computed: {\n    toggleClasses() {\n      return {\n        'active': this.isActive\n      };\n    },\n    searchResults() {\n      if (this.search.length > 2) {\n        return this.$static.allDocPage.edges.filter(post => {\n          return (post.node.title.toLowerCase().includes(this.search.toLowerCase().trim()) || post.node.content.toLowerCase().includes(this.search.toLowerCase().trim())) & post.node.path != this.$route.matched[0].path + '/';\n        });\n      } else return '';\n    }\n  },\n  methods: {\n    focusIn() {\n      this.isActive = true;\n    },\n    focusOut() {\n      this.isActive = false;\n    }\n\n    // SearchLinksFocus() {\n    //   document.querySelector('.search-container nav a:first-child').focus()\n    // }\n  },\n\n  watch: {\n    \"$route.path\": function () {\n      this.isActive = false;\n    }\n  }\n});\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "wQbG":
/*!***********************************!*\
  !*** ./src/components/Search.vue ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Search.vue?vue&type=template&id=64c7a3b8&scoped=true& */ \"ope7\");\n/* harmony import */ var _Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Search.vue?vue&type=script&lang=js& */ \"BO/4\");\n/* empty/unused harmony star reexport *//* harmony import */ var _Search_vue_vue_type_style_index_0_id_64c7a3b8_prod_scoped_true_lang_css___WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Search.vue?vue&type=style&index=0&id=64c7a3b8&prod&scoped=true&lang=css& */ \"JaYo\");\n/* harmony import */ var _node_modules_vue_loader_lib_runtime_componentNormalizer_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../node_modules/vue-loader/lib/runtime/componentNormalizer.js */ \"KHd+\");\n/* harmony import */ var _Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Search.vue?vue&type=custom&index=0&blockType=static-query */ \"A2fM\");\n\n\n\n\n\n\n/* normalize component */\n\nvar component = Object(_node_modules_vue_loader_lib_runtime_componentNormalizer_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(\n  _Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  _Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__[\"render\"],\n  _Search_vue_vue_type_template_id_64c7a3b8_scoped_true___WEBPACK_IMPORTED_MODULE_0__[\"staticRenderFns\"],\n  false,\n  null,\n  \"64c7a3b8\",\n  null\n  \n)\n\n/* custom blocks */\n\nif (typeof _Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__[\"default\"] === 'function') Object(_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(component)\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (component.exports);\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ })

}]);