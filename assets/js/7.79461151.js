(window["webpackJsonp"] = window["webpackJsonp"] || []).push([[7],{

/***/ "A2fM":
/*!**********************************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=custom&index=0&blockType=static-query ***!
  \**********************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_babel_loader_lib_index_js_ref_14_0_node_modules_gridsome_lib_plugins_vue_components_lib_loaders_static_query_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/babel-loader/lib??ref--14-0!../../node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=custom&index=0&blockType=static-query */ \"r2nM\");\n/* empty/unused harmony star reexport */ /* harmony default export */ __webpack_exports__[\"default\"] = (_node_modules_babel_loader_lib_index_js_ref_14_0_node_modules_gridsome_lib_plugins_vue_components_lib_loaders_static_query_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_0__[\"default\"]); \n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "BO/4":
/*!************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=script&lang=js& ***!
  \************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/babel-loader/lib??ref--1-1!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=script&lang=js& */ \"uifM\");\n/* empty/unused harmony star reexport */ /* harmony default export */ __webpack_exports__[\"default\"] = (_node_modules_cache_loader_dist_cjs_js_ref_1_0_node_modules_babel_loader_lib_index_js_ref_1_1_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_0__[\"default\"]); \n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "Lr+N":
/*!******************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=template&id=2d5d749c& ***!
  \******************************************************************/
/*! exports provided: render, staticRenderFns */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_709914d4_vue_loader_template_node_modules_vue_loader_lib_loaders_templateLoader_js_vue_loader_options_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/cache-loader/dist/cjs.js?{\"cacheDirectory\":\"node_modules/.cache/gridsome\",\"cacheIdentifier\":\"709914d4-vue-loader-template\"}!../../node_modules/vue-loader/lib/loaders/templateLoader.js??vue-loader-options!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=template&id=2d5d749c& */ \"hPWg\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"render\", function() { return _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_709914d4_vue_loader_template_node_modules_vue_loader_lib_loaders_templateLoader_js_vue_loader_options_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__[\"render\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"staticRenderFns\", function() { return _node_modules_cache_loader_dist_cjs_js_cacheDirectory_node_modules_cache_gridsome_cacheIdentifier_709914d4_vue_loader_template_node_modules_vue_loader_lib_loaders_templateLoader_js_vue_loader_options_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__[\"staticRenderFns\"]; });\n\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "ZbFX":
/*!********************************************************************************!*\
  !*** ./src/components/Search.vue?vue&type=style&index=0&lang=scss&scope=true& ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_4_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_4_oneOf_1_2_node_modules_sass_loader_dist_cjs_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! -!../../node_modules/mini-css-extract-plugin/dist/loader.js!../../node_modules/css-loader/dist/cjs.js??ref--4-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src??ref--4-oneOf-1-2!../../node_modules/sass-loader/dist/cjs.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib??vue-loader-options!./Search.vue?vue&type=style&index=0&lang=scss&scope=true& */ \"iJZR\");\n/* harmony import */ var _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_4_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_4_oneOf_1_2_node_modules_sass_loader_dist_cjs_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_4_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_4_oneOf_1_2_node_modules_sass_loader_dist_cjs_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_0__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_4_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_4_oneOf_1_2_node_modules_sass_loader_dist_cjs_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_0__) if([\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _node_modules_mini_css_extract_plugin_dist_loader_js_node_modules_css_loader_dist_cjs_js_ref_4_oneOf_1_1_node_modules_vue_loader_lib_loaders_stylePostLoader_js_node_modules_postcss_loader_src_index_js_ref_4_oneOf_1_2_node_modules_sass_loader_dist_cjs_js_node_modules_cache_loader_dist_cjs_js_ref_0_0_node_modules_vue_loader_lib_index_js_vue_loader_options_Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_0__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ }),

/***/ "hPWg":
/*!*********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/cache-loader/dist/cjs.js?{"cacheDirectory":"node_modules/.cache/gridsome","cacheIdentifier":"709914d4-vue-loader-template"}!./node_modules/vue-loader/lib/loaders/templateLoader.js??vue-loader-options!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=template&id=2d5d749c& ***!
  \*********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: render, staticRenderFns */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"render\", function() { return render; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"staticRenderFns\", function() { return staticRenderFns; });\nvar render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"search-container\",class:_vm.toggleClasses,attrs:{\"tabindex\":\"0\"},on:{\"focusin\":_vm.focusIn,\"focusout\":_vm.focusOut}},[_c('input',{directives:[{name:\"model\",rawName:\"v-model\",value:(_vm.search),expression:\"search\"}],attrs:{\"type\":\"search\",\"aria-label\":_vm.$st('Search', _vm.$store.state.locale),\"placeholder\":_vm.$st('Search', _vm.$store.state.locale)},domProps:{\"value\":(_vm.search)},on:{\"input\":function($event){if($event.target.composing){ return; }_vm.search=$event.target.value}}}),(_vm.searchResults.length > 0)?_c('div',{staticClass:\"searchresults\",attrs:{\"role\":\"listbox\"}},[_c('div',{staticClass:\"layout__content\"},[_c('div',{staticClass:\"search-msg-count\",attrs:{\"aria-hidden\":\"true\"}},[_vm._v(_vm._s(_vm.$st('Search Found', _vm.$store.state.locale))+\": \"+_vm._s(_vm.searchResults.length))]),_c('nav',_vm._l((_vm.searchResults),function(post){return _c('g-link',{key:post.node.id,attrs:{\"to\":post.node.path},on:{\"focusout\":_vm.SearchLinksNextFocus}},[_vm._v(_vm._s(post.node.title))])}),1)])]):_vm._e()])}\nvar staticRenderFns = []\n\n\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/cache-loader/dist/cjs.js?%7B%22cacheDirectory%22:%22node_modules/.cache/gridsome%22,%22cacheIdentifier%22:%22709914d4-vue-loader-template%22%7D!./node_modules/vue-loader/lib/loaders/templateLoader.js??vue-loader-options!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "iJZR":
/*!******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/mini-css-extract-plugin/dist/loader.js!./node_modules/css-loader/dist/cjs.js??ref--4-oneOf-1-1!./node_modules/vue-loader/lib/loaders/stylePostLoader.js!./node_modules/postcss-loader/src??ref--4-oneOf-1-2!./node_modules/sass-loader/dist/cjs.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=style&index=0&lang=scss&scope=true& ***!
  \******************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// extracted by mini-css-extract-plugin\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/mini-css-extract-plugin/dist/loader.js!./node_modules/css-loader/dist/cjs.js??ref--4-oneOf-1-1!./node_modules/vue-loader/lib/loaders/stylePostLoader.js!./node_modules/postcss-loader/src??ref--4-oneOf-1-2!./node_modules/sass-loader/dist/cjs.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "r2nM":
/*!****************************************************************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/babel-loader/lib??ref--14-0!./node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=custom&index=0&blockType=static-query ***!
  \****************************************************************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var vue__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! vue */ \"Kw5r\");\nvar computed=vue__WEBPACK_IMPORTED_MODULE_0__[\"default\"].config.optionMergeStrategies.computed;var data={\"allDocPage\":{\"edges\":[{\"node\":{\"id\":\"777cbed389d6fff60827a2e7a3ef3d24\",\"title\":\"Connect Sensors with Zigbee2MQTT\",\"path\":\"/docs/ru/zigbee2-mqtt/\",\"content\":\"\\n## Mosquitto MQTT broker\\n\\nFor this method, you neet to install MQTT broker to the Raspberry Pi:\\n\\n```bash\\nsudo apt update\\nsudo apt install mosquitto mosquitto-clients\\n```\\nThe Mosquitto program will run automatically after installation.\\n\\n## Zigbee2MQTT setup\\n\\nIf you have the JetHome USB JetStick Z2 it will already have the necessary firmware so you don't need to flash it. However, if you have another adapter the first thing you need to flash it with zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nThen we need to install the ziqbee2mqtt software on the  Raspberry PI. Connect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\nInstall zigbee2MQTT:\\n```bash\\n# Setup Node.js repository\\nsudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\\n\\n# NOTE 1: If you see the message below please follow: https://gist.github.com/Koenkk/11fe6d4845f5275a2a8791d04ea223cb.\\n# ## You appear to be running on ARMv6 hardware. Unfortunately this is not currently supported by the NodeSource Linux distributions. Please use the 'linux-armv6l' binary tarballs available directly from nodejs.org for Node.js 4 and later.\\n# IMPORTANT: In this case instead of the apt-get install mentioned below; do: sudo apt-get install -y git make g++ gcc\\n\\n# NOTE 2: On x86, Node.js 10 may not work. It's recommended to install an unofficial Node.js 14 build which can be found here: https://unofficial-builds.nodejs.org/download/release/ (e.g. v14.16.0)\\n\\n# Install Node.js;\\nsudo apt-get install -y nodejs git make g++ gcc\\n\\n# Verify that the correct nodejs and npm (automatically installed with nodejs)\\n# version has been installed\\nnode --version  # Should output v10.X, v12.X, v14.X or v15.X\\nnpm --version  # Should output 6.X or 7.X\\n\\n# Clone Zigbee2MQTT repository\\nsudo git clone https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\nsudo chown -R ubuntu:ubuntu /opt/zigbee2mqtt\\n\\n# Install dependencies (as user \\\"ubuntu\\\")\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\nThen you need to configure it. Open configuration file:\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\nAnd paste this:\\n```\\npermit_join: true\\nmqtt:\\n  # MQTT base topic for Zigbee2MQTT MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n```\\nNow you can run zigbee2mqtt:\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n## Pairing device\\n\\nThen you need to pair your sensor. For that just long press the power button until it starts to blink (zigbee2MQTT must be launched). After sensor connects you will see the message like:\\n```\\nZigbee2MQTT:info  2019-11-09T12:19:56: Successfully interviewed '0x00158d0001dc126a', device has successfully been paired\\n```\\n> Remember this number `0x00158d0001dc126a` it will be the topic name for your sensor's data.\\nThen open configuration file again and set `permit_join: false`.\\n\\nThen lets make a service. Create the file:\\n```bash\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\nAdd the following to this file:\\n```\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\n# Or use StandardOutput=null if you don't want Zigbee2MQTT messages filling syslog, for more options see systemd.exec(5)\\nStandardError=inherit\\nRestart=always\\nUser=pi\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nVerify that the configuration works:\\n\\n```bash\\nsudo systemctl start zigbee2mqtt\\n```\\n\\n```bash\\nsystemctl status zigbee2mqtt.service\\n```\\n\\nOutput should look like:\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\nNow that everything works, we want systemctl to start Zigbee2MQTT automatically on boot, this can be done by executing:\\n\\n```bash\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n## Home Assistant Setup\\n\\nOpen Home Assistant configuration file:\\n\\n```bash\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add the following to setup MQTT broker and sensor (replace `topic_name` with the topic name from previous step):\\n\\n```\\n# MQTT broker setup\\nmqtt:\\n  broker: localhost\\n  port: 1883\\n\\n# Sensor setup\\nsensor:\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Humidity\\\"\\n    unit_of_measurement: '%'\\n    value_template: \\\"{{ value_json.humidity }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Temperature\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.temperature }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Pressure\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.pressure }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Battery\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.battery }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Link Quality\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.linkquality }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Voltage\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.voltage }}\\\"\\n\\n# Trigger on receiving data\\nautomation:\\n  - alias: \\\"send_datalog_climate\\\"\\n    trigger:\\n      platform: mqtt\\n      topic: \\\"zigbee2mqtt/0x00158d0006bcd022\\\"\\n    action:\\n      service: shell_command.send_datalog_climate\\n\\n# Shell command that will run on the trigger\\nshell_command:\\n  send_datalog_climate: 'python3 python_scripts/send_datalog.py temperature={{ states(\\\"sensor.mqtt_climate_temperature\\\")  }} humidity={{ states(\\\"sensor.mqtt_climate_humidity\\\") }} pressure={{ states(\\\"sensor.mqtt_pressure\\\") }} battery={{ states(\\\"sensor.mqtt_climate_battery\\\") }} linkquality={{ states(\\\"sensor.mqtt_climate_link_quality\\\") }} voltage={{ states(\\\"sensor.mqtt_climate_voltage\\\") }}'\\n```\\n\\nThen start Home Assistant with new configuration:\\n\\n```bash\\ncd /srv/homeassistant\\nhass\\n```\\n\\nTo see the sensor data in Home Assistant you need to add it. For that open the browser on your computer and go to:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nPress on three dots on the right side and choose `Edit Dashboard`\\n\\n![edit_dashboard](../images/home-assistant/dashboard.png)\\n\\nThen press `Add Card`\\n\\n![card](../images/home-assistant/card.png)\\n\\nGo to `By Entity` and tick all sensors that you need\\n\\n![sensors](../images/home-assistant/sensors.png)\\n\\nPress continue and you will be able to see sensor data at the homepage (you may see `unknown` before sensor send new data)\\n\\nIn a similar way you can add card for Robonomics Service. With this you can start or stop the servise or send current measurements with `run action` button.\\n\\n![action](../images/home-assistant/datalog.png)\\n\\nYou homepage will look like this\\n\\n![home](../images/home-assistant/home.png)\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. You can decrypt the data with script [decrypt.py](https://github.com/airalab/robonomics-smarthome/blob/main/python_scripts/decrypt.py), download it:\\n\\n```bash\\ncd /srv/homeassistant/python_scripts\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\n```\\nAnd run with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"e32ae24eb0b2fffd551ccccb2d03c640\",\"title\":\"Passing dynamic parameters\",\"path\":\"/docs/ja/hardware-passing-dynamic-parameters/\",\"content\":\"\\nIn [previous](/docs/connect-simple-cps/) example we discussed how to create a simple CPS with Arduino. Our first CPS is able to do only one task: to blink a led. We suggest you to get through the first lesson. Now let's expand the example and teach our board to blink blue or red led depending on objective parameter.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_with_args).\\n\\n\\n## Arduino\\n\\nThe only difference in Arduino source code is instead of subscribing to one topic now we subscribe to `/blink_red` and `/blink_blue` topics\\n\\n```c\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void blinkRedCb(const std_msgs::Empty& msg) {\\n    blink(13, 500);\\n    blink(13, 500);\\n    blink(13, 500);\\n  }\\n\\n  void blinkBlueCb(const std_msgs::Empty& msg) {\\n    blink(12, 500);\\n    blink(12, 500);\\n    blink(12, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> subRed(\\\"blink_red\\\", &blinkRedCb);\\n  ros::Subscriber<std_msgs::Empty> subBlue(\\\"blink_blue\\\", &blinkBlueCb);\\n\\n  void setup()\\n  {\\n    pinMode(13, OUTPUT);\\n    pinMode(12, OUTPUT);\\n\\n    nh.initNode();\\n    nh.subscribe(subRed);\\n    nh.subscribe(subBlue);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n<!-- Here is the diagram of all connections:\\n\\n.. image:: ../img/6.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\n\\n## ROS\\n\\nWe can pass arguments via objective which points to rosbag file. Have a look at `blink.py` script. The main difference is `blink()` method:\\n\\n```python\\ndef blink(self, data):\\n  if data.data == \\\"blue\\\":\\n      rospy.loginfo(\\\"Blinking blue...\\\")\\n      self.blink_blue.publish(Empty())\\n\\n  if data.data == \\\"red\\\":\\n      rospy.loginfo(\\\"Blinking red...\\\")\\n      self.blink_red.publish(Empty())\\n\\n  rospy.wait_for_service('/liability/finish')\\n  fin = rospy.ServiceProxy('/liability/finish', FinishLiability)\\n  fin(FinishLiabilityRequest(address=self.liability, success=True))\\n  rospy.loginfo(\\\"Finished\\\")\\n```\\n\\nNow `/blink` topic has a `String` type. You can find prepared rosbags in `rosbag` folder.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh/). Do not forget to add `COM1` port in settings. Run the following command:\\n\\n```\\n$ rosrun arduino_with_args blink.py\\n```\\n\\nAlso we need to add rosbag files to IPFS:\\n\\n```\\n$ ipfs add rosbag/blink_blue.bag\\n$ ipfs add rosbag/blink_red.bag\\n```\\n\\n**Before the next step you should approve XRT tokens on the Factory.**\\n\\nThe last step is to build Dapp and launch. Take a look at the previous [lesson](/docs/connect-simple-cps/). To make Arduino blink the blue led send blue demand and blue offer messages. For the red one send corresponding messages.\\n\\nThat's it! Now you are able to pass dynamic parameters to your cyber-physical system agent!\"}},{\"node\":{\"id\":\"9f28c46934d908f9f908c9a8ebf514ae\",\"title\":\"Connect an Air Pollution Sensor\",\"path\":\"/docs/ja/hardware-connect-sensor/\",\"content\":\"\\nIn this lesson you are going to learn how to connect your sensor to the network and make it publish data. You will see how it is easy to become a member of a global sensor network!\\n\\nSource code is located [here](https://github.com/airalab/robonomics_tutorials/tree/master/sensor_city).\\n\\nIn this section we are not going to create a liability contract. Instead we will teach Arduino with sensors to publish the data by a request. All measurements will be published as a Result message.\\n\\n## Arduino\\n\\nLet's begin with an Arduino circuit. You need the following components:\\n\\n* Arduino Uno\\n* Optical Dust Sensor Sharp GP2Y1010AU0F\\n* Gas Sensor MQ-2\\n* Gas Sensor MQ-7\\n* Resistor 150 Ohm\\n* Capacitor 220 uF\\n* Wires\\n\\nConnect all parts as described below:\\n\\n<!-- .. image:: ../img/7.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\nA firmware for Arduino Uno is in `sensor_city/scetches` folder. In order to upload it to the board use [Arduino IDE](https://www.arduino.cc/en/Main/Software).\\n\\n<!-- .. image:: ../img/8.png\\n   :alt: Arduino IDE\\n   :align: center\\n -->\\n\\n## Aira\\n\\nThe following steps are performed in Aira client. You can download the latest image from [this page](https://github.com/airalab/aira/releases). It's convenient to [connect via SSH](/docs/aira-connecting-via-ssh/).\\n\\nAfter you have imported the image to VirtualBox, connect Arduino via USB to your PC and enable serial port forwarding. You should check `Enable Serial Port` and assign `/dev/ttyACM0` in `Path/Address`. Inside the virtual machine `/dev/ttyS0` refers to your external Arduino.\\n\\n<!-- .. image:: ../img/9.png\\n   :alt: Set a port\\n   :align: center -->\\n\\nFinally launch the image and run these command:\\n\\n```\\n$ roslaunch sensor_city publish_data.launch\\n```\\n\\n**Check out the source code to learn how it works under the hood!**\\n\\nNow Aira patiently waits for a signal to publish the measurements. Go to [Dapp](https://dev.aira.life/smart-city/#/) and click on `Broadcast signal`. You should see the data!\"}},{\"node\":{\"id\":\"c2a11bf3f9f324ccc064a91b7baf8c3b\",\"title\":\"Connect Sensors with Xiaomi Gateway\",\"path\":\"/docs/ru/xiaomi-gateway/\",\"content\":\"\\nYou need your Xiaomi gateway along with all the sensors to be connected to the Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your hub (it must be in connecting mode which is achieved via a long press of the power button) and follow instructions in the app. After you add the gateway, you need to add sensors: press on your gateway, then go to `Child device` and press `+`. Find required device and follow the instructions on the screen. For more details refer to the user manual of your Xiaomi Gateway hub.\\n\\n## Add Gateway to Home Assistant\\nBe sure that you're logged in you raspberry as `homeassistant` user, if not do the following:\\n```bash\\nsudo -u homeassistant -H -s\\n```\\n\\nIn your Home Assistant:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations` and press `Add Intagration`. There you need to Find `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Hub (Aqara Hub in this example):\\n\\n![hub](../images/home-assistant/hub.png)\\n\\nPress `Submit` and you will be able to see your gateway in Integrations page.\\n\\n## Add Gateway to Home Assistant using Homekit Controller integration\\n\\nYou can also connect your hub to Aqara Home app on ios and then add it to Home Assistant through Homekit Controller integration. \\n\\nAdd your hub to the app using `add device` or `+` button. Right after your hub added to Aqara Home app you will be proposed to bind it with your Homekit account. \\n\\n![homekit](../images/home-assistant/homekit.png)\\n\\nWhen you see a menu like the picture, open your Home Assistant page:\\n\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations`. Here you can find your device discovered and click `Configure` button to add it by Homekit Controller integration. You have to enter pairing code of your device, which you can find on the sticker on your device.\\n\\n![configure1](../images/home-assistant/configure1.png)\\n\\n![configure2](../images/home-assistant/configure2.png)\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"653cfe3e804d77e003753e00803ba26a\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ru/xcm-robobank/\",\"content\":\"\\n\\nMain goal of this project is simplification of parachain runtime development, when cross-chain messages are used. \\nAllows to develop runtime code with integration tests with high repeatablility and simple usage.\\nAutomates building, construction of pre-set network configuration (f.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and running tests, sending messages, using call to runtime, constructed and composed in Python.\\n\\nXCM Testsuite is used for testing production cycle for Robobank - the set of Substrate pallets, allowing robots to register in external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside Robonomics network with all needed infrastructure, but, in the same time, offer their services in any external parachain.\\n\\nVideo example is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe demo scenary main steps are:\\n- launch relay chain and two parachains in pack of 6 processes\\n- setup XCM messages channels between parachains\\n- register a robot in both parachains\\n- create order for this robot in client parachain (reserving payment for completion of order)\\n- send XCM message to Robonomica\\n- creating \\\"mirrored\\\" order record in Robonomica parachain\\n- accept order by robot in Robonomica\\n- send XCM message about order acceptance back to client parachain\\n- accept order in client parachain (reserving penalty fee for no-completion of order until deadline)\\n- complete order by robot in Robonomica\\n- send XCM message about order completion to client parachain\\n- settle all payments (client payment is transfered to robot, as well as penalty fee)\\n- close order\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nContains code of runtime pallets being tested.\\nAs in original node code of parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] First build can take a lot of time, up to several hours on weak machines\\n\\n[NOTE] Script works with FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains\\n\\n[NOTE] By default script re-creates same environment every launch, by removing all previous states. this behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for relay chain and for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (f.e. 4 validators of some stable Rococo revision)\\n    - collators for parachain-100 (f.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (f.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing to study any chain using frontend apps (explorer, DApp)\\n - keep printing all output of all chains to console\\n\\n[WARNING] After launch, wait until a network is up, make sure that blocks finalization started, and parachains are registered. These processes require approximately 5 min (50 blocks x 6 sec ).\\n\\n## Checking if all works \\n\\nUse standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, consensus started off, we can proceed to run test cases (in a new terminal)\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to relay.\\nWhen relay receives message it will transfer 15 tokens from `para 100` account to the Charlie's.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to `sibling 200` one.\\nBefore that, it endows `subl 100` account with 1000 tokens and  establish a channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace balances and authorities with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit code. The above command will rebuild project and update collator node before start.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent version of software. For this change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\"}},{\"node\":{\"id\":\"5922f7ab6a5688e09512c16082972dce\",\"title\":\"Lesson 4, Robonomics parachain in practice\",\"path\":\"/docs/ru/wschool2021-robonomics-parachain-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\nRobonomics parachain is not a general purpose parachain on Polkadot ecosystem. The target of Robonomics\\nis building economy of machines, the parachain in this scope of aims helps to integrate Polkadot ecosystem\\nwith IoT, Smart Cities and Industry 4.0 concepts.\\n\\n## Requirements\\n\\n* Docker, please [install it](https://docs.docker.com/engine/install/).\\n* Polkadot-launch, please [install it](https://github.com/paritytech/polkadot-launch#install) (optionally, if you don't want to use docker).\\n\\n## Launch the relay\\n\\nThe relay chain is a core of Polkadot, it provides [shared security](https://wiki.polkadot.network/docs/en/learn-security)\\nfor all child parachains and implements message passing mechanics for them. Let's launch local instance of Rococo (polkadot testnet)\\nrelay chain with two robonomics-based parachains as a childs. I'll use prepared [Docker image tag: \\\"winter-school-2\\\"](https://hub.docker.com/layers/robonomics/robonomics/winter-school-2/images/sha256-92f4795262f3ded3e6a153999d2777c4009106a7d37fd29969ebf1c3a262dc85?context=explore) but all source code of examples\\navailable in [Robonomics GitHub](https://github.com/airalab/robonomics/tree/master/scripts/polkadot-launch).\\n```\\ndocker run -ti --rm --network host robonomics/robonomics:winter-school-2 bash\\ncd polkadot-launch/\\n./launch.sh\\n```\\n\\n<Asciinema vid=\\\"419Jrg22ziFfMFPZlh2WtiLvg\\\"/>\\n\\nIt could take a time, but be partient. As result you should have three chain instances at ports:\\n\\n* `9944` - local rococo relay chain.\\n* `9988` - robonomics parachain with `id=100`\\n* `9989` - robonomics parachain with `id=200`\\n\\nIf you use remote server, you need to create some ssh tunnels on local machine:\\n```\\nssh -f -N -L 9944:127.0.0.1:9944 root@REMOTE_SERVER_IP\\nssh -f -N -L 9988:127.0.0.1:9988 root@REMOTE_SERVER_IP\\nssh -f -N -L 9989:127.0.0.1:9989 root@REMOTE_SERVER_IP\\n```\\nAfter that, you can use `ws://127.0.0.1:9944` for relaychain, `ws://127.0.0.1:9988`and `ws://127.0.0.1:9989` for parachains in https://parachain.robonomics.network/\\n\\n![relay](../images/ws_lesson4/upcoming.jpg)\\n\\nSome time ago parachains should be registered.\\n\\n![relay2](../images/ws_lesson4/parachains.jpg)\\n\\nAnd start to produce blocks.\\n\\n![relay3](../images/ws_lesson4/parachains2.jpg)\\n\\nAs next step let's create HRMP channel to pass messages between parachains. I'll use `sudo` module call on relay chain page.\\n\\n![hrmp](../images/ws_lesson4/hrmp.jpg)\\n\\nWhen channel created, the XCM calls is available. Let's use `datalogXcm` pallet - a XCM version of `datalog` pallet in first parachain.\\n\\n![datalogXcmSend](../images/ws_lesson4/datalogXcmSend.jpg)\\n\\nAs result message on second parachain will call `datalog` pallet and write data on chain.\\n\\n![datalogXcmRecv](../images/ws_lesson4/datalogXcmRecv.jpg)\\n\\nAs result, this example demonstrate how XCM could be used for cross chain usage of standard robonomics pallets.\\n\"}},{\"node\":{\"id\":\"b61cd25ef2aa518313eb6a03ee50f720\",\"title\":\"Lesson 3, Robonomics IO in practice\",\"path\":\"/docs/ru/wschool2021-robonomics-io-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\n## Requirements\\n\\n* the Docker is required, please [install](https://docs.docker.com/engine/install/) it first.\\n* the [Nova SDS011](https://aqicn.org/sensor/sds011) sensor is *optional*.\\n\\n### SDS011 check (optional)\\n\\nIf you have connected SDS011 sensor then please check that it presented in `/dev` and have correct access rights.\\n\\n<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>\\n\\n## Quick start\\n\\nWhen docker is installed let's launch robonomics docker image from [Official repository](https://hub.docker.com/r/robonomics/robonomics). I'll use `winter-school` tag during this lesson.\\n\\n<Asciinema vid=\\\"wM43jozIVfcRmt52ENrJ6yPlH\\\"/>\\n\\nWhen docker image is ready let's try to read a data using `robonomics io` command (optionaд if you have SDS011 device).\\n\\n<Asciinema vid=\\\"iztt22tKGaV8wq3cMXY1oUEYv\\\"/>\\n\\nIf you have no SDS011 sensor then feel free to use virtual SDS011 sensor available in the same docker container via `vsds011.sh`. And everywhere in folloding command please use it as transparent replacement for physical sensor.\\n\\n<Asciinema vid=\\\"GCkSiJBA1DgpLAAHiMhIOSpgG\\\"/>\\n\\nThe Robonomics IO subsystem have two kind of commands:\\n\\n* `read` - get data from device that support read access;\\n* `write` - write data into device that support write access.\\n\\nSome devices support them both, in that case devices presented in both command arguments.\\n\\n> For example, virtual device `ipfs` supports `read` data from IPFS by hash as same as `write` data into IPFS.\\n\\nFull list of supported devices is possible to get running `robonomics io read` or `robonomics io write` without arguments.\\n\\n## IPFS access\\n\\nOn next step runned IPFS daemon is required. For this purpose let's run init IPFS and run daemon on dedicated\\nterminal tab.\\n\\n<Asciinema vid=\\\"ir6ziXSBUDrRltTmNxg7sdXVY\\\"/>\\n\\nWhen daemon launched is possible to connect docker image in separate tab and use `robonomics io` for writing and reading a data.\\n\\n<Asciinema vid=\\\"ZtwcmpB9Lhum2Sc221QmNwHG4\\\"/>\\n\\nThe output forwarding is also works here, that means it's possible to forward SDS011 sensor data into IPFS using `|` (pipe) symbol in console. Let's try to do it.\\n\\n<Asciinema vid=\\\"XS0QESWG7f8ELsQe1bGQllb9O\\\"/>\\n\\nWhere JSON data from SDS011 forwarded as input for IPFS writer and result is published on stdout.\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs\\n```\\n\\nThis approach permits engineer extrimely quickly make a simple program just combine a primitive readers and writers from `robonomics io` tools.\\n\\n```bash\\nrobonomics io read sds011 | gz | robonomics io write pubsub my-sensor-data\\n```\\n\\n## Robonomics Datalog\\n\\n> The target of Robonomics [Datalog](https://crates.robonomics.network/robonomics_protocol/datalog/index.html) is data blockchainization. This pallet provides function to store custom data on blockchain to make it immutable, impossible to change in future.\\n\\nFor the final part of this lesson runned robonomics node is required. Development mode is preffered because of quick block time and already distributed balances on preset accounts. Let's launch it on separate terminal tab in the same container.\\n\\n<Asciinema vid=\\\"QnN9l0sdaZZOyK9ah0DntvCXt\\\"/>\\n\\nThen private seed also required as argument for `datalog` device. This seed is used to sign transaction and presents account as a sender. Let's generate it using embedded `robonomics key` command.\\n\\n<Asciinema vid=\\\"4Cdfl9F0GgjNWv1c1ZcTBBktF\\\"/>\\n\\nSave generated address and seed on safe place for use it later.\\n\\nCurrently address balance is zero and the network don't permits to send transactions from this address. To fix it let's transfer a bit of tokens from `Alice` account. I'll use Robonomics Portal on https://parachain.robonomics.network connected to local node with address `ws://127.0.0.1:9944`.\\n\\n![portal transfer](../images/ws_lesson3/tran.jpg)\\n\\nAnd then `datalog` device could be used for saving any data on blockchain. The key `-s` is used to set secret seed of account. Account should have non-zero balance to send transactions.\\n\\n<Asciinema vid=\\\"FzERH9TmFB8oRuas8ZU202Pv8\\\"/>\\n\\nIf every thing is correct the you should see `Datalog` event on `Explorer` page of Robonomics portal.\\n\\n![portal datalog](../images/ws_lesson3/datalog.jpg)\\n\\nThe final step is a bit complex but it's good to try use all knowledge of this lesson. Let's make a simple program\\nthat collects data from SDS011 sensor (or file), pack it into IPFS and then send `datalog` transaction to save hash on blockchain.\\n\\n```\\nSDS011 -> IPFS -> Blockchain\\n```\\n\\nIt's easy to implement using Robonomics IO, let's do that.\\n\\n<Asciinema vid=\\\"MTpiawGo8DKEn081OozbYb5mU\\\"/>\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n\\n\\nIf everything well the `Datalog` event with IPFS hash should be presented.\\n\\n![portal datalog complex](../images/ws_lesson3/datalog_complex.jpg)\"}},{\"node\":{\"id\":\"d0fc95e8d40b0b2edd5dce170db9885c\",\"title\":\"Lesson 2, Robonomics AIRA overview\",\"path\":\"/docs/ru/wschool2021-robonomics-github-overview/\",\"content\":\"\\n## Step 1: AIRA Installation on VirtualBox\\n\\nhttps://youtu.be/ISKilRfY3Ow\\n\\n## Step 2: Connecting Aira via SSH\\n\\nhttps://youtu.be/W0rOcRA2sEc\\n\\n## Step 3: Interact with AIRA\\n\\nhttps://youtu.be/fhRTF2mddfU\"}},{\"node\":{\"id\":\"eb860b2d92e7c0308e2c50355c842b57\",\"title\":\"Robonomics Winter School 2021 introduction\",\"path\":\"/docs/ru/wschool2021-intro/\",\"content\":\"\\nRobonomics Winter School 2021 is held from 10 to 24 February **online**. It's **free**.\\n\\nWe are publishing **lessons** online in different ways: text here in Wiki, video on our [YouTube channel](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ), announce in [Twitter account](https://twitter.com/AIRA_Robonomics). Please, keep in mind, that video lessons and text lessons are not the same. For the start we plan to publish two language versions: English and Russian. \\n\\nJoin us, take your steps through the lessons, **discuss and ask questions** in [Discord](https://discord.gg/5UWNGNaAUf).\\n\\n## Watch opening ceremony\\n\\nhttps://youtu.be/kQaSwNYHJQ8\\n\\n## Basic information\\n\\nTake a look at [page about school](https://robonomics.network/blog/winter-robonomics-school/) on our website. We are collecting there all basic information: shedule, infopartners, links.\\n\\n## Links, links, links\\n\\nLets repeat what links do we have for following Robonomics Winter School 2021:\\n\\n- [Summary on website](https://robonomics.network/blog/winter-robonomics-school/)\\n- Wiki for text lessons, YOU ARE HERE 🤓\\n- [Video lessons](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ)\\n- [Fast announce on Twitter](https://twitter.com/AIRA_Robonomics)\\n- [Questions, Discussions, Quizes in Discord](https://discord.gg/5UWNGNaAUf)\\n\\n**Lets start learn Robonomics!**\"}},{\"node\":{\"id\":\"61ad524f06777c580d9eeac4106fcc4f\",\"title\":\"Lesson 1, Connect robotics to user app\",\"path\":\"/docs/ru/wschool2021-connect-robotics-to-user-app/\",\"content\":\"\\nhttps://youtu.be/NOQxyojvaao\\n\\n- [Reference tutorial on Wiki](https://wiki.robonomics.network/docs/get-weather-on-fuji-mountain/)\\n- [Dapp](https://dapp.robonomics.network/#/)\"}},{\"node\":{\"id\":\"594be39ba5f64870ee24748a04b9071e\",\"title\":\"Lesson 5, Connectivity\",\"path\":\"/docs/ru/wschool2021-connectivity-service/\",\"content\":\"\\n## IoT as a Multiple Pie\\n\\n* Device Software\\n    * FreeRTOS\\n    * ESP/Arduino\\n    * Single-board computers (RPi, LattePanda etc)\\n* Connectivity\\n    * IoT Hub\\n    * IoT Manager\\n* Analytics Services\\n    * AWS\\n    * Google Cloud IoT Core\\n    * ThingsBoard\\n\\nAs a rule, most are not interested in sensors and servers, but data analytics.\\nTo get it, you need to decide which device to use, how to work with it and where to connect\\n\\n## Device Software\\n\\nConsider the example of a home weather station. It is necessary to collect data on air pollution (SDS011), temperature and humidity (BME). The ESP8266 microcontroller can handle this task.\\n\\nRequirements:\\n\\n* Correctly read data from sensors\\n* Have a unique identifier\\n* Transfer data to a known server\\n* Provide digital signature of data (optional)\\n\\nYou can find the current firmware [here](https://github.com/LoSk-p/sensors-software/tree/366b19bf447a5fc19220ef89eab0f2440f8db1c2)\\n\\n## What is Connectivity? \\n\\nIn the IoT world, connectivity refers to the connection of various IoT devices to the Internet to send data and / or control the device.\\n\\nWell-known architectural solutions can be roughly divided into 3 groups:\\n\\n* Fully decentralized. For example, devices are connected by a mesh network. Not suitable for wide area networks due to high hardware requirements\\n* Centralized. For example, AWS. Provides a single entry point and ease of connection, but there is a high risk of failure in case of server problems\\n* Hybrid. For example, [Robonomics Connectivity](https://github.com/airalab/sensors-connectivity). Provides an address for devices on a \\\"local\\\" network and publishes data to a distributed IPFS message channel\\n\\n## Comparison of AWS and Robonomics Connectivity\\n\\n| Management services \\t| AWS                               \\t|               Robonomics              \\t|\\n|---------------------\\t|-----------------------------------\\t|---------------------------------------\\t|\\n| Transaction type    \\t| Technical                         \\t| Technical and economic                \\t|\\n| Security            \\t| IT-company cloud control          \\t| Polkadot and Ethereum                 \\t|\\n| Protocol            \\t| HTTPS, MQTT                       \\t| IPFS, Robonomics                      \\t|\\n| Ecosystem           \\t| Private                           \\t| Shared                                \\t|\\n| Access to DeFi      \\t| No                                \\t| Yes                                   \\t|\\n| Costs               \\t| Pushing data - $1-2 a sensor      \\t| Pushing data - $0                     \\t|\\n|                     \\t| Shadow         - from $10 a month \\t| Digital Twin    - $0,01 a transaction \\t|\\n\\n## Installing Connectivity on Aira\\n\\nhttps://www.youtube.com/watch?v=JbBNMHAzJKM\\n\\n### Requirements\\n\\n* [VirtualBox 6.1](https://www.virtualbox.org/wiki/Downloads) and above\\n* [Aira OS ova image](https://static.aira.life/ova/airaos-21.03_robonomics-winter-school.ova)\\n\\nImport Aira image in VirtualBox as described [here](/docs/aira-installation-on-vb/)\\n\\nSet up a connection over [SSH](/docs/aira-connecting-via-ssh/)\\n\\nWhen everything is set and you successfully log in via SSH, let's clone the main package and build it \\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\ngit checkout v0.9\\nnix build -f release.nix\\n```\\n\\nNow let's create a copy of the default configuration file for later usage. \\nTo learn about all the options check [this article](/docs/configuration-options-description/) out.\\nThen launch the package with `roslaunch`\\n\\n```\\ncp config/default.json config/my.json\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n## Connect Sensor to Connectivity\\n\\nhttps://www.youtube.com/watch?v=yxqxBk-6bpI\\n\\n### Requirements\\n\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) sensor \\n* [Yarn Packet Manager](https://yarnpkg.com/getting-started/install)\\n\\nNow let's connect a real sensor, forward USB port to the virtual machine, set up a map and look at our own measurements\\n\\nFirst, stop the Aira OS if it was running and add a corresponding USB device\\n\\n![VB USB Forwarding](../images/vb_forward_usb.jpg)\\n\\nStart the VM, connect via SSH and set `comstation/port` option according to your USB device in the VM. Also enable `comstation` and set your latitude and longitude. In the end `config/my.json` should look like this:\\n\\n```\\n{\\n   \\\"general\\\":{\\n      \\\"publish_interval\\\":30\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":0,\\n      \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"connectivity.robonomics.network\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\":{\\n      \\\"enable\\\":false\\n   },\\n   \\\"robonomics\\\":{\\n      \\\"enable\\\":true,\\n      \\\"ipfs_provider\\\":\\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\":\\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\":{\\n      \\\"enable\\\":false,\\n      \\\"path\\\":\\\"\\\",\\n      \\\"suri\\\":\\\"\\\",\\n      \\\"remote\\\":\\\"wss://substrate.ipci.io\\\",\\n      \\\"dump_interval\\\":3600,\\n      \\\"temporal_username\\\":\\\"\\\",\\n      \\\"temporal_password\\\":\\\"\\\"\\n   },\\n   \\\"dev\\\":{\\n      \\\"sentry\\\":\\\"\\\"\\n   }\\n}\\n```\\n\\n> If you don't have a real sensor, you can use `sensors-connectivity/utils/virtual-sensor.py` script to emulate one\\n> \\n> Enable `HTTPStation` and disable `COMStation` by changing the configuration file as:\\n> ```\\n> {\\n>    \\\"general\\\":{\\n>       \\\"publish_interval\\\":30\\n>    },\\n>    \\\"comstation\\\":{\\n>       \\\"enable\\\":false,\\n>       \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n>       \\\"work_period\\\":0,\\n>       \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n>       \\\"public_key\\\":\\\"\\\"\\n>    },\\n>    \\\"httpstation\\\":{\\n>       \\\"enable\\\":true,\\n>       \\\"port\\\":8001\\n>    },\\n>    ...\\n> }\\n> ```\\n>\\n> and launching `utils/virtual-sensor.py` in a dedicated terminal in the VM\\n\\nSave the file and launch connectivity from `sensors-connectivity` folder:\\n\\n```\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\nYou should see first measurements in the console output\\n\\nLook for your IPFS ID in the VM. It appears right after booting the image or via `ipfs id` command. We will need it later.\\n\\nNow let's set up our own instance of the map. On your laptop (not in the VM) clone [this](https://github.com/airalab/sensors.robonomics.network) repository and build the app:\\n\\n```\\ngit clone https://github.com/airalab/sensors.robonomics.network\\ncd sensors.robonomics.network\\nyarn install\\n```\\n\\nEdit `src/agents.json` file and put your IPFS ID. For example:\\n\\n```\\n[\\n  \\\"12D3KooWSCFAD3Lpew1HijniE6oFTuo4jsMwHzF87wNnXkpCRYWn\\\"\\n]\\n```\\n\\nLaunch the map:\\n\\n```\\nyarn serve\\n```\\n\\nGo to [http://localhost:8080/](http://localhost:8080/) or the address yarn gave you and look for the sensor.\\n\\n## Practice\\n\\n### Trajectory 1. Flash a sensor ESP + SDS011\\n\\nRequirements:\\n\\n* ESP8266\\n* At least one of sensors SDS011, BME280, HTU21D\\n\\nUse the [instruction](https://wiki.robonomics.network/docs/connect-sensor-to-robonomics/) to connect a sensor to Robonomics Connectivity. \\n\\nCheck that your sensor appears on our [map](https://sensors.robonomics.network/#/).\\n\\n### Trajectory 2. Launch Connectivity\\n\\nRequirements:\\n\\n* ROS\\n* Python\\n* Nix (optional)\\n\\nBuild and launch [sensors-connectivity](https://github.com/airalab/sensors-connectivity#get-a-package-and-build)\\n\\n> How it build, install [here](https://wiki.robonomics.network/docs/iot-sensors-connectivity/) and configure [here](https://wiki.robonomics.network/docs/configuration-options-description/)\\n\\nGeneral scheme of the package:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nThe choice is proposed to implement either a new station, for example, a random number generator, or a new feeder, for example, displaying a string on the screen.\\n\\nInterface `IStation` [here](https://github.com/airalab/sensors-connectivity/blob/master/src/stations/istation.py#L73).\\n\\nInterface `IFeeder` [here](https://github.com/airalab/sensors-connectivity/blob/master/src/feeders/ifeeder.py#L5)\\n\\n\"}},{\"node\":{\"id\":\"cac162909e00f6ed8548f14af8ea4670\",\"title\":\"Lesson 6.2, Build IoT Dapps For End Users\",\"path\":\"/docs/ru/wschool2021-build-dapp-interface/\",\"content\":\"\\n![Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot](../images/build-dapp-interface/sum.gif \\\"Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot\\\")\\n\\n## Introduction\\n\\nThis tutorial continues the previous lesson, where you have already built simple application and were focused on connecting an account to a node, sending transactions and other vital functions of the dapp. Now we will **build user-friendly interface** for this application.\\n\\n## Prerequisites\\n\\nThis tutorial is designed for people who are familiar with **HTML, CSS, JavaScript** a bit and want to learn how to apply these skills for decentralized applications.\\n\\nFor building your dapp's interface you can choose any JavaScript framework which is comfortable for you or even try to build interface without any framework. In Robonomics 2021 we use [Vue.js](https://vuejs.org) as it is quite scalable and easy to use.\\n\\n## Set up for this tutorial\\n\\nIf you start with this step and prefer to **learn by doing**, please, follow this to-do list to launch the resulting dapp from the previous lesson:\\n\\n1. Download a local Robonomics node v 0.22 from [releases page](https://github.com/airalab/robonomics/releases/tag/v0.22.0) that fits your OS. If you do not find your system in the latest release, please, find the most recent version in the previous releases.\\n\\n2. Launch the Robononomics node in the Developer mode by typing `./robonomics --dev --tmp` in your terminal.\\n\\n3. Download the Polkadot Extension for Chrome or Firefox [here](https://polkadot.js.org/extension/)\\n\\n4. Clone [this repository](https://github.com/vol4tim/example-robonomics-dapp/).\\n\\n5. Install [Yarn](https://yarnpkg.com).\\n\\n6. Install [@vue/cli](https://cli.vuejs.org/guide/installation.html)\\n\\n7. Start developing dapp with  commands in your terminal:\\n```shell\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n\\n**You should get this screen in your browser:**\\n\\n![Dapp Start](../images/build-dapp-interface/dapp-start.png \\\"Dapp Start\\\")\\n\\n\\n<details>\\n\\n  <summary>Some additional tips for launching</summary>\\n\\n  - Make sure your **node is running**:\\n    ![Example of running a Robonomics node](../images/build-dapp-interface/robonomics-node-launch.png \\\"Example of running Robonomics node\\\")\\n\\n  - In **macOS** you may need to change the **access permissions** `chmod +x robonomics`\\n\\n  - Make sure you allowed **access for Polkadot Extension**:\\n    ![Polkadot Extension giving access](../images/build-dapp-interface/polkadot-permission.png \\\"Polkadot Extension giving access\\\")\\n\\n  - If you have errors in log of the running node and dapp is not loading correctly, please, try to delete data base of dev chain: `sudo rm -rf <YOUR LOCAL PATH>/robonomics/chains/dev/db/` and restart the node. If it does not help, restart your machine.\\n\\n</details>\\n\\n## Inspecting the code\\n\\nLet's inspect the structure of the dapp to clear up what and where we can fix in order to change UI.\\n\\n```\\n.\\n├── public/\\n│   ├── favicon.ico           # Icon for your dapp\\n│   └── index.html            # The template file (injects icons links, JavaScript and CSS files for the app)\\n├── src/\\n│   ├── assets/               # Folder for images and global styles\\n│   ├── components/           # Folder with components\\n│   │   ├── Datalog.vue       # Tab 'Datalog' in dapp\\n│   │   ├── Demo.vue          # Tab 'Demo' in dapp\\n│   │   ├── Launch.vue        # Tab 'Launch' in dapp\\n│   ├── utils/                # Folder with important for app js functions (we will touch api.js in this tutorial)\\n│   ├── App.vue               # The root of our app, contains HTML, CSS, JS for the whole page. In fact it is Vue Component also\\n│   ├── main.js               # The app’s entry file, we will import here global styles\\n├── ...                       # There are config files and dependencies files, that we will not change mannually\\n├── README.md                 # You can write here any instructions for your dapp\\n\\n```\\n\\n> **The code of this tutorial is in this [repository](https://github.com/positivecrash/wscool21-ui-dapp)**\\n\\n## CSS-in-JS VS. Global stylesheets\\n\\nIn this tutorial I show how to change the interface of a small dapp from scratch without any stable library of UI components. So I will import and create not only different Vue components, but also write my own styles.\\n\\nIf your application is big or your project has the whole bunch of dapps, in future you'd better look for building library of components specifically for your project to make UI more organized and efficient ([for example, here is a tool for organizing components](https://storybook.js.org)). Or if you are okay with standart interface themes, you can use any UI Libraries of third party ([for example](https://vuetifyjs.com/)).\\n\\n## First import or where to start\\n\\nI don't have any specific design for this dapp, but I have [Brandbook](https://static.robonomics.network/assets/Robonomics-Visual-Identity.pdf) and [quit well-established](https://robonomics.network) typography, fonts, button styles etc. So for the start I will import the following css files globally:\\n\\n```\\n...\\n├── src/\\n│   ├── assets/\\n│   │   ├── styles/\\n│   │   │   ├── reset.css         # The goal is to reduce browser inconsistencies\\n│   │   │   ├── variables.css     # Contains specific values to be reused such as colors, font-names, space values etc.\\n│   │   │   ├── typography.css    # Global typography for the whole dapp\\n│   │   │   ├── animation.css     # Keyframe animations used throughout the dapp\\n...\\n\\n```\\n\\nThe content of any of these files you can write in App.vue instead, if it fits your perception better. But I recommend to import some CSS files globally for this example to keep App.vue a little bit more clear.\\n\\nImport these CSS files into your app by editing **main.js** file:\\n\\n![Import global CSS in Vue app](../images/build-dapp-interface/import-css-vue-1.png \\\"Import global CSS in Vue app\\\")\\n\\n```JS\\nimport './assets/styles/reset.css'\\nimport './assets/styles/variables.css'\\nimport './assets/styles/typography.css'\\nimport './assets/styles/animation.css'\\n```\\n\\n**Check if fonts have been changed in the dapp:**\\n\\n![Dapp Interface changing step 1](../images/build-dapp-interface/dapp-1.png \\\"Dapp Interface changing step 1\\\")\\n\\n\\n## Change layout and prettify the title\\n\\nLet's change layout of the application. As I mentioned earlier, you can write your styles directly in App.vue, but for this example I prefer to separate this process.\\n\\n- Comment or delete styles from tag `<style>` in **App.vue**\\n\\n- Create css file **app.css** in styles folder for this application and import it into **main.js**\\n\\n```JS\\nimport './assets/styles/app.css'\\n```\\n\\n<details>\\n\\n<summary>Write in app.css first basic styles for the app:</summary>\\n\\n```css\\n#app {\\n  display: grid;\\n  grid-template-rows: auto 1fr;\\n  align-items: stretch;\\n\\n  text-align: center;\\n}\\n\\nbody {\\n  background-color: var(--color-gray-light);\\n}\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Change the title of the app [App.vue]</summary>\\n\\n```html\\n<div class=\\\"top\\\">\\n    <h1>dApp Robonomics Demo</h1>\\n    <i>Winter School 2021</i>\\n    <img class=\\\"label\\\" alt=\\\"\\\" src=\\\"./assets/images/robonomics-winter-school-2021-logo.png\\\"/>\\n</div>\\n```\\n\\n</details>\\n\\n\\n\\n<details>\\n\\n<summary>Write styles for the title [app.css]</summary>\\n\\n```css\\n.top {\\n  position: relative;\\n  padding-top: var(--space);\\n  padding-bottom: calc(var(--space)*2);\\n\\n  border-bottom: 2px solid var(--color-dark);\\n  background-color: var(--color-light);\\n}\\n\\n.top h1 {\\n  font-size: 1.8rem;\\n}\\n\\n.top i {\\n  display: block;\\n}\\n\\n.top .loader-label {\\n  display: block;\\n  margin: calc(var(--space)/3) auto;\\n  max-width: 150px;\\n\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.5s FadeIn 0.3s ease forwards, 0.5s ScaleDown 0.1s ease forwards;\\n}\\n\\n.top .label {\\n  position: absolute;\\n  width: 100px;\\n  bottom: -50px;\\n  left: calc(50% - 50px);\\n  display: block;\\n\\n  transform: translateY(1rem);\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.7s FadeIn 0.5s ease forwards, 1s ScaleUp 0.5s ease forwards;\\n}\\n```\\n\\n</details>\\n\\n- Place a file with the logo of the Robonomics winter school 2021 in the folder **./src/assets/images**\\n\\n**You will get the following screen:**\\n![Dapp Interface changing step 2](../images/build-dapp-interface/dapp-2.png \\\"Dapp Interface changing step 2\\\")\\n\\n## Define styles according to the dapp's data\\n\\nNow I will wrap the app's content in `<div>` element. Also I will need different styles for different states of the dapp (loaded or not loaded).\\n\\n- Open the **App.vue** and write a wrapping element:\\n```html\\n<div class=\\\"content\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n- Find the variable `load`, it has already been defined in `<script>`.\\n- Pass an object to `v-bind:class` to dynamically toggle classes (I use shortened version `:class`):\\n```html\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\nThat's how you can easily toggle styles in your app according to the data you get. You will see the usage of this class below.\\n\\n## Define views according to the dapp's data\\n\\nLet's change the loader for the app.\\n- For this purpose I will import my component from another Robonomics project \\n\\n<details>\\n\\n<summary>./src/components/AnimatedRobonomicsLogo.vue</summary>\\n\\n```HTML\\n<template>\\n  <div class=\\\"logo-animated\\\" :style=\\\"{transform: 'scale('+scale+')'}\\\">\\n      <svg version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" width=\\\"196.9px\\\" height=\\\"170.3px\\\" viewBox=\\\"0 0 196.9 170.3\\\" style=\\\"enable-background:new 0 0 196.9 170.3;\\\" xml:space=\\\"preserve\\\">\\n\\t\\t<g transform=\\\"translate(2530 155)\\\">\\n            <path class=\\\"line\\\" d=\\\"M-2523.4,7.9l184.2,0.5l-91.7-158.1L-2523.4,7.9z\\\"/>\\n\\n            <circle class=\\\"dot\\\" cx=\\\"-2339.7\\\" cy=\\\"8.7\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2523.4\\\" cy=\\\"8.2\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2430.8\\\" cy=\\\"-148.4\\\" r=\\\"6.6\\\"/>\\n            \\n            <path class=\\\"triangle-1\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-45.8-79L-2477.3-18.3z\\\"/>\\n            <path class=\\\"triangle-2\\\" d=\\\"M-2431.2-18.1l46,0.1l-45.8-79L-2431.2-18.1z\\\"/>\\n            <path class=\\\"triangle-3\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-46-20.3L-2477.3-18.3z\\\"/>\\n          </g>\\n\\t</svg>\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style scoped>\\n    /*\\n    Global styles required:\\n    FadeIn - keyframe animation from animation: .css\\n    all --color- variables from variables.css\\n    */\\n\\n    .logo-animated {\\n        transform-origin: 0 0;\\n    }\\n\\n    .logo-animated .dot {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 1s FadeIn 0.3s ease forwards;\\n    }\\n\\n    .logo-animated .line {\\n        fill: transparent;\\n        stroke: var(--color-blue);\\n        stroke-miterlimit:10;\\n        stroke-dasharray: 700;\\n        stroke-dashoffset: 700;\\n        animation: 1s DrawSvgPath 0.5s ease-in-out forwards; \\n    }\\n\\n    .logo-animated .triangle-1 {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-1 0.1s linear infinite;\\n    }\\n\\n    .triangle-2 {\\n        fill: var(--color-violet-light);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-2 0.1s linear infinite;\\n    }\\n\\n    .triangle-3 {\\n        fill: var(--color-violet-mid);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-3 0.1s linear infinite;\\n    }\\n\\n\\n    @keyframes DrawSvgPath\\n        {\\n        to {\\n            stroke-dashoffset: 0;\\n        }\\n        }\\n\\n    @keyframes logo-triangle-1\\n    {\\n        0% { fill: var(--color-blue); }\\n        25% { fill: var(--color-blue); }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-violet-light); }\\n        100% { fill: var(--color-blue); }\\n    }\\n\\n    @keyframes logo-triangle-2\\n    {\\n        0% { fill: var(--color-violet-light); }\\n        25% { fill: #E0BDED; }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-blue); }\\n        100% { fill: var(--color-violet-light); }\\n    }\\n\\n    @keyframes logo-triangle-3\\n    {\\n        0% { fill: var(--color-violet-mid); }\\n        25% { fill: var(--color-violet-light); }\\n        50% { fill: var(--color-violet-light); }\\n        75% { fill: var(--color-violet-dark); }\\n        100% { fill: var(--color-violet-mid); }\\n    }\\n</style>\\n```\\n\\n</details>\\n\\n- Register this component in **App.vue**\\n```JS\\nexport default {\\n  components: {\\n    Loader: () => import(\\\"./components/AnimatedRobonomicsLogo\\\")\\n  }\\n}\\n```\\n- Insert it with conditional Vue directive `v-if`, using the already known variable `load`:\\n```HTML\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <Loader v-if=\\\"load\\\" />\\n  <template v-else>\\n    <!-- here will be main content of loaded dapp -->\\n  </template>\\n</div>\\n```\\n- Watch the result in browser. It has some issues that we will fix now:\\n\\n1. Loader pops up to the title (it should be in the center). Let's insert these lines to **app.css**:\\n```css\\nbody, html, #app {\\n  height: 100%;\\n  position: relative;\\n}\\n```\\n2. If your connection goes too fast, you will see just blinking loader for a moment. It may confuse a lot. Let's set a timeout for the app's responce. To do that open **api.js** and find in the function `initAccount` this code:\\n```JS\\nconst timeout = new Promise(resolve => {\\n  setTimeout(resolve, 300);\\n});\\n```\\nI set `1700` instead of `300` and check the result:\\n\\n![Dapp Interface changing step 3](../images/build-dapp-interface/dapp-3.gif \\\"Dapp Interface changing step 3\\\")\\n\\n\\n## Using reusable components\\n\\nYou have already watched how to register and use a component in the previous section about Loader, but now I want to focus on it more carefully.\\n\\nLet's change the Account section. Here I will use self-written components (box, button, icon) and the third party's one ([from Vue Polkadot Library](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon )).\\n\\n### Adding the box\\n\\n<details>\\n\\n<summary>Create Box component in ./src/components/Box.vue file </summary>\\n\\n```HTML\\n<template>\\n    <section class=\\\"box\\\" :class=\\\"classList\\\">\\n        <slot />\\n    </section>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    classList: {\\n      type: String\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .box {\\n        background-color: var(--color-light);\\n        border: 1px solid var(--color-dark);\\n        padding: calc(var(--space)*0.5) var(--space);\\n        box-shadow: 2px 2px 0 var(--color-dark);\\n        margin-bottom: calc(var(--space)*1.5);\\n    }\\n</style>\\n```\\n</details>\\n\\nNow we can use it many times throught out the dapp. Let's see this on the Account section example:\\n\\n- Register component (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Box: () => import(\\\"./components/Box\\\")\\n  }\\n}\\n```\\n\\n- Use it for the Account section with an additional class passed with prop `classList`:\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }} |\\n  <button @click=\\\"faucet\\\">\\n    faucet\\n  </button>\\n</Box>\\n```\\n\\n**Check the result:**\\n![Dapp Interface changing step 4](../images/build-dapp-interface/dapp-4.png \\\"Dapp Interface changing step 4\\\")\\n\\n### Adding the button\\n\\nYou may even not notice the button in the box that we have added. Let's fix it and add a component for buttons as it is not the only button in the app.\\n\\n<details>\\n\\n<summary>Create Button component in ./src/components/Button.vue file </summary>\\n\\n```HTML\\n<template>\\n  <button type=\\\"button\\\" :class=\\\"classList\\\" @click=\\\"onClick\\\" :disabled=\\\"disabled\\\" class=\\\"inline-block\\\">\\n    {{ label }}\\n  </button>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  components: {\\n    Icon: () => import(\\\"./Icon\\\")\\n  },\\n\\n  props: {\\n    label: {\\n      type: String,\\n    },\\n    type: {\\n      type: String,\\n      default: 'primary',\\n      validator: function (value) {\\n        return ['primary', 'secondary'].indexOf(value) !== -1;\\n      }\\n    },\\n    disabled: {\\n      type: Boolean,\\n      default: false,\\n    },\\n    size: {\\n      type: String,\\n      default: 'medium',\\n      validator: function (value) {\\n        return ['small', 'medium', 'large'].indexOf(value) !== -1;\\n      }\\n    }\\n  },\\n\\n  computed: {\\n    classList() {\\n      return {\\n        'button': true,\\n        [`${this.type}`]: true,\\n        [`button__${this.size}`]: true,\\n      };\\n    },\\n  },\\n\\n  methods: {\\n    onClick() {\\n      this.$emit('onClick');\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .button {\\n        appearance: none;\\n        -webkit-appearance: none;\\n        outline: 0;\\n        border: 0;\\n\\n        transition: 0.1s all linear;\\n\\n        padding: .15rem 0.6rem;\\n        border-width: 1px;\\n        border-style: solid;\\n        border-radius: .25rem;\\n  \\n        cursor: pointer;\\n\\n        font-family: var(--font-family);\\n        font-size: calc(var(--font-size)*0.9);\\n        line-height: 1;\\n        font-weight: 500;\\n\\n        text-transform: uppercase;\\n        letter-spacing: 1px;\\n    }   \\n\\n    .button:not([disabled]):hover {\\n    filter: saturate(1.5);\\n    }\\n\\n    .button[disabled] {\\n        cursor: default;\\n        opacity: 0.6;\\n    }\\n\\n    button.primary {\\n        border-color: var(--color-green);\\n        background-color: var(--color-green);\\n        color: var(--color-light);\\n    }\\n\\n    button.secondary {\\n        border-color: var(--color-blue);\\n        color: var(--color-blue);\\n    }\\n\\n    button.secondary:not([disabled]):hover {\\n        background-color: var(--color-blue);\\n        color: var(--color-light);\\n    }\\n\\n    .button__small {\\n        font-size: .85rem;\\n        padding: .1rem 0.45rem;\\n    }\\n\\n    .button__large {\\n        font-size: 1.2rem;\\n        padding: .5rem 1.7rem;\\n    }\\n\\n</style>\\n```\\n</details>\\n\\n\\n- Register the component (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Button: () => import(\\\"./components/Button\\\")\\n  }\\n}\\n```\\n\\n- Use it for the 'Faucet' button with props defined in the 'Button' component\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }}\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n</Box>\\n```\\n\\n**We get this view:**\\n![Dapp Interface changing step 5](../images/build-dapp-interface/dapp-5.png \\\"Dapp Interface changing step 5\\\")\\n\\nFor the Button component we have emited the click from prop with `@onClick`, so I will pay attention if the faucet function is working correctly now (the balance should change on click):\\n\\n![Dapp Interface changing step 6](../images/build-dapp-interface/dapp-6.gif \\\"Dapp Interface changing step 6\\\")\\n\\n### Adding the icon\\n\\nLet's add an icon to this button to attract more attention to this element of the interface, as user can't interact with the dapp properly without units and clicking on this button.\\n\\nFor this purpose you can use any ready Vue library for icons, I will create my own component with the icon.\\n\\n- I found an appropriate icon on [the big online archive of icons](https://www.flaticon.com).\\n- Downloaded .svg file and edited it in the vector graphics editor to make the proper size.\\n- Inserted svg as a text in the Icon.vue component.\\n\\n<details>\\n\\n<summary>Here is what I got as the Icon.vue component</summary>\\n\\n```JS\\n<template>\\n  <div class=\\\"icon inline-block\\\" :class=\\\"classList\\\">\\n    <svg v-if=\\\"icon == 'faucet'\\\" class=\\\"icon-fill\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" :width=\\\"SvgWidth(20)\\\"  viewBox=\\\"0 0 20 24.9\\\" style=\\\"enable-background:new 0 0 20 24.9;\\\" xml:space=\\\"preserve\\\">\\n      <path d=\\\"M2.7,24.9c0.2,0,2.4,0,2.4-2.4c0-2-2.2-5.2-2.2-5.2s-2.5,3.3-2.5,5.3C0.4,24.6,2.4,24.9,2.7,24.9z M20,10.8V7.2V3.1h-2.6v2.6h-3.1V1.5h2.6c0.4,0,0.8-0.3,0.8-0.8S17.3,0,16.9,0h-6.7C9.8,0,9.5,0.3,9.5,0.8s0.3,0.8,0.8,0.8h2.6v4.1H7.9c-4.7,0-6.2,3.2-6.3,4.8c0,0,0,0.1,0,0.1v2.8H0v2.1h6.2v-2.1H4.6v-2.7c0-0.3,0.4-1.9,3.3-1.9h9.6v2.1L20,10.8L20,10.8z\\\"/>\\n    </svg>\\n\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n  props: {\\n    icon: {\\n      type: String\\n    },\\n    classList: {\\n      type: String\\n    },\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n  methods: {\\n    SvgWidth(SvgWidth) {\\n      return `${SvgWidth * this.scale}px`;\\n    }\\n  }\\n};\\n</script>\\n\\n<style>\\n.icon {\\n    line-height: 1;\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\nTo use it with the button, edit the Button component.\\n\\nImport the Icon in **Button.vue**:\\n\\n```JS\\ncomponents: {\\n    Icon: () => import(\\\"./Icon\\\")\\n}\\n```\\n\\nRegister prop:\\n\\n```JS\\nprops: {\\n  icon: {\\n    type: String,\\n    default: 'none'\\n  }\\n}\\n```\\n\\nAdd the Icon to the button (we can specify different templates with `v-if` condition):\\n\\n```HTML\\n<template v-if=\\\"icon != 'none'\\\">\\n  <Icon :icon=\\\"icon\\\" />\\n  <span v-if=\\\"label != ''\\\" class=\\\"inline-block\\\">{{ label }}</span>\\n</template>\\n<template v-if=\\\"icon == 'none' & label != ''\\\">\\n  {{ label }}\\n</template>\\n```\\n\\nAdd styles:\\n\\n```CSS\\n.button .icon-fill path {\\n  fill: var(--color-light);\\n}\\n\\n.button > *:not(:last-child) {\\n  margin-right: calc(var(--space)/2);\\n}\\n\\n```\\n\\nAdd the icon prop into the button in **App.vue**:\\n\\n```HTML\\n<Button label=\\\"Faucet\\\" size=\\\"large\\\" icon=\\\"faucet\\\" @onClick=\\\"faucet\\\" />\\n```\\n\\n**Check:**\\n\\n![Dapp Interface changing step 7](../images/build-dapp-interface/dapp-7.png \\\"Dapp Interface changing step 7\\\")\\n\\n### Add the Polkadot avatar\\n\\n- Install [@vue-polkadot/vue-identicon](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon)\\n\\n- Import to App.vue:\\n```JS\\ncomponents: {\\n    Identicon: () => import(\\\"@vue-polkadot/vue-identicon\\\")\\n}\\n```\\n\\n- Insert the avatar instead of the word 'Account', pass props according to the documentation, use `account` data as a value prop:\\n```HTML\\n<Identicon\\n  :value=\\\"account\\\"\\n  :theme=\\\"'polkadot'\\\"\\n  :size=\\\"40\\\"\\n  :class=\\\"'inline-block'\\\"\\n/>\\n```\\n\\n**Check:**\\n\\n![Dapp Interface changing step 8](../images/build-dapp-interface/dapp-8.png \\\"Dapp Interface changing step 8\\\")\\n\\n## Data manipulation for the better view\\n\\nLet's cut the account address:\\n\\n- Wrap the variable `account` in the computed property:\\n\\n```JS\\ncomputed: {\\n  AccountAddress() {\\n    return this.account.slice(0, 6) + \\\"...\\\" + this.account.slice(-4);\\n  }\\n}\\n```\\n\\n- Replace the variable `account` with `AccountAddress` in the template\\n\\n**Check:**\\n\\n![Dapp Interface changing step 9](../images/build-dapp-interface/dapp-9.png \\\"Dapp Interface changing step 9\\\")\\n\\n## CSS magic\\n\\nLet's prettify the account section a little bit more:\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n              \\n  <div class=\\\"account__address\\\">\\n    <Identicon\\n      :value=\\\"account\\\"\\n      :theme=\\\"'polkadot'\\\"\\n      :size=\\\"40\\\"\\n      :class=\\\"'inline-block'\\\"\\n    />\\n\\n    <code class=\\\"inline-block\\\">{{ AccountAddress }}</code>\\n  </div>\\n  \\n  <div class=\\\"account__balance\\\">{{ balance }}</div>\\n\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n  \\n</Box>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.account {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  align-items: center;\\n  justify-items: stretch;\\n  column-gap: var(--space);\\n}\\n\\n.account__balance {\\n    font-size: 150%;\\n    font-weight: 500;\\n    font-family: var(--font-family-code);\\n    white-space: nowrap;\\n}\\n\\n.account__address > *:not(:last-child) {\\n    margin-right: calc(var(--space)/2);\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 10](../images/build-dapp-interface/dapp-10.gif \\\"Dapp Interface changing step 10\\\")\\n\\nLet's edit styles for the tabs:\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.tabs {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  margin-top: calc(var(--space)*2.5);\\n}\\n\\n.tabs button {\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  border-width: 0 0 1px;\\n  font-family: var(--font-family);\\n  font-size: calc(var(--font-size)*1.5);\\n  font-weight: 300;\\n  cursor: pointer;\\n  transition: 0.2s all linear;\\n}\\n\\n.tabs button:not(.active) {\\n  opacity: 0.5;\\n  border-color: var(--color-gray)\\n}\\n\\n.tabs-content {\\n  padding-top: var(--space);\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>Minimal template changes:</summary>\\n\\n```HTML\\n<div class=\\\"tabs-content\\\">\\n  <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" /> \\n</div>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 11](../images/build-dapp-interface/dapp-11.gif \\\"Dapp Interface changing step 11\\\")\\n\\n> Let me remind you that the finished code for this tutorial is in [this](https://github.com/positivecrash/wscool21-ui-dapp) repository. And let's shift to the next steps :)\\n\\n## Datalog\\n\\nStart with fixing UI elements that are already known in the dapp: buttons (same as we have done for the 'Faucet', but with different props).\\n\\nThen I will wrap these elements in `<fieldset>` to separate them by meaning. And I will write my own styles for the fieldset and input elements.\\n\\n<details>\\n\\n<summary>Template in Datalog.vue:</summary>\\n\\n```HTML\\n<div class=\\\"tools\\\">\\n  <fieldset>\\n    <Button label=\\\"Read data\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"read\\\" />\\n  </fieldset>\\n\\n  <fieldset>\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" class=\\\"large\\\" />\\n    <Button label=\\\"Write\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"write\\\" />\\n  </fieldset>\\n</div>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Styles for input elements in app.css - it's supposed to be global:</summary>\\n\\n```CSS\\ninput, select{\\n  padding: .3rem 0.6rem;\\n  border: 1px solid var(--color-gray);\\n  background-color: var(--color-light);\\n  border-radius: var(--radius);\\n  font-size: var(--font-size);\\n  font-family: var(--font-family-code);\\n  border-radius: .25rem;\\n  transition: 0.2s ease all;\\n}\\n\\ninput:focus {\\n  border-color: var(--color-dark);\\n}\\n\\ninput.large, select.large {\\n  font-size: 1.2rem;\\n  padding: .35rem 1rem;\\n}\\n\\n\\n.tools *, .tools fieldset:not(:last-child):after {\\n  display: inline-block;\\n  vertical-align: middle;\\n  vertical-align: -moz-middle-with-baseline;\\n  vertical-align: -webkit-baseline-middle;\\n}\\n\\n.tools fieldset {\\n  border: 0;\\n}\\n\\n.tools fieldset:not(:last-child):after {\\n  content: \\\"•\\\";\\n}\\n\\n.tools fieldset > *,  .tools > * {\\n  margin-right: calc(var(--space)/2)\\n}\\n```\\n\\n</details>\\n\\n**Let's check that everything works fine after updates:**\\n\\n![Dapp Interface changing step 12](../images/build-dapp-interface/dapp-12.gif \\\"Dapp Interface changing step 12\\\")\\n\\nWe have a datalog section through out the dapp, so I'll make a component for it.\\n\\n<details>\\n\\n<summary>I have got the following code for a new component DatalogSection.vue</summary>\\n\\n```HTML\\n<template>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <h4 class=\\\"log-title\\\">Datalog</h4>\\n\\n        <div class=\\\"log-content\\\">\\n\\n          <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n\\n          <details v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"box\\\" :open=\\\"k === 0\\\">\\n              <summary>{{ item[0] }}</summary>\\n              <pre>{{ item[1] }}</pre>\\n          </details>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    log: {\\n      type: Array\\n    }\\n  },\\n\\n}\\n\\n</script>\\n\\n<style>\\n\\n.log {\\n  text-align: left;\\n  margin: var(--space) auto;\\n  width: 100%;\\n}\\n\\n.log-content {\\n  border: 1px solid var(--color-gray);\\n  max-height: 500px;\\n  overflow-y: auto;\\n  padding: var(--space);\\n  background-color: var(--color-gray-middark);\\n  outline: 1px solid #fff;\\n  box-shadow: 0 0 60px 20px #fff inset;\\n}\\n\\n.log-title {\\n  color: var(--color-gray-dark);\\n  font-weight: 300;\\n  font-family: var(--font-family-code);\\n\\n  border-bottom: 1px solid var(--color-gray);\\n}\\n\\n.log .box {\\n  margin-bottom: var(--space);\\n}\\n\\ndetails {\\n  transition: 0.2s all ease;\\n}\\n\\ndetails summary {\\n  cursor: pointer;\\n}\\n\\ndetails.box {\\n  padding-top: 0;\\n  padding-bottom: 0;\\n}\\n\\ndetails.box[open] {\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box:focus {\\n  box-shadow: 0 0 5px var(--color-gray)\\n}\\n\\ndetails.box summary {\\n  padding-top: calc(var(--space)*0.5);\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box[open] summary {\\n  border-bottom: 1px solid var(--color-dark);\\n  margin-bottom: calc(var(--space)*0.5);\\n  font-weight: 500;\\n}\\n\\n.log details.box summary {\\n  font-family: var(--font-family-code);\\n}\\n\\n</style>\\n```\\n\\n</details>\\n\\nWhat you should pay attention to here: we pass prop `log` as an array. I assume that this multidimensional array will contain log of entries and every entry has a title (I wrote there date for all logs in the dapp) and content. We need to reformat arrays in components **Datalog.vue** and **Launch.vue**.\\n\\nNow edit **Datalog.vue**. Find method, where we get the log:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n}\\n```\\n\\nNow we have to format data in **Datalog.vue**, and pass ready log array for **DatalogSection.vue**. So let's map the log array:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray().map((item) => {\\n    return [new Date(Number(item[0])).toLocaleString(), u8aToString(item[1])]\\n  });\\n}\\n```\\n\\nWe don't need this code anymore:\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return u8aToString(v);\\n  }\\n}\\n```\\n\\n**Let's check the datalog section in Datalog tab:**\\n\\n![Dapp Interface changing step 13](../images/build-dapp-interface/dapp-13.gif \\\"Dapp Interface changing step 13\\\")\\n\\n## Launch\\n\\nFor this step, most of improvements have already been done, we just need to apply them to the template: import Button and Datalog components, remove the excessive title:\\n\\n![Dapp Interface changing step 14](../images/build-dapp-interface/dapp-14.gif \\\"Dapp Interface changing step 14\\\")\\n\\nLet's replace `select` control element with `checkbox`.\\n\\nInstead of this:\\n```HTML\\n<select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n  <option value=\\\"ON\\\">ON</option>\\n  <option value=\\\"OFF\\\">OFF</option>\\n</select>\\n```\\n\\nWrite this:\\n```HTML\\n<div class=\\\"toggler inline-block\\\">\\n  <input v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\" type=\\\"checkbox\\\" id=\\\"robot-switch\\\" />\\n  <label for=\\\"robot-switch\\\"><span></span></label>\\n</div>\\n```\\n\\n<details>\\n\\n<summary>Styles in app.css:</summary>\\n\\n```CSS\\n.toggler input { display: none; }\\n.toggler label {\\n  position: relative;\\n  display: block;\\n  width: 60px;\\n  height: 40px;\\n  border-radius: 4px;\\n  font-weight: 500;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  cursor: pointer;\\n  background-color: var(--color-gray);\\n  color: var(--color-light);\\n  text-align: center;\\n}\\n\\n.toggler label:before {\\n  content: 'Off';\\n  width: 100%;\\n  text-align: center;\\n  line-height: 40px;\\n}\\n\\n.toggler label:after {\\n  content: '';\\n  display: block;\\n  width: 6px;\\n  height: 100%;\\n  border-radius: 10px;\\n  background-color: var(--color-gray-dark);\\n\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  z-index: 10;\\n\\n  transition: 0.3s ease-out all;\\n}\\n\\n.toggler input:checked + label {\\n  background-color: var(--color-green);\\n}\\n\\n.toggler input:checked + label:before {\\n  content: 'On';\\n}\\n\\n.toggler input:checked + label:after {\\n  transform: translateX(54px);\\n  background-color: #007038;\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 15](../images/build-dapp-interface/dapp-15.gif \\\"Dapp Interface changing step 15\\\")\\n\\nI want to clarify something with the interface: with these elements we start some device. Let's visualize it. I've chosen a drone, so I will toggle classes according to `item.parameter`.\\n\\nCreate a new property in `data`:\\n```JS\\ndata() {\\n  status: false\\n}\\n```\\n\\nAssign value of `parameter` to `status` after button is clicked and tx is sent to the block:\\n```JS\\nmethods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n            this.status = this.parameter; // new line here\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n```\\n\\nWrite styles for the drone in **Launch.vue**. Don't forget `scoped` for `<style>` tag, to apply styles only for this component.\\n\\n<details>\\n\\n<summary>CSS for drone:</summary>\\n\\n```CSS\\n<style scoped>\\n.tools {\\n  position: relative;\\n  padding-left: 120px;\\n  text-align: left;\\n  display: inline-block;\\n}\\n\\n.launch-drone {\\n  position: absolute;\\n  width: 100px;\\n  left: 0;\\n  filter: grayscale(1);\\n  transition: 1s all ease-in;\\n}\\n\\n.launch-drone.on {\\n  filter: grayscale(0);\\n  animation: DroneLaunch 10s linear infinite;\\n}\\n\\n@keyframes DroneLaunch {\\n  0%, 20%, 40%, 60%, 80%, 100% {\\n    transform: translateY(0);\\n  }\\n  10%, 30%, 50%, 70%, 90% {\\n    transform: translateY(-20%);\\n  }\\n}\\n</style>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 16](../images/build-dapp-interface/dapp-16.gif \\\"Dapp Interface changing step 16\\\")\\n\\nNow let's add the **DatalogSection.vue** component.\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\nReformat the log array from:\\n\\n```JS\\nthis.log.push({\\n  sender,\\n  robot,\\n  parameter\\n});\\n```\\n\\nto (for structure like `[[\\\"entry 1 date\\\", \\\"entry 1 content\\\"], [\\\"entry 2 date\\\", \\\"entry 2 content\\\"]]`):\\n\\n```JS\\nthis.log.push([new Date().toLocaleString(), {\\n  sender,\\n  robot,\\n  parameter\\n}]);\\n```\\n\\nReplace the code from the template:\\n\\n```HTML\\n<div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    sender: <b>{{ item.sender }}</b>\\n    <br />\\n    robot: <b>{{ item.robot }}</b>\\n    <br />\\n    parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n  </div>\\n</div>\\n```\\n\\nwith this:\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n**Check:**\\n![Dapp Interface changing step 17](../images/build-dapp-interface/dapp-17.gif \\\"Dapp Interface changing step 17\\\")\\n\\nSometimes you get some errors, it's almost inevitable. Something can go wrong with the connection or anything else can happen. So we have fallbacks with error messages through out the dapp, I haven't changed them from the start, in the code they look like:\\n\\n```HTML\\n<div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n```\\n\\nOn the interface errors look this way now:\\n\\n![Dapp Interface changing step 18](../images/build-dapp-interface/dapp-18.png \\\"Dapp Interface changing step 18\\\")\\n\\nAdd styles for the `.error` in **app.css**:\\n\\n```CSS\\n.error {\\n  font-weight: 400;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  color: var(--color-red);\\n}\\n```\\n\\nAnd I will fix a space between the `.tools` section and other content from the bottom as well in **app.css**:\\n\\n```CSS\\n.tools {\\n  margin-bottom: var(--space);\\n}\\n```\\n\\nWe get:\\n\\n![Dapp Interface changing step 19](../images/build-dapp-interface/dapp-19.png \\\"Dapp Interface changing step 19\\\")\\n\\nNow on this page we have to \\\"primary\\\" buttons. Technically it is okay, but this is not okay from the above user experience. It's better not to use more than one prevailing button on the screen. So let's fix it and add for the `Button` in **Launch.vue** with property `type=\\\"secondary\\\"`:\\n\\n![Dapp Interface changing step 20](../images/build-dapp-interface/dapp-20.png \\\"Dapp Interface changing step 20\\\")\\n\\nGreat, now I'll fix some issues with my node and go to the Demo step.\\n\\n## Demo\\n\\nFor the start, I'd like to swap tabs, to pay more attention to the most relevant one, but this is not the first step that we do to practice. Reverse tabs in **App.vue**.\\n\\nDon't forget to replace the default data:\\n\\n```JS\\ndata() {\\n    return {\\n      ...\\n      tab: \\\"demo\\\"\\n    };\\n},\\n```\\n\\n![Dapp Interface changing step 21](../images/build-dapp-interface/dapp-21.png \\\"Dapp Interface changing step 21\\\")\\n\\nAs usual let's start with changing what we have already got.\\n\\n- Remove the title `<h2>Demo</h2>` as in the previous steps\\n- Find UI elements that we have already learn – datalog, buttons, account address. But not so fast. Now we'll change the datalog only.\\n\\nAdd the component to **Demo.vue**:\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\nWe've got raw data in the log, so we need to reformat the array with the log to pass in the component ready-view data as in the previous steps. Find the line `return [item[0], item[1]];` in `async created()` and replace it with:\\n\\n```JS\\nreturn [new Date(Number(item[0])).toLocaleString(), JSON.parse(u8aToString(item[1]))];\\n```\\n\\nRemove the unused code from the log:\\n\\n```HTML\\n<div v-if=\\\"log\\\" class=\\\"log\\\">\\n  <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    <b>{{ item[0] | dateFormat }}</b>\\n    <pre>{{ item[1] | dataFormat }}</pre>\\n  </div>\\n</div>\\n```\\n\\nand:\\n\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return JSON.parse(u8aToString(v));\\n  }\\n},\\n```\\n\\n**Check:**\\n![Dapp Interface changing step 22](../images/build-dapp-interface/dapp-22.png \\\"Dapp Interface changing step 22\\\")\\n\\nFor customization of this demo example with launching a robot, you are free to come up with any idea. Personally, I started with this town:\\n\\n![Dapp Interface changing step 23](../images/build-dapp-interface/dapp-23.gif \\\"Dapp Interface changing step 23\\\")\\n\\nI won't show the whole code for this not to confuse you at all, but schematically there will be something like this:\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back\\\"></div>\\n  <div class=\\\"demo-city\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n</div>\\n```\\n\\nThan within the element `.demo.play` write styles for moving the city backward, and the car forward.\\n\\nWhile working on this, I came up with the idea of realization the CyberPunk city. As I have no any particullar task, so the car became a taxi, driver became a passenger, and now on the interface we have an AI robot hologram welcoming the passenger (these all are just CSS and graphics tweaks&&tricks).\\n\\n**The code for the Cyberpunk city demo:**\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back-1\\\"></div>\\n  <div class=\\\"demo-back-2\\\"></div>\\n  <div class=\\\"demo-city-1\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n\\n  <div class=\\\"demo-data\\\">\\n    <div class=\\\"demo-data-driver inline-block\\\">\\n      <img alt=\\\"Driver's avatar\\\" src=\\\"../assets/images/cabman.png\\\" v-if=\\\"robot.state\\\"/>\\n    </div>\\n    <div class=\\\"demo-data-lines inline-block\\\">\\n      <div class=\\\"demo-data-line\\\">\\n          <div>Robot</div>\\n          <div>[ {{ addressShort(robot.address) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-line\\\" v-if=\\\"robot.state\\\">\\n          <div>Passenger</div>\\n          <div>[ {{ addressShort(robot.driver) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-welcome\\\" v-if=\\\"robot.state\\\">\\n          <span>Hello, passenger. </span>\\n          <span>I've linked to the vehicle. </span>\\n          <span>Your ride begins, congrats! </span>\\n      </div>\\n    </div>\\n\\n  </div>\\n\\n  <Button :label=\\\"robot.state ? 'stop' : 'run'\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" @onClick=\\\"run\\\" />\\n</div>\\n```\\n\\n</details>\\n\\nThere are more than one hash address that should be shortenned, so I added the method:\\n\\n```JS\\nmethods: {\\n  addressShort(address) {\\n    return address.slice(0, 6) + \\\"...\\\" + address.slice(-4);\\n  }\\n}\\n```\\n\\nDon't forget to register the Button component\\n\\n```JS\\ncomponents: {\\n  Button: () => import(\\\"./Button\\\")\\n}\\n```\\n\\n<details>\\n\\n<summary>Styles</summary>\\n\\n```CSS\\n<style scoped>\\n.demo {\\n    --h: 120px;\\n    --color-yellow: #F2F209;\\n\\n    background-color: #AFCCD3;\\n\\n    background: linear-gradient(#010123, #4baac7);\\n\\n    position: relative;\\n    height: 500px;\\n    overflow: hidden;\\n\\n    border-width: 2px 2px 2px 15px;\\n    border-style: solid;\\n    border-color: var(--color-yellow);\\n    \\n}\\n\\n.demo:before {\\n    content: '[ Delamain cabs rental DEMO ]';\\n    background-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    padding: .5rem 1rem;\\n\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 300;\\n\\n    border-width: 0 6px 2px 0;\\n    border-style: solid;\\n    border-color: #7B186E;\\n}\\n\\ndiv[class^=demo-back-], div[class^=demo-city-] {\\n    position: absolute;\\n    left: 0;\\n    width: 100%;\\n    z-index: 2;\\n}\\n\\ndiv[class^=demo-back-]{\\n    border-top: 1px solid #364444;\\n}\\n\\ndiv[class^=demo-city-] {\\n    background-repeat: repeat-x;\\n    background-size: cover;\\n    background-position: 100% 0;\\n\\n    height: 300px;\\n    bottom: var(--h);\\n\\n    animation: 50s MoveCity infinite linear 1.5s;\\n}\\n\\ndiv.demo-back-1 {\\n    background-color: #060236;\\n    background: linear-gradient(#7B186E, #060236);\\n    height: var(--h);\\n    bottom: 0;\\n}\\n\\ndiv.demo-back-2 {\\n    background-color: #c515ae;\\n    border-width: 2px 0;\\n    border-style: solid;\\n    border-color: #69045c;\\n\\n    height: 20px;\\n    bottom: var(--h);\\n    z-index: 10;\\n}\\n\\ndiv.demo-city-1 {\\n    background-image: url(../assets/images/city-1.png);\\n}\\n\\n.demo-car {\\n    background-image: url(../assets/images/car.png);\\n    background-size: contain;\\n    background-repeat: no-repeat;\\n    background-position: 100% 0;\\n\\n    width: calc(508px * 0.5);\\n    height: calc(257px * 0.5);\\n    position: absolute;\\n    bottom: calc(var(--h) + 4px);\\n    z-index: 10;\\n\\n    transform: translateX(-100px);\\n    animation: MoveCar 50s infinite 1.5s linear;\\n}\\n\\n.demo.play div[class^=demo-city-], .demo.play .demo-car { animation-play-state: running; }\\n.demo.stop div[class^=demo-city-], .demo.stop .demo-car { animation-play-state: paused; }\\n\\n.demo.play .demo-car {\\n    background-image: url(../assets/images/car-ride.png);\\n}\\n\\n\\n.demo button {\\n    background-color: var(--color-yellow);\\n    border-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    bottom: 30px;\\n    right: 30px;\\n    z-index: 1000;\\n}\\n\\n.demo-data {\\n    position: absolute;\\n    bottom: 30px;\\n    left: 30px;\\n    z-index: 1000;\\n\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    padding: .5rem;\\n    font-family: var(--font-family-code);\\n\\n    transition: 0.2s all ease;\\n}\\n\\n.demo-data-lines {\\n    max-width: 400px;\\n}\\n\\n.demo-data-line {\\n    display: grid;\\n    grid-template-columns: 100px auto;\\n    gap: .5rem;\\n    text-align: left;\\n}\\n\\n.demo-data-line div:first-child {\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 700;\\n}\\n\\n.demo-data-driver {\\n    margin-right: 1rem;\\n}\\n\\n.demo-data-driver img {\\n    display: block;\\n    max-width: 100px;\\n\\n    visibility: hidden;\\n    opacity: 0;\\n    animation: FadeInBlink .3s cubic-bezier(0.075, 0.82, 0.165, 1) 0.6s forwards;\\n}\\n\\n.demo-data-welcome {\\n    text-align: left;\\n    padding-top: .5rem;\\n}\\n\\n.demo-data-welcome span {\\n    visibility: hidden;\\n    opacity: 0;\\n\\n    animation-name: FadeIn;\\n    animation-timing-function: cubic-bezier(0.075, 0.82, 0.165, 1);\\n    animation-duration: 0.6s;\\n    animation-fill-mode: forwards;\\n}\\n\\n.demo-data-welcome span:nth-child(1) { animation-delay: 1.5s; }\\n.demo-data-welcome span:nth-child(2) { animation-delay: 2.5s; }\\n.demo-data-welcome span:nth-child(3) { animation-delay: 3.2s; }\\n\\n\\n@keyframes MoveCity\\n{\\n  100% {\\n    background-position: -1000px 0;\\n  }\\n}\\n\\n@keyframes MoveCar\\n{\\n    0% {\\n        transform: translateX(-100px);\\n    }\\n    100% {\\n        transform: translateX(960px);\\n    }\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n**Result:**\\n\\n![Dapp Interface changing step 25](../images/build-dapp-interface/dapp-25.gif \\\"Dapp Interface changing step 25\\\")\\n\\n## Conclusion\\n\\nCongratulations! Now you have redesigned the dapp and clues how to start building your application's interface.\\n\\n### Checkout links\\n\\n- [Full code of this tutorial](https://github.com/positivecrash/wscool21-ui-dapp)\\n- [Discuss in Discord](https://discord.gg/5UWNGNaAUf)\\n- [View the Robonomics Winter School 2021 schedule and summary](https://robonomics.network/blog/winter-robonomics-school/)\\n- [Github of contributor](https://github.com/positivecrash)\\n\\n### Practice\\n\\nIf you have some extra time or want to practice your skills, there are some ideas for improvements that you could make to this demo:\\n\\n- Adapt UI for narrow screens, make the dapp mobile-friendly\\n- Add the 'day/night' mode, by editing the **_variables.scss** file and the template file of the dapp\\n- Add 'Copy to clipboard' buttons for addresses\\n- Make delicate popus to inform users about changes (e.g. you can popup a message that units are received after clicking the 'Faucet' button, or you can move in the popup an error that we had in the 'Launch' section).\\n\\nPlease, fill free to ask questions and share your results in [Discord](https://discord.gg/5UWNGNaAUf), mark me in your message `@positivecrash`\\n\\n\\n\\n\\n\\n\\n\"}},{\"node\":{\"id\":\"ecd3bb67f6bd0a89db828bb9c97e87be\",\"title\":\"Lesson 6.1, Build IoT Dapps For End Users\",\"path\":\"/docs/ru/wschool2021-build-dapp-for-end-users/\",\"content\":\"\\n## Getting ready\\n\\n### Robonomics node launch\\n\\nFor dApp development and testing, we will use a local Robonomics node. To do this, you need to download the compiled binary file v0.24 from https://github.com/airalab/robonomics/releases. I will be using Ubuntu, so I download the appropriate version.\\n\\nUnpack the archive\\n```sh\\nwget https://github.com/airalab/robonomics/releases/download/v0.24.0/robonomics-ubuntu-0.24.0-x86_64.tar.xz\\ntar -xvf robonomics-ubuntu-0.24.0-x86_64.tar.xz\\nchmod +x robonomics\\n```\\n\\nNow we can start the node in development mode. To do this, use the --dev flag\\n```sh\\n./robonomics --dev --tmp\\n```\\n\\n> Troubleshooting\\n```sh\\n./robonomics purge-chain --dev\\n```\\n\\n### Browser extension\\n\\nTo store keys in a browser, there is a `polkadot{.js} extension`. In dApp we will use it to sign transactions.\\n\\nThe extension is currently available for `Google chrome` and `Firefox` https://polkadot.js.org/extension/\\n\\nAfter installing the extension, create a new account.\\n![screen1](../images/build-iot-dapps/screen1.png)\\n\\n> The first step is completed.\\n\\n## DApp development\\n\\n### Step 1\\n\\n> We will write the dApp using the vue.js framework, although you can use whatever you like/can.\\n\\nLet's start developing the dApp by creating a startup application with vue.js And here you can do it in two ways.\\n\\nWay 1:\\n\\nUsing the `Vue cli` console utility.\\nTo do this, you need to install [it](https://cli.vuejs.org/guide/installation.html\\nAlso we will need `yarn`. Install it from [here](https://yarnpkg.com)\\n\\nAfter installation, you can run the command in the terminal\\n\\n```sh\\nvue create mydapp\\n```\\n\\nAnswer a few questions of the setup wizard. We will be using version Vue 2, so we keep the default version `Default ([Vue 2] babel, eslint)`.\\n\\nWay 2:\\n\\nClone the prepared git repository with the example and switch to step 1\\n\\n```sh\\ngit clone https://github.com/airalab/example-robonomics-dapp.git mydapp\\ncd mydapp\\ngit checkout step-1\\n```\\n\\nAs a result, we will get a directory with the installed startup application, which can already be launched and opened in the browser.\\n\\n```sh\\nyarn\\nyarn serve\\n```\\n\\n### Step 2. Getting started with polkadot.js\\n\\n#### Installing dependencies\\n\\nTo connect the dApp to the Robonomics chain, there is the `@polkadot/api` library. And for interaction of dApp with an extension with keys, we have the `@polkadot/extension-dapp` library. We need to install them into our application.\\nMore details on using this library can be found in the documentation https://polkadot.js.org/docs/.\\n\\nWay 1:\\n\\n```sh\\nyarn add @polkadot/api @polkadot/extension-dapp\\n```\\n\\nYou also need to add the `vue.config.js` file to support `mjs` extension.\\n\\n`vue.config.js`\\n```js\\nmodule.exports = {\\n  publicPath: \\\"\\\",\\n  configureWebpack: {\\n    resolve: {\\n      extensions: [\\\"*\\\", \\\".mjs\\\", \\\".js\\\", \\\".vue\\\", \\\".json\\\", \\\".gql\\\", \\\".graphql\\\"]\\n    },\\n    module: {\\n      rules: [\\n        {\\n          test: /\\\\.mjs$/,\\n          include: /node_modules/,\\n          type: \\\"javascript/auto\\\"\\n        }\\n      ]\\n    }\\n  }\\n};\\n```\\n\\n#### Connecting to Robonomics\\n\\nFirst, let's create a configuration file with the parameters for connecting to the Robonomics node. In the demo repository, there is an example of this file `config.template.json`.\\n\\n`src/config.json`\\n```json\\n{\\n  \\\"endpoint\\\": \\\"ws://localhost:9944\\\",\\n  \\\"types\\\": {\\n    \\\"Record\\\": \\\"Vec<u8>\\\",\\n    \\\"Parameter\\\": \\\"Bool\\\",\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\"\\n  }\\n}\\n```\\n\\nIn this file, we indicate the node, which we are going to connect to, and custom types.\\n\\nNow we need to write a script to connect to our running node.\\n\\n`src/utils/api.js`\\n```js\\nimport { ApiPromise, WsProvider } from \\\"@polkadot/api\\\";\\nimport config from \\\"../config.json\\\";\\n\\nlet api;\\nexport async function initApi() {\\n  const provider = new WsProvider(config.endpoint);\\n  api = await ApiPromise.create({\\n    provider,\\n    types: config.types\\n  });\\n  return api;\\n}\\n\\nexport function getApi() {\\n  return api;\\n}\\n```\\n\\nSo that we can sign transactions with the key from the extension, let’s add two functions for connecting to the extension and the function for initializing the account.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport {\\n  web3Accounts,\\n  web3Enable,\\n  web3FromAddress\\n} from \\\"@polkadot/extension-dapp\\\";\\n\\nasync function getExtension() {\\n  const extensions = await web3Enable(\\\"demo\\\");\\n  if (extensions.length === 0) throw new Error(\\\"no extension\\\");\\n  return extensions[0];\\n}\\n\\nexport async function initAccount(index = 0) {\\n  const timeout = new Promise(resolve => {\\n    setTimeout(resolve, 300);\\n  });\\n  await timeout;\\n  await getExtension();\\n  const accounts = await web3Accounts();\\n  if (accounts.length > 0) {\\n    const injector = await web3FromAddress(accounts[index].address);\\n    api.setSigner(injector.signer);\\n    return accounts[index].address;\\n  }\\n  throw new Error(\\\"no accounts\\\");\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nOur account will have a zero balance, while we need a little funds. So we need to create another faucet function. As we launched Robonomics with the `--dev` flag, we have `Alice` account with a large balance, so we will request funds from there.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport { Keyring } from \\\"@polkadot/keyring\\\";\\n\\nexport function getBalance(account, cb) {\\n  api.query.system.account(account, ({ data: { free: currentFree } }) => {\\n    cb(currentFree);\\n  });\\n}\\n\\nexport const keyring = new Keyring({ type: \\\"sr25519\\\" });\\n\\nexport async function faucet(address) {\\n  keyring.setSS58Format(api.registry.chainSS58);\\n  const account = keyring.addFromUri(\\\"//Alice\\\");\\n  const tx = api.tx.balances.transfer(address, 1000000000000000);\\n  await tx.signAndSend(account);\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nThe full version of script https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/api.js\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then in order to complete these steps, it will be enough to switch to step 2 and install the rest of the dependencies.\\n\\n```sh\\ngit checkout step-2\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n### Step 3. Vue connecting component\\n\\n#### Connecting\\n\\nWe have already written a script for connecting. Now we can use it on our interface. It is enough to call the written `initApi` function in  the root component `App.vue`. And while the user is waiting for a connection, we will show him a small loader, for now in the form of an ellipsis.\\n\\nWay 1:\\n\\nComponent template and base styles.\\n\\n`src/App.vue`\\n```js\\n<template>\\n  <div id=\\\"app\\\">\\n    <h1>Robonomics dApp</h1>\\n    <div v-if=\\\"load\\\">...</div>\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api\\\">\\n        connected\\n      </template>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style>\\n#app {\\n  font-family: Avenir, Helvetica, Arial, sans-serif;\\n  -webkit-font-smoothing: antialiased;\\n  -moz-osx-font-smoothing: grayscale;\\n  text-align: center;\\n  color: #2c3e50;\\n  margin-top: 60px;\\n}\\nbutton {\\n  font-size: 14px;\\n  padding: 5px 12px;\\n}\\nbutton:hover {\\n  cursor: pointer;\\n}\\ninput {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nselect {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nbutton:focus,\\ninput:focus {\\n  outline: none;\\n}\\n.error {\\n  color: rgb(151, 31, 31);\\n  font-weight: bold;\\n  text-align: center;\\n  margin: 10px 0;\\n}\\n</style>\\n```\\n\\nThere is the component code where the  `initApi` function will be called\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi } from \\\"./utils/api\\\";\\n\\nexport default {\\n  name: \\\"App\\\",\\n  data() {\\n    return {\\n      load: false,\\n      api: null,\\n      error: null\\n    };\\n  },\\n  created() {\\n    this.init();\\n  },\\n  methods: {\\n    async init() {\\n      try {\\n        this.load = true;\\n        this.api = await initApi();\\n        this.load = false;\\n      } catch (error) {\\n        this.error = error.message;\\n        this.load = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\n#### Account with balance\\n\\nNow we can use our account, top up its balance and show it on the interface.\\n\\nLet’s add the appropriate markup to the template\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n  ...OTHER_CODE...\\n\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api && account\\\">\\n        <p>\\n          Account: <b>{{ account }}</b> {{ balance }} |\\n          <button @click=\\\"faucet\\\">\\n            faucet\\n          </button>\\n        </p>\\n      </template>\\n    </template>\\n\\n  ...OTHER_CODE...\\n\\n</template>\\n```\\n\\nLet’s add new fields for account address and balance\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\ndata() {\\n  return {\\n\\n    ...OTHER_CODE...\\n\\n    account: null,\\n    balance: 0,\\n\\n    ...OTHER_CODE...\\n\\n  };\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nWe need to add the account initialization to the `init` function and get its balance\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi, initAccount, getBalance, faucet } from \\\"./utils/api\\\";\\nimport { formatBalance } from \\\"@polkadot/util\\\";\\n\\n...OTHER_CODE...\\n\\nasync init() {\\n\\n  ...OTHER_CODE...\\n\\n  this.api = await initApi();\\n  this.account = await initAccount();\\n  getBalance(this.account, balance => {\\n    this.balance = formatBalance(balance);\\n  });\\n\\n  ...OTHER_CODE...\\n\\n}\\n\\n...OTHER_CODE...\\n</script>\\n```\\n\\nIt remains to add the function of replenishing the balance, when clicking on the button\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\n  methods: {\\n    faucet() {\\n      faucet(this.account);\\n    },\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/step-3/src/App.vue\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 3.\\n\\n```sh\\ngit checkout step-3\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen2](../images/build-iot-dapps/screen2.png)\\n\\n### Step 4. Datalog\\n\\nTo save and read any data in the chain, we use the `datalog` module.\\n\\nFor an example of how to use this module, let's make a `Datalog.vue` component.\\n\\nWay 1:\\n\\nIn the markup, we will have a button for reading data `read` with a block, where we will display a list in the form of a date and the data itself. And there will be a form with a text input, into which you can enter any data in the form of a string, and a `write` button.\\n\\n`src/components/Datalog.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Datalog</h2>\\n    <button @click=\\\"read\\\">read</button> |\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" />\\n    <button @click=\\\"write\\\" :disabled=\\\"isWrite\\\">write</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n      <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        date: <b>{{ item[0] | dateFormat }}</b>\\n        <br />\\n        data: <b>{{ item[1] | dataFormat }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nComponent code. Here the main point in sending a transaction is to call the function, into which we transfer data and which we sign with our account, via api `this.api.tx.datalog.record(stringToHex(this.data)).signAsync(this.account);`\\n\\n`src/components/Datalog.vue`\\n```js\\n<script>\\nimport { stringToHex, u8aToString } from \\\"@polkadot/util\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      data: \\\"data string\\\",\\n      log: null,\\n      isWrite: false,\\n      error: \\\"\\\"\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return u8aToString(v);\\n    }\\n  },\\n  methods: {\\n    async read() {\\n      this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n    },\\n    async write() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.datalog\\n          .record(stringToHex(this.data))\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.read();\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Datalog.vue\\n\\nTo switch between components, added to `App.vue` the output of our component\\n\\n`src/App.vue`\\n```js\\n...OTHER_CODE...\\n\\n<template v-else-if=\\\"api && account\\\">\\n  <p>\\n    Account: <b>{{ account }}</b> {{ balance }} |\\n    <button @click=\\\"faucet\\\">faucet</button>\\n  </p>\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\n\\n...OTHER_CODE...\\n\\nexport default {\\n  name: \\\"App\\\",\\n  components: {\\n    Datalog\\n  },\\n  data() {\\n    return {\\n      tab: \\\"datalog\\\"\\n\\n...OTHER_CODE...\\n</script>\\n\\n<style>\\n...OTHER_CODE...\\n\\n.tabs button {\\n  font-size: 14px;\\n  padding: 10px 20px;\\n  font-weight: bold;\\n  background: #ececec;\\n  border: 1px solid #aaa;\\n}\\n.tabs button:hover {\\n  background: #bfbfbf;\\n}\\n.tabs button:last-child {\\n  border-left: none;\\n}\\n.tabs button.active {\\n  background: #ced5e2;\\n}\\n</style>\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 4.\\n\\n```sh\\ngit checkout step-4\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen3](../images/build-iot-dapps/screen3.png)\\n\\n### Step 5. Launch\\n\\nThis function is used to start and stop the robot. To demonstrate how to use this module, let's write the `Launch.vue` component.\\n\\nWay 1:\\n\\nIn the component template, we will have a form where you can specify the address of the robot, the ON/OFF clicker and the button for sending.\\n\\n`src/components/Launch.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Launch</h2>\\n    <input v-model=\\\"robot\\\" :disabled=\\\"isWrite\\\" placeholder=\\\"Robot address\\\" />\\n    <select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n      <option value=\\\"ON\\\">ON</option>\\n      <option value=\\\"OFF\\\">OFF</option>\\n    </select>\\n    <button @click=\\\"launch\\\" :disabled=\\\"isWrite\\\">launch</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        sender: <b>{{ item.sender }}</b>\\n        <br />\\n        robot: <b>{{ item.robot }}</b>\\n        <br />\\n        parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nThe code looks like the `Datalog.vue` component. The difference is just in reading. The robot will receive the command through events.\\n\\n`src/components/Launch.vue`\\n```js\\n<script>\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      robot: this.account,\\n      parameter: \\\"ON\\\",\\n      log: [],\\n      isWrite: false,\\n      error: \\\"\\\",\\n      unsubscribe: null\\n    };\\n  },\\n  async created() {\\n    this.unsubscribe = await this.api.query.system.events(events => {\\n      events.forEach(record => {\\n        const { event } = record;\\n        if (event.section === \\\"launch\\\" && event.method === \\\"NewLaunch\\\") {\\n          const sender = event.data[0].toString();\\n          const robot = event.data[1].toString();\\n          const parameter = event.data[2].toHuman();\\n          this.log.push({\\n            sender,\\n            robot,\\n            parameter\\n          });\\n        }\\n      });\\n    });\\n  },\\n  destroyed() {\\n    if (this.unsubscribe) {\\n      this.unsubscribe();\\n    }\\n  },\\n  methods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Launch.vue\\n\\nFor display, add a new component to `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 5.\\n\\n```sh\\ngit checkout step-5\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen4](../images/build-iot-dapps/screen4.png)\\n\\n### Step 6. Demo\\n\\nIn this demo, we will have a car that can be started and stopped through the dApp. The car collects a log during the trip, and after stopping, saves it to the chain. Here we will use both modules, which we tried separately, in conjunction.\\n\\nTo emulate the behavior of a robot (car), we will write a Robot class. We will use the `Alice` key as an account for this robot. The `Robot` class will watch for `NewLaunch` events to turn itself on and off. After turning on, it starts collecting data into the log, in terms of data it will be just a timestamp. And after shutdown, it saves this log to the `datalog` module.\\n\\nWay 1:\\n\\nCreate file `src/utils/robot.js`. The full code of the file https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/robot.js\\n\\nFor visualization, we will create a `Demo.vue` component, where we will have a start button, car animation and log output.\\n\\n`src/components/Demo.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Demo</h2>\\n    <template v-if=\\\"robot\\\">\\n      <h3>Robot: {{ robot.address }}</h3>\\n      <p v-if=\\\"robot.state\\\">Driver: {{ robot.driver }}</p>\\n      <button @click=\\\"run\\\" :disabled=\\\"isWrite\\\">\\n        <template v-if=\\\"!robot.state\\\">run</template>\\n        <template v-else>stop</template>\\n      </button>\\n      <div class=\\\"road\\\">\\n        <div\\n          class=\\\"robot\\\"\\n          :class=\\\"[robot.state ? 'robot-play' : 'robot-stop']\\\"\\n        ></div>\\n      </div>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n        <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n          <b>{{ item[0] | dateFormat }}</b>\\n          <pre>{{ item[1] | dataFormat }}</pre>\\n        </div>\\n      </div>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n  height: 500px;\\n  overflow-y: auto;\\n}\\n.log .row {\\n  margin: 10px;\\n  border-bottom: 1px solid #eee;\\n}\\n.road {\\n  width: 1000px;\\n  margin: 20px auto;\\n  background-color: #eee;\\n  padding: 20px 0;\\n  border: 5px solid #a5a5a5;\\n  border-left: 0;\\n  border-right: 0;\\n  position: relative;\\n}\\n.road::before {\\n  content: \\\" \\\";\\n  width: 1000px;\\n  border-top: 5px dashed #a5a5a5;\\n  position: absolute;\\n  top: 50%;\\n  left: 0;\\n}\\n@keyframes move {\\n  from {\\n    transform: translateX(0);\\n  }\\n  to {\\n    transform: translateX(100%);\\n  }\\n}\\n.robot {\\n  height: 100px;\\n  width: 100px;\\n  color: #fff;\\n  font-weight: bold;\\n  font-style: 14px;\\n  animation: move 30s linear infinite;\\n  border-radius: 0 10px 10px 0;\\n  background: url(\\\"../images/build-iot-dapps/car.png\\\") no-repeat 0 0;\\n  background-size: cover;\\n}\\n.robot-play {\\n  animation-play-state: running;\\n}\\n.robot-stop {\\n  animation-play-state: paused;\\n}\\n</style>\\n```\\n\\nComponent code. Here we need to create an instance of the `Robot` class and a launch/stop function.\\n\\n`src/components/Demo.vue`\\n```js\\n...OTHER_CODE...\\n\\n<script>\\nimport { u8aToString } from \\\"@polkadot/util\\\";\\nimport Robot from \\\"../utils/robot\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      isWrite: false,\\n      error: \\\"\\\",\\n      robot: null,\\n      log: []\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return JSON.parse(u8aToString(v));\\n    }\\n  },\\n  async created() {\\n    this.robot = new Robot(\\\"//Alice\\\", this.api);\\n    await this.robot.subscribeLog(r => {\\n      this.log = r.reverse().map(item => {\\n        return [item[0], item[1]];\\n      });\\n    });\\n  },\\n  destroyed() {\\n    this.robot.destroy();\\n  },\\n  methods: {\\n    async run() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot.account.address, !this.robot.state)\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Demo.vue\\n\\n    Let's add another picture of our car to `src/images/build-iot-dapps/car.png` and to `src/assets/car.png`. Example https://github.com/airalab/example-robonomics-dapp/blob/master/src/assets/car.png\\n\\nFor display, add a new component to `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n      <button @click=\\\"tab = 'demo'\\\" :class=\\\"{ active: tab === 'demo' }\\\">\\n        demo\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\nimport Demo from \\\"./components/Demo\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch,\\n  Demo\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 6.\\n\\n```sh\\ngit checkout step-6\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen5](../images/build-iot-dapps/screen5.png)\\n\\nThis concludes our lesson.\\n\\nThanks!\\n\"}},{\"node\":{\"id\":\"43b919e1e5603a2e07be403d038e9faa\",\"title\":\"Connect Vacuum Cleaner\",\"path\":\"/docs/ru/vacuum-connect/\",\"content\":\"\\n## Connect to Home Assistant\\n\\nYou need your vacuum to be connected to Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your vacuum (it must be in connecting mode via a long press of the power button) and follow instructions in the app. For more details look at the user manual of your vacuum.\\n\\nOpen Home Assistant web page with this address:\\n```\\nhttp://<raspberry_address>:8123\\n```\\n\\nGo to `Integrations` tab, press `Add integration` and choose `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Vacuum (Robot vacuum in this example):\\n\\n![vacuum](../images/home-assistant/vacuum_int.png)\\n\\nAfter that you can connect your device to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"dc43e6292f7424f93d7ed6b3f06ff73f\",\"title\":\"Troubleshooting\",\"path\":\"/docs/ru/troubleshooting/\",\"content\":\"\\n## Can't create HRMP channel\\n\\nIt's not possible to create HRMP channel.\\n#### Solution\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n\\\"Address\\\": \\\"MultiAddress\\\",\\n\\\"LookupSource\\\": \\\"MultiAddress\\\",\\n\\\"AccountInfo\\\": \\\"AccountInfoWithRefCount\\\"\\n}\\n```\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n## Couldn't send XCM call with datalogXcm\\n If you try to send message between parachains and get error like this:\\n\\n![error_4lesson][im1]\\n\\n#### Solution\\n\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\n![XCM][im2]\\n\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n\\n\\n [im1]: <../images/troubleshooting/lesson4_error.jpg>\\n [im2]: <../images/troubleshooting/XCM.jpg>\\n\"}},{\"node\":{\"id\":\"ae94b68823336db895e807644b4436b2\",\"title\":\"Как участвовать в переводе Вики\",\"path\":\"/docs/ru/translate-wiki/\",\"content\":\"\\nКаждый может внести свой вклад в Робономику. Если вы хотите принять участие в переводе документации, вы на правильном пути: эта статья расскажет вам как это можно сделать.\\n\\n## Редактирование статьи\\n\\nЕсли поддержка вашего языка уже добавлена на сайт, то следуйте следующим шагам:\\n\\n1. Кликните кнопку \\\"Редактировать эту страницу\\\" в статье, которую хотели бы перевести. Каждая статья продублирована в поддерживаемом языке, даже если она ещё не переведена с английского.\\n2. Редактируйте, придерживаясь существующей разметки. Можете прочитать статью [Как редактировать в ВИКИ](/docs/edit-wiki)\\n3. Сделайте [RP](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) с внесенными вами изменениями.\\n\\n## Добавление нового языка\\n\\nЕсли язык, на который вы бы хотели перевести статью, ещё не добавлен, запросите его добавление у корневой команды разработчиков Робономики, [создав Issue](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) на GitHub.\\n\\nКогда мы добавим поддержку запрашиваемого языка на сайт, то закроем Issue, прокомментировав его при необходимости. Вам придет соответствующее уведомление. Это значит, что можно переводить страницы (они уже будут сдублировны на английском в папке вида `/docs/локаль-вашего-языка`)\\n\\n## Примечания\\n* Если вы заметили, как можно улучшить существующий перевод той или иной статьи, можете так же воспользовать функицоналом PR или Issue на GitHub\\n* При значительном вкладе в перевод вы можете поучаствовать в программе вознаграждений. \"}},{\"node\":{\"id\":\"400fa8f4aaadbc01ea8f4f4d665421be\",\"title\":\"How the technical committee is fast-tracking the democracy proposals\",\"path\":\"/docs/ru/technical-committee-fast-track/\",\"content\":\"\\nNote: The screenshots contained in this article were taken using v1.9.0 of Robonomics node implementation, launched in **dev** mode.\\n\\nThe Robonomics Technical Committee can use the **fast-track** function to speed up the proposals enacting in the Democracy module.\\n\\nIf you want to learn more about how Polkadot ecosystem Governance works, then we strongly recommend reading [this article](https://polkadot.network/blog/polkadot-governance/) on the Polkadot blog.\\n\\nThere are six members who make up the Technical Committee for the Robonomics parachain. For our example, let's create the same setup in our dev mode environment:\\n![Techcomm membership](../images/technical-committee-fast-track/techcomm_membership.png)\\n\\nBriefly, the process of fast-tracking a proposal involves a few steps:\\n1. Creating the proposal preimage\\n2. Creating the proposal using the created preimage hash\\n3. Technical committee votes on the created proposal\\n4. Initiating proposal fast-tracking \\n5. Technical committee votes regarding fast-tracking the proposal\\n6. Voting on enacted proposal in the Democracy pallet\\n\\nFor example, let's set the free balance for the account *4EnEc9ZD1jpA1H3HpVzr1v6SGGYGrue2k9Ny5KzFHhti5xQv* to 10 XRT\\n\\n## 1. Creating the proposal preimage\\nOpen the **Governance -> Democracy** page and click the **Submit preimage** button, and then input the required parameters:\\n![Creating preimage](../images/technical-committee-fast-track/creating_preimage.png)\\n\\nAfter all fields are filled, then we need to save generated preimage hash (*0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b* in this example). As we will need it in the next step.\\n\\nAfter saving the preimage hash we can click the **Submit preimage** button in this window and sign the transaction:\\n![Sign submitting preimage](../images/technical-committee-fast-track/sign_submitting_preimage.png)\\n\\n\\n## 2. Creating proposal using created preimage hash\\nOpen the **Governance -> Tech. comm.** page and go to the **Proposals** tab:\\n![Techcomm proposals interface](../images/technical-committee-fast-track/techcomm_proposals_interface.png)\\n\\nThen click **\\\"Submit proposal\\\"** button and create *democracy.externalProposeMajority(0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b)* using your technical committee account and the preimage hash from earlier:\\n![Create techcomm proposal 1](../images/technical-committee-fast-track/create_techcomm_proposal_1.png)\\n\\nAfter signing transaction, the proposal will appear on this page:\\n![Created techcomm proposal 1](../images/technical-committee-fast-track/created_techcomm_proposal_1.png)\\n\\n## 3. Technical committee voting for created proposal\\nOn this step the majority of the technical committee members need to vote **Aye** in this poll. For example:\\n![First vote result](../images/technical-committee-fast-track/first_vote_result.png)\\n\\nThen we can decide to close this vote/poll using the **Close** button. After this action the proposal will appear on the **Democracy** page on the **external** table. You may wonder how can you see the **Fast track** button. This button appears and is active ONLY if we used the **democracy.externalProposeMajority** function:\\n![Created democracy proposal](../images/technical-committee-fast-track/created_democracy_proposal.png)\\n\\n\\n## 4. Initiating proposal fast-tracking\\nGo to the **Governance -> Democracy** page and click on the **Fast track** button. In this newly opened window set the required parameters and click **Fast track**.\\n![Fast track interface](../images/technical-committee-fast-track/fast_track_interface.png)\\n\\nAfter this, the fast-track proposal should now appear on the Technical Committee proposals page:\\n![Techcomm fast-track proposal](../images/technical-committee-fast-track/techcomm_fasttrack_proposal.png)\\n\\n\\n## 5. Technical committee voting for fast-track the proposal\\nNow the technical committee need to vote unanimously for fast-tracking the earlier created proposal. It means that all six members need to vote **Aye**:\\n![Fast-track vote result](../images/technical-committee-fast-track/fasttrack_vote_result.png)\\n\\nAfter this anyone can **Close** this voting, and the proposal will be enacted and moved from **external** table to active **referenda**:\\n![Democracy enacted proposal](../images/technical-committee-fast-track/democracy_enacted_proposal.png)\\n\\n\\n## 6. Voting on enacted proposal in Democracy\\nNow at least one account needs to vote **Aye** on the referenda:\\n![Voting for enacted proposal](../images/technical-committee-fast-track/voting_for_enacted_proposal.png)\\n\\nAs a result we'll get the active referenda with one positive vote on it:\\n![Positive voted referenda](../images/technical-committee-fast-track/positive_voted_referenda.png)\\n\\nAfter the voting period ends, this democracy proposal will be executed. In current example this will be happen in block #3351. Let's wait for this block and check it:\\n![Result](../images/technical-committee-fast-track/result.png)\\n\"}},{\"node\":{\"id\":\"36388e7f175464eb1c585289e943bf90\",\"title\":\"Как отправить Launch с помощью подписки\",\"path\":\"/docs/ru/subscription-launch/\",\"content\":\"\\nЕсли Ваш адрес относится к устройствам с любой подпиской, Вы можете отправлять экстринсики без комиссии. Давайте попробуем отправить `launch`.\\n\\nПерейдите в `Developer/Extrinsics`, выберите Ваш аккаунт (`MAIN` на картинке) и `rws -> call`. Затем в поле `subscriptionID` впишите адрес владельца подписки (`SUBSCRIPTION OWNER` на картинке) и в следующем поле выберите `launch -> launch`. В поле `robot` впишите адрес, куда Вы хотите отправить транзакцию `launch` (`LIGHTBULB (EXTENTION)` на картинке) и выберите параметр `Yes` или `No`. Чтобы совершить транзакцию:\\n\\n![launch](../images/dev-node/launch.png)\\n\\n\\nПерейдите в `Network/Explorer`. В `Recent Events` вы увидите два события - `rws.NewCall` и `launch.NewLaunch`:\\n\\n![события](../images/dev-node/events.png)\\n\"}},{\"node\":{\"id\":\"85ecd2a8c3d3eaaadc5c297a5d265aa8\",\"title\":\"Try It Out\",\"path\":\"/docs/ru/spot-try-it-out/\",\"content\":\"\\nWith this tutorial you will be able to see in simulation what real Spot did.\\n\\n## Requirements\\n\\n* ROS melodic desktop (installation instructions [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n\\n## Install package\\n\\nCreate workspace and clone packages:\\n```bash\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/src\\ngit clone https://github.com/clearpathrobotics/spot_ros.git\\ngit clone https://github.com/ros/geometry2 --branch 0.6.5\\n```\\nOpen the `view_model.launch` file:\\n```bash\\nnano ~/catkin_ws/src/spot_ros/spot_viz/launch/view_model.launch\\n```\\n\\nAnd set `use_sim_time` parameter to `true`, file must look like this:\\n```xml\\n<launch>\\n  <param name=\\\"/use_sim_time\\\" value=\\\"true\\\"/>\\n  <include file=\\\"$(find spot_description)/launch/description.launch\\\"/>\\n\\n  <node name=\\\"joint_state_publisher_gui\\\" pkg=\\\"joint_state_publisher_gui\\\" type=\\\"joint_state_publisher_gui\\\" />\\n\\n  <node name=\\\"rviz\\\" pkg=\\\"rviz\\\" type=\\\"rviz\\\" args=\\\"-d $(find spot_viz)/rviz/model.rviz\\\" />\\n</launch>\\n```\\n\\nThen install dependencies:\\n```bash\\ncd ~/catkin_ws/\\nrosdep install --from-paths src --ignore-src -y\\ncatkin_make\\n```\\n\\n## Run\\n\\nGet example rosbag file:\\n```bash\\nwget -O spot_rosbag.bag https://gateway.ipfs.io/ipfs/QmTDrfMy7Zs7uDLN3KPBC1UYqXNMXBKEwX7ggVmJKAm7Ef\\n```\\n\\nRun rviz with the Spot model:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_model.launch\\n``` \\nThen in a new terminal:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_robot.launch\\n``` \\n![spot_viz](../images/spot/spot.jpg)\\n\\n\\nPlay rosbag file and you will see the robot move:\\n```bash\\nrosbag play spot_rosbag.bag\\n```\\n![spot_viz](../images/spot/spot2.jpg)\"}},{\"node\":{\"id\":\"4dac65b2d952a8c47152c833e6922c72\",\"title\":\"Troubleshooting\",\"path\":\"/docs/ru/spot-troubleshooting/\",\"content\":\"\\n### Admin socket already exists \\n\\nIf you can't run yggdrasil with this error:\\n```bash\\nAdmin socket /var/run/yggdrasil.sock already exists and is in use by another process\\n```\\nTry to remove file yggdrasil.sock and run it again:\\n```bash\\nsudo rm /var/run/yggdrasil.sock\\n```\\n\\n### Can't get lease\\n\\nIf you can't get lease with this error:\\n```python\\nGeneric exception during check-in:\\nNo lease for resource \\\"body\\\"\\n    (resuming check-in)\\n```\\nOr this error:\\n```python\\nGeneric exception during check-in:\\nbosdyn.api.RetainLeaseResponse (LeaseUseError): \\n    (resuming check-in)\\n```\\n\\nYou need to acquire lease (if you have already done it, try again):\\n```python\\nlease = lease_client.acquire()\\n```\\n\"}},{\"node\":{\"id\":\"96e5b5172b38051c78af64a9bf1947c4\",\"title\":\"Lesson 5. Robot service. Camera calibration and \\\"Spot check\\\" procedure\",\"path\":\"/docs/ru/spot-lesson5/\",\"content\":\"\\nIn this lesson you will learn what should you do if you just got the robot: the first run and network setup. Also you will learn how to run the calibration process that should be run monthly.\\n\\n## The challenge\\n\\nCreate and execute Python script implements behaviors described.\\n\\n1. Run \\\"spot check\\\" and save the result of the calibration in a `/home/student/result` directory as a text file.\\n2. Run camera calibration procedure.\\n\\n## Theory\\n\\n### First Run\\n\\nLook at [Startup Procedure](https://support.bostondynamics.com/s/article/Startup-Procedure) page in Documentation.\\n\\n### Networking\\n\\nSpot offers a variety of networking options to support a diverse set of applications and environments. Options include:\\n\\n* Spot as a connected peer. Physicall connection to Spot.\\n\\n* Spot as a WiFi access point. \\n\\n* Spot as a WiFi client. Spot can join an existing WiFi network, and applications can also join the same WiFi network to talk to Spot.\\n\\nFor more information look at [Networking page](https://dev.bostondynamics.com/docs/concepts/networking).\\n\\nSpot Core is connected to the Spot via payload port. Spot Core can be connected to the Internet with Wi-Fi dongle. The setup instructions you can find at [Spot Core Cockpit](https://dev.bostondynamics.com/docs/payload/spot_core_cockpit.html?highlight=spot%20check) page.\\n\\n### Calibration\\n\\nSpot Check is a full calibration of the robot. Also you can run the camera calibration \\n\\n* [run_spot_check](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L164) runs full spot check routine. The robot should be sitting on flat ground when this routine is started. This routine calibrates robot joints and checks camera health.\\n\\n* [run_camera_calibration](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L204). Run full camera calibration routine for robot. This function blocks until calibration has completed. This function should be called once the robot is powered on and standing with his back to the calibration stand at a distance of 1 meter. Calibation process takes about 20 minutes.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"6995ba0e206c98e6b3334458e61a0ba4\",\"title\":\"Lesson 3. Find and follow an object, navigate between them\",\"path\":\"/docs/ru/spot-lesson3/\",\"content\":\"\\nIn the third lesson you will learn how to find World Objects and go to them.\\n\\n## The challenge\\n\\nYou start with Spot in the place with some fiducials (a mark on the object) around. Create and execute Python script detects at least two fiducials and moves Spot to each of them within 1 m.\\n\\n## Theory\\n\\nSpot has the World Object Service that provides a way to track and store objects detected in the world around Spot. A world object is considered a higher-level item in the scene that has some amount of semantic information associated with it. More information you can find in [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services#world-object) tab in Spot SDK documentation.\\n\\nUsing world object service you can find fiducials near the Spot. \\n\\n> Spot can find objects around faster if he stands.\\n\\nIn the task you will need find fiducials' coordinates and go to them. You already know how to move to the local coordinates from the [Lesson 2](/docs/en/spot-lesson2.md). The example of how to find a fiducial and it's coordinates is in [fiducial_follow example](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/examples/fiducial_follow/fiducial_follow.py).\\n\\nIn your script, firstly, you need to find fiducial object with World Object Service:\\n\\n```python\\nfiducial_objects = world_object_client.list_world_objects(\\n            object_type=[world_object_pb2.WORLD_OBJECT_APRILTAG]).world_objects\\n```\\n\\nThen get fiducial coordinates in a visual frame:\\n\\n```python\\nfiducial = fiducial_objects[0]\\nvision_tform_fiducial = get_a_tform_b(fiducial.transforms_snapshot, VISION_FRAME_NAME,fiducial.apriltag_properties.frame_name_fiducial.to_proto()\\n```\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"d0c0123c0600367f2b5db8dea1dfebd4\",\"title\":\"Lesson 4. GraphNav service. Mapping and navigating on the map\",\"path\":\"/docs/ru/spot-lesson4/\",\"content\":\"\\nIn the fourth lesson you will learn how to record and play autonomous missions with GraphNav service.\\n\\n## The challenge\\n\\nThis lesson you can solve the challenge without writing your own Python script.\\n\\n1. Record a map avioding obstacles. You can use WASD remote control tool. Save your mission in `/home/student/result`.\\n2. Move Spot through recorded waypoints. You can use GraphNav service command line tool.\\n\\n## Theory\\n\\nThe Spot SDK includes APIs, client libraries, and examples that support the development of autonomous navigation behaviors for the Spot robot. Collectively, this service is referred to as GraphNav. Maps are recorded and saved and later can be replayed with any robot in your fleet. During the map recording process, you can assign actions and API callbacks to waypoints along the map route.\\n\\nRead [GraphNav Tech Summary](https://dev.bostondynamics.com/docs/concepts/autonomy/graphnav_tech_summary) to learn how it works. [Initialisation](https://dev.bostondynamics.com/docs/concepts/autonomy/initialization) is also important part, it will be usefull in this lesson.\\n\\n> You can view recorded maps with [View Map](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_view_map) example. For that you need to copy the map to your computer:\\n> ```bash\\n> scp -r student@strelka.ygg.merklebot.com:<path_to_the_map_on_spot> <path_to_the_map_to_download>\\n> ```\\n> Also you need [install spot packages](https://github.com/boston-dynamics/spot-sdk/blob/master/docs/python/quickstart.md#install-spot-python-packages).\\n\\nStudy [recording and playing missions](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_command_line) examples in order to use it to record the map and playback the mission recorded.\\nUse [wasd](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/wasd) example to move robot while recording the map.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\\nYou can run remote control tool from examples directory.\\n\\n```console\\ncd ~/spot-sdk/python/examples/wasd\\npython3 wasd.py --username <SPOT_AUTH_USERNAME> --password <SPOT_AUTH_PASSWORD> <SPOT_ADDRESS>\\n```\\n\\nGraphNav command line tool is located at `~/spot-sdk/python/examples/graph_nav_command_line`.\\n\"}},{\"node\":{\"id\":\"8b13dd114f9cdd8f095d9f169599ec07\",\"title\":\"Lesson 2. Remote controlled and programmed motion\",\"path\":\"/docs/ru/spot-lesson2/\",\"content\":\"\\nIn the second lesson you will learn how to use Spot Command services and walk with Spot.\\n\\n## The challenge\\n\\nYou have a list of points with their local coordinates in the `/home/student/lessons` directory. Spot should go through these points. The origin of the local coordinates is in the place where Spot was turned on. On each point Spot should make one of the motions from the following list, then go to the next point. \\n\\nThe list of moves:\\n* To turn around himself\\n* To lie down in pose to change battery\\n* To nod\\n* To change the stance of robot's legs\\n* To go sideways to the next point\\n\\nCreate and execute a Python script that implements behavior described.\\n\\n> You can find Spot local coordinates with:\\n> ```python\\n> get_vision_tform_body(robot_state_client.get_robot_state().kinematic_state.transforms_snapshot)\\n> ```\\n\\n## Theory\\n\\nYou can control Spot with `Robot Command Service`. Firstly you need to build a command to supply it to the command service.\\nSpot SDK has a `RobotCommandBuilder` class for it.\\nFull list of methods and its descriprions you can find [here](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/bosdyn-client/src/bosdyn/client/robot_command.py#L593). \\n\\nIn this lesson you may need to use:\\n\\n* Stand Command\\n\\n```python\\ndef stand_command(params=None, body_height=0.0, \\n                footprint_R_body=geometry.EulerZXY())\\n```\\n\\n* Go to point\\n\\n```python\\ndef synchro_se2_trajectory_point_command(goal_x, goal_y, goal_heading,      \\n                                    frame_name, params=None,\\n                                    body_height=0.0,\\n                                    locomotion_hint=spot_command_pb2.HINT_AUTO,\\n                                    build_on_command=None)\\n```\\n\\nCheck usage example [here](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/frame_trajectory_command/frame_trajectory_command.py).\\n\\n* Velocity Command\\n\\n```python\\ndef synchro_velocity_command(v_x, v_y, v_rot, params=None, body_height=0.0,\\n                            locomotion_hint=spot_command_pb2.HINT_AUTO, \\n                            frame_name=BODY_FRAME_NAME)\\n```\\n\\n* Stance Command\\n\\n```python\\ndef stance_command(se2_frame_name, pos_fl_rt_frame, pos_fr_rt_frame, \\n                        pos_hl_rt_frame,\\n                        pos_hr_rt_frame, accuracy=0.05, \\n                        params=None, body_height=0.0,\\n                        footprint_R_body=geometry.EulerZXY(), \\n                        build_on_command=None)\\n```\\n\\nThe example of use is [here](https://github.com/boston-dynamics/spot-sdk/blob/91ed30607264e795699995d6d7834ba0c8a94d36/python/examples/stance/stance_in_place.py)\\n\\n* Pose to change battery\\n\\n```python\\ndef battery_change_pose_command(dir_hint=1)\\n```\\n\\nExample of building and running velocity command:\\n\\n```python\\nfrom bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder\\nimport time\\n\\ncommand_client = robot.ensure_client(RobotCommandClient.default_service_name)\\ncmd = RobotCommandBuilder.velocity_command(0.5, 0, 0.5)\\ncommand_client.robot_command(cmd, end_time_secs=time.time() + 2)\\n```\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"7a57dd4b0c508f5e2b5c99a3d5f49fdb\",\"title\":\"Lesson 1. Emergency stop, initialization, body position control\",\"path\":\"/docs/ru/spot-lesson1/\",\"content\":\"\\nWelcome to the first lesson!\\n\\nDuring this lesson you will learn how to authorize yourself as a user, get motor power control and send basic commands to Spot.\\n\\nWatch our introductory video if you haven't seen it already:\\n\\nhttps://youtu.be/qdk7BjWJprc\\n\\n## The challenge\\n\\nCreate a Python script controls robot body position. Run your script on Spot to let it execute a sequence of motions:\\n\\n1. Stand-up,\\n2. Trace your initials with it's face (one letter, at least 3 points),\\n3. Sit-down.\\n\\n## Theory\\n\\nRead [Understanding Spot Programming](https://dev.bostondynamics.com/docs/python/understanding_spot_programming) page in Spot SDK documentation.\\nYou need to understand what is `E-Stop` and how make initialization in your Python script in order to to let the robot execute commands.\\n\\nYou can find more detailed information for this lesson in [Base Services](https://dev.bostondynamics.com/docs/concepts/base_services), [Geometry and Frames](https://dev.bostondynamics.com/docs/concepts/geometry_and_frames), [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services) and [E-Stop](https://dev.bostondynamics.com/docs/concepts/estop_service) sections of the Spot SDK documentation.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to SpotCORE by SSH from the terminal,\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Create a script can authenticate in Spot, acquire control (lease) and power on the robot.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file. Spot address is `192.168.50.3`.\\n\\n> In [Taking ownership of Spot (Leases)](https://dev.bostondynamics.com/docs/python/understanding_spot_programming#taking-ownership-of-spot-leases) section use `lease = lease_client.acquire()` before `lease_keep_alive = bosdyn.client.lease.LeaseKeepAlive(lease_client)`\\n\\n3. Try your script with stand-up and sit-down commands. Ensure robot moves as expected,\\n\\n> Make sure you run your script by Python 3 with `python3` command. Command `python` refers to an obsolete Python 2 interpreter.\\n\\n4. Add body position control to your script. Experiment with `bosdyn.geometry.EulerZXY` robot command argument builder in order to identify what yaw, roll and pitch parameters you need to set to solve the challenge. The range of Pitch, Yaw and Roll is from -0.5 to 0.5.\\n\"}},{\"node\":{\"id\":\"349508ca70132aecf9973994ab05f388\",\"title\":\"Lesson 0. Configure and test connection to Spot\",\"path\":\"/docs/ru/spot-lesson0/\",\"content\":\"\\nLet's start establishing connection to the robot.\\nOur goal is to get answers from Spot to our [ping](https://en.wikipedia.org/wiki/Ping_(networking_utility)) signals.\\nWe use Yggdrasil Network to expose Spot to the internet, that means we will need to configure Yggdrasil Network support on your computer first.\\n\\n## 1. Yggdrasil Installation \\n\\nYggdrasil is an early-stage implementation of a fully end-to-end encrypted IPv6 network. Before startitng the lessons you need to install it on your computer.\\n\\n### For Linux: \\nInstallation instructions [here](https://yggdrasil-network.github.io/installation-linux-deb.html).\\n\\n### For MacOS: \\nDownload .pkg file from [here](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4.0-macos-amd64.pkg).\\n\\nLocate the downloaded file in Finder. Right-click it and click Open. Step through the installer as usual.\\n\\n### For Windows:\\nDownload .msi file for [x64 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x64.msi) or for [x32 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x86.msi) and run it with double click.\\n\\n## 2. Open configuration file\\n\\nYou need to add a list of peers (public nodes) to configuration file so that you will be able to connect to Spot. \\n\\n### For MacOS and Linux:\\nFor that, edit the `yggdrasil.conf` file with this command in a terminal:\\n\\n```bash\\nsudo nano /etc/yggdrasil.conf\\n```\\n\\n### For Windows:\\nRun `updateconfig.bat` in `C:/Program Files/Yggdrasil`. \\n\\nThen in `C:/ProgramData/Yggdrasil` open `yggdrasil.conf` with any text editor.\\n\\n> `ProgramData` is a hidden folder, so you need to show hidden data.\\n\\n## 3. Write peers\\n\\nIn the file that you opened find line `Peers:` (it is at the beginning of the file) add 5-6 peers geografically near to you (write them inside the brackets). You can find list of available peers [here](https://github.com/yggdrasil-network/public-peers) or add peers from example below. Example in yggdrasil.conf:\\n\\n```bash\\n  Peers:\\n  [\\n    tcp://213.188.199.150:10010\\n    tcp://213.188.210.9:10010\\n    tcp://[2a09:8280:1::3:312]:10010\\n    tcp://[2a09:8280:1::a:2e2]:10010\\n    tcp://46.151.26.194:60575\\n    tcp://ygg-ru.cofob.ru:18000\\n    tcp://ygg.tomasgl.ru:61933\\n    tls://185.22.60.71:8443\\n    tcp://51.15.118.10:62486\\n    tls://ygg.loskiq.dev:17314\\n    tls://longseason.1200bps.xyz:13122\\n  ]\\n  ```\\nCheck if the peers online in [Puplic Peers](https://publicpeers.neilalexander.dev/).\\n\\n## 4. Save and close configuration file\\n\\n### For Linux and MacOS:\\n\\nPress `Ctrl+x`, then press `y` to save changes and press `Enter`.\\n\\n### For Windows:\\n\\nSave and close file.\\n\\n## 5. Restart service\\n\\n### For Linux:\\n\\nThen restart Yggdrasil using this command:\\n\\n```bash\\nsystemctl restart yggdrasil\\n```\\n### For macOS:\\n\\nUnload the service and run Yggdrasil with changed config file:\\n\\n```bash\\nsudo launchctl unload /Library/LaunchDaemons/yggdrasil.plist\\nsudo yggdrasil -useconffile /etc/yggdrasil.conf\\n```\\n> You will need to do that before every lesson.\\n\\n### For Windows:\\n\\nPress win + r and type `services.msc`, find Yggdrasil service, open it and restart (press Stop and Start).\\n\\n![win-service](../images/spot/spot-windows.jpg)\\n\\n## 6. Check Connection\\n\\nCheck if Yggdrasil works well.\\n\\nFor that try to ping Spot address:\\n```bash\\nping strelka.ygg.khassanov.xyz\\n```\\n> To open terminal in Windows press `Win+R`, type `cmd` and press `Enter`.\\n\\n> On MacOS use `ping6` instead of `ping`.\\n\\nIf you can't ping Spot or you had any errors during the Yggdrasil setup look in [Troubleshooting page](/docs/spot-troubleshooting). If you can't find the solution there, please email spot@robonomics.network.\\n\\n## 7. Create ssh key\\n\\nYou will connect to Spot via ssh, so you need to create ssh keys which you will use in booking lessons.\\n\\nRun following command in the terminal:\\n```bash\\nssh-keygen -t rsa\\n```\\n> SSH Client is available by default only in Windows 10, so if you use older versions you need to install it. For example you can use [PuTTY](https://www.putty.org/).\\n\\nRemember the path to your key (by default it is `/home/<user>/.ssh/id_rsa.pub` or `C:\\\\Users\\\\<user>\\\\.ssh\\\\id_rsa.pub`).\\n\"}},{\"node\":{\"id\":\"729d7576b1609aa38ebc221a64a72563\",\"title\":\"Setup SLS Gateway\",\"path\":\"/docs/ru/sls-setup/\",\"content\":\"\\nYou can use [SLS Gateway from Robonomics](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01) instead of Xiaomi/Aqara gateways. It works only in your local network and don't send any data to external servers, so you can control all data about your home.\\n\\n1. Ensure that the switches on the back of the gateway are properly positioned. Switches 5 (RX Zigbee to ESP) and 6 (TX Zigbee to ESP) must be in the ON position, the others must be off. \\n\\n2. Connect the type C power cable. The indicator light in the center should turn green.\\n\\n3. The first time it starts up, the gateway will begin distributing Wi-Fi with the SSID 'zgw****' to set up the SLS gateway connection. Connect to this network. Keep in mind that the signal may be quite weak, so it is best to keep the SLS Gateway closer to your computer. \\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). Configure the SLS Gateway to connect to your Wi-Fi by entering the user / pass. After that the gateway's Wi-Fi will shut down. \\n\\n5. Find the local IP of the SLS gateway to access the web interface. You can use the command 'arp -a' or 'nmap'. The resulting link should look like this: 'http://192.168.xxx.xxx'.\\n\\n6. Go to Setting/Hardware and make sure that the settings look like this. Correct the settings if necessary and reboot the gateway:\\n\\n![sls-hardware](../images/home-assistant/sls-hardware.jpg)\\n\\n7. Configure automatically adding devices to Home Assistant. Go to `Zigbee/Config` then tick `Home Assistant MQTT Discovery` and `Clear States`:\\n\\n![sls-hass](../images/home-assistant/sls-hass.png)\\n\\n8. Connect your devices by going to Zigbee/Join. Press the Enable Join button to connect and put your sensors in pairing mode. \\n\\nAfter that connect it to Home Assistant with the following [guide](/docs/sls-gateway-connect)\"}},{\"node\":{\"id\":\"c182e5799f81d8908d33dc6ebe494966\",\"title\":\"Connect SLS Gateway to Home Assistant\",\"path\":\"/docs/ru/sls-gateway-connect/\",\"content\":\"\\n## MQTT Brocker\\n\\nFirst, you need to run MQTT brocker on your raspberry with Home Assistant. Connect to it under `ubuntu` login. Then install [Mosquitto Brocker](https://mosquitto.org/):\\n\\n```bash\\nsudo apt update -y && sudo apt install mosquitto mosquitto-clients -y\\n```\\nConfigure username (you can use any username you want) and password (you will be asked to enter the password after the command):\\n```bash\\nsudo mosquitto_passwd -c /etc/mosquitto/passwd <username>\\n```\\nThen edit configuration file:\\n```bash\\nsudo nano /etc/mosquitto/mosquitto.conf\\n```\\nAdd the following at the end of the file:\\n```\\nlistener 1883\\nallow_anonymous false\\npassword_file /etc/mosquitto/passwd\\n```\\n\\nThen restart the service:\\n\\n```bash\\nsudo systemctl restart mosquitto\\n```\\n\\nAnd check the brocker status:\\n```bash\\nsystemctl status mosquitto\\n```\\n\\n![mosquitto](../images/home-assistant/mosquitto.png)\\n\\n## MQTT Integration\\n\\nThen you need to add MQTT integration to Home Assistant. Open web interface then go to `Configuration/Integrations` page and press `Add Integration` button. Find MQTT:\\n\\n![mqtt](../images/home-assistant/mqtt.png)\\n\\nPress on it and set up your brocker with address (localhost), port (1883) and your username and password, then press `submit`:\\n\\n![mqtt1](../images/home-assistant/mqtt1.png)\\n\\nThen press on three dots on MQTT integration and choose `System Options`:\\n\\n![mqtt_options](../images/home-assistant/mqtt_conf.png)\\n\\nAnd check if automatically adding new devices is enabled:\\n\\n![mqtt_dev](../images/home-assistant/add_dev.png)\\n\\n## MQTT on SLS Gateway\\n\\nAlso you need to configure MQTT on SLS Gateway. On your SLS Gateway go to `Settings/Link` -> `MQTT Setup`:\\n\\n![sls-mqtt](../images/home-assistant/sls-mqtt.png)\\n\\nAnd add your brocker address (address of the raspberry with Home Assistant in local network) and port (1883). Also write the topic name (you can choose any). Don't forget to tick `Enable` and `Retain states`:\\n\\n![sls-mqtt1](../images/home-assistant/sls-mqtt1.png)\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\"}},{\"node\":{\"id\":\"9b43a71f4bfbefd35c30e791b1327a1d\",\"title\":\"Введение\",\"path\":\"/docs/ru/sensors-network-introduction/\",\"content\":\"\\n## Что такое Sensors Robonomics Network?\\n\\nSensors Robonomics Network - это гражданская сеть датчиков для мониторинга качества воздуха. Каждый может собрать собственный датчик или воспользоваться готовым решением от команды разработки и установить у себя. Для датчиков используется ПО с открытым кодом и схемой подключения компонентов. Один из основных используемых датчиков - это датчик тонкодисперсных частиц PM10 и PM2.5.\\n\\n## Что такое PM10 и PM2.5?\\n\\nPM10 это частицы какого-либо вещества размером 10 мкм или менее, PM2.5 это частицы диаметром 2.5 мкм и меньше. Они постоянно витают в воздухе и не оседают из-за малого размера, для сравнения толщина человеческого волоса составляет 100 мкм. Такие частицы могут появляться из-за различных причин, в том числе в результате промышленных процессов, связанных с обработкой сыпучих материалов или сжиганием и переработкой полезных ископаемых. Также они выделяются после лесных пожаров и пыльных бурь. Кроме того их источником может быть обычный транспорт при сжигании топлива либо в результате износа шин и дорожного покрытия. Шины автомобиля стираются в мелкую крошку и ветер разносит ее от дорог по всему городу.\\n\\n## Зачем их измерять?\\n\\nЧастицы PM10 и PM2.5 наиболее опасны, потому что их размер позволяет проникать в легкие, тогда как частицы больших размеров, как правило, задерживаются в носу или горле. Более крупные частицы PM10 раздражают дыхательные пути, нос, горло и глаза. Частицы мельче 2.5 мкм способны проникать глубоко в легкие и даже попадать в кровь. Попадание данных частиц в организм человека влечет за собой различные пагубные последствия:\\n- отравление вредными веществами, попадающими в кровь\\n- аллергические реакции\\n- бактериальные и грибковые инфекции\\n- рак\\n- раздражение слизистых оболочек\\n- обострение симптомов респираторных заболеваний\\n\\n## Почему именно Sensors Robonomics Network?\\n\\nВ России существуют другие общественные сети мониторинга, такие как [Дыши Москва](https://breathe.moscow/), которые основаны на немецком проекте [sensor.community](https://sensor.community/ru/), однако они используют обычную клиент-серверную архитектуру, что в данном случае является недостатком, поскольку данные со всех датчиков вместе с запросами пользователей идут на один сервер, который не всегда справляется с такой нагрузкой, и возникают ситуации, когда карта с данными недоступна в самые ответственные моменты. В Sensors Robonomics Network датчики отправляют данные на несколько разных серверов, а также любой пользователь может поднять сервер Sensors Connectivity для своего датчика и увидеть его на карте. Сама карта не перегружается, потому что представляет из себя децентрализованное приложение (DApp), которое напрямую из вашего браузера работает с данными, которые сервера отправляют в IPFS pub-sub канал.\\n\\n\\n## Источники\\nhttp://www.npi.gov.au/resource/particulate-matter-pm10-and-pm25\\n\\nhttps://habr.com/ru/company/tion/blog/396111/\"}},{\"node\":{\"id\":\"887cbfea9b63e2ae6011d24fb54e7238\",\"title\":\"Sensors Connectivity\",\"path\":\"/docs/ru/sensors-connectivity-on-aira/\",\"content\":\"\\nДля получения и обработки данных Sensors Robonomics Network использует модуль sensors community от Робономики. Этот модуль позволяет любому пользователю поднять свой собственный сервер для получения данных с датчиков и дальнейшей их обработки. Сейчас разработчиками запущено несколько таких серверов и любой датчик может отправлять данные на них. Запуск нескольких серверов позволяет избежать потери данных при проблемах в работе одного из них, поскольку датчики с нерабочего сервера переключатся на рабочий.\\n\\nСхема работы Sensors Connectivity:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSensors Connectivity представляет из себя набор станций (station1, station2...), на которые приходят различные данные, в том числе данные с датчиков по http протоколу. Но также это могут быть датчики, подключенные к компьтеру по USB или любой другой истчник данных.\\n\\nПолученные со станций данные обрабатываются Sensors Connectivity и переходят к фидерам (feeder1, feeder2...). Фидеры же отправляют обработанные данные пользователю. В нашем случае данные отправляются в децентрализованный IPFS канал.\\n\\nКарта [sensors.robonomics.network](https://sensors.robonomics.network/) это децентрализванное приложение (DApp), работающее на вашем компьютере. Оно читает данные из IPFS канала и выводит их на карту. Таким образом нет прямой связи между сервером, собирающим данные с датчиков, и картой, которую видит пользователь, передача данных между ними происходит через IPFS pubsub, что снижает нагрузку на сервера.\\n\\nКроме того, раз в какое-то время файл с данными за последний промежуток времени сохраняется в IPFS, а хэш этих данных далее записывается в блокчейн. Так как IPFS это контентно-адресуемая сеть, то сохранение данных в ней дает гарантию, что любое изменение в них не пройдет незамеченным, потому что адрес нужного файла содержит хэш его содержимого, который поменяется при любом изменении данных. Блокчейн используется для передачи хэша дальше пользователю, который может использовать его, чтобы получить из IPFS нужные данные (что и происходит при запросе просмотра истории на карте [sensors.robonomics.network](https://sensors.robonomics.network/)). Так как сделанную транзакцию невозможно изменить, то можно быть уверенным, что это правильный хэш.\\n\\nИсходный код для Sensors Connectivity доступен по [ссылке](https://github.com/airalab/sensors-connectivity). Чтобы увидеть данные со своего сервера на карте, вам нужно обратиться к команде разработки по адресу vm@multi-agent.io и отправить ipfs id своего сервера.\\n\\n# Запуск собственного сервера Sensors Connectivity\\n\\n## Требования\\n\\nЧтобы собрать Python пакет вам нужен IPFS daemon. Установите его следующими командами:\\n\\n```\\nwget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_linux-amd64.tar.gz\\ntar -xzf go-ipfs_v0.8.0_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh \\nipfs init\\n```\\nВы можете получить IPFS ID следующей командой после запуска IPFS daemon (вам нужно то, что в графе `ID`)\\n\\n```console\\n$ ipfs id\\n{\\n\\t\\\"ID\\\": \\\"QmUZxw8jsRpSx5rWkTpJokPGKvWihTrt5rbRCFXzJ4eCAP\\\",\\n\\t\\\"PublicKey\\\": \\\"CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC/uMV3rLM/C+LOh2DGPo3chr+VM+vyYMKi...\\n    ...\\n```\\n\\n## Установка в качестве PyPi пакета\\n\\n```\\npip3 install py-sr25519-bindings\\npip3 install sensors-connectivity\\n```\\n\\n### Конфигурация\\n\\n[Здесь](/docs/configuration-options-description/) вы можете найти статью о том, как установить правильную конфигурацию для вашего сервера.\\n\\n### Запуск\\n\\nСначала запустите IPFS Daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nПосле настройки конфигурации можно запустить сервис (в другом терминале):\\n\\n```\\nsensors_connectivity \\\"path/to/your/config/file\\\"\\n```\\n\\nВы сможете увидеть логи в терминале и в файле `~/.logs`.\\n\\n## Сборка из источников\\n### Требования\\n\\nЧтобы собрать пакет из источников вам нужен установленный [poetry](https://python-poetry.org/docs/#osx--linux--bashonwindows-install-instructions) . Для linux:\\n\\n```\\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -\\n```\\n\\n### Получение пакета и установка зависимостей\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npoetry install\\n```\\n\\n### Документация\\n\\nЧтобы подготовить датчик к работе с собственным сервером, пройдите инструкцию на [Robonomics Wiki](/docs/connect-sensor-to-robonomics/).\\n\\n### Configuration\\n\\n[Здесь](/docs/configuration-options-description/) вы можете найти статью о том, как установить правильную конфигурацию для вашего сервера.\\n\\nСкопируйте `default.json` и заполните его использую информацию из статьи.\\n\\nВы также можете задать файл протоколирования. По умолчанию для логгирования используется файл `logging.py`, который по умолчанию использует обработчик `console` и `file`. Обратите внимание на обработчик `file`. Шаблон хранится в файле `connectivity/config/logging_template.py`. Вы можете указать путь (`filename`), в котором будут храниться ваши логи (не забудьте создать этот каталог, если он не существует). По умолчанию путь для логов - `~/.logs`. Вы можете использовать любые другие обработчики из [library](https://docs.python.org/3.8/library/logging.html).\\n\\n### Запуск\\n\\nЗапустите IPFS Daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nПосле настройки конфигурации и лог файлов можно запустить службу (в другом терминале):\\n\\n```\\npoetry run sensors_connectivity \\\"path/to/your/config/file\\\"  \\n```\\nЕсли в вашем файле журнала установлен обработчик `console`, вы сможете видеть логи в консоли.\\n\\n### Пример логов:\\n\\n```\\n2022-02-17 19:30:51,248 - INFO - Getting data from the stations...\\n2022-02-17 19:30:51,443 - INFO - airalab-http-v0.8.0: [[], [{MAC: c8e2650f254e, Uptime: 0:00:14.010502, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:30:51,443 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:07,517 - INFO - Frontier Datalog: Data sent to Robonomics datalog and included in block 0x04baf3d81c6d31ec6f3ca3e515b9a6920666ee17cbd66f57130eaa000bad2cd4\\n2022-02-17 19:31:07,519 - INFO - RobonomicsFeeder: {\\\"0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a\\\": {\\\"model\\\": 2, \\\"geo\\\": \\\"53.518475,49.397178000000004\\\", \\\"measurement\\\": {\\\"airtemp\\\": -8.0, \\\"windang\\\": 45.0, \\\"windspeed\\\": 0.13, \\\"windspeedmax\\\": 0.13, \\\"pm10\\\": \\\"\\\", \\\"pm25\\\": \\\"\\\", \\\"timestamp\\\": 1645113602.0}}}\\n2022-02-17 19:31:07,523 - INFO - Checking data base...\\n127.0.0.1 - - [17/Feb/2022 19:31:13] \\\"POST / HTTP/1.1\\\" 200 -\\n2022-02-17 19:31:21,248 - INFO - Getting data from the stations...\\n2022-02-17 19:31:21,429 - INFO - airalab-http-v0.8.0: [[{MAC: c8e2650f254e, Uptime: 0:00:43.818101, M: {Public: 133b761496539ab5d1140e94f644e2ef92c7ac32446dc782bfe1a768379a669a, geo: (1,200), measurements: {'pm10': 27.58, 'pm25': 15.02, 'temperature': 22.93, 'pressure': 758.0687068706872, 'humidity': 39.44, 'timestamp': 1645115473}}}], [{MAC: c8e2650f254e, Uptime: 0:00:43.996539, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:31:21,444 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:51,249 - INFO - Getting data from the stations...\\n```\\n\\n## Устранение неполадок\\n\\n### Python.h: No such file or directory\\n\\nЕсли при выполнении команды `poetry install` вы получаете такую ошибку, вам необходимо установить заголовочные файлы и статические библиотеки для python dev. Для установки используйте ваш менеджер пакетов. Например, для `apt` вам нужно выполнить команду\\n```\\nsudo apt install python3-dev\\n```\\n> Note:\\npython3-dev не охватывает все версии для python3. Для работы сервиса требуется как минимум python3.8, для этого вам может потребоваться указать версию `sudo apt install python3.8-dev`..\\n\\n[Здесь](https://stackoverflow.com/a/21530768) вы можете найти примеры для других менеджеров пакетов.\\n\\n### Несоответствие версий Python\\n\\nЕсли при выполнении команды `poetry install` вы получаете ошибку `SolverProblemError`, которая гласит \\\"The current project's Python requirement (3.6.9) is not compatible with some of the required packages Python requirement:...\\\", даже если у вас более старая версия python (например, python3.8), возможно, вам нужно указать версию python, которую использует poetry:\\n\\n```\\npoetry env use python3.8\\n```\\n\\n\"}},{\"node\":{\"id\":\"0b62e1f7487fbc174c723753a66cf016\",\"title\":\"How to contribute\",\"path\":\"/docs/ru/sensors-connectivity-contribution/\",\"content\":\"\\nIf you find any bugs or would like to propose an improvement, please, open a new issue in one of tre repositories, that you want to contribute.\\n\\n## Main Repositories\\n\\n- [sensors-connectivity](https://github.com/airalab/sensors-connectivity/issues) - Sensors Connectivity server\\n- [sensors-software](https://github.com/LoSk-p/sensors-software/issues) - firmware for the sensor\\n- [airrohr-firmware-flasher](https://github.com/LoSk-p/airrohr-firmware-flasher/issues) - application for microcontroller firmware\\n\"}},{\"node\":{\"id\":\"cd202774c4f705bee7e9cda2fca0cec0\",\"title\":\"Securely connect cloud AI to the factory floor\",\"path\":\"/docs/ru/securely-connect-cloud-ai-to-the-factory-floor/\",\"content\":\"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n![](../images/google-play-store.gif)\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n![](../images/Veracity_Protocol_Transaction.gif)\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n![](../images/Veracity_Protocol_Launch.gif)\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"}},{\"node\":{\"id\":\"cb705241a367d1beed029f56e0dd9cbe\",\"title\":\"Как установить ноду Робономики в режиме разработчика\",\"path\":\"/docs/ru/run-dev-node/\",\"content\":\"\\nДля тестирования Ваших приложений для Робономики Вам может понадобиться установка ноды в режиме разработчика.\\n\\nhttps://youtu.be/04GsVkZ7aVg\\n\\n## Запускаем\\n\\n1. Прежде всего, Вам понадобится двоичный файл. Загрузите архив с ним из последнего [релиза](https://github.com/airalab/robonomics/releases).\\n\\n2. Распакуйте его и измените разрешения:\\n\\n```bash\\ntar xf robonomics-1.7.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n3. Запустите в режиме разработчика:\\n\\n```bash\\n./robonomics --dev\\n```\\nВы увидите следующее:\\n\\n![robonomics](../images/dev-node/robonomics.png)\\n\\n## Получите токены\\n\\nТеперь Вы можете подключиться к Вашей локальной ноде через [Портал Полькадот](https://polkadot.js.org/apps/#/explorer).\\n\\nИзмените сеть на `Local Node` в верхнем левом углу и нажмите `Switch`.\\n\\n![локальная нода](../images/dev-node/portal.png)\\n\\nЗатем перейдите в `Accounts`:\\n\\n![аккаунты](../images/dev-node/accs.png)\\n\\nВы можете создать новый аккаунт, нажав `Add Account`.\\n\\n![добавить аккаунт](../images/dev-node/add_acc.png)\\n\\nНе забудьте сохранить сид-фразу в надежном месте.\\n\\nИспользуйте один из существующих аккаунтов для отправки токенов на Ваш новый аккаунт. Выберите, к примеру, Alice, и нажмите `Send`. Затем выберите Ваш новый аккаунт, введите количество токенов для отправки и нажмите `Make Transfer`:\\n\\n![отправить](../images/dev-node/send.png)\\n\"}},{\"node\":{\"id\":\"06691a2b8a7a1f08f5ae06880dca433f\",\"title\":\"ROS-based Projects for Smart Spaces\",\"path\":\"/docs/ru/ros-smart-projects/\",\"content\":\"\\nThroughout its 15 years of development, the Robot Operating System framework was integrated with dozens of [various robotic devices](https://robots.ros.org/), and there are even more packages with algorithms and tools developed by the community. Truth be told, there are now so many projects, and the chaoticness of the description style of their repositories grew so much that it is currently quite problematic to find projects dedicated to a specific subject topic. \\n\\nHere, you’ll find a modest list of ROS-based projects that are dedicated to robots and IoT-devices that are meant for use in a home or office environment. This subject matter is one of the pillars of the Robonomics platform. Our goal is to try and bring these projects on track with Robonomics, from both a technical integration point of view and the perspective of an interesting application of these devices in a robot economy. Feel free to use this list in your search for ideas and inspiration.\\n\\nYou can check out some examples of ROS-projects integrated with Robonomics in the [Playground Overview page](https://wiki.robonomics.network/docs/en/playground-overview/). New projects, including those described here, will be added to the Wiki with time.\\n\\nAs of right now (**April 2021**), Robonomics is oriented towards ROS **Melodic** and **Noetic** versions. Older versions can also work, but there may be additional integration work needed. In the future, support for ROS version 2 will be added.\\n\\nThe main resources to search for ROS repositories and packages can be accessed [here](https://index.ros.org/).\\n\\n## Simulation\\n\\nBefore shifting our attention solely to devices, it’s worth remembering that for a large quantity of ROS projects, there exists an option to test them in a simulation. The most popular tool for the 3D modeling of various robots under ROS is the [Gazebo](http://gazebosim.org/) simulator and its offshoot project, [Ignition](https://index.ros.org/r/ros_ign/). Both simulators allow to model devices in various difficult indoor and outdoor environments, alter the model and environment itself, test control algorithms and debug before moving over to the real device. Also, this is an excellent tool for training and situations when a real device is absent.\\n\\nOverall, this is one of the best options for trying to integrate Robonomics with a ROS device without any expenditures at all. A real scenario would merely require slight code modifications. For Gazebo, Robonomics has a detailed guide that consists of two parts that cover [settings](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) and [integrations](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/) (using a drone as an example). The main challenge is in finding a ready model (for example, [here](https://github.com/osrf/gazebo_models)) for Gazebo or trying to create your own model using the [SDFormat](http://sdformat.org/) developed for simulators. \\n\\n## Single-board computers and other boards\\n\\nSuch boards act as a base component for connecting other devices to ROS, primarily sensors and recording devices (audio, photo, and video recorders, cameras, temperature, pressure, and substance concentration sensors.) because the concept of a smart space implies the creation of a [digital twin](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf) of infrastructure objects. Also, boards can act as the main computing device and controller for constructing a robotic mobile device. A list of boards that support ROS is presented below:\\n\\n| Name and link                                                                                         |                                    Description                                  | ROS version | Last update |\\n|:-----------------------------------------------------------------------------------------------------:|---------------------------------------------------------------------------------|:-----------:|:-----------:|\\n|  [Raspberry Pi](http://wiki.ros.org/ROSberryPi/Installing%20ROS%20Melodic%20on%20the%20Raspberry%20Pi)| single board computer; RaspPi versions 2, 3 and 4 are available                 |   melodic   |     2020    |\\n|    [Arduino](http://wiki.ros.org/rosserial_arduino)                                                   | single board computer                                                           |    noetic   |     2021    |\\n|    [Phidgets](http://wiki.ros.org/phidgets)                                                           | sets of boards, various sensors and devices: Ph sensor, LED, RFID, motor control|    noetic   |     2020    |\\n|   [Sense HAT](https://wiki.ros.org/sensehat_ros)                                                      | shield for RaspPi with a set of sensors and LED                                 |    noetic   |     2020    |\\n|     [Navio2](https://navio2.emlid.com/)                                                               | autopliot shield for RaspPi 2,3,4                                               |    noetic   |     2020    |\\n|     [OpenCR](http://wiki.ros.org/opencr)                                                              | robot controller                                                                |    noetic   |     2021    |\\n\\n## Smart home devices and household robots\\n\\nPresented here are ROS devices whose initial use was for smart homes or offices. The list varies widely, from vacuum cleaners and robotic assistance to home control systems.\\n\\n| Name and link                                             | Description                                                 |          ROS version          | Last update |\\n|:---------------------------------------------------------:|-------------------------------------------------------------|:-----------------------------:|:-----------:|\\n|  [Care-O-bot 4](http://wiki.ros.org/care-o-bot)           | household robot-assistant; a simulation is available        |            melodic            |     2021    |\\n|     [Kobuki](http://wiki.ros.org/kobuki)                  | mobile platform with different use cases (e.g. a waiter)    |            melodic            |     2020    |\\n|    [QTrobot](http://wiki.ros.org/Robots/qtrobot)          | humanoid social robot                                       | kinetic (melodic can be used) |     2020    |\\n|      [Nao](http://wiki.ros.org/nao)                       | humanoid robot; a simulation is available                   |            Melodic            |     2020    |\\n|     [TIAGo](http://wiki.ros.org/Robots/TIAGo)             | service robot with a manipulator; a simulation is available |            kinetic            |     2020    |\\n|     [Roomba](https://github.com/AutonomyLab/create_robot) | robot vacuum cleaner                                        |            melodic            |     2020    |\\n|    [OpenHAB](http://wiki.ros.org/iot_bridge)              | home automation system                                      |            kinetic            |     2017    |\\n|     [Sesame](https://index.ros.org/p/sesame_ros/)         | smart lock                                                  |            melodic            |     2021    |\\n\\n## Mobile platforms and manipulators\\n\\nFirst and foremost, ROS is known for supporting mobile robotics, from drones to industrial manipulators, for which many packages were created that realize simultaneous localization and mapping ([SLAM](http://wiki.ros.org/rtabmap_ros)), solve the direct and inverse task of kinematics, [trajectory planning](https://moveit.ros.org/), and etc. Mobile robotics are gradually penetrating into everyday life, which is why it is certainly interesting to test existing ROS-robots in their use within a smart space. The general list of ROS-based mobile platforms is rather large, which is why here we have selected those that are potentially convenient to operate in a home or office space. \\n\\n| Name and link                                             | Description                                | ROS version | Last update |\\n|:---------------------------------------------------------:|--------------------------------------------|:-----------:|:-----------:|\\n|   [turtlebot](http://wiki.ros.org/turtlebot3)             | mobile platform tailored for ROS           |    noetic   |     2020    |\\n|    [GoPiGo3](http://wiki.ros.org/Robots/gopigo3)          | mobile robot based on RaspPi               |   melodic   |     2020    |\\n|    [LoCoBot](http://wiki.ros.org/locobot)                 | mobile manipulator                         |   kinetic   |     2020    |\\n|   [ROSbot 2.0](http://wiki.ros.org/Robots/ROSbot-2.0)     | mobile platform; a simulation is available |    noetic   |     2021    |\\n|     [VOLTA](http://wiki.ros.org/Robots/Volta)             | mobile platform; a simulation is available |   melodic   |     2021    |\\n|    [evarobot](http://wiki.ros.org/Robots/evarobot)        | mobile platform; a simulation is available |    noetic   |     2020    |\\n|    [Freight](http://wiki.ros.org/Robots/freight)          | mobile platform; a simulation is available |   melodic   |     2021    |\\n|      [PR2](http://wiki.ros.org/Robots/PR2)                | mobile platform; a simulation is available |   melodic   |     2021    |\"}},{\"node\":{\"id\":\"376e29b62ac7a29031f1e491d44b777f\",\"title\":\"Manual start of the Robonomics network, consisting of 3 nodes\",\"path\":\"/docs/ru/robonomics-test-network-manual/\",\"content\":\"\\n**Need to start Robonomics network of N (N> = 2) nodes**\\n\\n## Requirements\\n- Robonomics binary, download latest here: https://github.com/airalab/robonomics/releases/\\n- Subkey tool, download latest here: https://github.com/airalab/robonomics/releases/\\n- 3 servers with root shell. Their ip-addresses in the current instruction will be `165.227.171.127`, `159.89.25.75` and `159.89.30.50`\\n\\n## Introduction\\nIn this tutorial, we will first create all key files locally, and then upload them to their corresponding nodes. \\n\\n## Prepare directories\\nDownload 2 archives from the links above and open the folder with them in the terminal.\\nThen create a directory for the project, unpack the archives into it and go to the created folder:\\n```\\n$ mkdir robonomics_test_network\\n$ tar -xf ./robonomics-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ tar -xf ./subkey-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ cd ./robonomics_test_network/\\n```\\n\\nNext, create a separate **uploads** directory and the necessary subdirectories for each server. All files intended for uploading to a specific server will be stored in these subdirectories:\\n```\\n$ mkdir -p uploads/165.227.171.127/keystore && mkdir -p uploads/165.227.171.127/network\\n$ mkdir -p uploads/159.89.25.75/keystore && mkdir -p uploads/159.89.25.75/network\\n$ mkdir -p uploads/159.89.30.50/keystore && mkdir -p uploads/159.89.30.50/network\\n```\\n\\nAlso, create a **local** folder with **validators** and **sudo** folders, which will store the validators and sudo keys locally.\\n```\\n$ mkdir -p local/validators && mkdir -p local/sudo\\n```\\n\\n## Prepare spec.json\\nUsing the robonomics binary, generate a **spec.json** file, which will use as the basis:\\n```\\n$ ./robonomics build-spec --chain dev > uploads/spec.json\\n```\\n\\nNext, edit this file. At first correct the first three fields, make them look like this:\\n```\\n\\\"name\\\": \\\"Test Robonomics Network\\\",\\n\\\"id\\\": \\\"dev\\\",\\n\\\"chainType\\\": \\\"Live\\\",\\n```\\n\\n### bootNodes\\nThe **bootNodes** field is a list of strings of special format. For each of the bootnodes must write the corresponding string here.\\nTo do this, first create a key file for each bootnode using **subkey**:\\n```\\n$ ./subkey generate-node-key uploads/165.227.171.127/network/secret_ed25519  \\n12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\n$ ./subkey generate-node-key uploads/159.89.25.75/network/secret_ed25519\\n12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\n$ ./subkey generate-node-key uploads/159.89.30.50/network/secret_ed25519\\n12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\n```\\n\\nEach command creates a key file in the specified directory and outputs to stdout the string that will be needed to fill in the **bootNodes** field in the **spec.json** file. As a result, the **bootNodes** section should look like following example:\\n```\\n\\\"bootNodes\\\": [\\n\\\"/ip4/165.227.171.127/tcp/30333/p2p/12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\\",\\n\\\"/ip4/159.89.25.75/tcp/30333/p2p/12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\\",\\n\\\"/ip4/159.89.30.50/tcp/30333/p2p/12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\\"\\n],\\n```\\nThe next 3 fields (telemetryEndpoints, protocolId, properties) can be filled like this:\\n```\\n \\\"telemetryEndpoints\\\": [\\n     [\\n       \\\"/dns4/telemetry.polkadot.io/tcp/443/x-parity-wss/%2Fsubmit%2F\\\",\\n       0\\n     ]\\n ],\\n\\\"protocolId\\\": \\\"txrt\\\",\\n\\\"properties\\\": {\\n    \\\"ss58Format\\\": 32,\\n    \\\"tokenDecimals\\\": 9,\\n    \\\"tokenSymbol\\\": \\\"TXRT\\\"\\n},\\n```\\nFurther up to the **palletBalances** field leave unchanged.\\n\\n\\n### palletBalances\\nTo fill the palletBalances field create **the number of nodes + 1** (the last key is for **sudo**) keys. This can be done using **subkey**, in the file name must specify **SS58 Address** from the generated key, in the file content must specify **seed** phrase in quotes. \\n\\nExample creating one key.\\n - Generate key:\\n    ```\\n    $ ./subkey -n robonomics generate\\n    Secret phrase `display cargo domain april joy still bundle notice bridge pencil fat approve` is account:\\n      Network ID/version: substrate\\n      Secret seed:        0x0275ab9bce53e4359184f02112943162c708f483009e0b7b3ba63549c5c2e514\\n      Public key (hex):   0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      Account ID:         0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      SS58 Address:       4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n - Create key file:\\n    ```\\n    $ touch ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx && echo '\\\"display cargo domain april joy still bundle notice bridge pencil fat approve\\\"' | tee ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n  \\nCommand template for creating a validator key file:  \\n`touch ./local/validators/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/validators/**SS58_Address**`\\n\\nCommand template for creating a sudo key file:   \\n`touch ./local/sudo/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/sudo/**SS58_Address**`\\n\\nThree keys are stored in the **local/validators** folder and one in the **local/sudo** folder. As a result, the following content should appear in the **local** directory:\\n```\\n./local/\\n├── sudo\\n│   └── 4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\n└── validators\\n    ├── 4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ├── 4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\n    └── 4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\n```\\n\\nNow fill the palletBalances section in the spec.json file with these keys.\\nAs a result, it should look like this:\\n```\\n\\\"palletBalances\\\": {\\n  \\\"balances\\\": [\\n    [\\n      \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Generated validator 1 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Generated validator 2 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Generated validator 3 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\",    <-- Generated sudo key\\n      1000000000000000000\\n    ],\\n  ]\\n},\\n```\\nThe values that were previously presented in the palletBalances section must be deleted.\\n\\n### palletSession\\nNext step is the **palletSession** section in file **spec.json**. First let's describe its format. \\nThis section contains the \\\"keys\\\" field, that contains a list of three lists (equals of nodes count). Each of these lists looks like follows:\\n```\\n[\\n    \\\"%validator_SS58_address%\\\",\\n    \\\"%validator_SS58_address%\\\",\\n    {\\n        \\\"babe\\\": \\\"%sr25519_babe_SS58_address%\\\",\\n        \\\"im_online\\\": \\\"%sr25519_im_online_SS58_address%\\\"\\n        \\\"authority_discovery\\\": \\\"%sr25519_authority_discovery_SS58_address%\\\",\\n        \\\"grandpa\\\": \\\"%ed25519_grandpa_SS58_address%\\\",\\n    }\\n]\\n```\\n**%validator_SS58_address%** is the validator key that was generated for each node in the **palletBalances** section of this manual. Just copy it twice for each node.\\n\\nTo fill in the remaining 4 lines for each node, you need to create 4 key files for each node and store them in the **keystore** folders.\\nAs key files are generated, you can fill **palletSession**.\\n\\nEach key file must contain a **seed** phrase in quotes.\\nMaking of the name of each key file require separate consideration.\\nThe name of each key file is formed as **prefix** + **account_id without leading hexadecimal zero**.\\n\\nPrefixes matching:  \\n>      grandpa: '6772616e'  \\n>      babe: '62616265'\\n>      im_online: '696d6f6e'  \\n>      authority_discovery: '61756469'  \\n\\nAn example of creating keys for one node:\\n- Creating a **babe** (prefix *62616265*) key file.   \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  >  Secret phrase **cover once garment syrup income chair elder business diary frozen rack damage** is account:  \\n  >\\n  >  Network ID/version: `substrate`\\n  >\\n  >  Secret seed:        `0x90ddeee3a9a0c464572021d311c245eefc41f9a59c739faefda47efcf4755677`\\n  >\\n  >  Public key (hex):   `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  >\\n  >  Account ID:         `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  > \\n  >  SS58 Address:       `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`\\n  \\n ```\\n $ touch uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 && echo '\\\"cover once garment syrup income chair elder business diary frozen rack damage\\\"' | tee ./uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 \\n ```\\n This command creates a **babe** key file for the `165.227.171.127` node. To fill in **spec.json**, need to take from this output the value **SS58 Address**: `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`. This address need to insert instead of `%sr25519_babe_SS58_address%` in the above **palletSession** template.\\n   \\n **babe** key file creation command template:  \\n`touch ./uploads/[node_ip]/keystore/62616265+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/62616265+[Account_ID]`  \\n\\nAs you can see, the name of the babe key file is the sum of two substrings: `babe prefix ('62616265')`, and the `account_id` of the generated key, without the leading zero (`fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`). \\n  Note that the keys `babe, im_online, authority_discovery` are generated with the indication `--sr25519`.  \\n  **grandpa** key have to generate with the indication `--ed25519`.\\n \\n\\n- Creating an **im_online** (prefix *696d6f6e*) key file.  \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  > Secret phrase **envelope truly balance turkey undo casual waste skill average ordinary gun split** is account:\\n  >\\n  >   Network ID/version: `substrate`\\n  > \\n  >   Secret seed:        `0x8a19df08feeff9f1fa3581902ca22a305252aea32e284d32f10e990d00bb8926`\\n  > \\n  >   Public key (hex):   `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   Account ID:         `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   SS58 Address:       `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt`\\n   \\n  ```\\n  $ touch uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09 && echo '\\\"envelope truly balance turkey undo casual waste skill average ordinary gun split\\\"' | tee uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n  ```\\n  **im_online** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID]`\\n  \\n  **spec.json**: `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt` need to insert instead of `%sr25519_im_online_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating an **authority_discovery** (prefix *61756469*) key file.\\n   ```\\n   $ ./subkey --sr25519 -n robonomics generate\\n   ```\\n   > Secret phrase **boy harsh because omit equip atom apart spring undo explain walnut crystal** is account:\\n   >\\n   > Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0x27838c9ea0524353da3717862ef0ecef123f40e81b73bb5ef377d12b47d1c543`\\n   > \\n   >   Public key (hex):   `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   > \\n   >   Account ID:         `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   >  \\n   >   SS58 Address:       `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t`\\n   \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07 && echo '\\\"boy harsh because omit equip atom apart spring undo explain walnut crystal\\\"' | tee uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n   ```\\n  **authority_discovery** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/61756469+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/61756469+[Account_ID]` \\n  \\n   **spec.json**: `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t` need to insert instead of `%sr25519_authority_discovery_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating a **grandpa** (prefix *6772616e*) key file.\\n   ```\\n   $ ./subkey --ed25519 -n robonomics generate\\n   ```\\n   > Secret phrase **squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle** is account:\\n   > \\n   >   Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0xef0a9f51a4da7b789c0a25d39b44428d4da7262cc3fe013d4383b45216e8b83e`\\n   >  \\n   >   Public key (hex):   `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   >  \\n   >   Account ID:         `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   > \\n   >   SS58 Address:       `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa`\\n    \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009 && echo '\\\"squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle\\\"' | tee uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n   ```\\n   **grandpa** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/6772616e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/6772616e+[Account_ID]`\\n   \\n   **spec.json**: `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa` need to insert instead of `%sr25519_grandpa_SS58_address%` in the above **palletSession** template.\\n   \\n   \\n**Now 4 key files have been created for one node. Need to repeat this actions for the remaining two nodes.**\\n\\nYou should get the following **uploads** directory structure after creating all the keys:\\n```\\n./uploads/\\n├── 165.227.171.127\\n│   ├── keystore\\n│   │   ├── 617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n│   │   ├── 62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43\\n│   │   ├── 6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n│   │   └── 696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n│   └── network\\n│       └── secret_ed25519\\n├── 159.89.25.75\\n│   ├── keystore\\n│   │   ├── 617564692ac9bd30c0168fa623cfd66abb4327992d900a652bcbb238b740bdde497a565f\\n│   │   ├── 626162657cd666bb540c41cb33896a34d7413ffb86fcef1eddddfcd4edb325166df6335d\\n│   │   ├── 6772616e084402349bc08ef90c2837e8e3f12ebe8bd4ab86809e9ee5f4f8ca26e73a0518\\n│   │   └── 696d6f6e6ed2d507c0283ae869ba6514975bd8765eb8e06abd22afc09e8f36ef3950a116\\n│   └── network\\n│       └── secret_ed25519\\n└── 159.89.30.50\\n|   ├── keystore\\n|   │   ├── 61756469f20a4e16a0ee79431d6f9a70c38892c7532ad1347c2226d43ef6ffe8966e9b30\\n|   │   ├── 62616265e695aa459dbfd42bea7ed3b87970f164f34b6fee4d5a831ffbecd89eb9769b26\\n|   │   ├── 6772616eadef59f896ea6b94bcd4519be8cc4b70263fc318cec1a3be14850bbc22117c34\\n|   │   └── 696d6f6e2cb4dc8f8a67f477da15045ca40ef3861a2a6b2034ae0c64a179b4431341ea2c\\n|   └── network\\n|       └── secret_ed25519\\n└── spec.json\\n```\\n\\nThe palletSession section should look like this:\\n```\\n\\\"palletSession\\\": {\\n    \\\"keys\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t\\\",\\n                \\\"babe\\\": \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",\\n                \\\"grandpa\\\": \\\"4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa\\\",\\n                \\\"im_online\\\": \\\"4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt\\\"\\n            }\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4F6daoG2gBXRLvbT4mVRajExZdZBHH7APmX3wDuLYJyzxHSS\\\",\\n                \\\"babe\\\": \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",\\n                \\\"grandpa\\\": \\\"4G3Ai6BGUjqtCoM2aTvWyR19gQ8WZiNnh1KFM47RyiYTwkE6\\\",\\n                \\\"im_online\\\": \\\"4FHA7gzKfSLvd8jP85JUCWV6RyeRLm331KHcjnynGx7TWm7D\\\"\\n            }\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address                        \\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4CqzJFkdSZg52PfV6Fd4gJ3vPLmRu1HGuPvNivjJ8dDWaz1a\\\",\\n                \\\"babe\\\": \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",\\n                \\\"grandpa\\\": \\\"4Cqi4rG3CzWRZairhZX4isT8qG2jyz9fGDXJMrP6uBYkrft5\\\",\\n                \\\"im_online\\\": \\\"4C7V6R59cZVbabExqgWvHVE1vj1E1cV42SZr8d8zZD3gmsqk\\\"\\n            }\\n        ]\\n    ]\\n},\\n```\\n\\n### palletStaking\\n**palletStaking** must be filled in as follows:\\n```\\n\\\"palletStaking\\\": {\\n    \\\"historyDepth\\\": 84,\\n    \\\"validatorCount\\\": 10,\\n    \\\"minimumValidatorCount\\\": 2,\\n    \\\"invulnerables\\\": [\\n        \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",     <-- Validator 1 SS58 Address\\n        \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",     <-- Validator 2 SS58 Address\\n        \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\"      <-- Validator 3 SS58 Address\\n    ],\\n    \\\"forceEra\\\": \\\"NotForcing\\\",\\n    \\\"slashRewardFraction\\\": 100000000,\\n    \\\"canceledPayout\\\": 0,\\n    \\\"stakers\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",  <-- Validator 1 SS58 Address\\n            \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",  <-- Validator 1 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",  <-- Validator 2 SS58 Address\\n            \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",  <-- Validator 2 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",   <-- Validator 3 SS58 Address\\n            \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",   <-- Validator 3 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ]\\n    ]\\n},\\n```\\nThe example specified in which fields what values should be substituted.\\n\\n### palletSudo\\nIn the rest of the **spec.json** file, you need to change only the contents of **palletSudo**, substituting the previously generated **sudo** address there:\\n```\\n            \\\"palletBabe\\\": {\\n                \\\"authorities\\\": []\\n            },\\n            \\\"palletGrandpa\\\": {\\n                \\\"authorities\\\": []  \\n            },\\n            \\\"palletImOnline\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletAuthorityDiscovery\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletTreasury\\\": {},\\n            \\\"palletElectionsPhragmen\\\": {\\n                \\\"members\\\": []\\n            },\\n            \\\"palletCollectiveInstance1\\\": {\\n                \\\"phantom\\\": null,\\n                \\\"members\\\": []\\n            },\\n            \\\"palletSudo\\\": {\\n                \\\"key\\\": \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\"   <-- sudo address\\n            }\\n        }\\n    }\\n}\\n```\\n\\n## systemd unit file\\nNow create systemd unit file:\\n```\\n$ touch ./uploads/robonomics.service\\n```\\n\\nAnd fill it like this:\\n```\\n[Unit]\\nDescription=robonomics\\nAfter=network.target\\n\\n[Service]\\nUser=root\\nGroup=root\\nType=users\\nWorkingDirectory=/root\\nRestart=on-failure\\nExecStart=/usr/bin/robonomics  --chain /etc/substrate/spec.json --name ${HOSTNAME} --validator\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\nAs you can see from the \\\"ExecStart\\\" line, the **robonomics** binary is stored in the **/usr/bin/** directory, and the **spec.json** file is stored in the **/etc/substrate/** directory.\\n\\n## Uploading files\\nThe following one-line command uploads all files to the required directories on the servers. It is important that there are no other folders in the **uploads** directory, except for the folders with the ip-addresses of the nodes:\\n```\\n$ \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n    ssh root@\\\"$IP\\\" \\\"mkdir -p /root/.local/share/robonomics/chains/dev\\\" && \\\\\\n    scp -r ./uploads/$IP/* root@$IP:/root/.local/share/robonomics/chains/dev/ && \\\\\\n    scp ./uploads/robonomics.service root@$IP:/etc/systemd/system/ && \\\\\\n    scp ./robonomics root@$IP:/usr/bin/ && \\\\\\n    ssh root@$IP \\\"mkdir -p /etc/substrate\\\" && \\\\\\n    scp ./uploads/spec.json root@$IP:/etc/substrate/ \\\\\\n; done\\n```\\n\\n## Network launch\\nNow connect to all nodes, enable and start the **robonomics.service** unit:\\n```\\n$  \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n   ssh root@$IP \\\"systemctl enable robonomics.service && systemctl start robonomics.service\\\" \\\\\\n; done\\n```\\nAfter starting the service on all three nodes, you can view the node logs using **journalctl**. \\nTo do this, you can connect to any existing server via ssh and run the following command:\\n```\\n$ journalctl -u robonomics.service -f\\n```\\n![Robonomics Chart](../images/robonomics-test-network-manual/result-journalctl.jpg \\\"Robonomics Network journalctl stdout\\\")\\n\"}},{\"node\":{\"id\":\"7e865494bb6a151103643b9968791e02\",\"title\":\"Robonomics + Prometheus + Grafana\",\"path\":\"/docs/ru/robonomics-prometheus-grafana/\",\"content\":\"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](../images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](../images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](../images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](../images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](../images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](../images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](../images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](../images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](../images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"}},{\"node\":{\"id\":\"d387a8898ca613aebd4a505af12d2eaa\",\"title\":\"Robonomics Liability\",\"path\":\"/docs/ru/robonomics-liability/\",\"content\":\"\\nThe package is responsible for receiving `New Liability` events (`listener` node) and playing topics from `objective` field (`executor` node).\\nThe launch file also include `ipfs_channel` node and `signer` node.\\n\\n## ROS Parameters\\n\\n### ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~web3_ws_provider\\n\\nWeb3 WebSocket provider address. The type is `string`, defaults to `ws://127.0.0.1:8546`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~enable_executor\\n\\nEnable or disable executor node. If it's `false`, no topics from objective would be published. The type is `boolean`, defaults to `true`\\n\\n### ~master_check_interval\\n\\nPeriod (in seconds) to check master for new topic publications. It's necessary for the Recorder, which records all the topics a CPS publishes. The type is `double`, defaults to `0.1`\\n\\n### ~recording_topics\\n\\nList of topics name separated by comma. It allows you to specify which topics would be recorded. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Subscribed topics\\n\\n### /liability/infochan/eth/signing/demand (robonomics_msgs/Demand)\\n\\n[robonomics_msgs/Demand](/docs/market-messages#demand) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/offer (robonomics_msgs/Offer)\\n\\n[robonomics_msgs/Offer](/docs/market-messages#offer) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/result (robonomics_msgs/Result)\\n\\n[robonomics_msgs/Result](/docs/market-messages#result) message to sign and send further to IPFS channel\\n\\n\\n## Published topics\\n\\n### /liability/infochan/incoming/demand (robonomics_msgs/Demand)\\n\\nContains a [robonomics_msgs/Demand](/docs/market-messages#demand) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/offer (robonomics_msgs/Offer)\\n\\nContains a [robonomics_msgs/Offer](/docs/market-messages#offer) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/result (robonomics_msgs/Result)\\n\\nContains a [robonomics_msgs/Result](/docs/market-messages#result) message which was read from IPFS channel\\n\\n### /liability/incoming (robonomics_liability/Liability)\\n\\nContains all the information about the last created [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)\\n\\n### /liability/ready (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)is ready for execution\\n\\n### /liability/complete (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg) has done its job\\n\\n### /liability/finalized (std_msgs/String)\\n\\nSignals when a liability has been finalized\\n\\n## Services\\n\\n### /liability/start (robonomics_liability/StartLiability)\\n\\nThe service tells executor to play topics from the objective. It's required to pass a liability address ([robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)), which you can get from `/liability/ready` topic\\n\\n### /liability/finish (robonomics_liability/FinishLiability)\\n\\nCPS should call the service after performing the task. The input is [robonomics_liability/FinishLiability](/docs/robonomics-liability-messages#robonomics_liabilityfinishiabilitysrv)\\n\\n### /liability/restart (robonomics_liability/StartLiability)\\n\\nThe service allows to restart a liability after the system shutdown. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/resume (robonomics_liability/StartLiability)\\n\\nThe service allows to resume a liability from the last timestamp available in the persistence store. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/read (robonomics_liability/ReadLiability)\\n\\nThe service returns all the data about a liability by its address. The input is [robonomics_liability/ReadLiability](/docs/robonomics-liability-messages#robonomics_liabilityreadliabilitysrv)\\n\"}},{\"node\":{\"id\":\"6672b366b26214aab25ab0f021ed72da\",\"title\":\"Robonomics Liability Messages\",\"path\":\"/docs/ru/robonomics-liability-messages/\",\"content\":\"\\n## robonomics_liability/Liability.msg\\n\\n| Field        \\t| Type                                                                         \\t| Description                                    \\t|\\n|--------------\\t|------------------------------------------------------------------------------\\t|------------------------------------------------\\t|\\n| address      \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The Liability’s address                        \\t|\\n| model        \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model Identifier                \\t|\\n| objective    \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model parameters in rosbag file \\t|\\n| result       \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| Liability result hash                          \\t|\\n| promisee     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisee address                           \\t|\\n| promisor     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisor address (usually CPS)             \\t|\\n| lighthouse   \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The address of lighthouse your CPS works on    \\t|\\n| token        \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Operational token address                      \\t|\\n| cost         \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| CPS behavioral model implementation cost       \\t|\\n| validator    \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Observing network address                      \\t|\\n| validatorFee \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| Observing network commission                   \\t|\\n\\n## robonomics_liability/StartLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                                           |\\n|---------  |-----------------  |-----------------------------------------------------  |\\n| address   | std_msgs/String   | The address of Liability you are willing to execute   |\\n\\n**Response**\\n\\n| Field     | Type              | Description                               |\\n|---------  |-----------------  |------------------------------------------ |\\n| success   | std_msgs/Bool     | Weather or not the Liability was started  |\\n| msg       | std_msgs/String   | Status of launch                          |\\n\\n## robonomics_liability/FinishLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                           |\\n|---------  |-----------------  |------------------------------------   |\\n| address   | std_msgs/String   | The address of Liability to finish    |\\n| success   | std_msgs/Bool     | The status of execution               |\\n\\n**Response**\\n\\nThe response is empty\\n\\n## robonomics_liability/ReadLiability.srv\\n\\n**Request**\\n\\n| Field     | Type                                                                          | Description                   |\\n|---------  |------------------------------------------------------------------------------ |----------------------------   |\\n| address   | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)  | The address of a liability    |\\n\\n**Response**\\n\\n| Field         | Type                                                                  | Description           |\\n|-----------    |---------------------------------------------------------------------  |---------------------  |\\n| read          | std_msgs/Bool                                                         | Status of execution   |\\n| liability     | [robonomics_liability/Liability](#robonomics_liabilityliabilitymsg)   | Liability             |\\n\"}},{\"node\":{\"id\":\"565fea83eab6b4ceb2728e5152d37406\",\"title\":\"Robonomics-js\",\"path\":\"/docs/ru/robonomics-js/\",\"content\":\"\\n[Robonomics-js](https://github.com/airalab/robonomics-js) is a simple Javascript library for working with Robonomics Network.\\n\\n## Installation\\n\\n```\\nnpm install robonomics-js --save\\n```\\n\\nor\\n\\n```\\nyarn add robonomics-js\\n```\\n\\n### Dependencies \\n\\n* [Web3](https://github.com/ethereum/web3.js/) version 1.2.4\\n* [Ipfs](https://github.com/ipfs/js-ipfs) version 0.34.0\\n\\n\\n## Usage \\n\\nCreates a Robonomics instance\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\n```\\n\\n### options\\n\\nThe object of properties:\\n\\n```\\noptions.web3\\n```\\n\\nAn instance of [web3.js](https://github.com/ethereum/web3.js/):\\n\\n```JavaScript\\n// metamask\\nconst options = {\\n  web3: new Web3(window.ethereum),\\n  ...\\n};\\n\\n// infura\\nconst options = {\\n  web3: new Web3(\\n    new Web3.providers.WebsocketProvider(\\n      \\\"wss://mainnet.infura.io/ws/v3/0b2f2a5026264b57b6d698b480332e89\\\"\\n    )\\n  ),\\n  ...\\n};\\n```\\n\\n```\\noptions.messageProvider\\n```\\n\\nThis is an instance of MessageProviderIpfs which uses a [js-ipfs](https://github.com/ipfs/js-ipfs) node with pubsub support\\n\\n```JavaScript\\nconst ipfs = new Ipfs({\\n  repo: 'robonomics-example',\\n  relay: {\\n    enabled: true,\\n    hop: {\\n      enabled: true\\n    }\\n  },\\n  EXPERIMENTAL: {\\n    pubsub: true\\n  },\\n  config: {\\n    Addresses: {\\n      Swarm: [\\n        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star',\\n        '/dns4/1.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/2.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/3.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/'\\n      ]\\n    },\\n    Bootstrap: [\\n      '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',\\n      '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',\\n      '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',\\n      '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',\\n      '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',\\n      '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',\\n      '/dns4/1.pubsub.aira.life/tcp/443/wss/ipfs/QmdfQmbmXt6sqjZyowxPUsmvBsgSGQjm4VXrV7WGy62dv8',\\n      '/dns4/2.pubsub.aira.life/tcp/443/wss/ipfs/QmPTFt7GJ2MfDuVYwJJTULr6EnsQtGVp8ahYn9NSyoxmd9',\\n      '/dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw'\\n    ]\\n  }\\n})\\n\\nconst options = {\\n  messageProvider: new MessageProviderIpfs(ipfs),\\n  ...\\n};\\n```\\n\\n```\\noptions.account\\n```\\n\\nThis is an account object which will be used to sign messages. It's necessary to specify either account address (that one must be unlocked) or a private key (the address will be recovered from the given private key).\\n\\nOption `isSignPrefix` tells whether or not a prefix must be appended. Default is `true`.\\n\\n```JavaScript\\nconst options = {\\n  account: {\\n    address: '0x0000000000000000000000000000000000000000',\\n    privateKey: '0x0000000000000000000000000000000000000000000000000000',\\n    isSignPrefix: true\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.ens\\n```\\n\\nThis is a `ens` contract object. This one is not required. If it's necessary you may specify `address` of the contract if the network is not set to mainnet. `suffix` may be `sid` for sidechain or `eth` for mainnet. `eth` is default. `version` is the version of Robonomics Network. Default is the latest deployed version.\\n\\n```JavaScript\\nconst options = {\\n  ens: {\\n    address: '0x314159265dD8dbb310642f98f50C066173C1259b',\\n    suffix: 'eth',\\n    version: 5\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.lighthouse\\n```\\n\\nENS name of a lighthouse, not required. Default is `airalab.lighthouse.5.robonomics.eth`. It's possible to specify only the first part of the name, like `airalab`.\\n\\n```JavaScript\\nconst options = {\\n  lighthouse: 'airalab.lighthouse.5.robonomics.eth',\\n  ...\\n};\\n```\\n\\nIt's necessary to wait until full initialization\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\nrobonomics.ready().then(() => {\\n  console.log('Robonomics instance ready')\\n})\\n```\\n\\n## API\\n\\n### Messages\\n\\n#### Demand \\n\\nThe message specification\\n\\n```JavaScript\\nconst demand = {\\n  // REQUIRED\\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost\\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED \\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  validatorFee: 0,                                              // validator fee \\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendDemand`\\n\\nSigning and broadcasting the demand message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendDemand(demand).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onDemand`\\n\\nListens to demand messages with a defined model. If model is `null` returns any demand message.\\n\\n```JavaScript\\nrobonomics.onDemand(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Offer \\n\\nThe message specification\\n\\n```JavaScript\\nconst offer = {\\n  // REQUIRED \\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost \\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED\\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  lighthouseFee: 0,                                             // lighthouse fee\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendOffer`\\n\\nSigns and broadcasts an offer message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendOffer(offer).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onOffer`\\n\\nListens to offer messages with a defined model. If model is `null` returns any offer message\\n\\n```JavaScript\\nrobonomics.onOffer(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Result \\n\\nThe message specification\\n\\n```JavaScript\\nconst result = {\\n  // REQUIRED \\n  liability: \\\"0x0000000000000000000000000000000000000000\\\",  // liability contract address\\n  success: true,                                            // status of the task\\n  result: \\\"QmWXk8D1Fh5XFJvBodcWbwgyw9htjc6FJg8qi1YYEoPnrg\\\"  // ipfs hash of the rosbag log file\\n};\\n```\\n\\n`robonomics.sendResult`\\n\\nSigns and broadcasts a result message\\n\\n```JavaScript\\nrobonomics.sendResult(result).then(() => {\\n  console.log(\\\"ok\\\");\\n});\\n```\\n\\n`robonomics.onResult`\\n\\nListens to result messages. These results may be not valid. Valid results are stored in a liability contract\\n\\n```JavaScript\\nrobonomics.onResult(result => {\\n  console.log(result);\\n});\\n```\\n\\n### Smart Contracts \\n\\n#### Liability \\n\\n`liability.getInfo`\\n\\nReturn a property object of the contract\\n\\n```JavaScript\\nliability.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    model,\\n    objective,\\n    result,\\n    token,\\n    cost,\\n    lighthouseFee,\\n    validatorFee,\\n    demandHash,\\n    offerHash,\\n    promisor,\\n    promisee,\\n    lighthouse,\\n    validator,\\n    isSuccess,\\n    isFinalized\\n  }\\n  */\\n});\\n```\\n\\n`liability.onResult`\\n\\nWaits until a liability is finished. Returns a result\\n\\n```JavaScript\\nliability.onResult().then(result => {\\n  console.log(result);\\n});\\n```\\n\\n#### Lighthouse \\n\\n`robonomics.lighthouse.getInfo`\\n\\nReturns a property object of the contract\\n\\n```JavaScript\\nrobonomics.lighthouse.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    minimalStake,\\n    timeoutInBlocks,\\n    keepAliveBlock,\\n    marker,\\n    quota\\n  }\\n  */\\n});\\n```\\n\\n`robonomics.lighthouse.getProviders`\\n\\nReturns a list of providers on the lighthouse\\n\\n```JavaScript\\nrobonomics.lighthouse.getProviders().then(list => {\\n  console.log(list);\\n});\\n```\\n\\n##### Creation of a new lighthouse\\n\\n```JavaScript\\nconst minimalFreeze = 1000      // Wn\\nconst timeout = 25              // blocks\\nconst name = 'mylighthouse'     // lighthouse name\\nrobonomics.factory.methods.createLighthouse(minimalFreeze, timeout, name).send({ from: robonomics.account.address })\\n    .then((tx) => console.log(tx))\\n\\nrobonomics.factory.onLighthouse((lighthouse) => {\\n    console.log(lighthouse.name)\\n})\\n```\\n\\n##### Become a provider \\n\\nPreliminarily you must call `approve` for the tokens `XRT`\\n\\n```JavaScript\\nconst name = \\\"mylighthouse\\\";    // lighthouse name\\nconst stake = 1000;             // Wn\\nrobonomics.lighthouse.methods\\n  .refill(stake)\\n  .send({ from: robonomics.account.address })\\n  .then(tx => console.log(tx));\\n```\\n\\n#### Token \\n\\n`robonomics.xrt.getInfo`\\n\\nReturns property object of the token\\n\\n```JavaScript\\nrobonomics.xrt.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    name,\\n    totalSupply,\\n    decimals,\\n    symbol\\n  }\\n  */\\n});\\n```\\n\\n##### Check balance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .balanceOf(robonomics.account.address)\\n  .call()\\n  .then(balance => console.log(balance));\\n```\\n\\n##### Check allowance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .allowance(robonomics.account.address, robonomics.factory.address)\\n  .call()\\n  .then(allowance => console.log(allowance));\\n```\\n\\n##### Approve \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .approve(robonomics.lighthouse.address, 100)\\n  .send({\\n    from: robonomics.account.address\\n  })\\n  .then(tx => console.log(tx));\\n```\\n\\n## Links \\n\\n- [Website](https://robonomics.network/)\\n- [Minimal template of dApp](https://github.com/airalab/vue-dapp-robonomics-template)\\n- [dApp example](https://codesandbox.io/s/robonomics-vue-template-ewuiw)\\n\"}},{\"node\":{\"id\":\"99ab44fc12312cb6e32aa1fa1a255b5a\",\"title\":\"How Robonomics Network Works\",\"path\":\"/docs/ru/robonomics-how-it-works/\",\"content\":\"\\nIn this section we will discuss the Robonomics Network scenario.\\n\\nThere are few main parts in the Robonomics network:\\n\\n- IPFS for the messages exchanging\\n- the Ethereum blockchain for storing new liability contracts\\n- a provider that is responsible for matching messages\\n- an agent\\n\\nLet's have a look at the following diagram that describes the scenario without any additional details:\\n\\n![The main scenario of Robonomics Network](../images/robonomics_network_scenario.jpg \\\"The main scenario of Robonomics Network\\\")\\n\\nThere are three types of [messages](/docs/market-messages) in IPFS: Demand, Offer, Result.\\n\\n**Below there is the specification for a Demand message:**\\n\\n| Field         | Type                      | Description                                       | Example                                           |\\n|-------------- |-------------------------  |------------------------------------------------   |------------------------------------------------   |\\n| model         | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model Identifier                   | QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC    |\\n| objective     | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    | QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r    |\\n| token         | ethereum_common/Address   | Operational token address                         | 0xbD949595eE52346c225a19724084cE517B2cB735        |\\n| cost          | ethereum_common/UInt256   | CPS behavioral model implementation cost          | 1                                                 |\\n| lighthouse    | ethereum_common/Address   | Lighthouse address                                | 0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1       |\\n| validator     | ethereum_common/Address   | Observing network address                         | 0x0000000000000000000000000000000000000000        |\\n| validatorFee  | ethereum_common/UInt256   | Observing network commission                      | 0                                                 |\\n| deadline      | ethereum_common/UInt256   | Deadline block number                             | 6393332                                           |\\n| sender        | ethereum_common/Address   | Message sender address                            | 0x0000000000000000000000000000000000000000        |\\n| signature     | std_msgs/UInt8[]          | Sender’s digital signature                        | 0x23bc…c617                                       |\\n\\n<!--\\n=============== ============================================================== ================================================ ================================================\\n     Field                                   Type                                                Description                                        Example\\n=============== ============================================================== ================================================ ================================================\\n  model          :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model Identifier                  QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC\\n  objective      :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model parameters in rosbag file   QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r\\n  token          :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Operational token address                        0xbD949595eE52346c225a19724084cE517B2cB735\\n  cost           :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   CPS behavioral model implementation cost         1\\n  lighthouse     :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Lighthouse address                               0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1\\n  validator      :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Observing network address                        0x0000000000000000000000000000000000000000\\n  validatorFee   :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Observing network commission                     0\\n  deadline       :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Deadline block number                            6393332\\n  sender         :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Message sender address                           0x0000000000000000000000000000000000000000\\n  signature      std_msgs/UInt8[]                                               Sender's digital signature                       0x23bc...c617\\n=============== ============================================================== ================================================ ================================================\\n-->\\n\\nAn Offer message has the same fields but instead of `validatorFee` there is a `lighthouseFee` field. This field determines the amount of fee for a lighthouse.\\n\\nNow let's have a look at the following diagram and walk step by step from the moment of publishing messages to a liability finalization.\\n\\n![Robonomics Network detailed scenario](../images/robonomics_network_detailed_scenario.jpg \\\"Robonomics Network detailed scenario\\\")\\n\\nA liability contract is created only if the following fields match: `model`, `objective`, `token`, `cost`. A provider of Robonomics Network watches every message and finds those ones that have a match.\\nAfter the match is found the provider calls `createLiability(demand, offer)` method from the contract factory where `demand` and `offer` are serialized.\\n\\nBelow is the package diagram for the Robonomics communication stack:\\n\\n![Robonomics communication stack](../images/robonomics_network_communication_stack.jpg \\\"Robonomics communication stack\\\")\\n\\nThe factory deserializes arguments and recovers *promisee* and *promisor* addresses from signatures.\\n\\nNext step is token transfer. The factory transfers **cost** tokens from the *promisee* address and **validatorFee** and **lighthouseFee** from the *promisor* address to the new liability address.\\n\\n> - **You should approve sufficient amount of tokens for the factory.**\\n> - **It's not required to approve tokens from the *promisor* address if fees are null.**\\n\\nNow the factory emits a NewLiability event with the liability address. An agent gets the address, reads fields, perform a task and at the same time writes a log file in rosbag format.\\n\\nWhen the work is done the agent sends a Result message with the following fields: hash of the rosbag file, a success flag, a signature. If the **validator** field is not null it means that only validator is able to finalize the liability.\\n\\nAfter the successful liability finalization the agent gets **cost** tokens. Otherwise, the *promisee* gets tokens back.\"}},{\"node\":{\"id\":\"4a105098aac2c860e939c4947da9cb10\",\"title\":\"Обзор децентрализованного приложения Робономики\",\"path\":\"/docs/ru/robonomics-dapp-overview/\",\"content\":\"\\nВы можете взаимодействовать с сетью Робономики, используя интерфейс [децентрализованного приложения Робономики](https://dapp.robonomics.network/#/). Оно доступно для браузеров с [расширением Metamask](https://metamask.io). На главной странице Вы можете видеть статистику сети:\\n\\n![Главная страница децентрализованного приложения Робономики](../images/robonomics_dapp_first_page.jpg \\\"Главная страница децентрализованного приложения Робономики\\\")\\n\\nДавайте взглянем на нижнюю таблицу \\\"Robonomics Telemetry\\\".\\n\\nКаждый раз при запуске экземпляра AIRA он передает информацию о себе. Обычно децентрализованному приложению требуется какое-то время, чтобы получить данные от экземпляра AIRA.\\n\\nОзнакомьтесь со страницей [\\\"установка AIRA\\\"](/docs/ru/aira-installation), чтобы понять, откуда берутся `IPNS` и `Address Eth`.\\n\\n## IPNS\\n\\nЕго можно рассматривать как уникальный идентификатор Вашего экземпляра в сети IPFS. Под этим названием AIRA публикует метаданные о себе.\\n\\n## Address Eth\\n\\nПо умолчанию AIRA генерирует новый адрес Ethereum для Вас (Вы можете [сгенерировать](/docs/ru/aira-faq#how-to-change-ethereum-address-of-aira) новый).\\n\\nОн используется, главным образом, для подписания всех исходящих сообщений.\\n\\n## Lighthouse\\n\\nВ сети Робономики агент должен выбрать lighthouse (маяк) для работы. По умолчанию это `airalab.lighthouse.5.robonomics.eth`.\\n\\nВы можете выбрать существующий или создать свой собственный на странице [Маяки](https://dapp.robonomics.network/#/lighthouse).\\n\\n## Peers\\n\\nКоличество IPFS пабсаб [узлов](/docs/ru/aira-faq#how-to-check-the-quantity-of-ipfs-peers).\\n\\n## Date\\n\\nДата и время последнего обновления.\\n\\n## Network\\n\\nСеть Робономики официально работает в основной сети Ethereum.\\nЕсть также [сайдчейн](https://github.com/airalab/airalab-sidechain), в основном используемый для тестирования.\\n\\n\\n\"}},{\"node\":{\"id\":\"5c87576509494ad06f31e8c7e0885e70\",\"title\":\"Robonomics Coffee\",\"path\":\"/docs/ru/robonomics-coffee/\",\"content\":\"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](../images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](../images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](../images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](../images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](../images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](../images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](../images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](../images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](../images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](../images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](../images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](../images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](../images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"}},{\"node\":{\"id\":\"017e7ff4697e29e302b39ccb172f7a00\",\"title\":\"Contracts deployment\",\"path\":\"/docs/ru/robonomics-contracts-deployment/\",\"content\":\"\\nRobonomics network works on top of the existing Ethereum network. The protocol is implemented by smart contracts. A source code is on [Github](https://github.com/airalab/robonomics_contracts). Airalab team deploys new version of contracts and supports a current one. \\n\\nIn this lesson we are going to learn more about these contracts. To do this we will deploy our test copy. Also we are going to use these contracts in the future lessons. \\n\\nYou need a client running Ethereum node. You can use either one of existing network (e.g. Mainnet, Ropsten, Kovan) or your local one. For testing purpose we suggest to use this [docker container](https://github.com/f-o-a-m/cliquebait) \\n\\n    $ docker run --rm -d -p 9545:8545 -p 9546:8546 foamspace/cliquebait:latest\\n\\nNext step is obtain a copy of robonomics contracts source code:\\n\\n    $ git clone --recursive https://github.com/airalab/robonomics_contracts\\n\\nA file truffle.js contains available networks for migration. We will work with development network. When you are in `robonomics_contracts` directory install dependencies and run a migration:\\n\\n    npm install // to install dependencies\\n    truffle migrate --network development\\n\\nIt's time to learn how to create a new lighthouse. For more information about Robonomics network and Lighthouse in particular read [white paper](http://static.robonomics.network/docs/book-the-economy-of-robots-1-2017/robonomics.network-book-the-economy-of-robots-1-2017-en.pdf). Briefly lighthouse o distributes the running time of providers. Every lighthouse serves its own broadcast channel. Ask and Bid messages come into this channel. XRT tokens are used as a payment. \\n\\nWhen XRT contracts was deployed some tokens were issued on our account. Let's check the balance:\\n\\n    $ truffle --network development console\\n    > xrt = XRT.at(XRT.address)\\n    > xrt.balanceOf(web3.eth.accounts[0])\\n\\nAnd that's how we create a lighthouse:\\n\\n    > factory = LiabilityFactory.at(LiabilityFactory.address)\\n    > tx = factory.createLighthouse(1000, 10, \\\"test\\\")\\n    > tx.then(x => {laddress = x.logs[0].args.lighthouse})\\n    > l = LighthouseLib.at(laddress)\\n\\nInstead of deploying a lighthouse contract every time we need a new one, we ask a factory to do this job. A `l` variable contains lighthouse instance. The lighthouse should be able to spend our tokens. Let's make an approve and check everything went well:\\n\\n    > xrt.approve(l.address,1000)\\n    > xrt.allowance(web3.eth.accounts[0],l.address)\\n\\nAnd a very important step is become a worker:\\n\\n    > l.refill(1000)\\n\\nEach worker has to put a stake. In this case it's 1000 Wn.\\n\\nBelow is a table of our addresses:\\n\\n| Contract          | Address                                       | ENS name                          |\\n|------------------ |--------------------------------------------   |---------------------------------- |\\n| ENSRegistry       | 0x80c77a7de64a15450bb8cf45ece4fbb7bae6fb49    |                                   |\\n| XRT               | 0x673583a369eb3a830a5571208cf6eb7ce83987f8    | xrt.3.robonomics.eth              |\\n| LiabilityFactory  | 0x1b3190e00c1903266862af1f31714d4b81ef59b2    | factory.3.robonomics.eth          |\\n| Lighthouse        | 0xd2b78c032b6c8851a8b6cbf950caa02a77618d8e    | test.lighthouse.3.robonomics.eth  |\\n\"}},{\"node\":{\"id\":\"519ea3a4dd6a86e66a7a68ca437d81a6\",\"title\":\"Become a Provider\",\"path\":\"/docs/ru/robonomics-become-a-provider/\",\"content\":\"\\nThis page describes how to create a lighthouse and become a provider in the Robonomics network.\\n\\n## Prepare an address\\n\\nFirst of all, an Ethereum address is required. You must have access to a private key of the address. In case you don't have one, below are steps to create an address via [Parity](https://www.parity.io/ethereum/).\\n\\n```\\n$ sudo snap install parity\\n$ parity.ethkey generate random\\nsecret:  15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539\\npublic: 38b800bfd90d486c78c646da79bb94b9d038aca8aad221062ce1b148df7764bfef02f6b3cf931786b6997540b798ea226ae60bd201c222d8f702e408a1a5cbff\\naddress: c531fa8f141493df3da264a864bdcbec19695b4c\\n```\\n\\nThe `secret` field is a private key, you'll need it to run the provider client. Save it to a file:\\n\\n```\\n$ echo '0x15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539' > private.key\\n```\\n\\nThe next step is to deposit some ethers and XRT tokens to the address which is held in the `address` field.\\n\\n## Create a lighthouse\\n\\nGo to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse) and fill in a name in the right side:\\n\\n![The Right Side](../images/become_a_provider_1.jpg \\\"The Right Side\\\")\\n\\nClick on the `Create lighthouse and connect to the network` button and sign a transaction. After a while you should see:\\n\\n![Success of Creating a Lighthouse](../images/become_a_provider_2.jpg \\\"Success of Creating a Lighthouse\\\")\\n\\nNow it's time to put a stake. Select the new lighthouse and click `Connect to the network`:\\n\\n![Selecting the Lighthouse](../images/become_a_provider_3.jpg \\\"Selecting the Lighthouse\\\")\\n\\nOn this page in the `Provider` section click the `Approve` button, sign a transaction. When it's mined click the `Refill` button and do the same.\\n\\n## Install the client\\n\\nNow you need to install [robonomics-tools](https://github.com/airalab/robonomics-tools) at least 0.4.2 version. You can build from the source or do the following steps:\\n\\n**Make sure you have Nix and Stack installed:**\\n    \\n```\\n$ curl -sSL https://get.haskellstack.org/ | sh\\n$ curl https://nixos.org/nix/install | sh\\n```\\n\\n* Setup Airalab binary cache at [https://aira.cachix.org](https://aira.cachix.org/)\\n* Import Airalab channel:\\n\\n```\\n$ nix-channel --add http://aira.life/channels/aira-unstable/ aira\\n$ nix-channel --update\\n```\\n* Install from the binary cache:\\n\\n```\\n$ nix-env -iA aira.robonomics-tools\\n```\\n* Run the client:\\n\\n```\\n$ xrtd --lighthouse mobilerobotics.lighthouse.5.robonomics.eth --private $(cat private.key)\\n```\\n\\n**Get familiar with the `xrtd` options via `xrtd --help`.**\\n\\n## Test the provider\\n\\nTo test your provider go again to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse/) and connect to the just created lighthouse.\\n\\nAt the bottom you should see the `TEST LIGHTHOUSE` section.\\n\\nClick on the `Demand` button and then on the `Offer` one. You should see something similar to:\\n\\n![Demand and Offer messages](../images/provider_mobilerobotics_demand_offer.jpg \\\"Demand and Offer messages\\\")\\n\\nDon't forget to sign every message with the MetaMask extension.\\n\\nFinally you should see a new liability contract created:\\n\\n![Liability is created](../images/provider_mobilerobotics_liability.jpg \\\"Liability is created\\\")\\n\"}},{\"node\":{\"id\":\"cff67e4359f9ff0d91a389f630be5e11\",\"title\":\"Robonomics IO Overview\",\"path\":\"/docs/ru/rio-overview/\",\"content\":\"\\nThe [crate](https://crates.robonomics.network/robonomics_io/index.html) provides a convenient way to interact with blockchain and includes a set of tools. The latest release can be found [here](https://github.com/airalab/robonomics/releases)\\n\\n```\\n% ./robonomics io\\nrobonomics-io 0.21.0\\nRobonomics Framework I/O operations\\n\\nUSAGE:\\n    robonomics io [FLAGS] [OPTIONS] <SUBCOMMAND>\\n\\nFLAGS:\\n        --dev        Specify the development chain\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nOPTIONS:\\n    -d, --base-path <PATH>        Specify custom base path\\n        --chain <CHAIN_SPEC>      Specify the chain specification (one of dev, local, or staging)\\n    -l, --log <LOG_PATTERN>...    Sets a custom logging filter. Syntax is <target>=<level>, e.g. -lsync=debug\\n\\nSUBCOMMANDS:\\n    help     Prints this message or the help of the given subcommand(s)\\n    read     Read information from device\\n    write    Write information into device\\n```\\n\\n## The Pipeline Philosophy \\n\\nThe tool is designed in order to be included in a pipeline chain of processes. From Unix user experience everyone is familiar with commands like:\\n\\n```\\nps aux | grep robonomics\\n```\\n\\nIt means standard output produced by the `ps` program becomes standard input for the `grep` program. \\n\\nThe `robonomics io` consists of several subcommands with reading, writing abilities or both. It treats everything as a virtual or physical device ([everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file))\\n\\n## Read Overview\\n\\nIn general `read` means it reads data from a device or a network and prints it in `stdout`.\\n\\nHow to use it for:\\n\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io read\\nrobonomics-io-read 0.4.0\\nRead information from device\\n\\nUSAGE:\\n    robonomics io read <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    help      Prints this message or the help of the given subcommand(s)\\n    ipfs      Download data from IPFS storage\\n    launch    Robot launch request events\\n    pubsub    Subscribe for broadcasing data\\n    sds011    Nova SDS011 particle sensor\\n```\\n\\n## Write Overview\\n\\nUsually it writes data to blockchain or publishes to pubsub channel. \\n\\nHow to use it for:\\n\\n* [datalog](/docs/rio-datalog)\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io write\\nrobonomics-io-write 0.4.0\\nWrite information into device\\n\\nUSAGE:\\n    robonomics io write <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    datalog    Data blockchainization subsystem command\\n    help       Prints this message or the help of the given subcommand(s)\\n    ipfs       Upload data into IPFS storage\\n    launch     CPS launch subsystem command\\n    pubsub     Broadcast data into PubSub topic\\n```\\n\\n## Local Testnet\\n\\nFor testing purpose it's possible to run the development environment:\\n\\n```\\n% ./robonomics --dev --rpc-cors all\\n```\\n\\n`--rpc-cors all` allows the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) to be connected to local node. After launching the node, go to the dapp, click on Robonomics icon in the upper left corner, choose Development and put node's local address\\n\\n![Robonomics Dapp Connect to Local Node](../images/robonomics-dapp-connect-local.jpg \\\"Robonomics Dapp Connect to Local Node\\\")\\n\\nFinally click Switch and you should be connected to the local node. Check out Accounts tab. There you can create new accounts and transfer tokens.\\n\\n\"}},{\"node\":{\"id\":\"8383d42e69455b21c62fdd04606fe1f7\",\"title\":\"Robonomics IO Launch\",\"path\":\"/docs/ru/rio-launch/\",\"content\":\"\\nA simple way to turn on and off an IoT device or a robot. Basically sending \\\"ON\\\" will result in `true` state for a device, anything else will result in `false`.\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Accounts on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Usage\\n\\nTo see the result of transaction first of all run `read` part:\\n\\n```\\n% ./robonomics io read launch\\n```\\n\\nNow let's turn a robot on:\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nThen you should see in the first terminal window:\\n\\n```\\n% ./robonomics io read launch\\n5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH >> 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL : true\\n```\\n\\nLet's describe all the accounts and options above.\\n\\n* `-r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL` means robot's address\\n* `-s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` private key of the account to launch from (must have tokens for a transaction)\\n* `5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH` address that launches a robot\\n* `true` turn it on\\n\\nIf we pass anything else but \\\"ON\\\" the state becomes `false`\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\\nand\\n\\n```\\n% ./robonomics io read launch --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"47cc6cb919e92e8b98adcae0154d972e\",\"title\":\"Robonomics IO IPFS\",\"path\":\"/docs/ru/rio-ipfs/\",\"content\":\"\\nIt serves downloading and uploading files from/to IPFS network\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Running [IPFS](https://ipfs.io/#install) daemon \\n\\n## Write\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\n## Read\\n\\n```\\n% echo QmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy | ./robonomics io read ipfs\\nHello Robonomics\\n```\\n\\n## Remote IPFS node\\n\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs --remote https://ipfs.infura.io:5001/\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\nThe same applies for `read`\\n\\n\"}},{\"node\":{\"id\":\"af48592a7bd5bce8445c0dfa6fc8e51a\",\"title\":\"Robonomics IO Datalog\",\"path\":\"/docs/ru/rio-datalog/\",\"content\":\"\\nDatalog module allows you to store any string on blockchain\\n\\nhttps://www.youtube.com/watch?v=rs67AMyd-gE\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Account on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Write\\n\\nAssuming local node is running:\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nwhere `0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` is a private key for the account with tokens.\\nIn this example the public key is 5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH. Let's go to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/)\\nand see what happened.\\n\\nIn the Dapp go to Developer -> Chain state. In the \\\"selected state query\\\" list choose datalog and below choose your account. Click plus button on the right and you should see the following:\\n\\n![Robonomics Chain State Datalog](../images/robonomics-dapp-chain-state-datalog.jpg \\\"Robonomics Chain State Datalog\\\")\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"d90dbf60e8925f315885697caf5a90da\",\"title\":\"Raspberry Setup\",\"path\":\"/docs/ru/raspberry-setup/\",\"content\":\"\\nFor both methods, the first thing you need to do is setup a Raspberry Pi.\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card and run the Imager program. From the menu, select 64-bit Ubuntu Server as the operating system and ensure to select your SD card from the storage dropdown, and then press `write`.\\n\\n![pi](../images/home-assistant/pi.png)\\n\\nOpen the SD card's storage from your computer and navigate inside the root folder of the card. The name of the folder should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Copy the below text and paste it into the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end (also you can use `arp -a`):\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\n\\nIn this example we can see that the Raspberry Pi's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\".\\n\\n## Home Assistant\\n\\nNow we need to install Home Assistant to the Raspberry Pi. Detailed instructions can be found [here](https://www.home-assistant.io/installation/linux#install-home-assistant-core). You need to install `Home Assistant Core`. It's actual version is 2021.11.5 and instruction assumes that we already have installed Python 3.9 or newer.\\n\\nUpdate your system and install necessary packages:\\n```bash\\nsudo apt-get update\\nsudo apt-get upgrade -y\\nsudo apt-get install -y python3 python3-dev python3-venv python3-pip libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 tzdata libcurl4-openssl-dev\\n```\\n\\nCreate user `homeassistant` and the directory for homeassistant core:\\n```bash\\nsudo useradd -rm homeassistant\\nsudo mkdir /srv/homeassistant\\nsudo chown homeassistant:homeassistant /srv/homeassistant\\n```\\n\\nNext up is to create and change to a virtual environment for Home Assistant Core. This will be done as the homeassistant account.\\n```bash\\nsudo -u homeassistant -H -s\\ncd /srv/homeassistant\\npython3.9 -m venv .\\nsource bin/activate\\n```\\n![terminal1](../images/home-assistant/terminal1.png)\\n\\nThen install required Python packages:\\n```bash\\npython3 -m pip install wheel\\npip3 install homeassistant==2021.11.5\\n```\\n\\nStart Home Assistant Core for the first time. This will complete the installation for you, automatically creating the `.homeassistant `configuration directory in the `/home/homeassistant` directory, and installing any basic dependencies:\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant$ hass\\n```\\n\\nYou can now reach your installation via the web interface on `http://%RASPBERRY_IP_ADDRESS%:8123`. \\nIn this example: `http://192.168.43.56:8123`\\n\\n> You don't need to connect you raspberry to the screen, you can open Web UI from any computer connected to your local network\\n\\nCreate user and finish setup (first setup is described [here](https://www.home-assistant.io/getting-started/onboarding/) in more details), then stop Home Assistant with `Ctrl+C`.\\n\\nAfter this installation process has been completed, from the `python_scripts` folder import some necessary scripts:\\n\\n```bash\\nmkdir python_scripts\\ncd python_scripts/\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/send_datalog.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/control.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/utils.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/create_config.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/encrypt.py\\n```\\n\\nTo use Robonomics you need account (instructions of how to create it are [here](/docs/create-account-in-dapp/)). Add mnemonic or raw seed from it in `config.config` file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\n\\nIn this format:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\n\\n## Substrate Interface\\n\\nTo pub data to Robonomics you need to install `substrate-interface` python package (you need to install RUST before) to your raspberry. \\n\\nInstall RUST:\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nsource $HOME/.cargo/env\\nrustup default nightly\\n```\\n\\nAnd install necessary python packages to the virtual environment:\\n```bash\\npip3 install pynacl==1.4.0 packaging pycurl\\npip3 install substrate-interface==1.1.2 --use-feature=2020-resolver\\npip3 install python-miio==0.5.8 --use-feature=2020-resolver\\n```\\nBe sure that you-re on virtual environment:\\n\\n![terminal1](../images/home-assistant/terminal2.png)\\n\\n## Systemd services\\n\\nNow change user (you can run under any user, which allows you to use sudo):\\n\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant/python_scripts$ exit\\n```\\n\\nCreate new service for home assistant start: \\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/home-assistant@homeassistant.service \\n```\\n\\nPaste the following:\\n\\n```\\n[Unit]\\nDescription=Home Assistant\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/hass -c \\\"/home/%i/.homeassistant\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nDo the same for robonomics control service:\\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/robonomics-control@homeassistant.service \\n```\\n\\nWith:\\n```\\n[Unit]\\nDescription=Robonomics Control\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/python3.9 \\\"/srv/%i/python_scripts/control.py\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nAnd enable both services:\\n```bash\\nubuntu@ubuntu:~$ sudo systemctl enable home-assistant@homeassistant.service\\nubuntu@ubuntu:~$ sudo systemctl enable robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\"}},{\"node\":{\"id\":\"d8dfb04807ffa8981191cd272a513885\",\"title\":\"Setup with Prepared Image\",\"path\":\"/docs/ru/raspberry-image/\",\"content\":\"## Image\\nWe prepared an image to make it easier to use the Home Assistant with Xiaomi Miio and Robonomics with the Raspberry Pi.\\n\\nYou can get it here: [download image](https://ipfs.io/ipfs/bafybeihzzqoyycflxzxlxy2aplkzxo537ggqatdlbr24b4dnlyrtpkp2eu)\\n\\nSHA256 checksum: `7ec5ea99d7e339b54cbeaaae58c8295411769d27732ec2b5464dbb495ba24120`\\n\\nWhat preinstalled in the image:\\n- Ubuntu Server 21.10 (3/4/400): 64-bit server OS for arm64 archtectures\\n- Python 3.9.7\\n- Home Assistant Core 2021.11.5\\n- rustc 1.59.0-nightly (efec54529 2021-12-04)\\n- substrate-interface 1.1.2\\n- python-miio 0.5.8\\n\\n## How To Use The Prepared Image\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Insert SD card into your PC and run the Imager program. In `Operating System` select `Use custom` and choose the previously downloaded `.img.gz` file. Then select your SD card in the `Storage` dropdown and click `WRITE`.\\n\\n![imager](../images/home-assistant/use_custom_image.png)\\n![imager](../images/home-assistant/imager_prep.png)\\n\\nAfter writing is comleted, open the SD card's files on your computer and navigate inside the root folder of the card. The name should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Write this to the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end:\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\nThere raspberry's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\". Then follow the instructions to change the password.\\n\\nThen you need to write the seed from your Robonomics account to config file. Open it:\\n```bash\\nsudo -u homeassistant -H -s\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add mnemonic:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\nThen restart Robonomics Control service:\\n```bash\\nsystemctl restart robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n\"}},{\"node\":{\"id\":\"2f29c23a14ebe65b6b55f6f2fe61d0ff\",\"title\":\"R&D на базе Робономики\",\"path\":\"/docs/ru/r-and-d-based-on-robonomics-network/\",\"content\":\"\\nЗа 4 года участники проекта Робономика выполнили 13 R&D проектов в процессе написания текущей версии платформы Робономика. Ознакомьтесь со списком опробованных нами сценариев применения web3+robotics:\\n\\n### Запуск дрона под контролем децентрализованного компьютера.\\n2016 год - успешное испытание в полевых условиях совместимости 3DR X8 дронов с программным обеспечением Drone Employee. На видео - человек отправляет транзакцию квадрокоптеру через Ethereum Blockchain.\\n\\nhttps://www.youtube.com/watch?v=V_3rcP2Duv0&t=1s\\n\\n### Управление флотом дронов в децентрализованной сети.\\n[Распределенное небо](https://airmarket.io/wp-content/uploads/2018/09/Distributed-Sky-Whitepaper-v3.0.pdf) является основой системы управления движением беспилотных самолетов (UTM). Проект использует глобальную сеть компьютеров для обработки и хранения идентификационных данных, трафика и другой конфиденциальной информации, а также использует криптографию для обеспечения безопасности и масштабируемости процесса. На видео - агент Drone Passport в действии.\\n\\nhttps://www.youtube.com/watch?v=yxGTOkGkBJ8\\n\\n### Токенизация данных от IoT устройств.\\nЧетвертая промышленная революция знаменует собой полную интеграцию CPS в массовое производство и оказание услуг. Машины не ведут пустых разговоров, они честны в своей работе и могут быть независимой стороной, предоставляющей информацию, на основе алгоритмического анализа которой сама сеть может создавать ценности.\\nЦенности, основанные на труде машин, будут гораздо интереснее для нового поколения, чем другие, эмиссия которых построена на любом другом принципе. Дополнительная информация доступна [здесь](https://blog.aira.life/tokenization-and-the-4th-industrial-revolution-3208022be747)\\n\\n### Цифровые рынки для роботов.\\n\\n### Управление индустриальной зоной с помощью капитала.\\n[В данной статье](https://ieeexplore.ieee.org/abstract/document/8525391) представлена архитектура протокола связи для современных производственных процессов и бизнеса на основе киберфизических систем - Индустрии 4.0. Основное внимание уделяется одному из ключевых направлений этой концепции - экономическим автономным агентам, то есть роботам или умным вещам, которые могут принимать экономические решения независимо. Агенты начинают полноценно участвовать в бизнес-процессах, поэтому важно автоматизировать их и обеспечить формальную и безопасную связь между множеством разнородных агентов с учетом экономической составляющей отрасли. В статье показано, как организовать экономическое взаимодействие между агентами с помощью одноранговой сети на основе децентрализованной технологии Blockchain и смарт-контрактов. Более подробную информацию об Индустрии 4.0 можно найти в видео ниже.\\n\\nhttps://www.youtube.com/watch?v=yuxOF_z70us\\n\\n### Дроны, сенсоры и блокчейн для контроля качества воды на Волге.\\nВ рамках [этого проекта](https://github.com/airalab/drone_on_volga) было реализовано предложение услуги дроном через веб-приложение. Как правило, результатом оказания услуги является информация о положении дрона, скорости движения, параметры качества воды и другие важные сведения.\\nСеть Робономики используется для связи с роботом. Граждане или правительственные чиновники могут заказывать услуги, совершая платеж в криптовалюте через веб-сайт. Сеть Робономики построена на платформе блокчейна Ethereum и протоколе IPFS, Адреса файлов в IPFS хранятся в блокчейне без возможности фальсификации.\\nНиже - видео об экспериментах с водным дроном.\\n\\nhttps://www.youtube.com/watch?v=Mtqm5y6Bolo\\n\\n### Гражданские сенсорные сети.\\nВ августе 2018 года компания Airalab при поддержке Smart Distribution (дистрибьютор Libelium в России) [создала мониторинговую сеть в жилом районе Тольятти](https://www.libelium.com/libeliumworld/success-stories/preventing-asthsma-sensor-network-air-quality-pm10-dust-in-play-area/). Цель заключалась в создании основы для внедрения сети мониторинга качества воздуха в особо уязвимых районах (школы, детские площадки, дома престарелых, больницы и т.д.), которая может предоставить местным властям информацию для принятия мер по защите своих граждан.\\nПример использования датчика показан на видео. Исходный код можно найти [здесь](https://github.com/airalab/sensors-connectivity).\\n\\nhttps://www.youtube.com/watch?v=shqey3tmNUk\\n\\n### Робот-художник Gaka-chu.\\nСовременные технологии делают жизнь человека более комфортной и увлекательной, освобождая время для размышлений и экспериментов. Именно серия размышлений о статичности отрасли привела команду разработчиков к идее проведения эксперимента, демонстрирующего автономное преобразование производства для конкретного типа продукта.\\nТаким экспериментом стал [робот-художник](https://github.com/airalab/robot_painter/) - маленький неуклюжий манипулятор KUKA, живущий в большом мире серьезных промышленных роботов. И его зовут Gaka-Chu. Почему? Из-за любви к рисованию: «гака» по-японски - «художник». А «чу» добавили из-за необъяснимой любви к покемонам.\\n\\nhttps://youtu.be/xSD_lsrAA0I\\n\\n### Выпуск зеленых сертификатов на основе данных от ВИЭ.\\nКонцептуальная цель [DAO IPCI](https://ipci.io/ru/) - предоставить единое пространство, общую среду, инструменты и экосистему, которая является универсальной, надежной, простой в использовании, позволяющей множеству заинтересованных сторон, включая предприятия и людей, регистрировать количественные воздействия и количественные обязательства, инвестировать в проекты по смягчению негативного воздействия на окружающую среду, компенсировать углеродный след, получать и продавать результаты смягчения этих последствий, присоединяться к существующим программам или запускать новые. Исходный код доступен [здесь](https://github.com/DAO-IPCI/DAO-IPCI).\\n\\nhttps://www.youtube.com/watch?v=q9plB0TjUnw&list=PLLepqB9oh7WvUVzbeaiwQojrip2tLPA6P\\n\\n### Торговля машин за место на дороге.\\nНаша цель состояла в том, чтобы разработать [децентрализованную систему](https://github.com/khssnv/mobi_grand_challenge) для переговоров о дорожном пространстве, где автономные транспортные средства могут оплачивать маршруты и полосу движения. Мы считаем, что рыночный подход может быть использован для решения проблемы перегрузки на дорогах.\\n\\nhttps://youtu.be/JFQTknMZOYg\\n\\n### Блокчейн в задачах химической промышленности.\\nИзначально была поставлена следующая задача: разработать [систему контроля качества](https://github.com/Vourhey/chemistry-quality-control) для производства определенного химического продукта. Почему здесь так важен контроль качества? Основное действующее вещество этого химического продукта - диоксид хлора. В высоких концентрациях он опасен для здоровья. А если концентрация ниже нормы, то этот химический продукт бесполезен.\\nА при чем здесь Блокчейн? Блокчейн помогает укрепить доверие к производственной компании. Потребитель знает, что никто не может изменить информацию в цепочке блоков. Это означает, что производственная компания не может подделать результаты аудита.\\n\\n### Контроль износа оборудования  участниками цепочки обеспечения на основе данных от IoT.  \\n\\n### Робот, как услуга в сервисной робототехнике.\\nРобономика - это готовая к работе платформа с открытым исходным кодом, которую вы можете использовать для подключения вашего робота в качестве услуги для конечных пользователей, это называется ['Робот-как-услуга'](https://blog.aira.life/how-can-you-hire-a-robot-176ba29da565). Робономика поддерживает технологии Web3, которые осуществляют обмен технической и экономической информацией между людьми и машинами. Робономика - это чисто технический проект с открытым исходным кодом.\\n\\nhttps://www.youtube.com/watch?v=IEgvXcj3nSo\\n\"}},{\"node\":{\"id\":\"557de6c7b71d3b43b60bf282c8d9ba29\",\"title\":\"Обзор Playground\",\"path\":\"/docs/ru/playground-overview/\",\"content\":\"\\nРобономика позволяет использовать роботов как автономных агентов, которые принимают команды от человека или другого робота и делают какую-то полезную работу, сохраняя отчет о своих действиях в блокчейне. Взаимодействие между роботом и платформой Робономики достаточно простое при использовании [Robonomics IO](/docs/ru/rio-overview).\\n## Каких роботов можно контролировать\\nРаздел Playground содержит примеры подключения различных роботов к Робономике, которые каждый может пошагово повторить. В этом разделе Вы можете контролировать:\\n* [беспилотный летательный аппарат](/docs/ru/iris-drone/)\\n* [марсохода](/docs/ru/connect-mars-curiosity-rover-under-robonomics-parachain-control/)\\n* [манипулятора](/docs/ru/kuka/)\\n* [промышленного робота Baxter](/docs/ru/baxter2/).\\n\\nПоскольку все роботы доступны как имитационные модели, Вам не потребуется специальное оборудование. Вы можете попробовать подключить робота к сети Робономики прямо сейчас.\\n## Как контролировать робота\\nВсе наши демо запущены в локальной сети, но вы можете подключать робота к действующим сетям таким же способом.\\n\\nВсе демо в этом разделе следуют аналогичному сценарию. Вы [создаете аккаунт](/docs/ru/create-account-in-dapp/) для робота и отправляете ему токены для оплаты транзакций. Затем пользователь отправляет транзакцию `ON/OFF` на адрес робота, робот принимает ее и начинает работать. После выполнения работы телеметрия сохраняется в IPFS и хэш файла отправляется в журнал данных. Поэтому в любое время Вы можете видеть, как робот выполняет свою работу.\\n## Подключите своего собственного робота\\nДополнительно Вы можете создать свой собственный пакет управления для любого устройства, совместимого с ROS, с помощью [этой](/docs/ru/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) инструкции.\\n\\n\"}},{\"node\":{\"id\":\"02d946260be0219336908112b186b2e7\",\"title\":\"Market messages\",\"path\":\"/docs/ru/market-messages/\",\"content\":\"\\nMarket messages is used for exchange **Demand** and **Offer** information. It also used for delivery **Result** messages with liability execution reports.\\n\\n> This is spec for Robonomics `Generation 5`.\\n\\n- Currently for message delivery is used [IPFS PubSub](https://ipfs.io/blog/25-pubsub/) broadcaster.\\n- IPFS PubSub **topic** is set according to *Lighthouse [ENS](https://ens.domains/) name*.\\n\\n## Messages content\\n\\nRobonomics market message use [JSON](https://www.json.org/) data format.\\n\\n\\n### Demand\\n\\n| Field | ROS Type | Description |\\n|-------------- |-------------------------  |------------------------------------------------ |\\n| model | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model identifier |\\n| objective | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model parameters in rosbag file |\\n| token | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Operational token address |\\n| cost | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | CPS behavioral model execution cost |\\n| lighthouse | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Lighthouse contract address |\\n| validator | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Observing network address |\\n| validatorFee  | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Observing network fee |\\n| deadline | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Deadline block number |\\n| nonce | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Robonomics message counter |\\n| sender | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Message sender address |\\n| signature | std_msgs/UInt8[] | Sender’s Ethereum signature |\\n\\n### Offer\\n\\n| Field             | ROS Type                  | Description                                       |\\n|---------------    |-------------------------  |------------------------------------------------   |\\n| model             | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model identifier                   |\\n| objective         | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    |\\n| token             | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Operational token address                         |\\n| cost              | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | CPS behavioral model execution cost               |\\n| validator         | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Observing network address                         |\\n| lighthouse        | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Lighthouse contract address                       |\\n| lighthouseFee     | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Liability creation fee                            |\\n| deadline          | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Deadline block number                             |\\n| nonce             | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Robonomics message counter                        |\\n| sender            | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Message sender address                            |\\n| signature         | std_msgs/UInt8[]          | Sender’s Ethereum signature                       |\\n\\n### Result\\n\\n| Field         | ROS Type                  | Description                       |\\n|-----------    |-------------------------  |---------------------------------- |\\n| liability     | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Liability contract address        |\\n| result        | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | Liability result multihash        |\\n| success       | std_msgs/Bool             | Is liability executed successful  |\\n| signature     | std_msgs/UInt8[]          | Sender’s Ethereum signature       |\\n\\n## Messages signing\\n\\nBefore signing the messages is packed using [abi.encodePacked](https://solidity.readthedocs.io/en/latest/abi-spec.html#non-standard-packed-mode\\n) solidity finction and hashed by Keccak_256.\\n\\n```\\n   demandHash = keccak256(abi.encodePacked(\\n        _model\\n      , _objective\\n      , _token\\n      , _cost\\n      , _lighthouse\\n      , _validator\\n      , _validator_fee\\n      , _deadline\\n      , IFactory(factory).nonceOf(_sender)\\n      , _sender\\n      ));\\n```\\n\\n**`nonce` parameter is counted by factory smart contract and incremented for each created liability smart contract.**\\n\\nMessage hash are signed using Ethereum ``secp256k1`` [signature](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sign).\\n\"}},{\"node\":{\"id\":\"6ce1e7bf6ac314cc0b9e8975f1357a29\",\"title\":\"Drone control with robonomics\",\"path\":\"/docs/ru/iris-drone/\",\"content\":\"\\n**Drone starts moving after transcation and store file with the coordinates in IPFS. The control script is based on the [GAAS demo script](https://github.com/generalized-intelligence/GAAS)**  \\n\\nhttps://youtu.be/4CwtGAX1OwM\\n\\n## Requirements\\n* dependencies for control:\\n``` sh\\nsudo apt install -y \\\\\\n\\tpython3-pip \\\\\\n\\tninja-build \\\\\\n\\texiftool \\\\\\n\\tpython-argparse \\\\\\n\\tpython-empy \\\\\\n\\tpython-toml \\\\\\n\\tpython-numpy \\\\\\n\\tpython-yaml \\\\\\n\\tpython-dev \\\\\\n\\tpython-pip \\\\\\n\\tninja-build \\\\\\n\\tprotobuf-compiler \\\\\\n\\tlibeigen3-dev \\\\\\n\\tgenromfs\\n```\\n```sh \\npip3 install \\\\\\n\\tpandas \\\\\\n\\tjinja2 \\\\\\n\\tpyserial \\\\\\n\\tcerberus \\\\\\n\\tpyulog \\\\\\n\\tnumpy \\\\\\n\\ttoml \\\\\\n\\tpyquaternion\\n```\\n* ROS Melodic + Gazebo [installation tutorial](http://wiki.ros.org/melodic/Installation)\\n* extra packages: \\n``` bash \\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\nsudo apt-get install python-jinja2\\nsudo apt-get install python-catkin-pkg\\nsudo apt-get install python3-catkin-pkg-modules\\n```\\n* IPFS verson 0.4.22\\n```bash\\nwget https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-amd64.tar.gz\\ntar -xvzf go-ipfs_v0.4.22_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh\\nipfs init\\n```\\n* ipfshttpclient\\n```sh\\npip3 install ipfshttpclient\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n## Environment Setup\\n```bash \\nsudo apt-get install ros-melodic-mavros ros-melodic-mavros-extras\\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\\nsudo ./install_geographiclib_datasets.sh\\ncd ~/catkin_ws/src\\ngit clone https://github.com/PX4/Firmware.git\\ncd Firmware\\ngit checkout v1.9.0\\nbash ./Tools/setup/ubuntu.sh\\n```\\n```bash\\ncd ~/catkin_ws/src\\ngit clone https://github.com/generalized-intelligence/GAAS.git\\ncp -r ~/catkin_ws/src/GAAS/simulator/models/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/models/\\ncp -r ~/catkin_ws/src/GAAS/simulator/worlds/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/worlds/\\ncp -r ~/catkin_ws/src/GAAS/simulator/posix-config/* ~/catkin_ws/src/Firmware/posix-configs/SITL/init/ekf2/\\n```\\n\\nModifying your `.bashrc` file, adding the following lines to the bottom:  \\n\\n`source ~/catkin_ws/devel/setup.bash `  \\n`source ~/catkin_ws/src/Firmware/Tools/setup_gazebo.bash ~/catkin_ws/src/Firmware/ ~/catkin_ws/src/Firmware/build posix_sitl_default `   \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware/Tools/sitl_gazebo`  \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models:~/catkin_ws/src/GAAS/simulator/models`  \\n\\n  \\n## Control Package Installation\\nIn a new Terminal:\\n```bash\\ncd catkin_ws/src\\ngit clone https://github.com/tubleronchik/robonomics_drone_sim.git\\ncd ..\\ncatkin build\\n```\\n## Robonomics Network\\nTo create a local robonomics network go to the folder with the robonomic binary file and run:  \\n`./robonomics --dev --rpc-cors all`  \\n\\nAdd robonomic's path to `config.py`\\n\\n![IPFS](../images/iris-drone-demo/IPFS.jpg)\\n\\nGo to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node.\\n![localNode](../images/iris-drone-demo/localNode.jpg)\\n\\nGo to **Accounts** and create **DRONE** and **EMPLOYER** accounts. Save the account names and keys and path to **robonomics** to `~/catkin_ws/src/drone_sim/src/config.py`. Transfer some money into the accounts.\\n\\n![accounts](../images/iris-drone-demo/addingAcc.jpg)\\n\\n## Running Simulation\\nRun IPFS daemon\\n```bash\\ncd go-ipfs\\nipfs daemon\\n```\\nIn another terminal launch the simulation:\\n```bash\\nroslaunch px4 mavros_posix_sitl.launch\\ncd ~/catkin_ws/src/robonomics_drone_sim/src\\npython3 takeoff.py\\n```\\nWaiting till \\\"Waiting for payment\\\" \\n\\n![launch](../images/iris-drone-demo/launch.jpg)\\n\\nTo send a transaction run in another window:\\n`echo \\\"ON\\\" | ./robonomics io write launch -r <drone_addres> -s <employer_key>` - where **<drone_address>** and **<employer_key>** should be replaced with the strings from `config.py` accordingly.\\n\\nAfter data was pushed to IPFS, go to the **Chain State** in [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/). Select **datalog** in query and add DRONE datalog using `+` button.\\n\\n![datalog](../images/iris-drone-demo/datalog.jpg)\\n\\nYou can find drone's telemetry running `https://gateway.ipfs.io/ipfs/<hash>` inserting the hash from above.\\n\\n![output](../images/iris-drone-demo/output.jpg)\\n\\nIt's important to remove `db` derictory before next launches using  \\n` rm -rf ~/.local/share/robonomics/chains/dev/db`\\n\"}},{\"node\":{\"id\":\"1159cec7738e6369271d84e6df6cbc65\",\"title\":\"Control Kuka manipulator with robonomics\",\"path\":\"/docs/ru/kuka/\",\"content\":\"\\nVideo with an example of work can be found here:\\n\\nhttps://youtu.be/z55HepXbHr8\\n\\n***\\n\\n## Requirements\\n* ROS melodic, Gazebo (installation instraction [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n* Some extra packages\\n```bash\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n* IPFS 0.4.22 (download from [here](https://www.npackd.org/p/ipfs/0.4.22) and install)\\n```bash\\ntar -xvzf go-ipfs_v0.4.22_linux-386.tar.gz\\ncd go-ipfs/\\nsudo bash install.sh\\nipfs init\\n```\\n* pip3\\n```bash\\nsudo apt-get install python3-pip\\n```\\n* ipfshttpclient\\n```bash\\npip3 install ipfshttpclient\\n```\\n* substrate-interface\\n```bash\\npip3 install substrate-interface\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n* IPFS browser extension (not necessary)\\n***\\n## Installation\\nInstall Kuka manipulator and control packages\\n```bash\\ncd catkin_wc/src/\\ngit clone https://github.com/orsalmon/kuka_manipulator_gazebo\\ngit clone https://github.com/LoSk-p/kuka_controller\\ncd ..\\ncatkin_make\\n```\\n***\\n## Running gazebo model\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch manipulator_gazebo manipulator_empty_world.launch\\n```\\nIn a new window\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun manipulator_gazebo move_arm_server\\n```\\n![model](../images/kuka-demo/1.png)\\n***\\n## Running robonomics\\nGo to the folder with robonomics file ad create a local robonomics network:\\n```bash\\n./robonomics --dev --tmp\\n```\\n\\n![robonomics](../images/kuka-demo/robonomics.png)\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node\\n\\n![local](../images/kuka-demo/local.png)\\n\\nThen go to Accounts and create `KUKA` account. Save account's mnemonic key, you will need it later. \\n\\n![acc](../images/kuka-demo/create_acc.png)\\n\\nSend some units to the new account from one of default accounts.\\n\\n![accs](../images/kuka-demo/send_money.png)\\n***\\n## Running ipfs\\nRun ipfs daemon:\\n```bash\\nipfs daemon\\n```\\n***\\n## Running control package\\nIn config directory in kuka_control package you need to create config file with this lines, where `<your_mnemonic>` is saved mnemonic seed:\\n```bash\\n{\\n    \\\"kuka_mnemonic\\\": \\\"<your_mnemonic>\\\",\\n    \\\"node\\\": \\\"ws://127.0.0.1:9944\\\"\\n}\\n```\\n\\nNow you can run control script:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun kuka_controller move_arm_client.py\\n```\\n![control](../images/kuka-demo/run.png)\\n\\n## Sending transaction\\nIn [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) go to `Developer/Extrinsics`, change `extrinsic` to `launch`. Chose your `KUKA` account in `robot` and change `param` to `Yes`. The press `Submit Transaction`\\n\\n![transaction](../images/kuka-demo/launch.png)\\n\\nIn the window with kuka_control package you will see:\\n\\n![done](../images/kuka-demo/res.png)\\n\\nThen go `Developer/Chain State` on the Robonomics portal, select `datalog` and `datalogItem((AccountId,u64)): RingBufferItem` in query and add `KUKA` datalog with button '+':\\n\\n![datalog](../images/kuka-demo/datalog.png)\\n\\nNow you can find robot's telemetry in IPFS via this link with your hash `https://gateway.ipfs.io/ipfs/<hash>`.\\n\\n## Troubleshooting\\n\\nIf `catkin_make` doesn't work with the message that it can't find MoveArm.h, try to remove last four lines in CMakeLists.txt in kuka_manipulator_gazebo package:\\n```\\ninclude_directories(include ${catkin_INCLUDE_DIRS})\\n\\nadd_executable(move_arm_server src/move_arm_server.cpp)\\ntarget_link_libraries(move_arm_server ${catkin_LIBRARIES})\\nadd_dependencies(move_arm_server beginner_tutorials_gencpp)\\n```\\nDo `catkin_make` without these lines, then returm them and do `catkin_make` again.\\n\"}},{\"node\":{\"id\":\"fd9c22979db2f5833a8f434d188c9a84\",\"title\":\"IPFS Common\",\"path\":\"/docs/ru/ipfs-common/\",\"content\":\"\\nThe package handle IPFS connections, provides useful services for working with IPFS Network. \\nIt's included in `robonomics_liability` launch file\\n\\n## ROS Parameters\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_file_providers\\n\\nA list of public nodes to pin result files. The type is `list of strings`, defaults to `[ipfs_public_providers]`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_swarm_connect_to\\n\\nA list of IPFS nodes to connect to. The type is `list of strings`, defaults to `[ipfs_swarm_connect_addresses]`\\n\\n## Subscribed topics\"}},{\"node\":{\"id\":\"07a5054bd7da0b691b5aff534768466e\",\"title\":\"IPFS Common Messages\",\"path\":\"/docs/ru/ipfs-common-messages/\",\"content\":\"\\n## ipfs_common/Filepath.msg\\n\\n| Field         | Type                  | Description           |\\n|------------   |-------------------    |--------------------   |\\n| filepath      | std_msgs/String       | A path to a file      |\\n\\n## ipfs_common/Multihash.msg\\n\\n| Field         | Type              | Description                               |\\n|-----------    |-----------------  |------------------------------------------ |\\n| multihash     | std_msgs/String   | A wrapper for model and objective fields  |\\n\\n## ipfs_common/IpfsDownloadFile.srv\\n\\n**Request**\\n\\n| Field         | Type                                                  | Description               |\\n|-------------- |---------------------------------------------------    |------------------------   |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of a file       |\\n| file          | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)       | Where to save the file    |\\n\\n**Response**\\n\\n| Field         | Type              | Description           |\\n|-----------    |-----------------  |---------------------  |\\n| success       | std_msgs/Bool     | Status of execution   |\\n| error_msg     | std_msgs/String   | Error message         |\\n\\n## ipfs_common/IpfsUploadFile.srv\\n\\n**Request**\\n\\n| Field     | Type                                              | Description                               |\\n|-------    |-------------------------------------------------  |---------------------------------------    |\\n| file      | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)   | Path to a file to be uploaded to IPFS     |\\n\\n**Response**\\n\\n| Field         | Type                                                  | Description                   |\\n|-------------- |---------------------------------------------------    |----------------------------   |\\n| success       | std_msgs/Bool                                         | Status of execution           |\\n| error_msg     | std_msgs/String                                       | Error message                 |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of uploaded file    |\\n\"}},{\"node\":{\"id\":\"76a7b929296defe740dd8dbf0d958866\",\"title\":\"IoT Sensors Connectivity\",\"path\":\"/docs/ru/iot-sensors-connectivity/\",\"content\":\"\\nRobonomics Network allows you to communicate with any sensor you wish and get data from the sensor all around the world. This data can be transferred to different destinations.\\n\\nOn this page you'll find step-by-step instructions to connect an ESP board to the connectivity server provided by AiraLab.\\n\\n## Requirements\\n\\n* ESP8266/ESP32 like board with WiFi\\n\\n## 1. Get the software\\n\\n### On Windows\\n\\nInstall [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\\n\\nInstall Ubuntu via Windows Store:\\n\\n![Windows Store](../images/windows_store.jpg \\\"Windows Store\\\")\\n\\nand clone the [package](https://github.com/airalab/sensors-connectivity)\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\n```\\n\\nThe next step is to install python and dependencies:\\n\\n```\\nsudo apt update && sudo apt install python3-pip\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n### On Ubuntu\\n\\n```\\nsudo apt update && sudo apt install python3-pip git\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n> You can ignore such warnings:\\n>\\n> ```\\n> The script ... is installed in '...' which is not on PATH.\\n> Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\n> ```\\n\\n### On NixOS\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\nnix build -f release.nix\\nsource result/setup.bash\\n```\\n\"}},{\"node\":{\"id\":\"50b226410ee8272c83e44699789ef9ac\",\"title\":\"IoT Firmware Upload\",\"path\":\"/docs/ru/iot-firmware-upload/\",\"content\":\" \\n\\nThere are few firmwares for ESP like boards:\\n\\n* [Ping](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/ping)\\n* [TCP](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/tcp)\\n* [Mobile GPS](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/mobile_gps)\\n\\nThere is a script to upload a firmware for each one, called `flash_firmware.py`. It's located in the root of the repository\\n\\n> **Requirements**\\n> In order to install all dependencies run in the root of the repository folder:\\n>\\n> ```\\n> pip install -r requirements.txt\\n> ```\\n>\\n> Python3 is required!\\n\\nUsually in order to upload a firmware to your board follow these steps:\\n\\n1. Assemble the board and connect it to PC\\n2. Edit a `config.yaml` in a corresponding folder (e.g. `boards/esp/tcp/config.yaml`)\\n3. Run `python flash_firmware.py -s PATH_TO_FOLDER -c PATH_TO_CONFIG` where `PATH_TO_FOLDER` is a path to the desired firmware (e.g. `boards/esp/ping`) and `PATH_TO_CONFIG` is a path to the configuration file (e.g. `boards/esp/ping/config.yaml`)\\n\\n\"}},{\"node\":{\"id\":\"0f0458f9f322337b673756a4a01ef2fa\",\"title\":\"Interact with AIRA\",\"path\":\"/docs/ru/interact-with-aira/\",\"content\":\"\\nAt this point you should be familiar with a [DApp](/docs/get-weather-on-fuji-mountain/) and how to launch [AIRA image](/docs/aira-installation-on-vb/).\\nNow you are ready to do more complicated stuff like installing a package and interacting with it via DApp.\\n\\n> **Important:**\\n> Make sure you have covered previous lessons before you continue.\\n\\n\\n> **Tip:**\\n> During the lesson you will type a few commands in terminal. AIRA image doesn't support clipboard, so to make life easier have a look at [Connect via SSH](/docs/aira-connecting-via-ssh/) and log in via SSH to the VM.\\n\\nWalkthrough video:\\n\\nhttps://www.youtube.com/embed/QM06l07_wuA\\n\\n## Package installation\\n\\nAfter you launched AIRA and logged in using your terminal do the following:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nRun one by one commands above. After the last one you should see a link to DApp generated specifically for your instance.\\n\\n![Terminal with AIRA](../images/aira_hello_terminal.jpg \\\"Terminal with AIRA\\\")\\n\\nClick on the link, the DApp should be shown.\\n\\n## DApp \\n\\nConnect [MetaMask](http://metamask.io/) if prompted and click on the button\\n\\n![Request connection in Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Request connection in Robonomics Dapp\\\")\\n\\nSign the message as usual and wait for the result\\n\\n![Wait for Result of request](../images/aira_hello_dapp_2.jpg \\\"Wait for Result of request\\\")\\n\\nMeanwhile have a look at the terminal. You should see the greeting\\n\\n![AIRA greeting in terminal](../images/aira_hello_terminal_2.jpg \\\"AIRA greeting in terminal\\\")\\n\\nIn the end the greeting will appear in the DApp\\n\\n![Robonomics DApp Greeting for AIRA](../images/aira_hello_dapp_3.jpg \\\"Robonomics DApp Greeting for AIRA\\\")\\n\\n## Troubleshooting\\n\\n### You click \\\"Request current values\\\" but see no greeting\\n\\nProbably you have just launched AIRA and IPFS hasn't finished initialization. Wait a minute or so and try again.\\n\\n### I see response hash but the data doesn't appear\\n\\nAgain most probably the issue comes from IPFS connection. Click and the hash and you'll see the result. It's not necessary to download the file.\\n\\n## Home Task (optional)\\n\\nIf you are familiar with [Python](https://www.python.org/) change the shown text to something different and complete the lesson with your version of `hello_aira`\\n\\n- Make a fork of the [repository](https://github.com/vourhey/hello_aira)\\n- The output text is located [here](https://github.com/Vourhey/hello_aira/blob/master/scripts/hello_aira#L45)\\n\"}},{\"node\":{\"id\":\"820531e1d4d216256374522bbb098579\",\"title\":\"How to launch the Robonomics collator\",\"path\":\"/docs/ru/how-to-launch-the-robonomics-collator/\",\"content\":\"\\nNote: In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is maintained by developers, but anyone can support the project. Every additional full node of the blockchain helps it to be more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it could be [built from source](/docs/how-to-build-collator-node/).\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nBut we recommend that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need use *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can simply launch a collator directly in the command line to check for errors.\\nAfter that we strongly recommend to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](../images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](../images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with : `journalctl -u robonomics.service -f` \\n\\nNow the robonomics collator is launched it will sync with the Kusama Relay Chain, this can take up quite some time depending on your network speed and system specifications, so we recommend to download a Kusama snapshot and use it. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the robonomics service. You can find more info about snapshots and usage instructions on the followin page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](../images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](../images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\"}},{\"node\":{\"id\":\"295a63f5015fe69f7d9ce73f554ac8bb\",\"title\":\"How to build collator node from source\",\"path\":\"/docs/ru/how-to-build-collator-node/\",\"content\":\"\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](../images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v1.4.0:\\n\\n```\\n  rustup install nightly-2021-11-02\\n```\\n![Install nightly](../images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2021-11-02\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2021-11-02\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v1.4.0 robonomics-node\\n```\\n![Start build Robonomics](../images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](../images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"}},{\"node\":{\"id\":\"837fc4ebd36d85b26322702f3150d454\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/ru/home-assistant-begin/\",\"content\":\"There are instructions on how to connect your smart home devices to the Robonomics network. You need Robonomics [accounts](/docs/create-account-in-dapp/) for each device, they will publish encrypted data in datalog. Also you need user account that will send commands to devices end encrypt/decrypt data.\\n\\nIn this video you can see the example of connecting temperature sensor:\\n\\nhttps://youtu.be/iB2Z8HtERgs\\n\\n# Requirements\\n\\n* Raspberry Pi 4 or 3\\n* SD card and SD adapter\\n* Temperature sensor - [Keen Home RS-THP-MP-1.0](https://www.zigbee2mqtt.io/devices/RS-THP-MP-1.0.html) (or another [supported device](https://www.zigbee2mqtt.io/information/supported_devices.html))\\n\\n### Method 1 (with SLS Gateway)\\n* [Robonomics SLS Gateway](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01)\\n\\n### Method 2 (with zigbee2MQTT)\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\n### Method 3 (with Xiaomi Gateway)\\n* Xiaomi Gateway (one of [supported](https://www.home-assistant.io/integrations/xiaomi_miio#xiaomi-gateway))\\n* [Mi Home app](https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&hl=ru&gl=US) or HomeKit app\\n\\nAlso you can connect some devices directly through Mi Home app (for example, Vacuum Cleaner).\\n\\n# Setup\\n\\n1. First you need to [setup Raspberry Pi](/docs/raspberry-setup/) (also you can [use prepared image](/docs/raspberry-image/)).\\n2. Then you need to connect devices to Home Assistant:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n3. And [connect them to Robonomics Network](/docs/add-smart-device-to-robonomics/).\\n\"}},{\"node\":{\"id\":\"1f6a9968edbaf9d5a7b6a5bce8a3235f\",\"title\":\"Passing dynamic parameters\",\"path\":\"/docs/ru/hardware-passing-dynamic-parameters/\",\"content\":\"\\nIn [previous](/docs/connect-simple-cps/) example we discussed how to create a simple CPS with Arduino. Our first CPS is able to do only one task: to blink a led. We suggest you to get through the first lesson. Now let's expand the example and teach our board to blink blue or red led depending on objective parameter.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_with_args).\\n\\n\\n## Arduino\\n\\nThe only difference in Arduino source code is instead of subscribing to one topic now we subscribe to `/blink_red` and `/blink_blue` topics\\n\\n```c\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void blinkRedCb(const std_msgs::Empty& msg) {\\n    blink(13, 500);\\n    blink(13, 500);\\n    blink(13, 500);\\n  }\\n\\n  void blinkBlueCb(const std_msgs::Empty& msg) {\\n    blink(12, 500);\\n    blink(12, 500);\\n    blink(12, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> subRed(\\\"blink_red\\\", &blinkRedCb);\\n  ros::Subscriber<std_msgs::Empty> subBlue(\\\"blink_blue\\\", &blinkBlueCb);\\n\\n  void setup()\\n  {\\n    pinMode(13, OUTPUT);\\n    pinMode(12, OUTPUT);\\n\\n    nh.initNode();\\n    nh.subscribe(subRed);\\n    nh.subscribe(subBlue);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n<!-- Here is the diagram of all connections:\\n\\n.. image:: ../img/6.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\n\\n## ROS\\n\\nWe can pass arguments via objective which points to rosbag file. Have a look at `blink.py` script. The main difference is `blink()` method:\\n\\n```python\\ndef blink(self, data):\\n  if data.data == \\\"blue\\\":\\n      rospy.loginfo(\\\"Blinking blue...\\\")\\n      self.blink_blue.publish(Empty())\\n\\n  if data.data == \\\"red\\\":\\n      rospy.loginfo(\\\"Blinking red...\\\")\\n      self.blink_red.publish(Empty())\\n\\n  rospy.wait_for_service('/liability/finish')\\n  fin = rospy.ServiceProxy('/liability/finish', FinishLiability)\\n  fin(FinishLiabilityRequest(address=self.liability, success=True))\\n  rospy.loginfo(\\\"Finished\\\")\\n```\\n\\nNow `/blink` topic has a `String` type. You can find prepared rosbags in `rosbag` folder.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh/). Do not forget to add `COM1` port in settings. Run the following command:\\n\\n```\\n$ rosrun arduino_with_args blink.py\\n```\\n\\nAlso we need to add rosbag files to IPFS:\\n\\n```\\n$ ipfs add rosbag/blink_blue.bag\\n$ ipfs add rosbag/blink_red.bag\\n```\\n\\n**Before the next step you should approve XRT tokens on the Factory.**\\n\\nThe last step is to build Dapp and launch. Take a look at the previous [lesson](/docs/connect-simple-cps/). To make Arduino blink the blue led send blue demand and blue offer messages. For the red one send corresponding messages.\\n\\nThat's it! Now you are able to pass dynamic parameters to your cyber-physical system agent!\"}},{\"node\":{\"id\":\"a4d547219e2f9675dd87ae7b45fa287e\",\"title\":\"Connect an Air Pollution Sensor\",\"path\":\"/docs/ru/hardware-connect-sensor/\",\"content\":\"\\nIn this lesson you are going to learn how to connect your sensor to the network and make it publish data. You will see how it is easy to become a member of a global sensor network!\\n\\nSource code is located [here](https://github.com/airalab/robonomics_tutorials/tree/master/sensor_city).\\n\\nIn this section we are not going to create a liability contract. Instead we will teach Arduino with sensors to publish the data by a request. All measurements will be published as a Result message.\\n\\n## Arduino\\n\\nLet's begin with an Arduino circuit. You need the following components:\\n\\n* Arduino Uno\\n* Optical Dust Sensor Sharp GP2Y1010AU0F\\n* Gas Sensor MQ-2\\n* Gas Sensor MQ-7\\n* Resistor 150 Ohm\\n* Capacitor 220 uF\\n* Wires\\n\\nConnect all parts as described below:\\n\\n<!-- .. image:: ../img/7.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\nA firmware for Arduino Uno is in `sensor_city/scetches` folder. In order to upload it to the board use [Arduino IDE](https://www.arduino.cc/en/Main/Software).\\n\\n<!-- .. image:: ../img/8.png\\n   :alt: Arduino IDE\\n   :align: center\\n -->\\n\\n## Aira\\n\\nThe following steps are performed in Aira client. You can download the latest image from [this page](https://github.com/airalab/aira/releases). It's convenient to [connect via SSH](/docs/aira-connecting-via-ssh/).\\n\\nAfter you have imported the image to VirtualBox, connect Arduino via USB to your PC and enable serial port forwarding. You should check `Enable Serial Port` and assign `/dev/ttyACM0` in `Path/Address`. Inside the virtual machine `/dev/ttyS0` refers to your external Arduino.\\n\\n<!-- .. image:: ../img/9.png\\n   :alt: Set a port\\n   :align: center -->\\n\\nFinally launch the image and run these command:\\n\\n```\\n$ roslaunch sensor_city publish_data.launch\\n```\\n\\n**Check out the source code to learn how it works under the hood!**\\n\\nNow Aira patiently waits for a signal to publish the measurements. Go to [Dapp](https://dev.aira.life/smart-city/#/) and click on `Broadcast signal`. You should see the data!\"}},{\"node\":{\"id\":\"0e00b81abe56ec93b4674a4e11cf0baa\",\"title\":\"Glossary\",\"path\":\"/docs/ru/glossary/\",\"content\":\"\\n## Agent\\n\\nIn terms of Robonomics Network agent is a program module that uses IPFS or blockchain or both interfaces of the network and does some actual work.\\nUsually it's represented as a ROS package and it may connect (but not necessarily) a real cyber-physical system to the Robonomics Network.\\n\\n## Cyber-physical system\\n\\nIt is a combination of a physical mechanism that is usually called a robot and a program algorithm that controls the behavior of the mechanism.\\n\\n## Dapp\\n\\nIt is a short form for Decentralized application. Usually it is a single page web based application that helps to interact with an agent.\\n\\n## IPFS\\n\\nAccording to the official [documentation](https://docs.ipfs.io/introduction/) \\\"IPFS is a distributed system for storing and accessing files, websites, applications, and data\\\".\\nFor more detail how it works go to the official website.\\n\\n## Lighthouse\\n\\nA lighthouse is an autonomous workflow that allows us to distribute the running time of providers that serve a single broadcast channel.\\n\\nFor more information read [Robonomics Whitepaper](https://static.robonomics.network/docs/whitepaper/Robonomics-whitepaper-en.pdf) section 5.2.\\n\\n## Sidechain\\n\\nEthereum based blockchain network with Proof-of-Authority consensus owned by Airalab.\\n\\n\"}},{\"node\":{\"id\":\"2412f765e5ec9f151ce1b81f8b82a157\",\"title\":\"Введение\",\"path\":\"/docs/ru/\",\"content\":\"\\n## Что такое Робономика\\n\\nПлатформа Робономики предоставляет инструменты для экономического взаимодейтсвия с роботами. Робономика позволяет разработчикам умных городов и сервисов Индустрии 4.0 построить доверительные отношения между [автономными роботизированными сервисами](/docs/glossary#cyber-physical-system) и обеспечить прямой доступ к услугам умных фабрик и сетей датчиков для пользователей через [децентрализованные приложения](/docs/glossary#dapp). \\n\\nУзнайте больше в документе [\\\"Robonomics whitepaper\\\"](https://github.com/airalab/robonomics_specs/blob/master/pdf/whitepaper_ru.pdf) на русском.\\n\\n![Сценарий сети Робономика](../images/robonomics_network_basic_scheme_ru.jpg \\\"Сценарий сети Робономика\\\")\\n\\n*Схема работы сети Робономика*\\n\\n## What the documentation contains\\n\\n### Robonomics Network quick start\\nStart with quick example of what Robonomics is able to do within 5 minutes: [DEMO \\\"Get Weather on Fuji Mountain\\\"](/docs/get-weather-on-fuji-mountain).\\n\\n### I'm interested in using Robonomics services\\n\\nTake a look at the [Robonomics Dapp](https://dapp.robonomics.network/#/). Get familiar with the statistic, average miner reward etc.\\nTry out existing [services](https://dapp.robonomics.network/#/services)\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"}},{\"node\":{\"id\":\"eaa678091da8874311dc3decc396e423\",\"title\":\"DEMO \\\"Get Weather on Fuji Mountain\\\"\",\"path\":\"/docs/ru/get-weather-on-fuji-mountain/\",\"content\":\"\\n**Давайте начнем с быстрого примера того, что Робономика способна сделать за 5 минут. Необходимо: [Расширение Метамаск](https://metamask.io/)**\\n\\nЧтобы получить погоду с датчика на горе Фудзи, откройте страницу [Датчик погоды г. Фуджи](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/) в Dapp приложении Робономики и следуйте инструкциям ниже.\\n\\nПошаговое видео:\\n\\nhttps://www.youtube.com/embed/t098NlMELk4\\n\\n## 1. Откройте Dapp (децентрализованное приложение)\\n\\nЕсли у вас нет расширения MetaMask, появится такая картинка. Перейдите по ссылке выше и установите его.\\n\\n![\\\"Robonomics dApp if no MetaMask installed\\\"](../images/sensor-demo/sensor-demo-1.png \\\"Robonomics dApp if no MetaMask installed\\\")\\n\\n## 2. Разрешите подключение к расширению\\n![\\\"Connection to Robonomics dApp via Metamask\\\"](../images/sensor-demo/sensor-demo-2.png \\\"Connection to Robonomics dApp via Metamask\\\")\\n\\n## 3. Нажмите \\\"Request current values\\\"\\n![\\\"Request sensor's data in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-3.png \\\"Request sensor's data in Robonomics network via dApp\\\")\\n\\n## 4. Подпишите сообщение (Sign). Токен или эфир не нужны!\\n![\\\"Sign a message in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-4.png \\\"Sign a message in Robonomics network via dApp\\\")\\n\\n## 5.Подождите, пока агент-приложения соберет данные и отправит их обратно\\n![\\\"Wait for response of the agent in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-5.png \\\"Wait for response of the agent in Robonomics network via dApp\\\")\\n\\n## 6.Подождите, пока Dapp загрузит файл результата из IPFS (межпланетная файловая система).\\n![\\\"Wait for IPFS file with results in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-6.png \\\"Wait for IPFS file with results in Robonomics network via dApp\\\")\\n\\n## 7. Посмотрите данные о погоде на горе Фудзи.\\n![\\\"The results of sensor network in Robonomics via dApp\\\"](../images/sensor-demo/sensor-demo-7.png \\\"The results of sensor network in Robonomics via dApp\\\")\\n\\nПоздравляем! Только что вы передали сообщение с запросом и получили результат от автономного агента! Файл результатов хранится в IPFS, сообщение результата подписывается закрытым ключом агента.\\n\"}},{\"node\":{\"id\":\"1f66d633f2f8c1ecfb44f33b28873d56\",\"title\":\"Как купить подписку\",\"path\":\"/docs/ru/get-subscription/\",\"content\":\"\\nhttps://youtu.be/EsUiG_4ZGcw\\n\\nДля тестирования подписки мы будем использовать [ноду Робономики в среде разработки](/docs/run-dev-node), но в производственной сети все работает точно так же.\\n\\nВ `Developer/Chain state` Вы можете видеть аукционы на подписку (чтобы получить подписку, необходимо выиграть быстрый аукцион). Выберите `rws` и `auctionQueue` и нажмите кнопку `+`. Вы увидите ID доступных аукционов:\\n\\n![очередь](../images/dev-node/queue.png)\\n\\nВы можете увидеть информацию о любой подписке с помощью `rws` `auction` и ID аукциона (на картинке ID аукциона - 0):\\n\\n![аукцион](../images/dev-node/auction.png)\\n\\nВ информации об аукционе имеется поле `winner`. В данный момент оно `null`, что означает, что ни у кого нет этой подписки и мы можем ее получить. Для этого перейдите в `Developer/Extrinsic`, выберите Ваш аккаунт и `rws -> bid`. Также задайте ID аукциона (0) и количество токенов для ставки (более 1000000000 Wn):\\n\\n![ставка](../images/dev-node/bid.png)\\n\\nСовершите транзакцию и проверьте информацию об аукционе с ID 0 (в `Chain state` выберите `rws -> auction` и ID 0):\\n\\n![победа](../images/dev-node/auc_win.png)\\n\\nСейчас в поле `winner` Вы увидите адрес Вашего аккаунта. Это значит, что у данного аккаунта подписка 0. Аукцион начинается с первой ставки и длится несколько блоков, так что если в течение этого времени кто-нибудь поставит больше токенов, чем Вы, он станет победителем и получит подписку.\\n\\nТеперь Вы можете добавлять устройства. Устройства - это аккаунты, которые могут пользоваться подпиской и отправлять экстринсики без комиссии. Чтобы протестировать это, давайте создадим новый аккаунт без токенов и добавим его к устройствам.\\n\\nЧтобы добавить устройства, выберите `rws -> setDevices` в `Developer/Extrinsic`. Затем нажмите кнопку `Add Item` и выберите недавно созданный аккаунт без токенов:  \\n\\n![добавить устройства](../images/dev-node/set_devices.png)\\nСовершите транзакцию. Теперь Вы можете проверить список устройств в `Chain state` с помощью `rws -> devices`. Здесь Вы увидите адрес Вашего аккаунта без токенов. Выберите аккаунт, с которого купили подписку, и нажмите `+`:\\n\\n![устройства](../images/dev-node/devices.png)\\n\\nСейчас Вы можете попытаться [отправить launch](/docs/subscription-launch) экстринсик с помощью подписки.\\n\"}},{\"node\":{\"id\":\"50a7edd0757b7dcc4d2fb8fb7335eecd\",\"title\":\"Gaka-Chu setup and software Installation\",\"path\":\"/docs/ru/gaka-chu/\",\"content\":\"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](../images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](../images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"}},{\"node\":{\"id\":\"57bff9b173a46c19da69c362882f4d7f\",\"title\":\"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\"path\":\"/docs/ru/freertos-mqtt/\",\"content\":\"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](../images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](../images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](../images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](../images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](../images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"}},{\"node\":{\"id\":\"55eae94f73899b4b85963c1aac99b2cb\",\"title\":\"Ethereum Common\",\"path\":\"/docs/ru/ethereum-common/\",\"content\":\"\\nThe packages contains two launch files: `erc20.launch` and `signer.launch`. The last one is included in [Robonomics Liability](/docs/robonomics-liability).\\n\\nBelow is the description for `erc20` node which contains utils for convenient work with Ethereum accounts and XRT token.\\n\\n## ROS Parameters\\n\\n###  ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~erc20_token\\n\\nERC20 token to work with. Type is `string`, defaults to `xrt.5.robonomics.eth`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Published topics\\n\\n### /eth/event/transfer (ethereum_common/TransferEvent)\\n\\nThe event [ethereum_common/TransferEvent](/docs/ethereum-common-messages#ethereum_commontransfereventmsg) is emitted after the transfer of tokens was made\\n\\n### /eth/event/approval (ethereum_common/ApprovalEvent)\\n\\nThe event [ethereum_common/ApprovalEvent](/docs/ethereum-common-messages#ethereum_commonapprovaleventmsg) is emitted after the approval of tokens was made\\n\\n## Services\\n\\n### /eth/accounts (ethereum_common/Accounts)\\n\\nList of available Ethereum accounts. See [ethereum_common/Accounts](/docs/ethereum-common-messages#ethereum_commonaccountssrv)\\n\\n### /eth/account_eth_balance (ethereum_common/AccountBalance)\\n\\nReturns the balance of the given address in Wei. See [ethereum_common/AccountBalance](/docs/ethereum-common-messages#ethereum_commonaccountbalancesrv)\\n\\n### /eth/eth_balance (ethereum_common/Balance)\\n\\nReturns the balance of the default address. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/current_block (ethereum_common/BlockNumber)\\n\\nReturns current block number. See :ref:`Ethereum-common-BlockNumber.srv`\\n\\n### /eth/transfer (ethereum_common/Transfer)\\n\\nTransfers tokens from the default account to a given one. See :ref:`Ethereum-common-Transfer.srv`\\n\\n### /eth/transfer_from (ethereum_common/TransferFrom)\\n\\nTransfers tokens from a given account to another one. See :ref:`Ethereum-common-TransferFrom.srv`\\n\\n### /eth/approve (ethereum_common/Approve)\\n\\nApproves tokens from the default account to a given one. See :ref:`Ethereum-common-Approve.srv`\\n\\n### /eth/account_xrt_balance (ethereum_common/AccountBalance)\\n\\nReturns the XRT balance of a given account. See :ref:`Ethereum-common-AccountBalance.srv`\\n\\n### /eth/xrt_balance (ethereum_common/Balance)\\n\\nReturn the XRT balance of the default account. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/account_xrt_allowance (ethereum_common/AccountToAddressAllowance)\\n\\nReturns how much one account is allowed to spend from another account. See :ref:`Ethereum-common-AccountToAddressAllowance.srv`\\n\\n### /eth/xrt_allowance (ethereum_common/Allowance)\\n\\nReturns how much the Factory is allowed to spend from the default account. See :ref:`Ethereum-common-Allowance.srv`\"}},{\"node\":{\"id\":\"561afe2ef0f44347c69a9812a6009e2c\",\"title\":\"Ethereum Common Messages\",\"path\":\"/docs/ru/ethereum-common-messages/\",\"content\":\"\\n## ethereum_common/Address.msg\\n\\n| Field   \\t| Type            \\t| Description                    \\t|\\n|---------\\t|-----------------\\t|--------------------------------\\t|\\n| address \\t| std_msgs/String \\t| Address in Ethereum blockchain \\t|\\n\\n## ethereum_common/UInt256.msg\\n\\n| Field   \\t| Type            \\t| Description                \\t|\\n|---------\\t|-----------------\\t|----------------------------\\t|\\n| uint256 \\t| std_msgs/String \\t| A wrapper for big integers \\t|\\n\\n## ethereum_common/TransferEvent.msg\\n\\n| Field      \\t| Type                                                  \\t| Description      \\t|\\n|------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_from  \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Sender address   \\t|\\n| args_to    \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Receiver address \\t|\\n| args_value \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/ApprovalEvent.msg\\n\\n| Field        \\t| Type                                                  \\t| Description      \\t|\\n|--------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_owner   \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Owner address    \\t|\\n| args_spender \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Spender address  \\t|\\n| args_value   \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/AccountBalance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field   \\t| Type                                                  \\t| Description    \\t|\\n|---------\\t|-------------------------------------------------------\\t|----------------\\t|\\n| balance \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wei \\t|\\n\\n## ethereum_common/AccountToAddressAllowance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n| to      \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field  \\t| Type                                                  \\t| Description   \\t|\\n|--------\\t|-------------------------------------------------------\\t|---------------\\t|\\n| amount \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wn \\t|\\n\\n## ethereum_common/Accounts.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------- |-------------------------------------------------------    |----------------------------   |\\n| accounts  | [ethereum_common/Address[]](#ethereum_commonaddressmsg)     | List of available accounts    |\\n\\n## ethereum_common/Allowance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                                       |\\n|--------   |-------------------------------------------------------    |-----------------------------------------------    |\\n| amount    | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | Amount of XRT the Factory is allowed to spend     |\\n\\n## ethereum_common/Approve.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------  |-------------------------------------------------------    |-----------------------------  |\\n| spender   | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Who is allowed to spend       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | How much tokens are allowed   |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/Balance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                       |\\n|---------  |-------------------------------------------------------    |--------------------------------   |\\n| balance   | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The balance of default account    |\\n\\n## ethereum_common/BlockNumber.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type              | Description           |\\n|--------   |-----------------  |---------------------- |\\n| number    | std_msgs/Uint64   | Current block number  |\\n\\n## ethereum_common/Transfer.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Ethereum address      |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/TransferFrom.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| owner     | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Owner's address       |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Another account       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\"}},{\"node\":{\"id\":\"993ecbb0ea7ea23d25951bc63eee693b\",\"title\":\"Digital Twins\",\"path\":\"/docs/ru/digital-twins/\",\"content\":\"\\n## Requirements\\n- `robonomics` [executable][ln1]\\n- Be familiar with [parachain.robonomics][ln2]\\n\\n## Digital Twins Schema\\n\\nDigital twins have the following structure:\\n\\n| DT id \\t| Topic Name \\t| Source    \\t|\\n|-------\\t|------------\\t|-----------\\t|\\n| 0     \\t| 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1     \\t| 0x00...001 \\t| 4GVi...Bn \\t|\\n|       \\t| 0x00...002 \\t| 4Hm...vLS \\t|\\n|       \\t| 0x00...... \\t| 4HQ...RQY \\t|\\n|       \\t| 0xFF...FFF \\t| 4Hw...CyK \\t|\\n| 2     \\t| 0x00...000 \\t| 4HJ...k3o \\t|\\n\\n Where:\\n* **DT id** - is unsigned integer unique number.\\n* **Topic name** - is 0x prefixed `H256 hex` or `ascii data` with 32 bytes length. For example: `0x1234....FF` and  `hello.parachain.robonomics.world`.\\n* **Source** - is Account address.\\n\\n## Create Digital Twin\\nGo to ***Developer -> Extrinsics*** and choose `digitalTwin.create()` extrinsic.\\n![digital Twin create][im1]\\n\\n Submit transaction and go to ***Network -> Explorer*** and in the **recent events** you will see information about digital twin.\\n ![digital Twin create info][im2]\\n\\n## Add DT Topic\\n\\nYou can create multiple topics for one digital twin. for creating topic you need go to ***Developer -> Extrinsics*** and choose `digitalTwin.setSource(id,topic,source)` extrinsic. Fill in the fields and submit transaction.\\n![DT topic fields][im3]\\n\\nAgain go to **Network -> Explorer*** and in the **recent events** you will see information about created topic.\\n![info about topic][im4]\\n\\nYou can create several topics for one twin.\\n![topics][im5]\\n\\n## Chain State\\n\\nYou can find all information about existing *digital twins in* ***Developer -> Chain state*** such as:\\n- Total number of Digital twins - total()\\n- Information about owner of digital twin - owner(u32)\\n- Information about topics in digital twin - digitalTwin(u32)\\n![chain info][im6]\\n\\n\\n[ln1]: <https://github.com/airalab/robonomics/releases>\\n[ln2]: </docs/create-account-in-dapp>\\n[im1]: <../images/digital-twin/twin-create.jpg>\\n[im2]: <../images/digital-twin/create-log.jpg>\\n[im3]: <../images/digital-twin/fields.jpg>\\n[im4]: <../images/digital-twin/topic.jpg>\\n[im5]: <../images/digital-twin/topics.jpg>\\n[im6]: <../images/digital-twin/chain-state.jpg>\\n\"}},{\"node\":{\"id\":\"f7b2d922a0cdf138a9c424b405a5b589\",\"title\":\"Как редактировать Вики\",\"path\":\"/docs/ru/edit-wiki/\",\"content\":\"\\n**Робономика – это набор репозиториев с открытым программным кодом. Корневая команда разработчиков приветствует любые правки со стороны сообщества: исправление багов, опечаток, неясной или устаревшей информации, перевод на любые языки. Вам понадобится аккаунт [GitHub](https://github.com/).**\\n\\n## Правка уже существующего документа\\n\\n1. Выберите страницу для редактирования\\n2. Нажмите на кнопку \\\"Редактировать страницу\\\"\\n3. Вас переведет на страницу GitHub репозитория, а именно страницу нужного .md файла.\\n4. При редактировании придерживайтесь общих правил разметки [Markdown](https://ru.wikipedia.org/wiki/Markdown) с учётом некоторых особенностей стека Вики:\\n\\n### Метаданные\\nНекоторые сведения о странице в документации указываются в блоке метаданных. Этот блок должен быть расположен вверху markdown файла, использовать корректный синтаксис YAML и ограничен разделителем (---). Вы можете указать следующие параметры:\\n\\n```YAML\\n---\\ntitle: How to contribute # Заголовок статьи. Заголовок не нужно дублировать в тексте статьи\\ncontributors: [positivecrash] # Основные контрибьюторы (добавляются вручную, исходя из внесенного вклада). Нужно указывать свой Github ник без доп символов\\ntranslated: true # \\\"true\\\" если страница переведена на текущий язык (ориентируйтесь на название папки локали, содержащей .md файл)\\n---\\n```\\n\\n### YouTube видео\\nВ документацию можно встраивать YouTube видео без дополнительной разметки, вставив ссылку на видео. Например: `https://youtu.be/kQaSwNYHJQ8`\\n\\n### Asciinema\\nВики Робономики поддерживает встраивание Asciinema. Для этого ознакомьтесь, пожалуйста, со следующей инструкцией:\\n* Импортируйте компонент сразу после блока метаданных сверху `import Asciinema from '~/components/Asciinema.vue'`\\n* Вставьте как отдельный параграф `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, где vid это ID вашего аскикаста.\\n\\n> You can get the widget script for a specific asciicast by clicking on “Embed” link on asciicast page.\\n> It looks like this:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Документация Asciinema](https://asciinema.org/docs/embedding)\\n\\nВ этом примере vid равно 14.\\n\\n## Добавление нового документа\\n\\nЕсли вы хотите добавить новый документ в Вики Робономики:\\n\\n1. Найдите папку с локалью, соответствующей языку добавляемой статьи, например `/docs/ru/`\\n2. Создайте файл .md, используя в имени латинские символы и следуйте общим правилам для [структуры url](https://developers.google.com/search/docs/advanced/guidelines/url-structure)\\n3. Заполните файл, придерживаясь рекомендаций выше\\n4. Продублируйте созданный файл в папки с другими локалями, даже если вы не планируете переводить документ на другие языки. Не забудьте в неперееденных документах поставить параметр `translated: false`\\n5. Добавьте документ в меню:\\n* Откройте файл `/data/sidebar_docs.yaml`\\n* Выберите место размещения ссылки\\n* Если вы хотите создать новый раздел, то напишите только заголовок без ссылки\\n* Добавляйте заголовки только с локалью, для которого есть перевод страницы. Если заголовок указывается для названия раздела, то правило такое: указываем названия только на тех языках, для которых есть хотя бы одна переведенная статья в разделе.\\n* Для документа добавьте ещё и ссылку. Ссылка должна быть одна для всех языков и не должна содержать код языка. Правильно: `/docs/url-of-your-doc`, неправильно: `/docs/en/url-of-your-doc`\\n* Для работы с `/data/sidebar_docs.yaml` используйте корректный синтаксис YAML и ориентируйтесь на существующую структуру документа\\n\\n## Отправьте PR\\n\\nОтправьте PR с соблюдением некоторых принципов, указанных [здесь](/docs/ru/contributing/#создание-pr).\"}},{\"node\":{\"id\":\"32727d898f8249f20a8d2096cb7a0afb\",\"title\":\"Межсетевой обмен сообщениями\",\"path\":\"/docs/ru/cross-chain-messages/\",\"content\":\"\\nXCM (протокол межсетевого обмена) позволяет отправлять сообщения между парачейнами.Вы можете отправлять транзакцию launchXcm для запуска/остановки Вашего робота или транзакцию datalogXcm для сохранения данных в блокчейне.\\n\\nhttps://www.youtube.com/watch?v=a6XrqoaYhK8&feature=emb_logo\\n\\n## Создаем аккаунт\\n\\nДавайте попробуем отправить сообщение с Земли на Марс.\\nПерейдите в [parachain.robonomics.network](https://parachain.robonomics.network/#/explorer) и выберите тестнет `Airalab Rococo`:\\n\\n![тестнеты](../images/cross-chain/testnet.jpg)\\n\\nВ `Network/Parachains` Вы увидите два парачейна с их ID:\\n\\n![id](../images/cross-chain/Parachains_id.jpg)\\n\\nДалее перейдите к парачейну Earth и [создайте](https://wiki.robonomics.network/docs/ru/create-account-in-dapp/) два аккаунта (например, `ROBOT` и `EMPLOYER`). В новой вкладке перейдите к парачейну Mars.\\n\\n## LaunchXcm\\n\\nВ парачейне Earth выберите `Developer/Extrinsics`, Ваш аккаунт `EMPLOYER` и launchXcm. Затем впишите ID парачейна Mars (2000) и выберите аккаунт `ROBOT`:\\n\\n![launch](../images/cross-chain/launch.jpg)\\n\\nТеперь нажмите `Submit Transaction`.\\n\\nЧтобы увидеть Ваши транзакции в парачейне Mars, перейдите в `Network/Explorer` и посмотрите Recent Events.\\n\\n![recent_launch](../images/cross-chain/recent_launch.jpg)\\n\\n## DatalogXcm\\n\\nВ парачейне Earth перейдите в `Developer/Extrinsics`, выберите Ваш аккаунт `ROBOT` и datalogXcm. Напишите ID парачейна Mars (2000) и сообщение:\\n\\n![datalog](../images/cross-chain/datalog.jpg)\\n\\nДалее нажмите `Submit Transaction`.\\n\\nВы можете видеть Вашу транзакцию в Recent Events в парачейне Mars:\\n\\n![recent_datalog](../images/cross-chain/recent_datalog.jpg)\\n\"}},{\"node\":{\"id\":\"b716e6f613b1d1473641f96ebcb7662c\",\"title\":\"Create digital identity run by Ethereum\",\"path\":\"/docs/ru/create-digital-identity-run-by-ethereum/\",\"content\":\"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](../images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](../images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](../images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](../images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](../images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](../images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"}},{\"node\":{\"id\":\"b2ae5b9414ba424ca67c0b26c0b33342\",\"title\":\"Создать аккаунт для парачейна Робономики\",\"path\":\"/docs/ru/create-account-in-dapp/\",\"content\":\"\\n**Чтобы взаимодействовать с парачейном Робономики, разработчикам и пользователям нужно создать аккаунт на портале Polkadot/Substrate. Аккаунт осуществляет базовые функции в сети - служит Вашим публичным адресом в сети (публичным ключом), дает доступ к контролю адреса и средств (приватный ключ), позволяет совершать транзакции в сети, показывает Ваши токены и их количество и т.д. Ниже рассмотрены два главных способа создания аккаунта для парачейна Робономики.**\\n\\n## 1. С помощью расширения для браузера Polkadot{.js}\\n\\nРасширение Polkadot предоставляет способ создать аккаунт и взаимодействовать со всеми проектами Полькадот/Кусамы, включая парачейн Робономики. Это не самый безопасный способ управления аккаунтом, но он самый удобный по соотношению безопасности и удобства использования. \\n\\n## 1.1. Установить расширение для браузера\\n\\nРасширение для браузера доступно для [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) и [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=ru) (а также для браузеров на базе Chromium).\\n\\n![Browser Extension](../images/creating-an-account/1.1-polkadot-extension.png \\\"Расширение для браузера\\\")\\n\\n## 1.2. Открыть приложение для парачейна Робономики\\n\\nОткройте [приложение для парачейна Робономики](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) на портале Polkadot/Substrate. Если Вы впервые пользуетесь порталом, он запросит доступ к расширению для браузера, предоставьте доступ.\\n\\nПосле открытия приложения обратите внимание на верхний левый угол - здесь указаны название сети, ее значок и номер последнего блока. Кликнув на эту область, Вы увидите список всех сетей Полькадот/Кусамы, включая тестовые сети и локальные ноды. Вы можете переключиться между сетями, выбрав нужную Вам сеть и нажав кнопку `Switch`. **Убедитесь, что вы подключились к парачейну Робономики**. \\n\\n![Приложение для парачейна Робономики](../images/creating-an-account/1.2-robonomics-app.png \\\"Приложение для парачейна Робономики\\\")\\n\\n## 1.3. Обновить метаданные расширения\\n\\nВполне вероятно, приложение попросит Вас обновить метаданные расширения, чтобы информация о сети, к которой Вы подключены, отображалась корректно. Перейдите в **Settings -> Metadata**, нажмите кнопку `Update metadata`, после чего появится всплывающее окно, где необходимо дать приложению разрешение на это действие.\\n\\n![Обновляем метаданные](../images/creating-an-account/1.3-metadata-update.png \\\"Обновляем метаданные\\\")\\n\\n## 1.4. Создать аккаунт в расширении\\n\\nОткройте расширение для браузера Polkadot{.js}. Кликните на большую кнопку \\\"+\\\" или выберете `Create new account`, нажав на маленькую икноку \\\"+\\\" в верхнем правом углу. Вы должны увидеть следующее меню со сгенерированной мнемотической фразой из 12 слов и адресом.\\n\\n![Создание аккаунта, шаг первый](../images/creating-an-account/1.4-create-account-step-1.png \\\"Создание аккаунта, шаг первый\\\")\\n\\nСид-фраза - это ваш ключ к аккаунту. Зная ее, Вы или любой другой человек может получить контроль над аккаунтом и даже пересоздать его в случае потери пароля. **Очень важно хранить сид-фразу в надежном месте**, лучше всего на бумаге или других нецифровых носителях информации, а не на цифровом носителе или компьютере. \\n\\nСохраните сид-фразу и нажмите `Next step`. Вы должны увидеть следующее меню.\\n\\n![Создание аккаунта, шаг второй](../images/creating-an-account/1.5-create-account-step-2.png \\\"Создание аккаунта, шаг второй\\\")\\n\\n- *Network* позволяет выбрать, для какой сети будет использоваться этот аккаунт. Вы можете использовать один и тот же адрес в разных сетях, однако по соображениям безопасности рекомендуется создать новый адрес для каждой сети, с которой Вы взаимодействуете.\\nВ выпадающем списке выберете сеть Робономики. Если вы не смогли ее найти, скорее всего, вы не обновили метаданные. Вернитесь назад и сделайте это.\\n\\n    - Вы заметите, что формат адреса и иконка аккаунта изменились - это нормально. Разные форматы сети - просто разные представления одного и того же публичного ключа. \\n\\n- *Name* - это просто название аккаунта исключительно для Вашего пользования. Оно не записывается в блокчейне и не видно другим пользователям. \\n\\n- *Password* используется для шифровки информации о Вашем аккаунте. Вам нужно будет заново вводить его при подписании транзакций на портале. Создайте пароль и запомните его.\\n\\nПосле создания аккаунта Вы увидите его в списке аккаунтов в расширении Polkadot{.js}. Кликнув на многоточие, Вы сможете переименовать аккаунт, экспортировать его, удалить его из расширения, а также изменить сеть для этого аккаунта.\\n\\nКроме того, аккаунт появится в меню **Accounts -> Accounts** на портале, где будет отмечено, что он был добавлен с помощью расширения.\\n\\n![Аккаунт успешно создан](../images/creating-an-account/1.6-account-injected.png \\\"Аккаунт успешно создан\\\")\\n\\n\\n## 2. Непосредственно в приложении для парачейна Робономики\\n\\nВы можете создать аккаунт на портале Polkadot/Substrate с помощью пользовательского интерфейса, хотя это не рекомендуется, так как это менее безопасный метод создания аккаунта. Его следует использовать, когда другие способы не подходят или в целях разработки и тестирования.\\n\\n## 2.1. Открыть приложение для парачейна Робономики\\n\\nПерейдите в [приложение для парачейна Робономики](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) на портале Polkadot/Substrate. **Проверьте в верхнем левом углу, что вы подключены к парачейну Робономики**.  \\n\\nПерейдите в **Accounts -> Accounts** и нажмите кнопку `Add account`. \\n\\n![Приложение для парачейна Робономики](../images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Приложение для парачейна Робономики\\\")\\n\\n## 2.2. Создать аккаунт\\n\\nВы должны увидеть следующее всплывающее окно с сид-фразой аккаунта. \\n\\n![Генерация сид-фразы аккаунта](../images/creating-an-account/2.2-robonomics-app-seed.png \\\"Генерация сид-фразы аккаунта\\\")\\n\\nУ нее есть две формы: *Mnemonic* (человекочитаемая) и *Raw* (последовательность цифр и букв). Сохраните сид-фразу в надежном месте и нажмите `Next`.\\n\\nВ следующем меню нужно задать имя и пароль аккаунта, как было рассмотрено выше в инструкции для расширения.\\n\\n![Генерация имени и пароля аккаунта](../images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Генерация имени и пароля аккаунта\\\")\\n\\nКликнув на кнопку `Next`, Вы увидите последнее окно. Нажмите `Save`, чтобы завершить создание аккаунта. Это также сгенерирует резервный файл JSON, который нужно сохранить в надежном месте. Вы можете использовать этот файл позже для восстановления аккаунта, если помните пароль.\\n\\n![Успешное создание аккаунта](../images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Успешное создание аккаунта\\\")\\n\\n## 3. Аккаунт успешно создан\\n\\nТеперь Вы можете делать любые операции с только что созданным аккаунтом. Отправляйте и получайте токены, сообщения, пишите даталог и др. Исследуйте все функции приложения. Чтобы скопировать адрес Вашего аккаунта, просто кликните по его иконке и адрес скопируется в буфер обмена.\\n\\nЕсли Вы хотите узнать больше об аккаунтах Polkadot/Kusama, а также о дополнительных способах их создания, посетите [эту](https://wiki.polkadot.network/docs/learn-accounts) и [эту](https://wiki.polkadot.network/docs/learn-account-generation) страницу.\\n\"}},{\"node\":{\"id\":\"4113122abf080efc4d2720d51b87056c\",\"title\":\"Как стать контрибьютором\",\"path\":\"/docs/ru/contributing/\",\"content\":\"\\nРобономика – сеть с открытым программным кодом, которая строится основной командой разаботчиков и активными участниками сообщества. Вы тоже можете принять участие: предлагать изменения как в основной код наших репозиториев, так и улучшать другие материалы, связанные с Робономикой – редактировать документацию, писать собственные туториалы, предлагать изменения в Вики.\\n\\n## Основные репозитории команды Аиралаб\\n\\n- [aira](https://github.com/airalab/aira) - AIRA клиент в сети Робономика. \\n- [robonomics_comm](https://github.com/airalab/robonomics_comm) - коммуникационный стек в сети Робономика.\\n- [robonomics_contracts](https://github.com/airalab/robonomics_contracts) - смарт контракты Робономики.\\n\\n## Обнаружение багов и предложения по улучшению\\n\\nЕсли вы нашли баг в клиенте AIRA, репозиториях Робономики, этой документации или хотели бы предложить улучшения, откройте [Issue или сделайте PR](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) в соотвествующем репозитории.\\n\\n### Правила создания Issue\\n\\nНе забывайте об общих правилах, когда создаете Issue:\\n\\n1. Обратите внимание, в том ли репозитории вы публикуете обращение.\\n\\n2. Если вы сообщаете о баге, убедитесь, что подобного Issue ещё нет.\\n\\n3. Заполняйте заголовок и описание как можно точнее.\\n\\n4. Желательно включать в заголовок Issue следующие флаги: [BUG], [PROPOSAL], [QUESTION].\\n\\n\\n## Создание PR\\n\\nЛюбой репозиторий корневой команды Аиралаб или документация могут быть изменены посредством [PR (Pull Request)](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) любым участником сообщества. Пожалуйста, не забудьте о простых правилах контрибуции.\\n\\n### Правила констрибуции в репозиториях\\n\\n1. Если вы хотели бы предложить небольшие изменения, например такие, как правки опечаток, форматирования, то предпочительнее PR.\\n\\n2. Понятно опишите проблему и её решение, которое вы предлагаете. При необходимости, можете указать номер Issue.\\n\\n3. Прежде чем править форматирование, убедитесь, что это действительно нужно.\\n\\n4. Пожалуйста, постарайтесь придерживаться преобладающего стиля оформления кода и разметки Markdown.\\n\\n\\n\"}},{\"node\":{\"id\":\"ffd3309723e20ada86c0dc4f7ecbb787\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ru/connectivity-terminal-readme/\",\"content\":\"\\n# Sensors-Connectivity Terminal Readme\\n\\n## Connection\\n\\nTo connect to the server:\\n\\n```bash\\nssh <user>@<address>\\n```\\nWhere user and address are replaced with user, which connectivity service runs under, and address of the VM respectively.\\n\\n## Installation\\n\\nInstallation guide can be found on this [page](https://wiki.robonomics.network/docs/en/sensors-connectivity-on-aira/).\\n\\n\\n## Status checking \\n\\nAssuming you launch the code as a systemd service. Therefore, to check service status:\\n\\n```bash\\nsystemctl status connectivity.service\\n```\\nThere you will find all necessary information about the service, including path to the log files.\\n\\n## Logs\\n\\nGeneral path for log files is: ` ~/.ros/log/latest/connectivity-worker-1.log` where `connectivity-worker-1.log` is the last recordered file.\\n\\nFor watching logs in real time:\\n```bash\\ntail -f  <path>\\n```\\nWhere path should be replced with the log path. To look through the whole file simply open the log file in your favourite editor.\\n\\nIt can be useful to copy log files to your local machine:\\n\\n```bash\\nscp -rv <user>@<address>: <path-to-log-files> <path-in-your-local-machine>\\n```\"}},{\"node\":{\"id\":\"19a438bca3c860db2885746c3416e62a\",\"title\":\"Connect the simplest CPS\",\"path\":\"/docs/ru/connect-simple-cps/\",\"content\":\"\\nIn this section we will build the simplest real cyber-physical system!\\n\\nWe will buy a \\\"wink\\\" from Arduino, e.g. make Arduino blink with its onboard led. The lesson is tested on Arduino Uno, but any other board with a led will do the job.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_blink).\\n\\n## Arduino\\n\\nThe firmware for the board is located in [arduino_blink/misc/arduino/arduino.ino](https://github.com/airalab/robonomics_tutorials/blob/master/arduino_blink/misc/arduino/arduino.ino). Use [Arduino IDE](https://www.arduino.cc/en/Main/Software) to load the code to your Arduino board.\\n\\nIn the code we subscribe for the ``/blink_led`` topic and set a callback. The type of the topic is ``Empty``, so the board waits until someone publishes to the topic and performs the LED blinking.\\n\\n```\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle  nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void messageCb( const std_msgs::Empty& toggle_msg){\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> sub(\\\"blink_led\\\", &messageCb );\\n\\n  void setup()\\n  {\\n    pinMode(LED_BUILTIN, OUTPUT);\\n    nh.initNode();\\n    nh.subscribe(sub);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n\\n## AIRA client\\n\\n> You can download the latest release from [here](https://github.com/airalab/aira/releases).\\n\\nSet up the COM port forwarding. You should forward your `/dev/ttyUSB0` or `/dev/ttyACM0` port (depending on the system) to `COM1`. In the client `/dev/ttyS0` will represent the board. After this launch the virtual machine.\\n\\n## ROS\\n\\nWhen new liability is created it goes to `/liability/ready` topic. We have to remember the address and call `/liability/start` service to get the data from objective.\\n\\n```\\n  def newliability(l):\\n    self.liability = l.address\\n    rospy.loginfo(\\\"Got new liability {}\\\".format(self.liability))\\n\\n    prefix = \\\"/liability/eth_\\\" + self.liability\\n    rospy.Subscriber(prefix + '/blink', Empty, self.blink)\\n\\n    rospy.wait_for_service(\\\"/liability/start\\\")\\n    rospy.ServiceProxy('/liability/start', StartLiability)(StartLiabilityRequest(address=self.liability))\\n  rospy.Subscriber(\\\"/liability/ready\\\", Liability, newliability)\\n```\\n\\nA message in the `/blink` topic come from the objective field. Have a look at [Basic usage](/docs/aira-basic-usage) page.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh). All tutorials are pre-installed. To launch the ros package run the following command:\\n\\n```\\n$ rosrun arduino_blink blink.py\\n```\\n\\nAlso we need to add a rosbag file to IPFS::\\n\\n```\\n$ ipfs add rosbag/blink.bag\\n```\\n\\n> Before the next step you should approve XRT tokens on the Factory.\\n\\nOn your host system build and launch an Dapp for the lesson:\\n\\n```\\n$ git clone https://github.com/airalab/robonomics_tutorials/\\n$ cd robonomics_tutorials/arduino_blink_dapp\\n$ npm i && npm run dev\\n```\\n\\nOpen [http://localhost:8000/](http://localhost:8000/) and press \\\"Demand\\\" then \\\"Offer\\\" buttons. Wait until a new liability is created and you should see the board blinking. Congratulations on the first agent!\\n\"}},{\"node\":{\"id\":\"c7eddb3f26c1e15b7e1d2f8382b21c23\",\"title\":\"Подключение датчика к Робономике\",\"path\":\"/docs/ru/connect-sensor-to-robonomics/\",\"content\":\"\\n## Устройство датчика\\n\\nУниверсальная плата для датчика качества воздуха, основана на ESP8266 позволяет использовать следующие модули:  NODEMCU v3, NODEMCU v2, WEMOS D1 MINI. Устройство расчитано на питание 6 - 24 вольта, при  использовании DC-DC преобразователя DC MINI560.\\n\\n![plata](../images/sensors-connectivity/plata.png)\\n\\nДанная плата позволяет подключить датчики PM:\\n\\n- [SDS011](https://cdn-reichelt.de/documents/datenblatt/X200/SDS011-DATASHEET.pdf)\\n- PMS1003-6003\\n- [PMS7003/G7](http://www.plantower.com/en/content/?110.html)\\n- [SPS 30 PM Sensor](https://sensirion.com/products/catalog/SPS30/)\\n\\nВозможность подключения по интерфейсу I2C :\\n\\n- [BMP180](https://cdn-shop.adafruit.com/datasheets/BST-BMP180-DS000-09.pdf) - температура и влажность\\n- [BME/P280](https://www.mouser.com/datasheet/2/783/BST-BME280-DS002-1509607.pdf) - температура, влажность, атмосферное давление\\n- [HTU21D](https://eu.mouser.com/ProductDetail/Measurement-Specialties/HTU21D?qs=tx5doIiTu8oixw1WN5Uy8A%3D%3D) - температура и влажность\\n- SHT3x (I2C) - температура и влажность\\n- [CCS811 VOC SENSOR](https://www.sciosense.com/wp-content/uploads/documents/Application-Note-Baseline-Save-and-Restore-on-CCS811.pdf) - Летучие органические вещества, еквивалент СО2\\n- LCD1602/ 2004 / OLED SSD1306 /  SH1106 - поддерживаемые дисплеи\\n\\nВозможность подключения по интерфейсу 1 Wire :\\n\\n- DTH22(AM2302) - температура и влажность\\n- DS18B20 - температура.\\n\\nТакже существует модель MINI уменьшенного размера и с урезанным списком подключаемых устройств. Исходные схемы для обеих моделей можно найти по ссылкам для [полной модели](https://oshwlab.com/ludovich88/aira_sensor_rev0-1) и [модели MINI](https://oshwlab.com/ludovich88/aira_sensor_d1_mini).\\n\\n> Чтобы получить готовую плату, свяжитесь с разработчиками по адресу vm@multi-agent.io.\\n\\nПосле получения/сборки датчика остается только прошить и настроить его.\\n\\n## Прошивка\\n\\nНаша прошивка основана на прошивке от [Sensor.Community](https://github.com/opendata-stuttgart/sensors-software), в которую были добавлены несколько датчиков и изменена схема отправки данных. Исходный код можно найти [по ссылке](https://github.com/LoSk-p/sensors-software/tree/master/airrohr-firmware). \\n\\nЧтобы прошить датчик вы можете использовать `airrohr-flasher`. Скачайте исполняемый файл для вашей операционной системы из [последнего релиза](https://github.com/airalab/sensors-connectivity/releases).\\n\\n### Для Linux\\n\\nСначала вам нужно добавить пользователя в группу `dialout` (для Ubuntu) для получения доступа к USB порту:\\n\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\n\\nПосле этого перезагрузите компьютер. Далее поменяйте разрешения файла и запустите его:\\n\\n```bash\\nchmod +x airrohr-flasher-linux\\n./airrohr-flasher-linux\\n```\\n\\n### Для Windows:\\nРаспакуйте флешер и запустите его двойным кликом. Также вам нужно установить драйвера для USB2serial (Windows 10 должен начать загрузку автоматически):\\n\\n* Драйвера для NodeMCU v3 (CH340): [Windows](http://www.wch.cn/downloads/file/5.html) ([2018/09/04 v3.4 зеркало](https://d.inf.re/luftdaten/CH341SER.ZIP))\\n\\n### Для MacOS\\nСкачайте флешер и запустите его. Также вам нужно установить драйвера для USB2serial: \\n* Драйвера for NodeMCU v3 (CH340): [MacOS](http://www.wch.cn/downloads/file/178.html) ([2018/09/04 v1.4 зеркало](https://d.inf.re/luftdaten/CH341SER_MAC.ZIP))\\n\\n---\\n\\nВыберите прошивку (на английском или на русском) и нажмите `Upload`. Загрузка прошивки займет некоторое время.\\n\\n![flasher](../images/sensors-connectivity/7_flasher.jpg)\\n\\n## Настройка\\n\\nПосле загрузки прошивки перезагрузите ESP (просто отключите и подключите заново USB).\\n\\nЧерез некоторое время после перезагрузки ESP создаст Wi-Fi сеть с названием RobonomicsSensor-xxxxxxx. Подключитесь к ней с телефона или с компьютера, далее откроется окно авторизации (если оно не открылось в любом браузере перейдите по адресу 192.168.4.1). Выберете в списке вашу Wi-Fi сеть (или напишите сами, если ее нет в списке) и заполните поле с паролем. Также напишите координаты места, где будет установлен датчик, в поле ниже:\\n\\n![guest](../images/sensors-connectivity/guest_ru.jpg)\\n\\nНажмите `Сохранить и перезапустить`.\\n\\nПлата подключится к указанной Wi-Fi сети и через пару минут вы сможете увидеть данные на [карте](https://sensors.robonomics.network/#/):\\n\\n![map](../images/sensors-connectivity/14_map.jpg)\\n\\n## Дополнительная настройка\\n\\nДля более детальной настройки (она может понадобиться для подключения дополнительных датчиков или отправки данных на собственный сервер) вам нужно найти адрес датчика в вашей Wi-Fi сети. Для этого можно использовать `airrohr-flasher` (ваш компьютер должен находиться в той же сети, к которой подключен датчик). Запустите его и перейдите во вкладку `Discovery`, далее нажмите `Refresh`, подождите немного и появится адрес вашего датчика.\\n\\n![addr](../images/sensors-connectivity/11_flaser2.jpg)\\n\\nПерейдите по этому адресу двойным кликом (или введите его в браузере), вы попадете в меню датчика:\\n\\n![home](../images/sensors-connectivity/home_ru.png)\\n\\nВо вкладке `Конфигурация` можно настроить используемые датчики:\\n\\n![sensors](../images/sensors-connectivity/sensors_ru.png)\\n\\nА также настроить отправку на собственный сервер. Для этого во вкладке `APIs` нужно убрать отметку с `Robonomics` и отметить `Отправить в свой API` и указать адрес сервера и порт (65 для sensors connectivity):\\n\\n![apis](../images/sensors-connectivity/apis_ru.png)\\n\\nДля сохранения настроек нажмите `Сохранить и перезапустить`.\"}},{\"node\":{\"id\":\"014c142832f57f070a312aabee48621b\",\"title\":\"Подключить марсоход Curiosity под управлением парачейна Робономики\",\"path\":\"/docs/ru/connect-mars-curiosity-rover-under-robonomics-parachain-control/\",\"content\":\"\\n**Давайте посмотрим, как контроль Парачейна Робономики заставляет двигаться марсоход Curiosity. Требования:**\\n- ROS Melodic + Gazebo + RViz (руководство по установке [здесь](http://wiki.ros.org/melodic/Installation))\\n- дополнительные пакеты:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n- IPFS до [0.6.0](https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz)\\n- расширение [IPFS Companion](https://github.com/ipfs/ipfs-companion)\\n- узел Робономики (двоичный файл) (скачайте последнюю версию [здесь](https://github.com/airalab/robonomics/releases). Это руководство было успешно протестировано на v1.1)\\n\\nВ этом видео показан успешный запуск:\\n\\nhttps://www.youtube.com/watch?v=6BSOyRbmac8\\n\\n### 1. Настройте симуляцию\\nСкачайте пакет для марсохода Curiosity:\\n```shell\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src\\ngit clone https://bitbucket.org/theconstructcore/curiosity_mars_rover/src/master/\\ncd ..\\ncatkin build\\n```\\nНужно настроить начальные условия, чтобы наш марсоход успешно появился:\\n- Перейдите в\\n\\n`src/master/curiosity_mars_rover_description/worlds` и измените строку 14 файла `mars_curiosity.world` на \\n`<pose>0 0 8 0 0 0</pose>`\\n\\n- Перейдите в\\n\\n`src/master/curiosity_mars_rover_description/launch` и измените строку 4 файла `mars_curiosity_world.launch` на\\n`<arg name=\\\"paused\\\" default=\\\"false\\\"/>`\\n\\nНе забудьте добавить команду source в `~/.bashrc`\\n`source /home/$USER/robonomics_ws/devel/setup.bash`\\n\\n\\n- Перезагрузите консоль и запустите симуляцию:\\n\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\n![марсоход](../images/curiosity-demo/rover.jpg?raw=true \\\"Марсоход\\\")\\n\\nЗаметьте: если картинка темная, например, затененная, измените `Camera` на `Orthorgraphic` в панели инструментов Gazebo.\\nСимуляцию можно закрыть на некоторое время.\\n\\n------------\\n\\n### 2. Скачайте пакет контроллера Робономики\\nЧтобы загрузить пакет контролера для типа марсоход, введите в терминале:\\n```shell\\ncd ~/robonomics_ws/src\\ngit clone https://github.com/PaTara43/robonomics_sample_controller\\ncd robonomics_sample_controller\\npip3 install -r requirements.txt\\npip3 install rospkg\\ncd ..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3 # The controller supports python3\\n```\\n\\n------------\\n\\n### 3. Управление аккаунтами в децентрализованном приложении\\nТак как мы тестируем, давайте создадим локальную сеть Робономики с двоичным файлом Робономики:\\n```shell\\n./robonomics --dev --tmp\\n```\\n\\n![Запускаем узел](../images/curiosity-demo/robonomics.jpg?raw=true \\\"Запускаем узел\\\")\\n\\n\\nПерейдите на [портал парачейна Робономики](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) и переключитесь на локальный узел. \\n\\n![Локальный узел](../images/curiosity-demo/local_node.jpg?raw=true \\\"Локальный узел\\\")\\n\\n\\nПерейдите в Accounts и создайте аккаунты **CURIOSITY** и **EMPLOYER**.\\n\\n**Важно**! Скопируйте адрес каждого аккаунта (чтобы это сделать, кликните на иконку аккаунта) и **сид-фразу** аккаунта Curiosity (сгенерированную при создании аккаунта). Отправьте токены на эти аккаунты. Подробнее об аккаунтах Робономики можно прочесть [здесь](https://wiki.robonomics.network/docs/ru/create-account-in-dapp/)\\n\\n![Создание аккаунта](../images/curiosity-demo/account_creation.jpg?raw=true \\\"Создание аккаунта\\\")\\n\\n\\nДобавьте эти адреса, сид и адрес узла (по умолчанию `ws://127.0.0.1:9944` - узел разработчика) в `config.config` в `robonomics_ws/src/robonomics_sample_controller/src`. Без кавычек.\\n\\n------------\\n\\n\\n### 4. Запустите Робономику\\n\\nПеред тем как двигаться дальше, убедитесь, что Вы установили [расширение IPFS Companion](https://github.com/ipfs/ipfs-companion).\\n\\nВ отдельном терминале запустите IPFS:\\n```shell\\nifps init #you only need to do this once per IPFS installation\\nipfs daemon\\n```\\n\\nВ другом отдельном терминале запустите симуляцию Curiosity, если она еще не запущена:\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\nДождитесь выполнения операций.\\n\\nВ другом терминале запустите контроллера:\\n```shell\\nrosrun robonomics_sample_controller sample_controller.py\\n```\\n![Контроллер](../images/curiosity-demo/controller.jpg?raw=true \\\"Контроллер\\\")\\n\\n\\nТеперь Вы можете отправлять транзакции, запускающие движение и сборку данных марсоходом. Чтобы это сделать, Вы можете использовать все тот же [портал парачейна Робономики](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/).\\nПерейдите в `Developer->Extrinsics` и выберите аккаунт employer для Curiosity, экстринсик `launch`, аккаунт Curiosity как целевой аккаунт и `yes` как параметр.\\nОтправьте экстринсик.\\n\\n![Экстринсик](../images/curiosity-demo/extrinsic.jpg?raw=true \\\"Экстринсик\\\")\\n\\n\\nРобот должен начать двигаться. Он не будет принимать команды от других аккаунтов, а также команды с параметром `no`. Марсоход будет двигаться и собирать данные примерно около минуты.\\nЗатем, после выполнения работы:\\n\\n![Работа выполнена](../images/curiosity-demo/job_done.jpg?raw=true \\\"Работа выполнена\\\")\\n\\n\\nНа портале Робономики перейдите в `Developer -> Chain state` и получите журнал данных `CURIOSITY`, используя кнопку “+” с выбранным `datalog -> RingBufferItem` в качестве запроса: \\n\\n![Журнал данных](../images/curiosity-demo/datalog.jpg?raw=true \\\"Журнал данных\\\")\\n\\nТеперь хэш IPFS телеметрии сохранен в блокчейне. Чтобы посмотреть данные, просто скопируйте хэш и найдите его на шлюзе:\\n\\n![Данные в IPFS](../images/curiosity-demo/data_in_ipfs.jpg?raw=true \\\"Данные в IPFS\\\")\\n\\n\\nЭта телеметрия хранится в децентрализованном хранилище, а ее хэш хранится в блокчейне!\\n\"}},{\"node\":{\"id\":\"81ca73c72133bc227a37623af3a10b13\",\"title\":\"Connect any ROS-compatible robot under Robonomics parachain control. Part 2, IPFS\",\"path\":\"/docs/ru/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/\",\"content\":\"\\n**In this article we will continue using Robonomics tools to make a drone be controlled by a parachain. This time we will add sending data to IPFS and hash storing in chain options. Below is the instruction and code snippets. Requirements:**\\n- [**Part 1 of this tutorial**](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1)\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- IPFS 0.4.22 (download from [here](https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-386.tar.gz) and install)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n- Python dependencies:\\n```\\npip install cv_bridge ipfshttpclient\\n```\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=dliLb6GHgpo&feature=youtu.be\\n\\n\\n## 1. Add dependencies\\nIf we launch a simulation and look at the topic list (see previous tutorial), we will see, that there is one topic containing front camera data and using `sensor_msgs/Image` message type:\\n\\n![front_camera](../images/drone-demo/front_camera.jpg \\\"front_camera\\\")\\n\\nLet's try to take a picture every 1 second and after the flight publish these photos to IPFS. If you have completed the first tutorial, you don't need to download anything else. It's the `drone_sample_controller_pictures.py` script.\\n## 2. Manage accounts in DAPP\\nAs done in a previous tutorial, create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 3. Launch\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nIn another one launch ipfs daemon:\\n```\\nifps init # you only need to do this once\\nipfs daemon\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller_pictures.py\\n```\\nNow you can send a transaction triggering the drone to start flying and taking pictures. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying and taking pictures:\\n\\n![flying_picturing](../images/drone-demo/flying_picturing.jpg \\\"flying_picturing\\\")\\n\\nLater, when the job is done, on the Robonomics portal go to `Developer` -> `Chain state` and add a `DRONE` datalog using `“+”` button with selected `datalog` as state query. The IPFS hash of the telemetry has been saved in the blockchain. To see the data simply copy the hash and add it to the local [gateway](https://gateway.ipfs.io/ipfs/QmeYYwD4y4DgVVdAzhT7wW5vrvmbKPQj8wcV2pAzjbj886/docs/getting-started/) address `localhost:8080/ipfs/`:\\n\\n![Voila](../images/drone-demo/datalog.jpg \\\"Voila\\\")\\n\"}},{\"node\":{\"id\":\"ac1566c2461e18b5e7757bc8baae80e4\",\"title\":\"Connect ROS-compatibale Drone To Robonomics Parachain. Part 1. Launch by Transaction\",\"path\":\"/docs/ru/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/\",\"content\":\"\\n**In this article we will show that with the help of Robonomics tools you can control any ROS-compatible device. We will find a random drone simulation package on the web and adjust it to run with Robonomics.**\\n**Requirements:**\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=fDpwhBasQ5o&feature=youtu.be\\n\\n## 1. Find a simulation\\nLet's surf the web. Google for `ROS drone simulator`. The first link will mostly likely show you the `tum_simulator` page on [http://wiki.ros.org/tum_simulator](http://wiki.ros.org/tum_simulator)\\n\\n![tum_simulator](../images/drone-demo/tum_simulator.jpg \\\"tum_simulator\\\")\\n\\nIt's pretty outdated, so we better find a fork for our system. Google for `tum_simulator Ubuntu 18 Gazebo 9 fork`. The first result is a GitHub [repo](https://github.com/tahsinkose/sjtu-drone) with an appropriate package. Dowload it\\n```\\nmkdir -p drone_simulator_ws/src\\ncd drone_simulator_ws/src\\ngit clone https://github.com/tahsinkose/sjtu-drone\\ncd ..\\ncatkin build\\n```\\nDon’t forget to add source command to `~/.bashrc`:\\n```\\necho \\\"source /home/$USER/drone_simulator_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource \\\"~/.bashrc\\\"\\n```\\nNow we can run the simulation to see what do we need to do to take the drone under parachain control.\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\n\\n## 2. Inspect ROS topics\\nWhen the simulation is runnung, in a new tab run the following command to see the list of topics used by the drone:\\n```\\nrostopic list\\n```\\nLet's take a look at `/cmd_vel`, `/drone/takeoff` and `/drone/land`:\\n```\\nrostopic info /cmd_vel\\nrostopic info /drone/takeoff\\nrostopic info /drone/land\\n```\\n\\n![topics_info](../images/drone-demo/topics_info.jpg \\\"topics_info\\\")\\n\\nAs may be seen, there should be messages of `Twist` and `Empty` types, they are parts of `std_msgs` and `geometry_msgs`, we'll use this in the controller. Shut the simulation for a while.\\n## 3. Download controller package\\nGlobally, the main difference from the casual ROS robot controller is a block of code, which checks all the transactions in the network using [Robonomics IO](https://wiki.robonomics.network/docs/rio-overview/). The package itself is available on GitHub. Download it and build the workspace:\\n```\\ncd ~/drone_simulator_ws/src\\ngit clone https://github.com/PaTara43/drone_simulator_controller\\ncd drone_simulator_controller/src\\nchmod +x *.py\\ncd ~/drone_simulator_ws/src\\ncatkin build\\n```\\n## 4. Manage accounts in DAPP\\nSince we are testing, let's create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 5. Launching the drone under parachain control\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller.py\\n```\\n\\n![launched_drone](../images/drone-demo/launched_drone.jpg \\\"launched_drone\\\")\\n\\nNow you can send a transaction triggering the drone to start flying. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying:\\n\\n![flying](../images/drone-demo/flying.jpg \\\"flying\\\")\\n\\nThat's how any ROS-compatible robot can be controlled by Robonomics parachain control. Proceed to [part 2](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2) to learn more\\n\"}},{\"node\":{\"id\":\"bc82c01b7a4e599133a92df5625ef3ea\",\"title\":\"Configuration Options Description\",\"path\":\"/docs/ru/configuration-options-description/\",\"content\":\"\\nBasically, you can think of the package as a black box with one input (sensor data) and many outputs.\\nFor now only SDS011 sensor is supported, but if you are familiar with Python it'd be easy to add other sensors as well.\\n\\nHave a look at [configuration](https://github.com/airalab/sensors-connectivity/blob/master/config/default.json) file:\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"port\\\": \\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\": 300,\\n      \\\"geo\\\": \\\"\\\",\\n      \\\"public_key\\\": \\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\nAt the moment it's possible to publish data to [Luftdaten](https://luftdaten.info/), [Robonomics Network](https://robonomics.network/) and [Datalog](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer).\\nThe last one is experimental!\\n\\n> DO NOT edit `config/default.json` file. Instead make a copy\\n\\nPlay around with the configuration!\\n\\nExplanation of options:\\n\\n| Field                         | Description                                                                                                                                                                                                                                           |\\n|------------------------------    |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |\\n| `general/publish_interval`         | integer number from 1 and above. Tells how often send measurements. Keep in mind that if measurements from sensors come less often than this number connectivity sends last data      |\\n| `general/db_path`                  |   path to the database (.db) file    |\\n| `comstation/enable`                | true/false. Enabling/disabling the station      |\\n| `comstation/port`                  | valid path to com port, for example `/dev/ttyUSB0`. It is where a sensor is connected to      |\\n| `comstation/work_period`           | integer from 0 to 1800. For SDS011 sensor 0 means continuous work. Recommended period is 300 seconds     |\\n| `comstation/geo`                   | `lat,lon` a string with two floats separated by a comma. It represents latitude and longitude of a sensor     |\\n| `comstation/public_key`            | Ed25519 verifying key in hex format. If not provided connectivity generates a new one      |\\n| `httpstation/enable`                | true/false. Enabling/disabling the station   |\\n| `httpstation/port`                  | what port listen to      |\\n| `mqttstation/enable`                | true/false. Enabling/disabling the station   |\\n|`mqttstation/host`                   | the hostname or IP address of the remote broker |\\n|`mqttstation/port`                   | the network port of the server host to connect to |\\n| `luftdaten/enable`                 | true/false. Whether or not publish data to [Luftdaten](https://devices.sensor.community/). Don't forget to register the sensor's mac address on the site         |\\n| `robonomics/enable`                | true/false. Whether or not publish data to IPFS topic according to Robonomics communication protocol      |\\n| `robonomics/ipfs_proveder`         | an endpoint for IPFS daemon. By default it's `/ip4/127.0.0.1/tcp/5001/http` that means local daemon. The endpoint must by in multiaddr format. For example for [Infura.io](https://infura.io/) it would be `/dns/ipfs.infura.io/tcp/5001/https`       |\\n| `robonomics/ipfs_topic`            | IPFS topic's name. If you want to use [DApp](https://sensors.robonomics.network) provided by Robonomics team leave it untouched                 |\\n| `datalog/enable`                   | true/false. Enable/Disable saving log to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)    |\\n| `datalog/suri`                     | a private key from robonomics parachain account  |\\n| `datalog/dump_interval`            | specify a period of time for collecting log in seconds                                      |\\n| `datalog/temporal_username`        | set username to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `detalog/temporal_password`        | set password to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `datalog/pinata_api`                | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) api key                      |\\n| `datalog/pinata_secret`            | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) secret api key                |\\n| `dev/sentry`                       | for development purpose. If you have a [Sentry.io](https://sentry.io/) account you can put sentry's credentials in here   |\\n| `frontier/enable`                  | true/false. Whether or not publish telemetry to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)   |\\n| `frontier/suri`                    | a private key from robonomics parachain account                                                       |\\n| `trackagro/enable`                 | true/false. Enabling/disabling the station from [TrackAgro](https://tmeteo.docs.apiary.io/#)          |\\n| `trackagro/token`                  | authorization token for [TrackAgro](https://tmeteo.docs.apiary.io/#)                                  |\\n\\n## Scenario #1: Connect SDS011 to serial port\\n\\nThe easiest and the most straightforward way to connect your sensor to the network is using the serial port\\n\\nConnect you SDS011 sensor to a USB port, let's assume it got `/dev/ttyUSB0` address\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #2: Connect SDS011 via HTTP\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n> Do not forget to open the port in system firewall\\n>\\n> On NixOS you can do:\\n> ```\\n> networking.firewall.allowedTCPPorts = [ 31313 ];\\n> ```\\n\\n## Scenario #3: Connect SDS011 via MQTT\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #4: Connect Multiple Sensors and Publish to Datalog\\n\\n### Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": true\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n\\n\"}},{\"node\":{\"id\":\"6d4cdad1623c3fa47063e2a1f9eab850\",\"title\":\"Community\",\"path\":\"/docs/ru/community/\",\"content\":\"\\n**Here you can learn how to get involved in the Robonomics Network Community.**\\n\\nThere are many ways to contribute to Robonomics Network: you can contribute directly based on your skills and professional background, you can attend an event, join the conversation online or watch for our latest news and release.\\n\\n## For Developers\\n\\n- [Robonomics' code base and new releases on GitHub](https://github.com/airalab)\\n- [Ask your technical question on Riot](https://riot.im/app/#/room/#robonomics:matrix.org)\\n\\n## For Researchers & Academics\\n\\n- [Read Robonomics White Paper and our scientific articles](https://robonomics.network/community/#science)\\n\\nIf you have a background in mathematics, cryptography, or economics you might be interested for collaboration with us, write us to [research@aira.life](mailto:research@aira.life)\\n\\n## For All, even non-technical\\n\\n- [Get familiar with Robonomics services and statistics in dApp - open in browser with Metamask](https://dapp.robonomics.network)\\n- [Read our blog](https://blog.aira.life)\\n- [Stay tuned by following us on Twitter](https://twitter.com/AIRA_Robonomics)\\n\\nIf you are not a developer or a researcher, you can start with other suggestions for getting involeved in Robonomics Network Community. If you want to organize a meetup in your city, write content about Robonomics, translate Robonomics content into your native language, write to [community@aira.life](mailto:community@aira.life)\\n\"}},{\"node\":{\"id\":\"9ea2fa080ea89f80e354315680cbdea8\",\"title\":\"Offsetting Service\",\"path\":\"/docs/ru/carbon-footprint-service/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"}},{\"node\":{\"id\":\"77f26e177d3b984df110b9c9c8814f6b\",\"title\":\"Changing Exodus Bridge Receiving Address\",\"path\":\"/docs/ru/changing-exodus-receiving-address/\",\"content\":\"\\r\\nThis article will provide guidance on how you can change your Robonomics parachain receiving address in the event that you have input the wrong receiving address in the [Exodus bridge dapp](https://dapp.robonomics.network/#/exodus)\\r\\n\\r\\nPlease be aware that the process of changing the receiving address is not something that will be able to be carried out indefinitely, in fact the intervention of the development team is only possible during the early stages of the Robonomics parachain development, and eventually it will not be possible for the development team to conduct this kind of operation. **Please always ensure that you input the correct parachain address (i.e. one you have the seed phrase for) into the Exodus bridging application**.\\r\\n\\r\\n*Please be informed that the currently, if you input the wrong Robonomics parachain account address into the Exodus bridge dapp, then the process will be carried out as follows:*\\r\\n\\r\\n1. Complete the process as described in this article (i.e. signing the message & raising a GitHub issue).\\r\\n2. Bridged $XRT will be sent to the account originally input into the Exodus bridge dapp (i.e. the incorrect account).\\r\\n3. If no transactions are made on the incorrect account for 1 month, then the Robonomics team will transfer the $XRT tokens to the new address stipulated in the message (which you will sign as per the instructions below).\\r\\n\\r\\nOf course, the utmost priority for the Robonomics team is to ensure only valid changes of address are executed, as such you need to sign a message **from the Ethereum account which you originally deposited the $XRT tokens into the Exodus dapp**. We recommend that you utilize a site such as [MyCrypto](https://app.mycrypto.com/sign-message) to create this message (the following images will show how to conduct this process on MyCrypto).\\r\\n\\r\\nSelect the icon which corresponds to your web3 wallet, in our case we will choose MetaMask.\\r\\n\\r\\n![MyCrypto.com-Landing-Page](https://i.imgur.com/fyJyBG0.png)\\r\\n\\r\\nNow, click on the \\\"Connect to MetaMask\\\" button as shown above, and select the correct account (the account which you previously **sent $XRT tokens from**).\\r\\n\\r\\n![Page-after-selecing-metamask](https://i.imgur.com/1rd6izf.png)\\r\\n\\r\\nNow, we get the option to input a message, you shall follow the below template when inputting the message into this section, otherwise the process will not work. **These addresses relate to the Robonomics parachain addresses**.\\r\\n\\r\\n>Wrong target address: **WRONG_ADDRESS**. Right target address: **RIGHT_ADDRESS**\\r\\n\\r\\nSo, your message will look something like the message below (please make sure you input your own address, and not the one shown below). The message should all be on 1 line, don't use any line breaks (i.e. pressing enter). Afterwards, press the \\\"Sign Message\\\" button located under the message text.\\r\\n\\r\\n![example-of-how-the-message-should-look](https://i.imgur.com/jb1YqLs.png)\\r\\n\\r\\nNow you should get a notification on your web 3 wallet, click \\\"Sign\\\".\\r\\n\\r\\n![Example-metamask-notification](https://i.imgur.com/GTHEYTs.png)\\r\\n\\r\\nOnce signed, wait a few moments and then the MyCrypto page should change, and a signature shall appear.\\r\\n\\r\\n![signature-generated-from-signed-message](https://i.imgur.com/JemAEPm.png)\\r\\n\\r\\nNext, you need to head on over to the [Robonomics GitHub page](https://github.com/airalab/robonomics/issues/new), and open a new issue. The issue should have the title \\\"Robonomics exodus: a request to change the target address\\\", and the body / comment of the issue shall be the signature generated by MyCrypto. Afterwards, click \\\"Submit new issue\\\", and the Robonomics team will handle your issue and leave a reply to your issue regarding the status of your request.\\r\\n\\r\\n![example-of-GitHub-issue](https://i.imgur.com/6ZHSFRw.png)\"}},{\"node\":{\"id\":\"913a55baa4b53921c2dff12ff4a46a1c\",\"title\":\"Connect sensor\",\"path\":\"/docs/ru/carbon-footprint-sensor/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"}},{\"node\":{\"id\":\"ece893ddccda24f5c700ee5dc7cfca0d\",\"title\":\"Say \\\"Hello Baxter!\\\" with robonomics\",\"path\":\"/docs/ru/baxter2/\",\"content\":\"Example of how it works:\\n\\nhttps://youtu.be/2Dvuv0ZE2Bw\\n\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```sh\\nsudo apt-get install ros-melodic-qt-build ros-melodic-driver-common ros-melodic-gazebo-ros-control ros-melodic-gazebo-ros-pkgs ros-melodic-ros-control ros-melodic-control-toolbox ros-melodic-realtime-tools ros-melodic-ros-controllers ros-melodic-xacro python-wstool ros-melodic-tf-conversions ros-melodic-kdl-parser python-wstool python-catkin-tools qt4-default\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```sh\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node (binary file) (download latest [release][db4] here)\\n - Create __Baxter__ and __Employer__ accounts  on **Robonomics Portal**  \\n (you can find tutorial [\\\"Create an Account on Robonomics Portal\\\"][db8] here).\\n - IPFS browser extension (not necessary)\\n\\n## 0. install CV Bridge extension for python3\\n\\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n## 1. Download simulation and controller packages\\nWe will need to create 2 workspaces - one for main Baxter's packages and other for main control programme.\\nFirst workspace. It's main control programme. It will run under python3.\\n\\n```sh\\ncd ~\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src/\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\npip3 install -r requirements.txt\\n```\\nSecond workspace. There will be all Baxter's packages. Simulation is very old, so it could run only under python2.\\n```shell\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src/\\nwstool init .\\nwstool merge https://raw.githubusercontent.com/RethinkRobotics/baxter_simulator/master/baxter_simulator.rosinstall\\nwstool update\\n```\\nThese packages were created for ROS indigo. We have to change some files to run them on ROS melodic.\\nWe will use **patch** files.\\n```sh\\npatch ./baxter_simulator/baxter_sim_io/include/baxter_sim_io/qnode.hpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/qnode_patch\\npatch ./baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/arm_patch\\npatch ./baxter_interface/src/baxter_interface/robot_enable.py ~/robonomics_ws/src/Baxter_simulation_controller/patch/interface_patch\\n```\\nAnd let's build  all our packages:  \\nFirst build Baxter's packages\\n```sh\\ncd ../\\ncatkin build\\n```\\nThen return to first workspace and build it too:\\n```sh\\ncd ~/Baxter_simulation_controller/\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\necho \\\"source /home/$USER/robonomics_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```  \\n\\n\\n## 2. Start simulation\\n### Let's start our simulation:\\nAt first go to `robot_ws` and copy and edit baxter.sh\\n```sh\\ncd ~/robot_ws/\\ncp src/baxter/baxter.sh .\\n```\\nFind your local ip address with command:\\n```\\nip a\\n```\\n![ip_a][im14]\\n\\nEdit the following values in `baxter.sh` :\\n```\\nnano baxter.sh\\n```\\n\\n- your_ip - put your local ip address. See `ip a`\\n- ros_version - for example \\\"melodic\\\"\\n\\n![baxtersh][im15]\\n\\nRun the baxter shell script with sim specified:\\n```sh\\n./baxter.sh sim\\nroslaunch baxter_gazebo baxter_world.launch\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp\\n```\\n![robonomics][im3]\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts.\\n\\nYou can find The manual \\\"Create an Account on Robonomics Portal\\\" [here][db8]\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\n\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n![create account2][im16]\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robonomics_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same portal [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nWhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL:  \\n#### gateway.ipfs.io/ipfs/< put your hash here>\\n\\n\\n\\nThat's all!\\n\\n![result1][im12]\\n![result2][im13]\\n\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/ip_a.png>\\n[im15]: <../images/baxter_demo/baxter_sh.jpg>\\n[im16]: <../images/baxter_demo/create_account2.jpg>\\n[db8]: <https://wiki.robonomics.network/docs/create-account-in-dapp/>\"}},{\"node\":{\"id\":\"c5634d454f6ec5c4fa912b9964465993\",\"title\":\"Control Baxter robot with robonomics\",\"path\":\"/docs/ru/baxter/\",\"content\":\"\\nExample of how it works:\\n\\nhttps://www.youtube.com/watch?v=JivTDhDJLHo\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-melodic-cv-bridge\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```shell\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node download latest [release][db4] here (last tested release v1.1)\\n - IPFS browser extension (not necessary)\\n## 0. install CV Bridge extension for python3\\n \\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\n\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n\\n## 1. Download simulation and controller packages\\nDownload packages:\\n```sh\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\ngit checkout old_version\\npip3 install -r requirements.txt\\ncd ../..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n## 2. Start simulation\\nLet's start gazebo world and put our baxter in it:\\n```sh\\nroslaunch gazebo_ros empty_world.launch\\n```\\n![empty world][im1]\\n\\nOpen one more window in terminal:\\n```sh\\nrosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp --rpc-cors all\\n```\\n![robonomics][im3]\\n\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts (__Robot__ is not necessary)\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n\\n![create account2][im14]\\n\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robot_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nwhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL: gateway.ipfs.io/ipfs/< put your hash here >\\n\\n![ipfs][im11]\\n\\nClick  __View on Gateway__ and that's all!\\n\\n![result1][im12]\\n\\n![result2][im13]\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/create_account2.jpg>\"}},{\"node\":{\"id\":\"d64cd8cbb9e44e58aa922d71f030e665\",\"title\":\"AIRA Overview\",\"path\":\"/docs/ru/aira-overview/\",\"content\":\"\\n## Introduction\\n\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It implements the standard of economic interaction between human-robot and robot-robot. AIRA makes it possible to connect a variety of different robots under decentralized computer's control (currently supported Ethereum and Polkadot/Substrate).\\n\\nBasically it is the client for Robonomics Network developed by [Airalab](https://aira.life).\\n\\nAIRA is NixOS based operating system and officially supports the following architectures: x86, Raspberry Pi 3 B+ and Raspberry Pi 4.\\n\\nThe most simple way to get familiar with AIRA is to try installing AIRA as a [virtual machine](/docs/aira-installation-on-vb/).\\n\\nAIRA comes with a few preinstalled and configured services to help you focus on [agent](/docs/glossary#agent) development.\\n\\nMeanwhile it's highly customizable, but it's recommended to understand [NixOS](http://nixos.org/) and [Nix](https://nixos.org/nix/) language.\\n\\n## What's included? \\n\\nThe following services are included in the default distribution:\\n\\n* [Robonomics communication stack](https://github.com/airalab/robonomics_comm)\\n* [IPFS](https://ipfs.io/)\\n* OpenSSH\\n* [cjdns](https://github.com/cjdelisle/cjdns)\\n* [Yggdrasil-go](https://yggdrasil-network.github.io/)\\n\\nBesides at the first launch AIRA [generates](/docs/aira-installation-on-vb#launch-the-machine) for you new Ethereum address and IPNS identifier.\\n\\nIt's possible to use AIRA as a virtual machine or install as a main operating system. Also you can install only the services you need.\\n\"}},{\"node\":{\"id\":\"a7a334d4b1ab885e04e4ece8f98d6551\",\"title\":\"AIRA Installation\",\"path\":\"/docs/ru/aira-installation/\",\"content\":\"\\n- [**How to launch AIRA on VirtualBox**](/docs/aira-installation-on-vb/)\\n\\n- **The installation on Raspberry Pi** is as simple as writing an image of AIRA on SD card using `dd` or [Etcher](https://www.balena.io/etcher/), for example.\\n\\n\\n\"}},{\"node\":{\"id\":\"48123c82d1cf67b9dbe18bb8ec9cfd4a\",\"title\":\"AIRA Installation on VirtualBox\",\"path\":\"/docs/ru/aira-installation-on-vb/\",\"content\":\"\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It is the client for Robonomics Network developed by [Airalab](https://aira.life). It is an operating system based on [NixOS](https://nixos.org/). With AIRA you can  turn any cyber-physical system in an economic agent, where robots operate as a services for the reasonable payments. [More theory about AIRA here](/docs/aira-overview).\\n\\nIt's possible to install AIRA on a x86_64 PC. Also there are images for Raspberry Pi 3 and 4 supported by the team.\\n\\nThe best way to try AIRA is to start from installing it as a virtual machine on [VirtualBox](https://www.virtualbox.org/).\\n\\n## Requirements\\n\\n* VirtualBox\\n* [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2Gb of RAM for the machine\\n* 40Gb of free disk space\\n\\n## Obtain the image\\n\\nAIRA has [stable](https://aira.life/channels/aira-stable/) and [unstable](https://aira.life/channels/aira-unstable/) channels.\\n\\nTo get stable image download the file with `.ova` extension.\\n\\tThe link for stable image is [here](https://releases.aira.life/channels/aira/stable/862-aira-stable/nixos-20.03pre-git-x86_64-linux.ova)\\n\\nDon't forget to compare checksum of the downloaded image with the last column `SHA-256 hash` on the [download page](https://aira.life/channels/aira-stable/). It must be equal to the output of the following command (it is an example, please check the name of downloaded by you .ova file first):\\n\\n```\\nsha256sum nixos-20.03pre-git-x86_64-linux.ova\\n```\\n\\nYou may wish to check out the walkthrough video:\\n\\nhttps://www.youtube.com/embed/cDcaypYPBhI\\n\\n## Troubleshooting\\n\\nIf you have fresh installed VirtualBox, you need to install the [extension](https://www.virtualbox.org/wiki/Downloads) pack or disable USB 2.0 controller.\\n\\nAlso VirtualBox may show a warning about `Display settings`. Consider switching `Graphics Controller` in settings of the VM to `VMSVGA`.\\n\\n## Import to VirtualBox\\n\\nOpen VirtualBox and press `Ctrl+I` or go to `File > Import Applicance...`\\n\\n![AIRA import VB image](../images/aira-installation/aira_import_vb_image.jpg \\\"AIRA import VB image\\\")\\n\\nAt this moment the next step is not necessary but it will help you to connect to the VM via SSH easily.\\n\\nFirst add `Host-Only` adapter in VirtualBox menu `File > Host Network Manager...` or by pressing `Ctrl+H`\\n\\n![Host Only](../images/aira-installation/host_only_adapter.jpg \\\"Host Only\\\")\\n\\nThen go to the image's settings, Network and add the second network adapter\\n\\n![Second adapter](../images/aira-installation/add_second_adapter.jpg \\\"Second adapter\\\")\\n\\nFor more details look at the standalone [lesson](/docs/aira-connecting-via-ssh/).\\n\\nOptionally you can increase the amount of video memory and switch `Graphics Controller` to `VMSVGA`.\\n\\n## Launch the machine\\n\\nFinally press Start and you'll see AIRA welcoming you with generated Ethereum address and IPFS identifier\\n\\n![AIRA image ready, Welcome screen](../images/aira-installation/aira_image_ready.jpg \\\"AIRA image ready, Welcome screen\\\")\\n\\nAt the very first initialization AIRA generates new Ethereum address and IPNS identifier for you.\\n\\n\"}},{\"node\":{\"id\":\"a011775572e4ad0d172cc88867e316d1\",\"title\":\"Frequently Asked Questions about AIRA\",\"path\":\"/docs/ru/aira-faq/\",\"content\":\"\\n## How to see logs from main services?\\n\\nIPFS in real time:\\n\\n    journalctl -u ipfs -f\\n\\nand Liability::\\n\\n    journalctl -u liability -f\\n\\n## How to check the quantity of IPFS peers?\\n\\n    ipfs pubsub peers \\n\\n## IPFS can't connect to the daemon, what should I do?\\n\\nTry to specify `--api` option\\n\\n    ipfs swarm peers --api=/ip4/127.0.0.1/tcp/5001/\\n\\n## How to change ethereum address of AIRA?\\n\\nDelete `keyfile` and `keyfile-psk` in `/var/lib/liability` and restart the service\\n\\n```\\nsystemctl restart liability\\n```\\n\\n## IPFS daemon doesn't start\\n\\nThe error mostly occurs on single-board computers like Raspberry Pi or LattePanda after unexpected electricity lost.\\n\\nUsually the file `/var/lib/ipfs/api` is corrupted and one may see error:\\n\\n```\\nError: Failed to parse '/var/lib/ipfs/api' file.\\n  error: failed to parse multiaddr \\\"\\\": empty multiaddr\\nIf you're sure go-ipfs isn't running, you can just delete it.\\nOtherwise check:\\n  ps aux | grep ipfs\\n```\\n\\nYou can delete `/var/lib/ipfs/api` file and restart the service\\n\\n\"}},{\"node\":{\"id\":\"f3df71a7591e32ac83efeda8cede6018\",\"title\":\"Connecting AIRA via SSH\",\"path\":\"/docs/ru/aira-connecting-via-ssh/\",\"content\":\"\\nIt is more convenient to work with virtual machine via ssh connection. In this section we will configure VM.\\n\\n> **It's required to have your ssh public key on Github. In case you don't have one, please follow the [link](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\nBelow is the walkthrough video:\\n\\nhttps://www.youtube.com/embed/R6waDG5iwm0\\n\\n## Add Host Adapter\\n\\nGo to `File` -> `Host Network Manager...` or press `Ctrl+H`\\n\\n![VirtualBox Network Manager](../images/virtualbox_network_manager.png \\\"VirtualBox Network Manager\\\")\\n\\nClick `Create` button.\\n\\n## Add the Second Adapter to the VM\\n\\nSelect imported VM and click `Settings`. Go to `Network` tab and enable the second adapter\\n\\n![Add Second Adapter](../images/add_second_adapter_to_vm.png \\\"Add Second Adapter\\\")\\n\\n## Populate Authorized Keys\\n\\nLaunch the VM and run the following command replacing `<username>` with your Github user name:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nFind out the VM's IP address by running:\\n\\n```\\nip a\\n```\\n\\nYou should look for an address which starts with `192.168.xx.xx`\\n\\n## Log in via SSH\\n\\nNow open your terminal and log in via SSH as usual using the address from the previous step:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n\"}},{\"node\":{\"id\":\"87681d6e7594efcbde5260488adbae2f\",\"title\":\"Basic usage of AIRA\",\"path\":\"/docs/ru/aira-basic-usage/\",\"content\":\"\\nTo get familiar with AIRA, let's see what is under the hood.\\n\\nOnce you launch the client several ros nodes will already be on the run. Here's a list of robonomics communication stack nodes:\\n\\n```bash\\n$ rosnode list\\n/eth/erc20_token\\n/eth/eth_node\\n/graph/aira_graph\\n/liability/executor\\n/liability/infochan/eth/signer\\n/liability/infochan/ipfs_channel\\n/liability/persistence\\n/liability/listener\\n/rosout\\n```\\n\\n- `/eth/erc20_token`, `/eth/eth_node` - proved services for Ethereum blockchain and ERC20 tokens\\n- `/graph/aira_graph` - service node for exploring other AIRA instances\\n- `/liability/executor` - gets rosbag file from IPFS and plays it\\n- `/liability/infochan/ipfs_channel` - is responsible for offer, demand and result messages. It catches messages from the channel and sends signed messages back\\n- `/liability/infochan/eth/signer` - offers services for signing offer, demand and result messages\\n- `/liability/listener` - watches for a new liability contracts. When the event is received the node calls executor node\\n- `/liability/persistence` - helps to store incoming liabilities and restart them after shutdown\\n\\nAnd here's a list of robonomics stack topics.\\n\\n```bash\\n$ rostopic list\\n/eth/event/approval\\n/eth/event/transfer\\n/graph/greetings\\n/liability/complete\\n/liability/finalized\\n/liability/incoming\\n/liability/infochan/eth/sending/demand\\n/liability/infochan/eth/sending/offer\\n/liability/infochan/eth/sending/result\\n/liability/infochan/eth/signing/demand\\n/liability/infochan/eth/signing/offer\\n/liability/infochan/eth/signing/result\\n/liability/infochan/incoming/demand\\n/liability/infochan/incoming/offer\\n/liability/infochan/incoming/result\\n/liability/persistence/add\\n/liability/persistence/del\\n/liability/persistence/update_timestamp\\n/liability/ready\\n/liability/result\\n/rosout\\n/rosout_agg\\n```\\n\\nThe most important topics for us are:\\n\\n- `/liability/incoming` - when a new liability is created, this topic publishes Ethereum address of the contract\\n- `/liability/result` - this topic is for publishing results. But don't publish a result directly to this topic! Use a service instead\\n- `/liability/infochan/incoming/*` - a CPS gets information about offer, demand or result from corresponding topics\\n- `/liability/infochan/eth/signing/*` - a CPS sends offer, demand or result messages to corresponding topics\\n\\nFor the details check out the [API page](/docs/robonomics-liability/).\\n\\nLet's start with greetings - say hello to AIRA!\\n\\nYou should just launch a pre-installed package `hello_aira`:\\n\\n```\\n$ rosrun hello_aira hello_aira\\n```\\n\\nWe've launched our agent. It will wait for a demand message. Now it's time to send the message. Go to [dapp](https://airalab.github.io/robonomics_tutorials/) and press Order.\\nNow go back to the console and see the result!\"}},{\"node\":{\"id\":\"2d8bee2dbc4ede05215fc143c5113647\",\"title\":\"Agent development examples\",\"path\":\"/docs/ru/agent-development-examples/\",\"content\":\"\\nUseful pieces of code and a few scenarios. All source code is [here](https://github.com/vourhey/robonomics_tutorials).\\n\\n1. [Broadcast Demand](https://github.com/Vourhey/robonomics_tutorials/tree/master/01_broadcast_demand/)\\n2. [Broadcast Offer](https://github.com/Vourhey/robonomics_tutorials/tree/master/02_broadcast_offer/)\\n3. [Trader](https://github.com/Vourhey/robonomics_tutorials/tree/master/03_trader/)\\n4. [Trader with ACL](https://github.com/Vourhey/robonomics_tutorials/tree/master/04_trader_with_acl/)\\n5. [Open Sensor Data](https://github.com/Vourhey/robonomics_tutorials/tree/master/05_open_sensor_data/)\\n\\n\"}},{\"node\":{\"id\":\"5eca9535a454756ce2d16c88276e64d2\",\"title\":\"Add Device to Robonomics\",\"path\":\"/docs/ru/add-smart-device-to-robonomics/\",\"content\":\"For each device you need separate [Robonomics accounts](/docs/create-account-in-dapp/). After you've added your devices, you need to add them in a `config.config` file with their seeds. Firstly in `Configuration/Entities` tab in your Home Assistant find entity ids of your devices:\\n\\n![entity_id](../images/home-assistant/entity_id.png)\\n\\nOpen the configuration file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add there information of your devices in the following format:\\n\\n```\\n[device_name]\\nIDS = ['entity_id1', 'entity_id2']\\nSEED = word word word\\n```\\nWhere `device_name` is the name of your device (you can choose any name), `IDS` are entity ids of the data from the device (it may be one or more ids) and `SEED` is a mnemonic or raw seed from robonomics account to this device.\\n\\nAfter you fill the configuration file you need to get access token from Home Assistant. For that open your `profile` in the lower left corner:\\n\\n![profile](../images/home-assistant/profile.png)\\n\\nIn the end of the page find `Long-Lived Access Tokens` and press `create token`. Save it somewhere, you will not be able to see it again.\\n\\n![token](../images/home-assistant/token.png)\\n\\nNow run `create_config.py` script with your token:\\n\\n```bash\\ncd /srv/homeassistant\\nsource bin/activate\\npython3 python_scripts/create_config.py --token <access_token>\\n```\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\\n\\nYou can add the data from sensors to your homepage like in `Home Assistant setup` in the description to [Method 1](/docs/zigbee2-mqtt/).\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. Data looks like this:\\n\\n![datalog_data](../images/home-assistant/datalog_data.png)\\n\\nYou can decrypt it with script `decrypt.py`, run it with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"415375a94064d873e0012117697d89dd\",\"title\":\"Connect Sensors with Zigbee2MQTT\",\"path\":\"/docs/ko/zigbee2-mqtt/\",\"content\":\"\\n## Mosquitto MQTT broker\\n\\nFor this method, you neet to install MQTT broker to the Raspberry Pi:\\n\\n```bash\\nsudo apt update\\nsudo apt install mosquitto mosquitto-clients\\n```\\nThe Mosquitto program will run automatically after installation.\\n\\n## Zigbee2MQTT setup\\n\\nIf you have the JetHome USB JetStick Z2 it will already have the necessary firmware so you don't need to flash it. However, if you have another adapter the first thing you need to flash it with zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nThen we need to install the ziqbee2mqtt software on the  Raspberry PI. Connect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\nInstall zigbee2MQTT:\\n```bash\\n# Setup Node.js repository\\nsudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\\n\\n# NOTE 1: If you see the message below please follow: https://gist.github.com/Koenkk/11fe6d4845f5275a2a8791d04ea223cb.\\n# ## You appear to be running on ARMv6 hardware. Unfortunately this is not currently supported by the NodeSource Linux distributions. Please use the 'linux-armv6l' binary tarballs available directly from nodejs.org for Node.js 4 and later.\\n# IMPORTANT: In this case instead of the apt-get install mentioned below; do: sudo apt-get install -y git make g++ gcc\\n\\n# NOTE 2: On x86, Node.js 10 may not work. It's recommended to install an unofficial Node.js 14 build which can be found here: https://unofficial-builds.nodejs.org/download/release/ (e.g. v14.16.0)\\n\\n# Install Node.js;\\nsudo apt-get install -y nodejs git make g++ gcc\\n\\n# Verify that the correct nodejs and npm (automatically installed with nodejs)\\n# version has been installed\\nnode --version  # Should output v10.X, v12.X, v14.X or v15.X\\nnpm --version  # Should output 6.X or 7.X\\n\\n# Clone Zigbee2MQTT repository\\nsudo git clone https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\nsudo chown -R ubuntu:ubuntu /opt/zigbee2mqtt\\n\\n# Install dependencies (as user \\\"ubuntu\\\")\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\nThen you need to configure it. Open configuration file:\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\nAnd paste this:\\n```\\npermit_join: true\\nmqtt:\\n  # MQTT base topic for Zigbee2MQTT MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n```\\nNow you can run zigbee2mqtt:\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n## Pairing device\\n\\nThen you need to pair your sensor. For that just long press the power button until it starts to blink (zigbee2MQTT must be launched). After sensor connects you will see the message like:\\n```\\nZigbee2MQTT:info  2019-11-09T12:19:56: Successfully interviewed '0x00158d0001dc126a', device has successfully been paired\\n```\\n> Remember this number `0x00158d0001dc126a` it will be the topic name for your sensor's data.\\nThen open configuration file again and set `permit_join: false`.\\n\\nThen lets make a service. Create the file:\\n```bash\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\nAdd the following to this file:\\n```\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\n# Or use StandardOutput=null if you don't want Zigbee2MQTT messages filling syslog, for more options see systemd.exec(5)\\nStandardError=inherit\\nRestart=always\\nUser=pi\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nVerify that the configuration works:\\n\\n```bash\\nsudo systemctl start zigbee2mqtt\\n```\\n\\n```bash\\nsystemctl status zigbee2mqtt.service\\n```\\n\\nOutput should look like:\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\nNow that everything works, we want systemctl to start Zigbee2MQTT automatically on boot, this can be done by executing:\\n\\n```bash\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n## Home Assistant Setup\\n\\nOpen Home Assistant configuration file:\\n\\n```bash\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add the following to setup MQTT broker and sensor (replace `topic_name` with the topic name from previous step):\\n\\n```\\n# MQTT broker setup\\nmqtt:\\n  broker: localhost\\n  port: 1883\\n\\n# Sensor setup\\nsensor:\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Humidity\\\"\\n    unit_of_measurement: '%'\\n    value_template: \\\"{{ value_json.humidity }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Temperature\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.temperature }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Pressure\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.pressure }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Battery\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.battery }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Link Quality\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.linkquality }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Voltage\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.voltage }}\\\"\\n\\n# Trigger on receiving data\\nautomation:\\n  - alias: \\\"send_datalog_climate\\\"\\n    trigger:\\n      platform: mqtt\\n      topic: \\\"zigbee2mqtt/0x00158d0006bcd022\\\"\\n    action:\\n      service: shell_command.send_datalog_climate\\n\\n# Shell command that will run on the trigger\\nshell_command:\\n  send_datalog_climate: 'python3 python_scripts/send_datalog.py temperature={{ states(\\\"sensor.mqtt_climate_temperature\\\")  }} humidity={{ states(\\\"sensor.mqtt_climate_humidity\\\") }} pressure={{ states(\\\"sensor.mqtt_pressure\\\") }} battery={{ states(\\\"sensor.mqtt_climate_battery\\\") }} linkquality={{ states(\\\"sensor.mqtt_climate_link_quality\\\") }} voltage={{ states(\\\"sensor.mqtt_climate_voltage\\\") }}'\\n```\\n\\nThen start Home Assistant with new configuration:\\n\\n```bash\\ncd /srv/homeassistant\\nhass\\n```\\n\\nTo see the sensor data in Home Assistant you need to add it. For that open the browser on your computer and go to:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nPress on three dots on the right side and choose `Edit Dashboard`\\n\\n![edit_dashboard](../images/home-assistant/dashboard.png)\\n\\nThen press `Add Card`\\n\\n![card](../images/home-assistant/card.png)\\n\\nGo to `By Entity` and tick all sensors that you need\\n\\n![sensors](../images/home-assistant/sensors.png)\\n\\nPress continue and you will be able to see sensor data at the homepage (you may see `unknown` before sensor send new data)\\n\\nIn a similar way you can add card for Robonomics Service. With this you can start or stop the servise or send current measurements with `run action` button.\\n\\n![action](../images/home-assistant/datalog.png)\\n\\nYou homepage will look like this\\n\\n![home](../images/home-assistant/home.png)\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. You can decrypt the data with script [decrypt.py](https://github.com/airalab/robonomics-smarthome/blob/main/python_scripts/decrypt.py), download it:\\n\\n```bash\\ncd /srv/homeassistant/python_scripts\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\n```\\nAnd run with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"c075c39b7690ad510408082ab08c342f\",\"title\":\"Connect Sensors with Xiaomi Gateway\",\"path\":\"/docs/ko/xiaomi-gateway/\",\"content\":\"\\nYou need your Xiaomi gateway along with all the sensors to be connected to the Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your hub (it must be in connecting mode which is achieved via a long press of the power button) and follow instructions in the app. After you add the gateway, you need to add sensors: press on your gateway, then go to `Child device` and press `+`. Find required device and follow the instructions on the screen. For more details refer to the user manual of your Xiaomi Gateway hub.\\n\\n## Add Gateway to Home Assistant\\nBe sure that you're logged in you raspberry as `homeassistant` user, if not do the following:\\n```bash\\nsudo -u homeassistant -H -s\\n```\\n\\nIn your Home Assistant:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations` and press `Add Intagration`. There you need to Find `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Hub (Aqara Hub in this example):\\n\\n![hub](../images/home-assistant/hub.png)\\n\\nPress `Submit` and you will be able to see your gateway in Integrations page.\\n\\n## Add Gateway to Home Assistant using Homekit Controller integration\\n\\nYou can also connect your hub to Aqara Home app on ios and then add it to Home Assistant through Homekit Controller integration. \\n\\nAdd your hub to the app using `add device` or `+` button. Right after your hub added to Aqara Home app you will be proposed to bind it with your Homekit account. \\n\\n![homekit](../images/home-assistant/homekit.png)\\n\\nWhen you see a menu like the picture, open your Home Assistant page:\\n\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations`. Here you can find your device discovered and click `Configure` button to add it by Homekit Controller integration. You have to enter pairing code of your device, which you can find on the sticker on your device.\\n\\n![configure1](../images/home-assistant/configure1.png)\\n\\n![configure2](../images/home-assistant/configure2.png)\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"4b26165780893a8d1c9015e9788ffcbc\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ko/xcm-robobank/\",\"content\":\"\\n\\nMain goal of this project is simplification of parachain runtime development, when cross-chain messages are used. \\nAllows to develop runtime code with integration tests with high repeatablility and simple usage.\\nAutomates building, construction of pre-set network configuration (f.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and running tests, sending messages, using call to runtime, constructed and composed in Python.\\n\\nXCM Testsuite is used for testing production cycle for Robobank - the set of Substrate pallets, allowing robots to register in external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside Robonomics network with all needed infrastructure, but, in the same time, offer their services in any external parachain.\\n\\nVideo example is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe demo scenary main steps are:\\n- launch relay chain and two parachains in pack of 6 processes\\n- setup XCM messages channels between parachains\\n- register a robot in both parachains\\n- create order for this robot in client parachain (reserving payment for completion of order)\\n- send XCM message to Robonomica\\n- creating \\\"mirrored\\\" order record in Robonomica parachain\\n- accept order by robot in Robonomica\\n- send XCM message about order acceptance back to client parachain\\n- accept order in client parachain (reserving penalty fee for no-completion of order until deadline)\\n- complete order by robot in Robonomica\\n- send XCM message about order completion to client parachain\\n- settle all payments (client payment is transfered to robot, as well as penalty fee)\\n- close order\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nContains code of runtime pallets being tested.\\nAs in original node code of parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] First build can take a lot of time, up to several hours on weak machines\\n\\n[NOTE] Script works with FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains\\n\\n[NOTE] By default script re-creates same environment every launch, by removing all previous states. this behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for relay chain and for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (f.e. 4 validators of some stable Rococo revision)\\n    - collators for parachain-100 (f.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (f.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing to study any chain using frontend apps (explorer, DApp)\\n - keep printing all output of all chains to console\\n\\n[WARNING] After launch, wait until a network is up, make sure that blocks finalization started, and parachains are registered. These processes require approximately 5 min (50 blocks x 6 sec ).\\n\\n## Checking if all works \\n\\nUse standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, consensus started off, we can proceed to run test cases (in a new terminal)\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to relay.\\nWhen relay receives message it will transfer 15 tokens from `para 100` account to the Charlie's.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to `sibling 200` one.\\nBefore that, it endows `subl 100` account with 1000 tokens and  establish a channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace balances and authorities with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit code. The above command will rebuild project and update collator node before start.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent version of software. For this change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\"}},{\"node\":{\"id\":\"6a3b787735c38c5e863ab1fd4cb8b1f7\",\"title\":\"과, 실제 ROBONOMICS  파라체인\",\"path\":\"/docs/ko/wschool2021-robonomics-parachain-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\nRobonomics 파라체인은 Polkadot 생태계에서 범용 파라 체인이 아닙니다. Robonomics의 목표는 기계 경제를 구축하는 것이며,이 목표 범위의 파라체인은 Polkadot 생태계를 IoT, 스마트 시티 및 Industry 4.0 개념과 통합하는 데 도움이됩니다.\\n\\n## 요구 사항\\n\\n* Docker가 필요합니다. [먼저 설치하십시오](https://docs.docker.com/engine/install/).\\n* Polkadot-launch가 필요합니다. [설치하십시오](https://github.com/paritytech/polkadot-launch#install).\\n\\n## 릴레이 시작\\n\\n공유 보안    릴레이 체인은 Polkadot의 핵심이며 모든 하위 파라체인에 [공유 보](https://wiki.polkadot.network/docs/en/learn-security)을 제공하고 메시지 전달 메커니즘을 구현합니다. 두 개의 Robonomics 기반 파라체인이있는 Rococo (polkadot test net) 릴레이 체인의 로컬 인스턴스를 자식으로 시작해 보겠습니다. 준비된 [Docker 이미지 태그인 \\\"winter-school-2\\\"](https://hub.docker.com/layers/robonomics/robonomics/winter-school-2/images/sha256-92f4795262f3ded3e6a153999d2777c4009106a7d37fd29969ebf1c3a262dc85?context=explore)를 사용하지만 [Robonomics GitHub](https://github.com/airalab/robonomics/tree/master/scripts/polkadot-launch)에서 사용할 수있는 모든 예제 소스 코드를 사용합니다. \\n\\n<Asciinema vid=\\\"419Jrg22ziFfMFPZlh2WtiLvg\\\"/>\\n\\n시간이 걸릴 수 있지만 기다려주십시오. 결과적으로 포트에 세 개의 체인 인스턴스가 있어야합니다:\\n\\n* `9944` - 로컬 로코코 릴레이 체인.\\n* `9988` - `id=100` 인 robonomics 파라체인\\n* `9989` - `id=200` 인 robonomics 파라 체인\\n\\n원격 서버를 사용하는 경우 로컬 시스템에 몇 가지 ssh 터널을 만들어야합니다:\\n```\\nssh -f -N -L 9944:127.0.0.1:9944 root@REMOTE_SERVER_IP\\nssh -f -N -L 9988:127.0.0.1:9988 root@REMOTE_SERVER_IP\\nssh -f -N -L 9989:127.0.0.1:9989 root@REMOTE_SERVER_IP\\n```\\n그런 다음에는 https://parachain.robonomics.network/ 에서 `ws://127.0.0.1:9944`, `ws://127.0.0.1:9988` 및 `ws://127.0.0.1:9989`를 사용할 수 있습니다.\\n\\n![relay](../images/ws_lesson4/upcoming.jpg)\\n\\n잠시 후에 파라 체인을 등록해야합니다.\\n\\n![relay2](../images/ws_lesson4/parachains.jpg)\\n\\n그리고 블록 생산을 시작합니다.\\n\\n![relay3](../images/ws_lesson4/parachains2.jpg)\\n\\n다음 단계로 파라체인간에 메시지를 전달하는 HRMP 채널을 만들어 보겠습니다. 릴레이 체인 페이지에서 `sudo` 모듈 호출을 사용하겠습니다.\\n\\n![hrmp](../images/ws_lesson4/hrmp.jpg)\\n\\n채널이 생성되면 XCM 호출을 사용할 수 있습니다. `데이터 로그` 팔레트의 XCM 버전인 `datalogXcm` 팔레트를 사용해 보겠습니다.\\n\\n![datalogXcmSend](../images/ws_lesson4/datalogXcmSend.jpg)\\n\\n결과적으로 두 번째 파라체인의 메시지는 데이터 로그 팔레트를 호출하고 데이터를 체인에 기록합니다.\\n\\n![datalogXcmRecv](../images/ws_lesson4/datalogXcmRecv.jpg)\\n\\n결과적으로이 예제는 XCM을 표준 Robonomics 팔레트의 크로스체인 사용에 사용하는 방법을 보여줍니다.\"}},{\"node\":{\"id\":\"1426402607fc082d72bfc79b04dc2517\",\"title\":\"레슨 3, ROBONOMICS IO 실제\",\"path\":\"/docs/ko/wschool2021-robonomics-io-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\n## 요구 사항\\n\\n* Docker가 필요합니다, 먼저 [설치](https://docs.docker.com/engine/install/)하십시오.\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) 센서는 선택 사항입니다.\\n\\n### SDS011 체크 (선택 사항)\\n\\nSDS011 센서를 연결한 경우 `/dev`에 표시되고 올바른 액세스 권한이 있는지 확인하십시오.\\n\\n<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>\\n\\n## 빠른 시작\\n\\n도 커가 설치되면 [공식 저장소에서](https://hub.docker.com/r/robonomics/robonomics) robonomics 도커 이미지를 시작해 보겠습니다. 이 강의에서는 `winter-school` 태그를 사용하겠습니다.\\n\\n<Asciinema vid=\\\"wM43jozIVfcRmt52ENrJ6yPlH\\\"/>\\n\\n도커 이미지가 준비되면 `robonomics io` 명령 (SDS011 장치가있는 경우 옵션)을 사용하여 데이터를 읽어 보겠습니다.\\n\\n<Asciinema vid=\\\"iztt22tKGaV8wq3cMXY1oUEYv\\\"/>\\n\\nSDS011 센서가없는 경우 `vsds011.sh`를 통해 동일한 도커 컨테이너에서 사용할 수있는 가상 SDS011 센서를 자유롭게 사용하십시오. 그리고 다음 명령의 모든 곳에서 물리적 센서의 투명한 대체물로 사용하십시오.\\n\\n<Asciinema vid=\\\"GCkSiJBA1DgpLAAHiMhIOSpgG\\\"/>\\n\\nRobonomics IO 하위 시스템에는 두 가지 종류의 명령이 있습니다:\\n\\n* `read` - 읽기 액세스를 지원하는 장치에서 데이터를 가져옵니다;\\n* `write` - 쓰기 액세스를 지원하는 장치에 데이터를 씁니다.\\n\\n일부 장치는 그들 모두,이 경우, 장치가 모두 명령 인수에 제시된 지원합니다.\\n\\n> 예를 들어, 가상 장치 `ipfs`는 IPFS에 대한  `write` 데이터와 동일하게 해시별로 IPFS의 `read` 데이터를 지원합니다.\\n\\n지원되는 장치의 전체 목록은 인수없이 `robonomics io read` 또는 `robonomics io write`를 실행할 수 있습니다.\\n\\n## IPFS 액세스\\n\\n다음 단계에서 실행 IPFS 데몬이 필요합니다. 이를 위해 init IPFS를 실행하고 전용 터미널 탭에서 데몬을 실행 해 보겠습니다.\\n\\n<Asciinema vid=\\\"ir6ziXSBUDrRltTmNxg7sdXVY\\\"/>\\n\\n데몬이 실행되면 별도의 탭에서 도커 이미지를 연결하고 데이터 쓰기 및 읽기를 위해 `robonomics io`를 사용할 수 있습니다.\\n\\n<Asciinema vid=\\\"ZtwcmpB9Lhum2Sc221QmNwHG4\\\"/>\\n\\n출력 포워딩도 여기서 작동하므로 `|` (파이프) 기호를 사용하여 SDS011 센서 데이터를 IPFS로 포워딩 할 수 있습니다. \\n\\n<Asciinema vid=\\\"XS0QESWG7f8ELsQe1bGQllb9O\\\"/>\\n\\nSDS011의 JSON 데이터가 IPFS 작성기에 대한 입력으로 전달되고 결과가 stdout에 게시됩니다.\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs\\n```\\n\\n이 접근 방식을 통해 엔지니어는 `robonomics io` 도구의 원시 독자와 작성자를 결합하여 간단한 프로그램을 매우 빠르게 만들 수 있습니다.\\n\\n```bash\\nrobonomics io read sds011 | gz | robonomics io write pubsub my-sensor-data\\n```\\n\\n## Robonomics 데이터 로그\\n\\n> Robonomics [데이터 로그](https://crates.robonomics.network/robonomics_protocol/datalog/index.html)의 목표는 데이터 블록 체인화입니다. 이 팔레트는 블록 체인에 커스텀 데이터를 저장하는 기능을 제공하여 향후 변경이 불가능하고 변경이 불가능하도록합니다.\\n\\n이 레슨의 마지막 부분에서는 robonomics 노드를 실행해야합니다. 빠른 블록 시간과 미리 설정된 계정에 이미 분산 된 잔액 때문에 개발 모드가 선호됩니다. 동일한 컨테이너에있는 별도의 터미널 탭에서 시작하겠습니다.\\n\\n<Asciinema vid=\\\"QnN9l0sdaZZOyK9ah0DntvCXt\\\"/>\\n\\n그런 다음 `데이터 로그` 장치에 대한 인수로 개인 시드도 필요합니다. 이 시드는 트랜잭션에 서명하고 계정을 보낸 사람으로 표시하는 데 사용됩니다. 내장 된 `robonomics 키` 명령을 사용하여 생성 해 보겠습니다. \\n\\n<Asciinema vid=\\\"4Cdfl9F0GgjNWv1c1ZcTBBktF\\\"/>\\n\\n생성 된 주소를 저장하고 나중에 사용할 수 있도록 안전한 곳에 시드하십시오.\\n\\n현재 주소 잔액은 0이며 네트워크는이 주소에서 트랜잭션을 보내는 것을 허용하지 않습니다. 이 문제를 해결하기 위해 `Alice`의 계정에서 약간의 토큰을 전송 해 보겠습니다. https://parachain.robonomics.network에서 주소가 `ws : //127.0.0.1 : 9944` 인 로컬 노드에 연결된 Robonomics 포털을 사용하겠습니다. \\n\\n![포털 전송](../images/ws_lesson3/tran.jpg)\\n\\n그런 다음 `데이터 로그` 장치를 사용하여 블록 체인에 데이터를 저장할 수 있습니다. `-s` 키는 계정의 비밀 시드를 설정하는 데 사용됩니다. 거래를 보내려면 계정에 0이 아닌 잔액이 있어야합니다.\\n\\n<Asciinema vid=\\\"FzERH9TmFB8oRuas8ZU202Pv8\\\"/>\\n\\n모든 것이 올 바르면 Robonomics 포털의 `Explorer` 페이지에 `데이터 로그` 이벤트가 표시됩니다. \\n\\n![포털 데이터 로그](../images/ws_lesson3/datalog.jpg)\\n\\n마지막 단계는 약간 복잡하지만이 강의에 대한 모든 지식을 사용해 보는 것이 좋습니다. SDS011 센서 (또는 파일)에서 데이터를 수집하여 IPFS에 압축 한 다음 `데이터 로그` 트랜잭션을 전송하여 블록 체인에 해시를 저장하는 간단한 프로그램을 만들어 보겠습니다.\\n\\n```\\nSDS011 -> IPFS -> Blockchain\\n```\\n\\nRobonomics IO를 사용하여 쉽게 구현할 수 있습니다.\\n\\n<Asciinema vid=\\\"MTpiawGo8DKEn081OozbYb5mU\\\"/>\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n\\n\\n모든 것이 잘되면 IPFS 해시가있는 `데이터 로그` 이벤트가 표시되어야합니다.\\n\\n![portal datalog complex](../images/ws_lesson3/datalog_complex.jpg)\\n\"}},{\"node\":{\"id\":\"37ff193daefb991a235af5bb16bdca93\",\"title\":\"레슨 2, ROBONOMICS AIRA 개요\",\"path\":\"/docs/ko/wschool2021-robonomics-github-overview/\",\"content\":\"\\n## 1 단계 : VIRTUALBOX에 AIRA 설치\\n\\nhttps://youtu.be/ISKilRfY3Ow\\n\\n## 2 단계 : SSH를 통해 AIRA 연결\\n\\nhttps://youtu.be/W0rOcRA2sEc\\n\\n## 3 단계 : AIRA와 상호 작용\\n\\nhttps://youtu.be/fhRTF2mddfU\"}},{\"node\":{\"id\":\"638e322b660c75a649dbea654a7792ff\",\"title\":\"Robonomics Winter School 2021 introduction\",\"path\":\"/docs/ko/wschool2021-intro/\",\"content\":\"\\nROBONOMICS 겨울 학교 2021은 2 월 10 일부터 24 일까지 온라인으로 열립니다. 무료입니다.\\n\\n우리는 다양한 방식으로 온라인 강의를 게시하고 있습니다 (위키의 텍스트, [YouTube channel](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ) 비디오, [Twitter account](https://twitter.com/AIRA_Robonomics) 포스트).비디오 레슨과 텍스트 레슨은 동일하지 않습니다. 우선 영어와 러시아어의 두 가지 언어 버전을 게시 할 계획입니다.\\n\\n우리와 함께하고, 수업을 통해 단계를 수행하고, [Discord](https://discord.gg/5UWNGNaAUf)에서 토론하고 질문하시기 바랍니다.\\n\\n## 개막식보기\\n\\nhttps://youtu.be/kQaSwNYHJQ8\\n\\n## 기본 정보\\n\\n[저희 웹 사이트에서](https://robonomics.network/blog/winter-robonomics-school/) 학교에 관한 페이지를보십시오. 일정, 정보 파트너, 링크 등 모든 기본 정보를 수집하고 있습니다.\\n\\n## 링크, 링크, 링크\\n\\nRobonomics 겨울 학교 2021을 따르기 위해 어떤 링크가 있는지 반복 해 보십시오:\\n\\n- [웹사이트 요약](https://robonomics.network/blog/winter-robonomics-school/)\\n- 텍스트 레슨을위한 Wiki, YOU ARE HERE 🤓\\n- [비디오 레슨](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ)\\n- [트위터 포스트](https://twitter.com/AIRA_Robonomics)\\n- [Discord의 질문, 토론, 퀴즈](https://discord.gg/5UWNGNaAUf)\\n\\n**Robonomics를 배우기 시작합시다!**\"}},{\"node\":{\"id\":\"7f1bd342f1445f762b8a5601808bccb2\",\"title\":\"5과, 연결성\",\"path\":\"/docs/ko/wschool2021-connectivity-service/\",\"content\":\"\\n## 다중 파이로 IOT\\n\\n* 장치 소프트웨어\\n    * FreeRTOS\\n    * ESP/Arduino\\n    * 싱글 보드 컴퓨터 (RPi, LattePanda 등)\\n* 연결성\\n    * IoT Hub\\n    * IoT 매니저\\n* 분석 서비스\\n    * AWS\\n    * Google Cloud IoT Core\\n    * ThingsBoard\\n\\n일반적으로 대부분은 센서와 서버에 관심이 없지만 데이터 분석에 관심이 있습니다.\\n이를 얻으려면 사용할 장치, 작업 방법 및 연결할 위치를 결정해야합니다.\\n\\n## 장치 소프트웨어\\n\\n가정용 기상 관측소의 예를 고려하십시오. 대기 오염 (SDS011), 온도 및 습도 (BME)에 대한 데이터 수집이 필요합니다. ESP8266 마이크로 컨트롤러는이 작업을 처리 할 수 있습니다.\\n\\n요구 사항 :\\n\\n* 올바르게 센서로부터 데이터를 받기\\n* 고유 식별자가 있슴\\n* 알려진 서버로 데이터 전송\\n* 데이터의 디지털 서명 제공 (선택 사항)\\n\\n[여기에서](https://github.com/LoSk-p/sensors-software/tree/366b19bf447a5fc19220ef89eab0f2440f8db1c2) 현재 펌웨어를 찾을 수 있습니다.\\n\\n## 연결성이 무엇인가?\\n\\nIoT 세계에서 연결이란 다양한 IoT 장치를 인터넷에 연결하여 데이터를 전송하거나 장치를 제어하는 것을 말합니다.\\n\\n잘 알려진 아키텍처 솔루션은 크게 세 그룹으로 나눌 수 있습니다.\\n\\n* 분산전산망. 예를 들어, 장치는 메시 네트워크로 연결됩니다. 높은 하드웨어 요구 사항으로 인해 광역 네트워크에 적합하지 않습니다\\n* 집중형망.예 : AWS. 단일 진입 점 및 연결 용이성을 제공하지만 서버 문제 발생시 장애 위험이 높습니다.\\n* 하이브리드. 예를 들어, [Robonomics 연결성](https://github.com/airalab/sensors-connectivity) \\\"로컬\\\"네트워크에있는 장치에 대한 주소를 제공하고 분산 된 IPFS 메시지 채널에 데이터를 게시합니다. \\n\\n## AWS와 Robonomics 연결성의 비교\\n\\n| 관리 서비스              | AWS                                  |               Robonomics              \\t|\\n|---------------------\\t|-----------------------------------\\t|---------------------------------------\\t|\\n| 거래 유형               | 기술                                  | 기술 및 경제                             \\t |\\n| 보안                   | IT 회사 클라우드 제어                    | Polkadot 및 Ethereum                     |\\n| 프로토콜            \\t | HTTPS, MQTT                       \\t | IPFS, Robonomics                        |\\n| 생태계             \\t  | 개인                           \\t    | 공유                                \\t   |\\n| DeFi에  액세스          | 없음                                \\t| 있음                                   \\t|\\n| 소송 비용               | 데이터 푸시-센서 당 $ 1-2                 | 데이터 푸시-$ 0                            |\\n|                     \\t| Shadow-월 $ 10                        | 디지털 트윈-거래 당 $ 0,01                  |\\n\\n## 연결성 ON AIRA 설치하기\\n\\nhttps://www.youtube.com/watch?v=JbBNMHAzJKM\\n\\n### 요구 사항\\n\\n* [VirtualBox 6.1 이상](https://www.virtualbox.org/wiki/Downloads) and above\\n* [Aira OS ova 이미지](https://static.aira.life/ova/airaos-21.03_robonomics-winter-school.ova)\\n\\n[여기에](/docs/aira-installation-on-vb/)설명 된대로 VirtualBox에서 Aira 이미지 가져 오기\\n\\n[SSH](/docs/aira-connecting-via-ssh/)를 통한 연결 설정 \\n\\n모든 것이 설정되고 SSH를 통해 성공적으로 로그인되면 메인 패키지를 복제하고 빌드 해 보겠습니다.\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\ngit checkout v0.9\\nnix build -f release.nix\\n```\\n\\n이제 나중에 사용할 수 있도록 기본 구성 파일의 복사본을 만들어 보겠습니다.\\n모든 옵션에 대해 알아 보려면[이 기사를](/docs/configuration-options-description/)확인하십시오.\\n그런 다음 `roslaunch`로 패키지를 시작합니다.\\n\\n```\\ncp config/default.json config/my.json\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n## 센서를 연결성에 연결\\n\\nhttps://www.youtube.com/watch?v=yxqxBk-6bpI\\n\\n### 요구 사항\\n\\n* [Nova SDS011 센서1](https://aqicn.org/sensor/sds011) sensor \\n* [Yarn 패키지 매니저](https://yarnpkg.com/getting-started/install)\\n\\n이제 실제 센서를 연결하고 USB 포트를 가상 머신에 전달하고지도를 설정하고 자체 측정을 살펴 보겠습니다\\n\\n먼저 Aira OS가 실행 중이면 중지하고 해당 USB 장치를 추가하십시오\\n\\n![VB USB Forwarding](../images/vb_forward_usb.jpg)\\n\\nVM을 시작하고 SSH를 통해 연결 한 다음 VM의 USB 장치에 따라 `comstation/port` 옵션을 설정합니다. 또한 `comstation`을 활성화하고 위도와 경도를 설정하십시오. 결국 `config/my.json`은 다음과 같아야합니다.\\n\\n```\\n{\\n   \\\"general\\\":{\\n      \\\"publish_interval\\\":30\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":0,\\n      \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"connectivity.robonomics.network\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\":{\\n      \\\"enable\\\":false\\n   },\\n   \\\"robonomics\\\":{\\n      \\\"enable\\\":true,\\n      \\\"ipfs_provider\\\":\\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\":\\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\":{\\n      \\\"enable\\\":false,\\n      \\\"path\\\":\\\"\\\",\\n      \\\"suri\\\":\\\"\\\",\\n      \\\"remote\\\":\\\"wss://substrate.ipci.io\\\",\\n      \\\"dump_interval\\\":3600,\\n      \\\"temporal_username\\\":\\\"\\\",\\n      \\\"temporal_password\\\":\\\"\\\"\\n   },\\n   \\\"dev\\\":{\\n      \\\"sentry\\\":\\\"\\\"\\n   }\\n}\\n```\\n\\n> 실제 센서가없는 경우 `sensors-connectivity/utils/virtual-sensor.py` 스크립트를 사용하여 하나를 에뮬레이션 할 수 있습니다\\n> \\n> 구성 파일을 다음과 같이 변경하여 `HTTPStation`을 활성화하고 `COMStation`을 비활성화합니다 :\\n> ```\\n> {\\n>    \\\"general\\\":{\\n>       \\\"publish_interval\\\":30\\n>    },\\n>    \\\"comstation\\\":{\\n>       \\\"enable\\\":false,\\n>       \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n>       \\\"work_period\\\":0,\\n>       \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n>       \\\"public_key\\\":\\\"\\\"\\n>    },\\n>    \\\"httpstation\\\":{\\n>       \\\"enable\\\":true,\\n>       \\\"port\\\":8001\\n>    },\\n>    ...\\n> }\\n> ```\\n>\\n> VM의 전용 터미널에서 `utils/virtual-sensor.py` 실행\\n\\n파일을 저장하고`sensors-connectivity` 폴더에서 연결을 시작합니다.\\n\\n```\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n콘솔 출력에 첫 번째 측정이 표시되어야합니다.\\n\\nVM에서 IPFS ID를 찾으십시오. 이미지를 부팅 한 직후 또는 `ipfs id` 명령을 통해 나타납니다. 나중에 필요합니다.\\n\\n이제 맵의 자체 인스턴스를 설정하겠습니다. VM이 아닌 노트북에서이 [저장소를 복제하고](https://github.com/airalab/sensors.robonomics.network) 앱을 빌드합니다.\\n\\n```\\ngit clone https://github.com/airalab/sensors.robonomics.network\\ncd sensors.robonomics.network\\nyarn install\\n```\\n\\n`src/agents.json` 파일을 편집하고 IPFS ID를 입력하십시오. 예를 들면\\n\\n```\\n[\\n  \\\"12D3KooWSCFAD3Lpew1HijniE6oFTuo4jsMwHzF87wNnXkpCRYWn\\\"\\n]\\n```\\n\\nmap 시작 :\\n\\n```\\nyarn serve\\n```\\n\\n[http://localhost:8080/](http://localhost:8080/) 또는 yarn이 제공한 주소로 이동하여 센서를 찾으십시오. \\n\\n## 연습\\n\\n### Trajectory 1. 플래시 센서 ESP + SDS011\\n\\n요구 사항 :\\n\\n* ESP8266\\n* 센서 SDS011, BME280, HTU21D 중 하나 이상\\n\\n[지침을](https://wiki.robonomics.network/docs/connect-sensor-to-robonomics/) 사용하여 센서를 Robonomics Connectivity에 연결합니다.  \\n\\n센서가 [매프에 ](https://sensors.robonomics.network/#/)나타나는지 확인하십시오.\\n\\n### Trajectory 2. 연결성 시작\\n\\n요구 사항 :\\n\\n* ROS\\n* Python\\n* Nix (선택 과목)\\n\\n[센서 연결 구축 및 실행](https://github.com/airalab/sensors-connectivity#get-a-package-and-build)\\n\\n> 빌드, [설치](https://wiki.robonomics.network/docs/iot-sensors-connectivity/) 및 [구성하](https://wiki.robonomics.network/docs/configuration-options-description/)는 방법. \\n\\n패키지의 일반 계획 :\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\n예를 들어 난수 생성기와 같은 새로운 스테이션을 구현하거나, 예를 들어 화면에 문자열을 표시하는 새 피더를 구현하기 위해 선택이 제안됩니다.\\n\\n`IStation` 인터페이스 [여기](https://github.com/airalab/sensors-connectivity/blob/master/src/stations/istation.py#L73).\\n\\n`IFeeder` 인터페이스 [여기](https://github.com/airalab/sensors-connectivity/blob/master/src/feeders/ifeeder.py#L5)\"}},{\"node\":{\"id\":\"f8e17909e8c85b45d8d9135b18185abe\",\"title\":\"레슨 1, 로봇을 사용자 앱에 연결\",\"path\":\"/docs/ko/wschool2021-connect-robotics-to-user-app/\",\"content\":\"\\nhttps://youtu.be/NOQxyojvaao\\n\\n- [Wiki에 대한 참조 튜토리얼](https://wiki.robonomics.network/docs/get-weather-on-fuji-mountain/)\\n- [Dapp](https://dapp.robonomics.network/#/)\"}},{\"node\":{\"id\":\"9ba986f9d195dca2a70605723ed2aa96\",\"title\":\"6.2 강, 스크래치에서 DAPP 인터페이스 구축\",\"path\":\"/docs/ko/wschool2021-build-dapp-interface/\",\"content\":\"\\n![Robonomics 및 Polkadot 위에 분산 된 애플리케이션을위한 사용자 인터페이스 구축](../images/build-dapp-interface/sum.gif \\\"Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot\\\")\\n\\n## 서론\\n\\n이 자습서는 이전 단원을 계속합니다. 이미 간단한 애플리케이션을 구축했으며 계정을 노드에 연결하고 트랜잭션을 전송하고 dapp의 기타 중요한 기능에 집중했습니다. 이제이 애플리케이션을위한 사용자 친화적 인 인터페이스를 구축 할 것입니다.\\n\\n## 전제 조건\\n\\n이 튜토리얼은 **HTML, CSS, JavaScript**에 약간 익숙하고 이러한 기술을 분산 응용 프로그램에 적용하는 방법을 배우려는 사람들을 위해 설계되었습니다.\\n\\ndapp의 인터페이스를 구축하려면 자신에게 편안한 JavaScript 프레임 워크를 선택하거나 프레임 워크없이 인터페이스를 구축 할 수도 있습니다. Robonomics 2021에서는 확장 성이 뛰어나고 사용하기 쉬운 [Vue.js](https://vuejs.org)를 사용합니다.\\n\\n## 이 튜토리얼을위한 설정\\n\\n이 단계로 시작하고 학습을 선호하는 경우 다음 할 일 목록을 따라 이전 강의에서 얻은 결과 dapp을 시작하십시오 :\\n\\n1. [릴리스 페이지에서](https://github.com/airalab/robonomics/releases/tag/v0.22.0) OS에 맞는 로컬 Robonomics v0.22 노드를 다운로드하십시오. 최신 릴리스에서 시스템을 찾지 못한 경우 이전 릴리스에서 최신 버전을 찾으십시오.\\n\\n2. 터미널에 `./robonomics --dev --tmp`를 입력하여 개발자 모드에서 Robonomics 노드를 시작합니다. \\n\\n3. [여기](https://polkadot.js.org/extension/)에서 Chrome 또는 Firefox 용 Polkadot 프로그램을 다운로드하십시오. \\n\\n4. [이 저장소를 복제하시시오](https://github.com/vol4tim/example-robonomics-dapp/).\\n\\n5. [Yarn](https://yarnpkg.com)을 설치하십시오.\\n\\n6. [@vue/cli](https://cli.vuejs.org/guide/installation.html) 설치하십시오/.\\n\\n7. 터미널에서 명령으로 dapp 개발을 시작하십시오.\\n```shell\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n\\n**브라우저에 다음 화면이 표시되어야합니다 :**\\n\\n![Dapp 시작](../images/build-dapp-interface/dapp-start.png \\\"Dapp Start\\\")\\n\\n\\n<details>\\n\\n  <summary>시작을위한 몇 가지 추가 팁</summary>\\n\\n  - **노드가 실행 중인지** 확인합니다.:\\n    ![Robonomics 노드 실행의 예](../images/build-dapp-interface/robonomics-node-launch.png \\\"Example of running Robonomics node\\\")\\n\\n  - **macOS**에서는 **접근 권한**`chmod + x robonomics`를 변경해야 할 수 있습니다. \\n\\n  - **Polkadot Extension에 대한 액세스**를 허용했는지 확인합니다 :\\n    ![액세스를 제공하는 Polkadot 확장](../images/build-dapp-interface/polkadot-permission.png \\\"Polkadot Extension giving access\\\")\\n\\n  - 실행중인 노드의 로그에 오류가 있고 dapp이 올바르게로드되지 않는 경우 dev chain의 데이터베이스를 삭제 해보십시오.`sudo rm -rf <YOUR LOCAL PATH>/robonomics/chains/dev/db/`및 재시작 노드. 도움이되지 않으면 컴퓨터를 다시 시작하십시오. \\n\\n</details>\\n\\n## 코드 검사\\n\\nUI를 변경하기 위해 dapp의 구조를 살펴보고 수정할 수있는 항목과 위치를 정리해 보겠습니다.\\n\\n```\\n.\\n├── public/\\n│   ├── favicon.ico           # Icon for your dapp\\n│   └── index.html            # The template file (injects icons links, JavaScript and CSS files for the app)\\n├── src/\\n│   ├── assets/               # Folder for images and global styles\\n│   ├── components/           # Folder with components\\n│   │   ├── Datalog.vue       # Tab 'Datalog' in dapp\\n│   │   ├── Demo.vue          # Tab 'Demo' in dapp\\n│   │   ├── Launch.vue        # Tab 'Launch' in dapp\\n│   ├── utils/                # Folder with important for app js functions (we will touch api.js in this tutorial)\\n│   ├── App.vue               # The root of our app, contains HTML, CSS, JS for the whole page. In fact it is Vue Component also\\n│   ├── main.js               # The app’s entry file, we will import here global styles\\n├── ...                       # There are config files and dependencies files, that we will not change mannually\\n├── README.md                 # You can write here any instructions for your dapp\\n\\n```\\n\\n> **이 튜토리얼의 코드는이 저장소에 [있습니다](https://github.com/positivecrash/wscool21-ui-dapp)**\\n\\n## CSS-in-JS VS. Global stylesheets\\n\\n이 튜토리얼에서는 안정적인 UI 컴포넌트 라이브러리없이 처음부터 작은 dapp의 인터페이스를 변경하는 방법을 보여줍니다. 그래서 다른 Vue 컴포넌트를 가져 와서 생성 할뿐만 아니라 나만의 스타일도 작성하겠습니다.\\n\\n애플리케이션이 크거나 프로젝트에 여러 dapp이있는 경우 향후에는 UI를보다 체계적이고 효율적으로 만들기 위해 특별히 프로젝트 용 구성 요소 라이브러리를 구축하는 것이 좋습니다 ([예 : 구성 요소 구성](https://storybook.js.org)).또는 표준 인터페이스 테마에 문제가없는 경우 타사의 모든 UI 라이브러리를 사용할 수 있습니다 ([예 :](https://vuetifyjs.com/)).\\n\\n## 첫 번째 가져 오기 또는 시작 지점\\n\\n이 dapp에 대한 특정 디자인은 없지만 [Brandbook](https://static.robonomics.network/assets/Robonomics-Visual-Identity.pdf)과  [잘 정립](https://robonomics.network) 된 타이포그래피, 글꼴, 버튼 스타일 등이 있습니다. 처음에는 다음 CSS 파일을 전역으로 가져옵니다 :\\n\\n```\\n...\\n├── src/\\n│   ├── assets/\\n│   │   ├── styles/\\n│   │   │   ├── reset.css         # The goal is to reduce browser inconsistencies\\n│   │   │   ├── variables.css     # Contains specific values to be reused such as colors, font-names, space values etc.\\n│   │   │   ├── typography.css    # Global typography for the whole dapp\\n│   │   │   ├── animation.css     # Keyframe animations used throughout the dapp\\n...\\n\\n```\\n\\n이러한 파일의 내용은 사용자의 인식에 더 적합하다면 App.vue에서 작성할 수 있습니다. 그러나 App.vue를 좀 더 명확하게 유지하려면이 예제에서 일부 CSS 파일을 전역으로 가져 오는 것이 좋습니다.\\n\\n**main.js** 파일을 편집하여 다음 CSS 파일을 앱으로 가져옵니다 :\\n\\n![Vue App에서 글로벌 CSS 가져 오기](../images/build-dapp-interface/import-css-vue-1.png \\\"Import global CSS in Vue app\\\")\\n\\n```JS\\nimport './assets/styles/reset.css'\\nimport './assets/styles/variables.css'\\nimport './assets/styles/typography.css'\\nimport './assets/styles/animation.css'\\n```\\n\\n**dapp에서 글꼴이 변경되었는지 확인하십시오 :**\\n\\n![Dapp 인터페이스 변경 1 단계](../images/build-dapp-interface/dapp-1.png \\\"Dapp Interface changing step 1\\\")\\n\\n\\n## 레이아웃 변경 및 제목 꾸미기\\n\\n응용 프로그램의 레이아웃을 변경해 보겠습니다. 앞서 언급했듯이 App.vue에서 직접 스타일을 작성할 수 있지만이 예제에서는이 프로세스를 분리하는 것을 선호합니다.\\n\\n- **App.vue**의 `<style>` 태그에서 스타일 주석 처리 또는 삭제합니다 \\n\\n- 이 애플리케이션의 스타일 폴더에 css 파일 **app.css**를 만들고 **main.js**로 가져옵니다.\\n\\n```JS\\nimport './assets/styles/app.css'\\n```\\n\\n<details>\\n\\n<summary>앱의 첫 번째 기본 스타일 app.css 작성 :</summary>\\n\\n```css\\n#app {\\n  display: grid;\\n  grid-template-rows: auto 1fr;\\n  align-items: stretch;\\n\\n  text-align: center;\\n}\\n\\nbody {\\n  background-color: var(--color-gray-light);\\n}\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>앱 제목 변경 [App.vue]</summary>\\n\\n```html\\n<div class=\\\"top\\\">\\n    <h1>dApp Robonomics Demo</h1>\\n    <i>Winter School 2021</i>\\n    <img class=\\\"label\\\" alt=\\\"\\\" src=\\\"./assets/images/robonomics-winter-school-2021-logo.png\\\"/>\\n</div>\\n```\\n\\n</details>\\n\\n\\n\\n<details>\\n\\n<summary>제목 [app.css]의 스타일 작성</summary>\\n\\n```css\\n.top {\\n  position: relative;\\n  padding-top: var(--space);\\n  padding-bottom: calc(var(--space)*2);\\n\\n  border-bottom: 2px solid var(--color-dark);\\n  background-color: var(--color-light);\\n}\\n\\n.top h1 {\\n  font-size: 1.8rem;\\n}\\n\\n.top i {\\n  display: block;\\n}\\n\\n.top .loader-label {\\n  display: block;\\n  margin: calc(var(--space)/3) auto;\\n  max-width: 150px;\\n\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.5s FadeIn 0.3s ease forwards, 0.5s ScaleDown 0.1s ease forwards;\\n}\\n\\n.top .label {\\n  position: absolute;\\n  width: 100px;\\n  bottom: -50px;\\n  left: calc(50% - 50px);\\n  display: block;\\n\\n  transform: translateY(1rem);\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.7s FadeIn 0.5s ease forwards, 1s ScaleUp 0.5s ease forwards;\\n}\\n```\\n\\n</details>\\n\\n- Robonomics 겨울 학교 2021 로고가있는 파일을 **./src/assets/images** 폴더에 넣으십시오.\\n\\n**다음 화면이 표시됩니다 :**\\n![Dapp 인터페이스 변경 2 단계](../images/build-dapp-interface/dapp-2.png \\\"Dapp Interface changing step 2\\\")\\n\\n## DAPP 데이터에 따른 스타일 정의\\n\\n이제 `<div>` 요소에 앱의 콘텐츠를 래핑합니다. 또한 dapp의 다양한 상태 (로드 됨 또는로드되지 않음)에 대해 다른 스타일이 필요합니다.\\n\\n- **App.vue**를 열고 래핑 요소를 작성합니다 :\\n```html\\n<div class=\\\"content\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n- 변수 `load`를 찾으십시오. 이미 `<script>`에 정의되어 있습니다.\\n- 객체를 `v-bind:class`에 전달하여 클래스를 동적으로 토글합니다 (축약 된 버전 `:class` 사용).\\n```html\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n이렇게하면 얻은 데이터에 따라 앱에서 스타일을 쉽게 전환 할 수 있습니다. 아래에서이 클래스의 사용법을 볼 수 있습니다.\\n\\n## DAPP 데이터에 따른 뷰 정의\\n\\n앱의 로더를 변경해 보겠습니다.\\n- 이를 위해 다른 Robonomics 프로젝트에서 내 구성 요소를 가져옵니다\\n\\n<details>\\n\\n<summary>./src/components/AnimatedRobonomicsLogo.vue</summary>\\n\\n```HTML\\n<template>\\n  <div class=\\\"logo-animated\\\" :style=\\\"{transform: 'scale('+scale+')'}\\\">\\n      <svg version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" width=\\\"196.9px\\\" height=\\\"170.3px\\\" viewBox=\\\"0 0 196.9 170.3\\\" style=\\\"enable-background:new 0 0 196.9 170.3;\\\" xml:space=\\\"preserve\\\">\\n\\t\\t<g transform=\\\"translate(2530 155)\\\">\\n            <path class=\\\"line\\\" d=\\\"M-2523.4,7.9l184.2,0.5l-91.7-158.1L-2523.4,7.9z\\\"/>\\n\\n            <circle class=\\\"dot\\\" cx=\\\"-2339.7\\\" cy=\\\"8.7\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2523.4\\\" cy=\\\"8.2\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2430.8\\\" cy=\\\"-148.4\\\" r=\\\"6.6\\\"/>\\n            \\n            <path class=\\\"triangle-1\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-45.8-79L-2477.3-18.3z\\\"/>\\n            <path class=\\\"triangle-2\\\" d=\\\"M-2431.2-18.1l46,0.1l-45.8-79L-2431.2-18.1z\\\"/>\\n            <path class=\\\"triangle-3\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-46-20.3L-2477.3-18.3z\\\"/>\\n          </g>\\n\\t</svg>\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style scoped>\\n    /*\\n    Global styles required:\\n    FadeIn - keyframe animation from animation: .css\\n    all --color- variables from variables.css\\n    */\\n\\n    .logo-animated {\\n        transform-origin: 0 0;\\n    }\\n\\n    .logo-animated .dot {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 1s FadeIn 0.3s ease forwards;\\n    }\\n\\n    .logo-animated .line {\\n        fill: transparent;\\n        stroke: var(--color-blue);\\n        stroke-miterlimit:10;\\n        stroke-dasharray: 700;\\n        stroke-dashoffset: 700;\\n        animation: 1s DrawSvgPath 0.5s ease-in-out forwards; \\n    }\\n\\n    .logo-animated .triangle-1 {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-1 0.1s linear infinite;\\n    }\\n\\n    .triangle-2 {\\n        fill: var(--color-violet-light);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-2 0.1s linear infinite;\\n    }\\n\\n    .triangle-3 {\\n        fill: var(--color-violet-mid);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-3 0.1s linear infinite;\\n    }\\n\\n\\n    @keyframes DrawSvgPath\\n        {\\n        to {\\n            stroke-dashoffset: 0;\\n        }\\n        }\\n\\n    @keyframes logo-triangle-1\\n    {\\n        0% { fill: var(--color-blue); }\\n        25% { fill: var(--color-blue); }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-violet-light); }\\n        100% { fill: var(--color-blue); }\\n    }\\n\\n    @keyframes logo-triangle-2\\n    {\\n        0% { fill: var(--color-violet-light); }\\n        25% { fill: #E0BDED; }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-blue); }\\n        100% { fill: var(--color-violet-light); }\\n    }\\n\\n    @keyframes logo-triangle-3\\n    {\\n        0% { fill: var(--color-violet-mid); }\\n        25% { fill: var(--color-violet-light); }\\n        50% { fill: var(--color-violet-light); }\\n        75% { fill: var(--color-violet-dark); }\\n        100% { fill: var(--color-violet-mid); }\\n    }\\n</style>\\n```\\n\\n</details>\\n\\n-이 구성 요소를 **App.vue**에 등록합니다\\n```JS\\nexport default {\\n  components: {\\n    Loader: () => import(\\\"./components/AnimatedRobonomicsLogo\\\")\\n  }\\n}\\n```\\n- 이미 알려진 변수`로드를` 사용하여 조건부 Vue 지시문 `v-if`와 함께 삽입합니다 :\\n```HTML\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <Loader v-if=\\\"load\\\" />\\n  <template v-else>\\n    <!-- here will be main content of loaded dapp -->\\n  </template>\\n</div>\\n```\\n- 브라우저에서 결과를 확인하십시오. 지금 수정할 몇 가지 문제가 있습니다 :\\n\\n1. 로더가 제목에 팝업됩니다 (가운데에 있어야 함). 다음 줄을 **app.css**에 삽입 해 보겠습니다 :\\n```css\\nbody, html, #app {\\n  height: 100%;\\n  position: relative;\\n}\\n```\\n2. 연결 속도가 너무 빠르면 잠시 동안 로더 만 깜박입니다. 혼란 스러울 수 있습니다. 앱의 응답에 대한 시간 제한을 설정해 보겠습니다. 그렇게하려면 **api.js**를 열고 `initAccount` 함수에서이 코드를 찾으십시오 :\\n```JS\\nconst timeout = new Promise(resolve => {\\n  setTimeout(resolve, 300);\\n});\\n```\\n`300` 대신 `1700`을 설정하고 결과를 확인합니다 :\\n\\n![Dapp 인터페이스 변경 3 단계](../images/build-dapp-interface/dapp-3.gif \\\"Dapp Interface changing step 3\\\")\\n\\n\\n## 재사용 가능한 구성 요소 사용\\n\\nLoader에 대한 이전 섹션에서 구성 요소를 등록하고 사용하는 방법을 이미 살펴 봤지만 이제는 더주의 깊게 살펴 보겠습니다.\\n\\n계정 섹션을 변경해 보겠습니다. 여기서는 자체 작성 구성 요소 (상자, 버튼, 아이콘)와 타사 구성 요소 ([Vue Polkadot 라이브러리에서 제공](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon ))를 사용합니다.\\n\\n### The Box 추가\\n\\n<details>\\n\\n<summary>./src/components/Box.vue 파일에 Box 구성 요소 만듭니다 </summary>\\n\\n```HTML\\n<template>\\n    <section class=\\\"box\\\" :class=\\\"classList\\\">\\n        <slot />\\n    </section>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    classList: {\\n      type: String\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .box {\\n        background-color: var(--color-light);\\n        border: 1px solid var(--color-dark);\\n        padding: calc(var(--space)*0.5) var(--space);\\n        box-shadow: 2px 2px 0 var(--color-dark);\\n        margin-bottom: calc(var(--space)*1.5);\\n    }\\n</style>\\n```\\n</details>\\n\\n이제 dapp 전체에서 여러 번 사용할 수 있습니다. 계정 섹션 예제에서 이것을 보겠습니다 :\\n\\n- 구성 요소 등록 (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Box: () => import(\\\"./components/Box\\\")\\n  }\\n}\\n```\\n\\n- prop `classList`와 함께 전달 된 추가 클래스가있는 계정 섹션에 사용하십시오 :\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }} |\\n  <button @click=\\\"faucet\\\">\\n    faucet\\n  </button>\\n</Box>\\n```\\n\\n**결과 확인하십시오 :**\\n![Dapp 인터페이스 변경 4 단계](../images/build-dapp-interface/dapp-4.png \\\"Dapp Interface changing step 4\\\")\\n\\n### 버튼 추가\\n\\n우리가 추가 한 상자의 버튼을 눈치 채지 못할 수도 있습니다. 앱에서 유일한 버튼이 아니므로이를 수정하고 버튼에 대한 구성 요소를 추가해 보겠습니다.\\n\\n<details>\\n\\n<summary>./src/components/Button.vue 파일에 Button 구성 요소 만듭니다 </summary>\\n\\n```HTML\\n<template>\\n  <button type=\\\"button\\\" :class=\\\"classList\\\" @click=\\\"onClick\\\" :disabled=\\\"disabled\\\" class=\\\"inline-block\\\">\\n    {{ label }}\\n  </button>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  components: {\\n    Icon: () => import(\\\"./Icon\\\")\\n  },\\n\\n  props: {\\n    label: {\\n      type: String,\\n    },\\n    type: {\\n      type: String,\\n      default: 'primary',\\n      validator: function (value) {\\n        return ['primary', 'secondary'].indexOf(value) !== -1;\\n      }\\n    },\\n    disabled: {\\n      type: Boolean,\\n      default: false,\\n    },\\n    size: {\\n      type: String,\\n      default: 'medium',\\n      validator: function (value) {\\n        return ['small', 'medium', 'large'].indexOf(value) !== -1;\\n      }\\n    }\\n  },\\n\\n  computed: {\\n    classList() {\\n      return {\\n        'button': true,\\n        [`${this.type}`]: true,\\n        [`button__${this.size}`]: true,\\n      };\\n    },\\n  },\\n\\n  methods: {\\n    onClick() {\\n      this.$emit('onClick');\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .button {\\n        appearance: none;\\n        -webkit-appearance: none;\\n        outline: 0;\\n        border: 0;\\n\\n        transition: 0.1s all linear;\\n\\n        padding: .15rem 0.6rem;\\n        border-width: 1px;\\n        border-style: solid;\\n        border-radius: .25rem;\\n  \\n        cursor: pointer;\\n\\n        font-family: var(--font-family);\\n        font-size: calc(var(--font-size)*0.9);\\n        line-height: 1;\\n        font-weight: 500;\\n\\n        text-transform: uppercase;\\n        letter-spacing: 1px;\\n    }   \\n\\n    .button:not([disabled]):hover {\\n    filter: saturate(1.5);\\n    }\\n\\n    .button[disabled] {\\n        cursor: default;\\n        opacity: 0.6;\\n    }\\n\\n    button.primary {\\n        border-color: var(--color-green);\\n        background-color: var(--color-green);\\n        color: var(--color-light);\\n    }\\n\\n    button.secondary {\\n        border-color: var(--color-blue);\\n        color: var(--color-blue);\\n    }\\n\\n    button.secondary:not([disabled]):hover {\\n        background-color: var(--color-blue);\\n        color: var(--color-light);\\n    }\\n\\n    .button__small {\\n        font-size: .85rem;\\n        padding: .1rem 0.45rem;\\n    }\\n\\n    .button__large {\\n        font-size: 1.2rem;\\n        padding: .5rem 1.7rem;\\n    }\\n\\n</style>\\n```\\n</details>\\n\\n\\n- 구성 요소 등록합니다 (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Button: () => import(\\\"./components/Button\\\")\\n  }\\n}\\n```\\n\\n- 'Button'구성 요소에 정의 된 소품이있는 'Faucet'버튼에 사용합니다.\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }}\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n</Box>\\n```\\n\\n**우리는 다음과 같은 입장을 얻습니다 :**\\n![Dapp 인터페이스 변경 5 단계](../images/build-dapp-interface/dapp-5.png \\\"Dapp Interface changing step 5\\\")\\n\\nButton 구성 요소의 경우 `@onClick`을 사용하여 prop에서 클릭을 내보냈으므로 이제 수도꼭지 기능이 올바르게 작동하는지 확인하겠습니다 (클릭시 잔액이 변경되어야 함).\\n\\n![Dapp 인터페이스 변경 6 단계](../images/build-dapp-interface/dapp-6.gif \\\"Dapp Interface changing step 6\\\")\\n\\n### 아이콘 추가\\n\\n사용자가 유닛과이 버튼을 클릭하지 않고는 디앱과 제대로 상호 작용할 수 없기 때문에 인터페이스의이 요소에 더 많은 관심을 끌기 위해이 버튼에 아이콘을 추가합시다.\\n\\n이를 위해 준비된 Vue 라이브러리를 아이콘으로 사용할 수 있습니다. 아이콘으로 나만의 구성 요소를 만들겠습니다.\\n\\n- [큰 온라인 아이콘 아카이브에서](https://www.flaticon.com) 적절한 아이콘을 찾았습니다. \\n- .svg 파일을 다운로드하고 벡터 그래픽 편집기에서 적절한 크기로 편집합니다.\\n- Icon.vue 구성 요소에 svg를 텍스트로 삽입합니다\\n\\n<details>\\n\\n<summary>Icon.vue 구성 요소로 얻은 것은 다음과 같습니다</summary>\\n\\n```JS\\n<template>\\n  <div class=\\\"icon inline-block\\\" :class=\\\"classList\\\">\\n    <svg v-if=\\\"icon == 'faucet'\\\" class=\\\"icon-fill\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" :width=\\\"SvgWidth(20)\\\"  viewBox=\\\"0 0 20 24.9\\\" style=\\\"enable-background:new 0 0 20 24.9;\\\" xml:space=\\\"preserve\\\">\\n      <path d=\\\"M2.7,24.9c0.2,0,2.4,0,2.4-2.4c0-2-2.2-5.2-2.2-5.2s-2.5,3.3-2.5,5.3C0.4,24.6,2.4,24.9,2.7,24.9z M20,10.8V7.2V3.1h-2.6v2.6h-3.1V1.5h2.6c0.4,0,0.8-0.3,0.8-0.8S17.3,0,16.9,0h-6.7C9.8,0,9.5,0.3,9.5,0.8s0.3,0.8,0.8,0.8h2.6v4.1H7.9c-4.7,0-6.2,3.2-6.3,4.8c0,0,0,0.1,0,0.1v2.8H0v2.1h6.2v-2.1H4.6v-2.7c0-0.3,0.4-1.9,3.3-1.9h9.6v2.1L20,10.8L20,10.8z\\\"/>\\n    </svg>\\n\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n  props: {\\n    icon: {\\n      type: String\\n    },\\n    classList: {\\n      type: String\\n    },\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n  methods: {\\n    SvgWidth(SvgWidth) {\\n      return `${SvgWidth * this.scale}px`;\\n    }\\n  }\\n};\\n</script>\\n\\n<style>\\n.icon {\\n    line-height: 1;\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n버튼과 함께 사용하려면 Button 구성 요소를 편집합니다.\\n\\n**Button.vue**에서 아이콘 가져 오기 :\\n\\n```JS\\ncomponents: {\\n    Icon: () => import(\\\"./Icon\\\")\\n}\\n```\\n\\n소품 등록 :\\n\\n```JS\\nprops: {\\n  icon: {\\n    type: String,\\n    default: 'none'\\n  }\\n}\\n```\\n\\n버튼에 아이콘을 추가합니다 (`v-if` 조건으로 다른 템플릿을 지정할 수 있음) :\\n\\n```HTML\\n<template v-if=\\\"icon != 'none'\\\">\\n  <Icon :icon=\\\"icon\\\" />\\n  <span v-if=\\\"label != ''\\\" class=\\\"inline-block\\\">{{ label }}</span>\\n</template>\\n<template v-if=\\\"icon == 'none' & label != ''\\\">\\n  {{ label }}\\n</template>\\n```\\n\\n스타일 추가 :\\n\\n```CSS\\n.button .icon-fill path {\\n  fill: var(--color-light);\\n}\\n\\n.button > *:not(:last-child) {\\n  margin-right: calc(var(--space)/2);\\n}\\n\\n```\\n\\n**App.vue**의 버튼에 아이콘 소품을 추가합니다 :\\n\\n```HTML\\n<Button label=\\\"Faucet\\\" size=\\\"large\\\" icon=\\\"faucet\\\" @onClick=\\\"faucet\\\" />\\n```\\n\\n**확인 :**\\n\\n![Dapp 인터페이스 변경 7 단계](../images/build-dapp-interface/dapp-7.png \\\"Dapp Interface changing step 7\\\")\\n\\n### Polcadot 아바타 추가\\n\\n- [@vue-polkadot/vue-identicon](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon) 설치\\n\\n- App.vue로 가져 오기 :\\n```JS\\ncomponents: {\\n    Identicon: () => import(\\\"@vue-polkadot/vue-identicon\\\")\\n}\\n```\\n\\n- `계정`이라는 단어 대신 아바타를 삽입하고 문서에 따라 소품을 전달하고 계정 데이터를 값 소품으로 사용합니다.\\n```HTML\\n<Identicon\\n  :value=\\\"account\\\"\\n  :theme=\\\"'polkadot'\\\"\\n  :size=\\\"40\\\"\\n  :class=\\\"'inline-block'\\\"\\n/>\\n```\\n\\n**확인 :**\\n\\n![Dapp 인터페이스 변경 8 단계](../images/build-dapp-interface/dapp-8.png \\\"Dapp Interface changing step 8\\\")\\n\\n## 더 나은보기를위한 데이터 조작\\n\\n계정 주소를 잘라 봅시다 :\\n\\n- 계산 된 속성에서 변수 `계정`을 래핑합니다 :\\n\\n```JS\\ncomputed: {\\n  AccountAddress() {\\n    return this.account.slice(0, 6) + \\\"...\\\" + this.account.slice(-4);\\n  }\\n}\\n```\\n\\n- 템플릿에서 변수 `계정`을 `AccountAddress`로 바꿉니다.\\n\\n**확인 :**\\n\\n![Dapp 인터페이스 변경 9 단계](../images/build-dapp-interface/dapp-9.png \\\"Dapp Interface changing step 9\\\")\\n\\n## CSS magic\\n\\n계정 섹션을 좀 더 예쁘게 만들어 보겠습니다 :\\n\\n<details>\\n\\n<summary>주형</summary>\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n              \\n  <div class=\\\"account__address\\\">\\n    <Identicon\\n      :value=\\\"account\\\"\\n      :theme=\\\"'polkadot'\\\"\\n      :size=\\\"40\\\"\\n      :class=\\\"'inline-block'\\\"\\n    />\\n\\n    <code class=\\\"inline-block\\\">{{ AccountAddress }}</code>\\n  </div>\\n  \\n  <div class=\\\"account__balance\\\">{{ balance }}</div>\\n\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n  \\n</Box>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>스타일 (app.css)</summary>\\n\\n```CSS\\n.account {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  align-items: center;\\n  justify-items: stretch;\\n  column-gap: var(--space);\\n}\\n\\n.account__balance {\\n    font-size: 150%;\\n    font-weight: 500;\\n    font-family: var(--font-family-code);\\n    white-space: nowrap;\\n}\\n\\n.account__address > *:not(:last-child) {\\n    margin-right: calc(var(--space)/2);\\n}\\n```\\n\\n</details>\\n\\n![Dapp 인터페이스 변경 10 단계](../images/build-dapp-interface/dapp-10.gif \\\"Dapp Interface changing step 10\\\")\\n\\n탭의 스타일을 편집 해 보겠습니다.\\n\\n<details>\\n\\n<summary>스타일 (app.css)</summary>\\n\\n```CSS\\n.tabs {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  margin-top: calc(var(--space)*2.5);\\n}\\n\\n.tabs button {\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  border-width: 0 0 1px;\\n  font-family: var(--font-family);\\n  font-size: calc(var(--font-size)*1.5);\\n  font-weight: 300;\\n  cursor: pointer;\\n  transition: 0.2s all linear;\\n}\\n\\n.tabs button:not(.active) {\\n  opacity: 0.5;\\n  border-color: var(--color-gray)\\n}\\n\\n.tabs-content {\\n  padding-top: var(--space);\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>최소한의 템플릿 변경 :</summary>\\n\\n```HTML\\n<div class=\\\"tabs-content\\\">\\n  <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" /> \\n</div>\\n```\\n\\n</details>\\n\\n![Dapp 인터페이스 변경 11 단계](../images/build-dapp-interface/dapp-11.gif \\\"Dapp Interface changing step 11\\\")\\n\\n> 이 튜토리얼의 완성 된 코드가이 [저장소에 있음을](https://github.com/positivecrash/wscool21-ui-dapp) 상기시켜 드리겠습니다. 다음 단계로 이동하겠습니다 :)\\n\\n## 데이터 로그\\n\\ndapp : 버튼에 이미 알려진 UI 요소를 수정하는 것부터 시작합니다 ( '수도꼭지'에 대해 수행 한 것과 동일하지만 소품이 다릅니다).\\n\\n그런 다음 이러한 요소를 의미별로 구분하기 위해 `<fieldset>`에 래핑합니다. 그리고 fieldset 및 input 요소에 대한 고유 한 스타일을 작성합니다.\\n\\n<details>\\n\\n<summary>Dialogue.vue의 템플릿 :</summary>\\n\\n```HTML\\n<div class=\\\"tools\\\">\\n  <fieldset>\\n    <Button label=\\\"Read data\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"read\\\" />\\n  </fieldset>\\n\\n  <fieldset>\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" class=\\\"large\\\" />\\n    <Button label=\\\"Write\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"write\\\" />\\n  </fieldset>\\n</div>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>app.css의 입력 요소에 대한 스타일-전역이어야합니다 :</summary>\\n\\n```CSS\\ninput, select{\\n  padding: .3rem 0.6rem;\\n  border: 1px solid var(--color-gray);\\n  background-color: var(--color-light);\\n  border-radius: var(--radius);\\n  font-size: var(--font-size);\\n  font-family: var(--font-family-code);\\n  border-radius: .25rem;\\n  transition: 0.2s ease all;\\n}\\n\\ninput:focus {\\n  border-color: var(--color-dark);\\n}\\n\\ninput.large, select.large {\\n  font-size: 1.2rem;\\n  padding: .35rem 1rem;\\n}\\n\\n\\n.tools *, .tools fieldset:not(:last-child):after {\\n  display: inline-block;\\n  vertical-align: middle;\\n  vertical-align: -moz-middle-with-baseline;\\n  vertical-align: -webkit-baseline-middle;\\n}\\n\\n.tools fieldset {\\n  border: 0;\\n}\\n\\n.tools fieldset:not(:last-child):after {\\n  content: \\\"•\\\";\\n}\\n\\n.tools fieldset > *,  .tools > * {\\n  margin-right: calc(var(--space)/2)\\n}\\n```\\n\\n</details>\\n\\n**업데이트 후 모든 것이 잘 작동하는지 확인합시다 :**\\n\\n![Dapp 인터페이스 변경 12 단계](../images/build-dapp-interface/dapp-12.gif \\\"Dapp Interface changing step 12\\\")\\n\\ndapp 전체에 데이터 로그 섹션이 있으므로 구성 요소를 만들겠습니다\\n\\n<details>\\n\\n<summary>새 구성 요소 DatalogSection.vue에 대한 다음 코드가 있습니다.</summary>\\n\\n```HTML\\n<template>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <h4 class=\\\"log-title\\\">Datalog</h4>\\n\\n        <div class=\\\"log-content\\\">\\n\\n          <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n\\n          <details v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"box\\\" :open=\\\"k === 0\\\">\\n              <summary>{{ item[0] }}</summary>\\n              <pre>{{ item[1] }}</pre>\\n          </details>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    log: {\\n      type: Array\\n    }\\n  },\\n\\n}\\n\\n</script>\\n\\n<style>\\n\\n.log {\\n  text-align: left;\\n  margin: var(--space) auto;\\n  width: 100%;\\n}\\n\\n.log-content {\\n  border: 1px solid var(--color-gray);\\n  max-height: 500px;\\n  overflow-y: auto;\\n  padding: var(--space);\\n  background-color: var(--color-gray-middark);\\n  outline: 1px solid #fff;\\n  box-shadow: 0 0 60px 20px #fff inset;\\n}\\n\\n.log-title {\\n  color: var(--color-gray-dark);\\n  font-weight: 300;\\n  font-family: var(--font-family-code);\\n\\n  border-bottom: 1px solid var(--color-gray);\\n}\\n\\n.log .box {\\n  margin-bottom: var(--space);\\n}\\n\\ndetails {\\n  transition: 0.2s all ease;\\n}\\n\\ndetails summary {\\n  cursor: pointer;\\n}\\n\\ndetails.box {\\n  padding-top: 0;\\n  padding-bottom: 0;\\n}\\n\\ndetails.box[open] {\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box:focus {\\n  box-shadow: 0 0 5px var(--color-gray)\\n}\\n\\ndetails.box summary {\\n  padding-top: calc(var(--space)*0.5);\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box[open] summary {\\n  border-bottom: 1px solid var(--color-dark);\\n  margin-bottom: calc(var(--space)*0.5);\\n  font-weight: 500;\\n}\\n\\n.log details.box summary {\\n  font-family: var(--font-family-code);\\n}\\n\\n</style>\\n```\\n\\n</details>\\n\\n여기서주의해야 할 사항 : prop `log`를 배열로 전달합니다. 이 다차원 배열에는 항목 로그가 포함되고 모든 항목에는 제목 (dapp의 모든 로그에 대해 날짜를 썼습니다)과 내용이 있다고 가정합니다. **Datalog.vue** 및 **Launch.vue** 구성 요소의 배열을 다시 포맷해야합니다.\\n\\n이제 **Datalog.vue**를 편집하십시오. 로그를 얻는 Find 메서드 :\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n}\\n```\\n\\n이제 **Datalog.vue**의 데이터 형식을 지정하고 **DatalogSection.vue**에 대한 준비된 로그 배열을 전달해야합니다. 따라서 로그 배열을 매핑 해 보겠습니다 :\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray().map((item) => {\\n    return [new Date(Number(item[0])).toLocaleString(), u8aToString(item[1])]\\n  });\\n}\\n```\\n\\n이 코드는 더 이상 필요하지 않습니다 :\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return u8aToString(v);\\n  }\\n}\\n```\\n\\n**데이터 로그 탭에서 데이터 로그 섹션을 확인해 보겠습니다 :**\\n\\n![Dapp 인터페이스 변경 13 단계](../images/build-dapp-interface/dapp-13.gif \\\"Dapp Interface changing step 13\\\")\\n\\n## 시작\\n\\n이 단계에서는 대부분의 개선이 이미 완료되었으므로 템플릿에 적용하기 만하면됩니다. Import Button 및 Datalog 구성 요소는 과도한 제목을 제거합니다 :\\n\\n![Dapp 인터페이스 변경 14 단계](../images/build-dapp-interface/dapp-14.gif \\\"Dapp Interface changing step 14\\\")\\n\\n`선택` `컨트롤` 요소를 확인란으로 대체하겠습니다 :\\n\\n대신 :\\n```HTML\\n<select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n  <option value=\\\"ON\\\">ON</option>\\n  <option value=\\\"OFF\\\">OFF</option>\\n</select>\\n```\\n\\n이것을 쓰십시오 :\\n```HTML\\n<div class=\\\"toggler inline-block\\\">\\n  <input v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\" type=\\\"checkbox\\\" id=\\\"robot-switch\\\" />\\n  <label for=\\\"robot-switch\\\"><span></span></label>\\n</div>\\n```\\n\\n<details>\\n\\n<스타일 (app.css):</summary>\\n\\n```CSS\\n.toggler input { display: none; }\\n.toggler label {\\n  position: relative;\\n  display: block;\\n  width: 60px;\\n  height: 40px;\\n  border-radius: 4px;\\n  font-weight: 500;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  cursor: pointer;\\n  background-color: var(--color-gray);\\n  color: var(--color-light);\\n  text-align: center;\\n}\\n\\n.toggler label:before {\\n  content: 'Off';\\n  width: 100%;\\n  text-align: center;\\n  line-height: 40px;\\n}\\n\\n.toggler label:after {\\n  content: '';\\n  display: block;\\n  width: 6px;\\n  height: 100%;\\n  border-radius: 10px;\\n  background-color: var(--color-gray-dark);\\n\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  z-index: 10;\\n\\n  transition: 0.3s ease-out all;\\n}\\n\\n.toggler input:checked + label {\\n  background-color: var(--color-green);\\n}\\n\\n.toggler input:checked + label:before {\\n  content: 'On';\\n}\\n\\n.toggler input:checked + label:after {\\n  transform: translateX(54px);\\n  background-color: #007038;\\n}\\n```\\n\\n</details>\\n\\n![Dapp 인터페이스 변경 15 단계](../images/build-dapp-interface/dapp-15.gif \\\"Dapp Interface changing step 15\\\")\\n\\n인터페이스에 대해 명확히하고 싶습니다. 이러한 요소를 사용하여 일부 장치를 시작합니다. 시각화 해 봅시다. 드론을 선택 했으므로 `item.parameter`에 따라 클래스를 전환하겠습니다.\\n\\n`데이터`에 새 속성을 만듭니다 :\\n```JS\\ndata() {\\n  status: false\\n}\\n```\\n\\n버튼을 클릭하고 tx가 블록으로 전송 된 후 상태에 매개 변수 값을 할당합니다 :\\n```JS\\nmethods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n            this.status = this.parameter; // new line here\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n```\\n\\n**Launch.vue**에서 드론의 스타일을 작성하십시오. 이 구성 요소에만 스타일을 적용하려면 `<style>` 태그의 범위를 지정하는 것을 잊지 마십시오.\\n\\n<details>\\n\\n<summary>드론 용 CSS :</summary>\\n\\n```CSS\\n<style scoped>\\n.tools {\\n  position: relative;\\n  padding-left: 120px;\\n  text-align: left;\\n  display: inline-block;\\n}\\n\\n.launch-drone {\\n  position: absolute;\\n  width: 100px;\\n  left: 0;\\n  filter: grayscale(1);\\n  transition: 1s all ease-in;\\n}\\n\\n.launch-drone.on {\\n  filter: grayscale(0);\\n  animation: DroneLaunch 10s linear infinite;\\n}\\n\\n@keyframes DroneLaunch {\\n  0%, 20%, 40%, 60%, 80%, 100% {\\n    transform: translateY(0);\\n  }\\n  10%, 30%, 50%, 70%, 90% {\\n    transform: translateY(-20%);\\n  }\\n}\\n</style>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 16](../images/build-dapp-interface/dapp-16.gif \\\"Dapp Interface changing step 16\\\")\\n\\n이제 **DatalogSection.vue** 구성 요소를 추가하겠습니다.\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n다음에서 로그 배열을 다시 포맷하십시오 :\\n\\n```JS\\nthis.log.push({\\n  sender,\\n  robot,\\n  parameter\\n});\\n```\\n\\n(`[[ \\\"entry 1 date\\\", \\\"entry 1 content\\\"], [ \\\"entry 2 date\\\", \\\"entry 2 content\\\"]]`와 같은 구조의 경우) :\\n\\n```JS\\nthis.log.push([new Date().toLocaleString(), {\\n  sender,\\n  robot,\\n  parameter\\n}]);\\n```\\n\\n템플릿에서 코드를 바꿉니다 :\\n\\n```HTML\\n<div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    sender: <b>{{ item.sender }}</b>\\n    <br />\\n    robot: <b>{{ item.robot }}</b>\\n    <br />\\n    parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n  </div>\\n</div>\\n```\\n\\n이것으로 :\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n**확인 :**\\n![Dapp 인터페이스 변경 17 단계](../images/build-dapp-interface/dapp-17.gif \\\"Dapp Interface changing step 17\\\")\\n\\n때로는 약간의 오류가 발생하지만 거의 불가피합니다. 연결에 문제가 생기거나 다른 일이 발생할 수 있습니다. 그래서 우리는 dapp을 통해 오류 메시지와 함께 폴백을 가지고 있으며, 코드는 다음과 같이 처음부터 변경하지 않았습니다 :\\n\\n```HTML\\n<div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n```\\n\\n인터페이스에서 오류는 다음과 같이 보입니다 :\\n\\n![Dapp 인터페이스 변경 18 단계](../images/build-dapp-interface/dapp-18.png \\\"Dapp Interface changing step 18\\\")\\n\\n**app.css**에서 `.error`에 대한 스타일을 추가합니다 :\\n\\n```CSS\\n.error {\\n  font-weight: 400;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  color: var(--color-red);\\n}\\n```\\n\\n`.tools` 섹션과 하단의 다른 콘텐츠 사이의 공간도 **app.css**에서 수정합니다.\\n\\n```CSS\\n.tools {\\n  margin-bottom: var(--space);\\n}\\n```\\n\\n결과는 :\\n\\n![Dapp 인터페이스 변경 19 단계](../images/build-dapp-interface/dapp-19.png \\\"Dapp Interface changing step 19\\\")\\n\\n이제이 페이지에서 \\\"기본\\\"버튼이 필요합니다. 기술적으로는 괜찮지 만 위의 사용자 경험으로는 괜찮지 않습니다. 화면에서 하나 이상의 일반적인 버튼을 사용하지 않는 것이 좋습니다. 따라서이를 수정하고 속성 `type = \\\"secondary\\\"`로 **Launch.vue**에 `Button`을 추가해 보겠습니다. \\n\\n![Dapp 인터페이스 변경 20 단계](../images/build-dapp-interface/dapp-20.png \\\"Dapp Interface changing step 20\\\")\\n\\n좋습니다. 이제 노드의 일부 문제를 수정하고 데모 단계로 이동하겠습니다.\\n\\n## 데모\\n\\n처음에는 가장 관련성이 높은 탭에 더 많은주의를 기울이기 위해 탭을 바꾸고 싶지만 이것이 우리가 연습하는 첫 번째 단계는 아닙니다. 먼저 **App.vue**에서 탭을 뒤집습니다.\\n\\n기본 데이터를 바꾸는 것을 잊지 마십시오 :\\n\\n```JS\\ndata() {\\n    return {\\n      ...\\n      tab: \\\"demo\\\"\\n    };\\n},\\n```\\n\\n![Dapp 인터페이스 변경 21 단계](../images/build-dapp-interface/dapp-21.png \\\"Dapp Interface changing step 21\\\")\\n\\n평소처럼 이미 가지고있는 것을 변경하는 것부터 시작합시다.\\n\\n- 이전 단계에서와 같이 `<h2>Demo</h2>` 제목을 제거합니다.\\n- 이미 학습 한 UI 요소 (데이터 로그, 버튼, 계정 주소)를 찾습니다. 그러나 그렇게 빠르지는 않습니다. 이제 데이터 로그 만 변경하겠습니다.\\n\\n**Demo.vue**에 구성 요소를 추가합니다.\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n로그에 원시 데이터가 있으므로 이전 단계에서와 같이 구성 요소 준비보기 데이터를 전달하기 위해 로그로 배열을 다시 포맷해야합니다. 라인 `return [item [0], item [1]];`을 찾습니다 `async created()`에서 다음으로 바꿉니다 :\\n\\n```JS\\nreturn [new Date(Number(item[0])).toLocaleString(), JSON.parse(u8aToString(item[1]))];\\n```\\n\\n로그에서 사용하지 않는 코드를 제거하십시오 :\\n\\n```HTML\\n<div v-if=\\\"log\\\" class=\\\"log\\\">\\n  <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    <b>{{ item[0] | dateFormat }}</b>\\n    <pre>{{ item[1] | dataFormat }}</pre>\\n  </div>\\n</div>\\n```\\n\\n또는:\\n\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return JSON.parse(u8aToString(v));\\n  }\\n},\\n```\\n\\n**확인:**\\n![Dapp 인터페이스 변경 22 단계](../images/build-dapp-interface/dapp-22.png \\\"Dapp Interface changing step 22\\\")\\n\\n로봇을 시작하여이 데모 예제를 사용자 정의하려면 아이디어를 자유롭게 생각해 낼 수 있습니다. 개인적으로 저는이 도시에서 시작했습니다 :\\n\\n![Dapp 인터페이스 변경 23 단계](../images/build-dapp-interface/dapp-23.gif \\\"Dapp Interface changing step 23\\\")\\n\\n혼동하지 않도록 전체 코드를 보여주지는 않겠지 만 개략적으로 다음과 같은 내용이있을 것입니다 :\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back\\\"></div>\\n  <div class=\\\"demo-city\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n</div>\\n```\\n\\n그런 다음 `.demo.play` 요소 내에 도시를 뒤로 이동하고 자동차를 앞으로 이동하는 스타일을 작성합니다.\\n\\n이 작업을하면서 저는 CyberPunk 도시를 실현한다는 아이디어를 떠올 렸습니다. 특별한 작업이 없어서 차가 택시가되었고, 운전자가 승객이되었고, 이제 인터페이스에 승객을 맞이하는 AI 로봇 홀로그램이 있습니다 (모두 CSS와 그래픽 조정 및 트릭입니다).\\n\\n**Cyberpunk 도시 데모 코드 :**\\n\\n<details>\\n\\n<summary>주형</summary>\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back-1\\\"></div>\\n  <div class=\\\"demo-back-2\\\"></div>\\n  <div class=\\\"demo-city-1\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n\\n  <div class=\\\"demo-data\\\">\\n    <div class=\\\"demo-data-driver inline-block\\\">\\n      <img alt=\\\"Driver's avatar\\\" src=\\\"../assets/images/cabman.png\\\" v-if=\\\"robot.state\\\"/>\\n    </div>\\n    <div class=\\\"demo-data-lines inline-block\\\">\\n      <div class=\\\"demo-data-line\\\">\\n          <div>Robot</div>\\n          <div>[ {{ addressShort(robot.address) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-line\\\" v-if=\\\"robot.state\\\">\\n          <div>Passenger</div>\\n          <div>[ {{ addressShort(robot.driver) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-welcome\\\" v-if=\\\"robot.state\\\">\\n          <span>Hello, passenger. </span>\\n          <span>I've linked to the vehicle. </span>\\n          <span>Your ride begins, congrats! </span>\\n      </div>\\n    </div>\\n\\n  </div>\\n\\n  <Button :label=\\\"robot.state ? 'stop' : 'run'\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" @onClick=\\\"run\\\" />\\n</div>\\n```\\n\\n</details>\\n\\n축약해야 할 해시 주소가 두 개 이상 있으므로 메서드를 추가했습니다 :\\n\\n```JS\\nmethods: {\\n  addressShort(address) {\\n    return address.slice(0, 6) + \\\"...\\\" + address.slice(-4);\\n  }\\n}\\n```\\n\\nButton 구성 요소를 등록하는 것을 잊지 마십시오\\n\\n```JS\\ncomponents: {\\n  Button: () => import(\\\"./Button\\\")\\n}\\n```\\n\\n<details>\\n\\n<summary>스타일</summary>\\n\\n```CSS\\n<style scoped>\\n.demo {\\n    --h: 120px;\\n    --color-yellow: #F2F209;\\n\\n    background-color: #AFCCD3;\\n\\n    background: linear-gradient(#010123, #4baac7);\\n\\n    position: relative;\\n    height: 500px;\\n    overflow: hidden;\\n\\n    border-width: 2px 2px 2px 15px;\\n    border-style: solid;\\n    border-color: var(--color-yellow);\\n    \\n}\\n\\n.demo:before {\\n    content: '[ Delamain cabs rental DEMO ]';\\n    background-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    padding: .5rem 1rem;\\n\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 300;\\n\\n    border-width: 0 6px 2px 0;\\n    border-style: solid;\\n    border-color: #7B186E;\\n}\\n\\ndiv[class^=demo-back-], div[class^=demo-city-] {\\n    position: absolute;\\n    left: 0;\\n    width: 100%;\\n    z-index: 2;\\n}\\n\\ndiv[class^=demo-back-]{\\n    border-top: 1px solid #364444;\\n}\\n\\ndiv[class^=demo-city-] {\\n    background-repeat: repeat-x;\\n    background-size: cover;\\n    background-position: 100% 0;\\n\\n    height: 300px;\\n    bottom: var(--h);\\n\\n    animation: 50s MoveCity infinite linear 1.5s;\\n}\\n\\ndiv.demo-back-1 {\\n    background-color: #060236;\\n    background: linear-gradient(#7B186E, #060236);\\n    height: var(--h);\\n    bottom: 0;\\n}\\n\\ndiv.demo-back-2 {\\n    background-color: #c515ae;\\n    border-width: 2px 0;\\n    border-style: solid;\\n    border-color: #69045c;\\n\\n    height: 20px;\\n    bottom: var(--h);\\n    z-index: 10;\\n}\\n\\ndiv.demo-city-1 {\\n    background-image: url(../assets/images/city-1.png);\\n}\\n\\n.demo-car {\\n    background-image: url(../assets/images/car.png);\\n    background-size: contain;\\n    background-repeat: no-repeat;\\n    background-position: 100% 0;\\n\\n    width: calc(508px * 0.5);\\n    height: calc(257px * 0.5);\\n    position: absolute;\\n    bottom: calc(var(--h) + 4px);\\n    z-index: 10;\\n\\n    transform: translateX(-100px);\\n    animation: MoveCar 50s infinite 1.5s linear;\\n}\\n\\n.demo.play div[class^=demo-city-], .demo.play .demo-car { animation-play-state: running; }\\n.demo.stop div[class^=demo-city-], .demo.stop .demo-car { animation-play-state: paused; }\\n\\n.demo.play .demo-car {\\n    background-image: url(../assets/images/car-ride.png);\\n}\\n\\n\\n.demo button {\\n    background-color: var(--color-yellow);\\n    border-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    bottom: 30px;\\n    right: 30px;\\n    z-index: 1000;\\n}\\n\\n.demo-data {\\n    position: absolute;\\n    bottom: 30px;\\n    left: 30px;\\n    z-index: 1000;\\n\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    padding: .5rem;\\n    font-family: var(--font-family-code);\\n\\n    transition: 0.2s all ease;\\n}\\n\\n.demo-data-lines {\\n    max-width: 400px;\\n}\\n\\n.demo-data-line {\\n    display: grid;\\n    grid-template-columns: 100px auto;\\n    gap: .5rem;\\n    text-align: left;\\n}\\n\\n.demo-data-line div:first-child {\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 700;\\n}\\n\\n.demo-data-driver {\\n    margin-right: 1rem;\\n}\\n\\n.demo-data-driver img {\\n    display: block;\\n    max-width: 100px;\\n\\n    visibility: hidden;\\n    opacity: 0;\\n    animation: FadeInBlink .3s cubic-bezier(0.075, 0.82, 0.165, 1) 0.6s forwards;\\n}\\n\\n.demo-data-welcome {\\n    text-align: left;\\n    padding-top: .5rem;\\n}\\n\\n.demo-data-welcome span {\\n    visibility: hidden;\\n    opacity: 0;\\n\\n    animation-name: FadeIn;\\n    animation-timing-function: cubic-bezier(0.075, 0.82, 0.165, 1);\\n    animation-duration: 0.6s;\\n    animation-fill-mode: forwards;\\n}\\n\\n.demo-data-welcome span:nth-child(1) { animation-delay: 1.5s; }\\n.demo-data-welcome span:nth-child(2) { animation-delay: 2.5s; }\\n.demo-data-welcome span:nth-child(3) { animation-delay: 3.2s; }\\n\\n\\n@keyframes MoveCity\\n{\\n  100% {\\n    background-position: -1000px 0;\\n  }\\n}\\n\\n@keyframes MoveCar\\n{\\n    0% {\\n        transform: translateX(-100px);\\n    }\\n    100% {\\n        transform: translateX(960px);\\n    }\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n**결과:**\\n\\n![Dapp 인터페이스 변경 25 단계](../images/build-dapp-interface/dapp-25.gif \\\"Dapp Interface changing step 25\\\")\\n\\n## 결론\\n\\n축하합니다! 이제 dapp을 재 설계하고 애플리케이션 인터페이스 구축을 시작하는 방법에 대한 단서를 찾았습니다.\\n\\n### 체크 아웃 링크\\n\\n- [이 튜토리얼의 전체 코드](https://github.com/positivecrash/wscool21-ui-dapp)\\n- [Discord에서 소통](https://discord.gg/5UWNGNaAUf)\\n- [Robonomics Winter School 2021 일정 및 요약보기](https://robonomics.network/blog/winter-robonomics-school/)\\n- [기여자의 Github](https://github.com/positivecrash)\\n\\n### 연습\\n\\n시간이 더 있거나 기술을 연습하고 싶다면이 데모를 개선 할 수있는 몇 가지 아이디어가 있습니다 :\\n\\n- 좁은 화면에 맞게 UI를 조정하고 dapp을 모바일 친화적으로 만듭니다\\n- **_variables.scss** 파일과 dapp의 템플릿 파일을 편집하여 '날/밤'모드를 추가합니다.\\n- 주소에 '클립 보드에 복사'버튼 추가하십시오\\n- 사용자에게 변경 사항을 알리기 위해 섬세한 팝업을 만듭니다 (예 : '수도꼭지'버튼을 클릭 한 후 단위가 수신되었다는 메시지를 팝업하거나 '실행'섹션에서 발생한 오류를 팝업에서 이동할 수 있음).\\n\\n질문하고 [Discord](https://discord.gg/5UWNGNaAUf)에서 결과를 공유하십시오. `@positivecrash` 메시지에 저를 표시하십시오. \"}},{\"node\":{\"id\":\"0e9ab8f08483d35a8449dd9ff73c3f46\",\"title\":\"6.1과, 최종 사용자를위한 IOT DAPP 구축, 1 부\",\"path\":\"/docs/ko/wschool2021-build-dapp-for-end-users/\",\"content\":\"\\n## 준비하기\\n\\n### Robonomics 노드 출시\\n\\ndApp 개발 및 테스트를 위해 로컬 Robonomics 노드를 사용합니다. 이렇게하려면 컴파일 된 바이너리 파일 https://github.com/airalab/robonomics/releases를 다운로드해야합니다. Ubuntu를 사용할 예정이므로 적절한 버전을 다운로드합니다.\\n\\n아카이브 압축 풀기\\n```sh\\nwget https://github.com/airalab/robonomics/releases/download/v0.24.0/robonomics-ubuntu-0.24.0-x86_64.tar.xz\\ntar -xvf robonomics-ubuntu-0.24.0-x86_64.tar.xz\\nchmod +x robonomics\\n```\\n\\n이제 개발 모드에서 노드를 시작할 수 있습니다. 이렇게하려면 --dev 플래그를 사용하십시오.\\n```sh\\n./robonomics --dev --tmp\\n```\\n\\n> 문제 해결\\n```sh\\n./robonomics purge-chain --dev\\n```\\n\\n### 브라우저 확장\\n\\n브라우저에 키를 저장하기위한 `polkadot {.js}` 확장자가 있습니다. dApp에서는이를 사용하여 거래에 서명합니다.\\n\\n확장 `구글 크롬`과 `Firefox` 현재로 볼 수 있습니다 : https://polkadot.js.org/extension/\\n\\n확장 프로그램을 설치 한 후 새 계정을 만듭니다.\\n![screen1](../images/build-iot-dapps/screen1.png)\\n\\n> 첫 번째 단계가 완료되었습니다.\\n\\n## DAPP 개발\\n\\n### 1 단계\\n\\n> 우리는 vue.js framework를 사용하여 dApp을 작성할 것입니다.하지만 당신이 좋아하거나 할 수있는 것은 무엇이든 사용할 수 있습니다.\\n\\nvue.js로 시작 애플리케이션을 생성하여 dApp 개발을 시작하겠습니다. 여기서 두 가지 방법으로 수행 할 수 있습니다.\\n\\n방법 1 :\\n\\n`Vue cli` 콘솔 유틸리티 사용.\\n이렇게하려면 https://cli.vuejs.org/guide/installation.html을 설치해야합니다.\\nAlso we will need `yarn`. Install it from [here](https://yarnpkg.com)\\n\\n설치 후 터미널에서 명령을 실행할 수 있습니다.\\n\\n```sh\\nvue create mydapp\\n```\\n\\nSetupwizard의 몇 가지 질문에 답하십시오. 버전 Vue 2를 사용하므로 기본 버전 `디폴트 ([Vue 2] babel, eslint)`을 유지합니다. \\n\\n방법 2 :\\n\\n예제와 함께 준비된 git 저장소를 복제하고 1 단계로 전환합니다.\\n\\n```sh\\ngit clone https://github.com/airalab/example-robonomics-dapp.git mydapp\\ncd mydapp\\ngit checkout step-1\\n```\\n\\n결과적으로 이미 시작되어 브라우저에서 열 수있는 시작 응용 프로그램이 설치된 디렉토리를 얻게됩니다.\\n\\n```sh\\nyarn\\nyarn serve\\n```\\n\\n### 2 단계. POLKADOT.JS 시작하기\\n\\n#### 종속성 설치\\n\\ndApp을 Robonomics 체인에 연결하려면 `@polkadot/api` 라이브러리가 있습니다. 그리고 키가있는 확장과 dApp의 상호 작용을 위해 `@polkadot/extension-dapp` 라이브러리가 있습니다. 애플리케이션에 설치해야합니다\\n이 라이브러리 사용에 대한 자세한 내용은 https://polkadot.js.org/docs/ 문서에서 찾을 수 있습니다. \\n\\n방법 1 :\\n\\n```sh\\nyarn add @polkadot/api @polkadot/extension-dapp\\n```\\n\\n`mjs` 확장을 지원하려면 `vue.config.js` 파일도 추가해야합니다.\\n\\n`vue.config.js`\\n```js\\nmodule.exports = {\\n  publicPath: \\\"\\\",\\n  configureWebpack: {\\n    resolve: {\\n      extensions: [\\\"*\\\", \\\".mjs\\\", \\\".js\\\", \\\".vue\\\", \\\".json\\\", \\\".gql\\\", \\\".graphql\\\"]\\n    },\\n    module: {\\n      rules: [\\n        {\\n          test: /\\\\.mjs$/,\\n          include: /node_modules/,\\n          type: \\\"javascript/auto\\\"\\n        }\\n      ]\\n    }\\n  }\\n};\\n```\\n\\n#### Robonomics에 연결\\n\\n먼저 Robonomics 노드에 연결하기위한 매개 변수가있는 구성 파일을 생성 해 보겠습니다. 데모 저장소에는이 파일 `config.template.json`의 예가 있습니다.\\n\\n`src/config.json`\\n```json\\n{\\n  \\\"endpoint\\\": \\\"ws://localhost:9944\\\",\\n  \\\"types\\\": {\\n    \\\"Record\\\": \\\"Vec<u8>\\\",\\n    \\\"Parameter\\\": \\\"Bool\\\",\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\"\\n  }\\n}\\n```\\n\\n이 파일에서는 연결할 노드와 사용자 지정 유형을 나타냅니다.\\n\\n이제 실행중인 노드에 연결하는 스크립트를 작성해야합니다.\\n\\n`src/utils/api.js`\\n```js\\nimport { ApiPromise, WsProvider } from \\\"@polkadot/api\\\";\\nimport config from \\\"../config.json\\\";\\n\\nlet api;\\nexport async function initApi() {\\n  const provider = new WsProvider(config.endpoint);\\n  api = await ApiPromise.create({\\n    provider,\\n    types: config.types\\n  });\\n  return api;\\n}\\n\\nexport function getApi() {\\n  return api;\\n}\\n```\\n\\n확장 프로그램의 키로 거래에 서명 할 수 있도록 확장 프로그램에 연결하는 두 가지 기능과 계정을 초기화하는 기능을 추가해 보겠습니다.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport {\\n  web3Accounts,\\n  web3Enable,\\n  web3FromAddress\\n} from \\\"@polkadot/extension-dapp\\\";\\n\\nasync function getExtension() {\\n  const extensions = await web3Enable(\\\"demo\\\");\\n  if (extensions.length === 0) throw new Error(\\\"no extension\\\");\\n  return extensions[0];\\n}\\n\\nexport async function initAccount(index = 0) {\\n  const timeout = new Promise(resolve => {\\n    setTimeout(resolve, 300);\\n  });\\n  await timeout;\\n  await getExtension();\\n  const accounts = await web3Accounts();\\n  if (accounts.length > 0) {\\n    const injector = await web3FromAddress(accounts[index].address);\\n    api.setSigner(injector.signer);\\n    return accounts[index].address;\\n  }\\n  throw new Error(\\\"no accounts\\\");\\n}\\n\\n...OTHER_CODE...\\n```\\n\\n우리 계좌는 잔액이 0이되지만 약간의 자금이 필요합니다. 그래서 우리는 또 다른 수도꼭지 기능을 만들어야합니다. `--dev` 플래그로 Robonomics를 시작함에 따라 잔액이 많은 `Alice` 계정이 있으므로 거기에서 자금을 요청합니다.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport { Keyring } from \\\"@polkadot/keyring\\\";\\n\\nexport function getBalance(account, cb) {\\n  api.query.system.account(account, ({ data: { free: currentFree } }) => {\\n    cb(currentFree);\\n  });\\n}\\n\\nexport const keyring = new Keyring({ type: \\\"sr25519\\\" });\\n\\nexport async function faucet(address) {\\n  keyring.setSS58Format(api.registry.chainSS58);\\n  const account = keyring.addFromUri(\\\"//Alice\\\");\\n  const tx = api.tx.balances.transfer(address, 1000000000000000);\\n  await tx.signAndSend(account);\\n}\\n\\n...OTHER_CODE...\\n```\\n\\n스크립트 https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/api.js의 전체 버전\\n\\n앱 실행\\n\\n```sh\\nyarn serve\\n```\\n\\n방법 2 :\\n\\n리포지토리를 복제하여 응용 프로그램을 시작하는 경우이 단계를 완료하려면 2 단계로 전환하고 나머지 종속성을 설치하는 것으로 충분합니다.\\n\\n```sh\\ngit checkout step-2\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n### 3 단계. VUE 연결 구성 요소\\n\\n#### 연결\\n\\n우리는 이미 연결을위한 스크립트를 작성했습니다. 이제 인터페이스에서 사용할 수 있습니다. 루트 컴포넌트 `App.vue`에서 작성된 `initApi` 함수를 호출하는 것으로 충분합니다. 그리고 사용자가 연결을 기다리는 동안 지금은 줄임표 형태로 작은 로더를 보여줍니다.\\n\\n방법 1 :\\n\\n구성 요소 템플릿 및 기본 스타일.\\n\\n`src/App.vue`\\n```js\\n<template>\\n  <div id=\\\"app\\\">\\n    <h1>Robonomics dApp</h1>\\n    <div v-if=\\\"load\\\">...</div>\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api\\\">\\n        connected\\n      </template>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style>\\n#app {\\n  font-family: Avenir, Helvetica, Arial, sans-serif;\\n  -webkit-font-smoothing: antialiased;\\n  -moz-osx-font-smoothing: grayscale;\\n  text-align: center;\\n  color: #2c3e50;\\n  margin-top: 60px;\\n}\\nbutton {\\n  font-size: 14px;\\n  padding: 5px 12px;\\n}\\nbutton:hover {\\n  cursor: pointer;\\n}\\ninput {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nselect {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nbutton:focus,\\ninput:focus {\\n  outline: none;\\n}\\n.error {\\n  color: rgb(151, 31, 31);\\n  font-weight: bold;\\n  text-align: center;\\n  margin: 10px 0;\\n}\\n</style>\\n```\\n\\n`initApi` 함수가 호출되는 컴포넌트 코드가 있습니다.\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi } from \\\"./utils/api\\\";\\n\\nexport default {\\n  name: \\\"App\\\",\\n  data() {\\n    return {\\n      load: false,\\n      api: null,\\n      error: null\\n    };\\n  },\\n  created() {\\n    this.init();\\n  },\\n  methods: {\\n    async init() {\\n      try {\\n        this.load = true;\\n        this.api = await initApi();\\n        this.load = false;\\n      } catch (error) {\\n        this.error = error.message;\\n        this.load = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\n#### 잔액이있는 계정\\n\\n이제 계정을 사용하여 잔액을 충전하고 인터페이스에 표시 할 수 있습니다\\n\\n템플릿에 적절한 마크 업을 추가하겠습니다\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n  ...OTHER_CODE...\\n\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api && account\\\">\\n        <p>\\n          Account: <b>{{ account }}</b> {{ balance }} |\\n          <button @click=\\\"faucet\\\">\\n            faucet\\n          </button>\\n        </p>\\n      </template>\\n    </template>\\n\\n  ...OTHER_CODE...\\n\\n</template>\\n```\\n\\n계정 주소 및 잔액에 대한 새 필드를 추가하겠습니다\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\ndata() {\\n  return {\\n\\n    ...OTHER_CODE...\\n\\n    account: null,\\n    balance: 0,\\n\\n    ...OTHER_CODE...\\n\\n  };\\n}\\n\\n...OTHER_CODE...\\n```\\n\\n계정 초기화를 `init` 함수에 추가하고 잔액을 가져와야합니다\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi, initAccount, getBalance, faucet } from \\\"./utils/api\\\";\\nimport { formatBalance } from \\\"@polkadot/util\\\";\\n\\n...OTHER_CODE...\\n\\nasync init() {\\n\\n  ...OTHER_CODE...\\n\\n  this.api = await initApi();\\n  this.account = await initAccount();\\n  getBalance(this.account, balance => {\\n    this.balance = formatBalance(balance);\\n  });\\n\\n  ...OTHER_CODE...\\n\\n}\\n\\n...OTHER_CODE...\\n</script>\\n```\\n\\n버튼을 클릭하면 잔액 보충 기능이 추가됩니다\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\n  methods: {\\n    faucet() {\\n      faucet(this.account);\\n    },\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/step-3/src/App.vue\\n\\n앱 실행\\n\\n```sh\\nyarn serve\\n```\\n\\n방법 2:\\n\\n리포지토리를 복제하여 애플리케이션을 시작한 경우이 단계를 완료하려면 3 단계로 전환하기 만하면됩니다.\\n\\n```sh\\ngit checkout step-3\\nyarn serve\\n```\\n\\n결과적으로 브라우저에이 사진이 표시됩니다\\n\\n![screen2](../images/build-iot-dapps/screen2.png)\\n\\n### 4 단계. 데이터로그\\n\\n체인의 모든 데이터를 저장하고 읽으려면 `datalog` 모듈을 사용합니다\\n\\n이 모듈을 사용하는 방법의 예를 들어 `Datalog.vue` 구성 요소를 만들어 보겠습니다.\\n\\n방법 1 :\\n\\n마크 업에는 블록으로`읽`은 데이터를 읽는 것이 표시됩니다. 그리고 확장 형태로 데이터를 입력 할 수있는 텍스트 입력 양식과 `쓰기` 버튼이 있습니다.\\n\\n`src/components/Datalog.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Datalog</h2>\\n    <button @click=\\\"read\\\">read</button> |\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" />\\n    <button @click=\\\"write\\\" :disabled=\\\"isWrite\\\">write</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n      <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        date: <b>{{ item[0] | dateFormat }}</b>\\n        <br />\\n        data: <b>{{ item[1] | dataFormat }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\n구성 요소 코드. 여기서 트랜잭션을 보내는 주요 포인트는 API를 통해 데이터를 전송하고 계정으로 서명하는 함수를 호출하는 것입니다. `this.api.tx.datalog.record(stringToHex(this.data)).signAsync(this.account);`\\n\\n`src/components/Datalog.vue`\\n```js\\n<script>\\nimport { stringToHex, u8aToString } from \\\"@polkadot/util\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      data: \\\"data string\\\",\\n      log: null,\\n      isWrite: false,\\n      error: \\\"\\\"\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return u8aToString(v);\\n    }\\n  },\\n  methods: {\\n    async read() {\\n      this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n    },\\n    async write() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.datalog\\n          .record(stringToHex(this.data))\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.read();\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Datalog.vue\\n\\n컴포넌트 간 전환을 위해 컴포넌트 출력을 `App.vue`에 추가했습니다.\\n\\n`src/App.vue`\\n```js\\n...OTHER_CODE...\\n\\n<template v-else-if=\\\"api && account\\\">\\n  <p>\\n    Account: <b>{{ account }}</b> {{ balance }} |\\n    <button @click=\\\"faucet\\\">faucet</button>\\n  </p>\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\n\\n...OTHER_CODE...\\n\\nexport default {\\n  name: \\\"App\\\",\\n  components: {\\n    Datalog\\n  },\\n  data() {\\n    return {\\n      tab: \\\"datalog\\\"\\n\\n...OTHER_CODE...\\n</script>\\n\\n<style>\\n...OTHER_CODE...\\n\\n.tabs button {\\n  font-size: 14px;\\n  padding: 10px 20px;\\n  font-weight: bold;\\n  background: #ececec;\\n  border: 1px solid #aaa;\\n}\\n.tabs button:hover {\\n  background: #bfbfbf;\\n}\\n.tabs button:last-child {\\n  border-left: none;\\n}\\n.tabs button.active {\\n  background: #ced5e2;\\n}\\n</style>\\n```\\n\\n앱 실행\\n\\n```sh\\nyarn serve\\n```\\n\\n방법 2:\\n\\n리포지토리를 복제하여 애플리케이션을 시작한 경우이 단계를 완료하려면 4 단계로 전환하기 만하면됩니다\\n\\n```sh\\ngit checkout step-4\\nyarn serve\\n```\\n\\n결과적으로 브라우저에이 사진이 표시됩니다\\n\\n![screen3](../images/build-iot-dapps/screen3.png)\\n\\n### 5 단계. 시작\\n\\n이 기능은 로봇을 시작하고 중지하는 데 사용됩니다. 이 모듈을 사용하는 방법을 보여주기 위해 `Launch.vue` 구성 요소를 작성해 보겠습니다.\\n\\n방법 1 :\\n\\n컴포넌트 템플릿에는 로봇의 주소, ON / OFF 클리 커, 보내기 버튼을 지정할 수있는 양식이 있습니다.\\n\\n`src/components/Launch.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Launch</h2>\\n    <input v-model=\\\"robot\\\" :disabled=\\\"isWrite\\\" placeholder=\\\"Robot address\\\" />\\n    <select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n      <option value=\\\"ON\\\">ON</option>\\n      <option value=\\\"OFF\\\">OFF</option>\\n    </select>\\n    <button @click=\\\"launch\\\" :disabled=\\\"isWrite\\\">launch</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        sender: <b>{{ item.sender }}</b>\\n        <br />\\n        robot: <b>{{ item.robot }}</b>\\n        <br />\\n        parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\n코드는 `Datalog.vue` 구성 요소와 유사합니다. 차이점은 독서에 있습니다. 로봇은 이벤트를 통해 명령을받습니다.\\n\\n`src/components/Launch.vue`\\n```js\\n<script>\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      robot: this.account,\\n      parameter: \\\"ON\\\",\\n      log: [],\\n      isWrite: false,\\n      error: \\\"\\\",\\n      unsubscribe: null\\n    };\\n  },\\n  async created() {\\n    this.unsubscribe = await this.api.query.system.events(events => {\\n      events.forEach(record => {\\n        const { event } = record;\\n        if (event.section === \\\"launch\\\" && event.method === \\\"NewLaunch\\\") {\\n          const sender = event.data[0].toString();\\n          const robot = event.data[1].toString();\\n          const parameter = event.data[2].toHuman();\\n          this.log.push({\\n            sender,\\n            robot,\\n            parameter\\n          });\\n        }\\n      });\\n    });\\n  },\\n  destroyed() {\\n    if (this.unsubscribe) {\\n      this.unsubscribe();\\n    }\\n  },\\n  methods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Launch.vue\\n\\n표시를 위해 `App.vue`에 새 구성 요소 추가\\n\\n`src/App.vue`\\n```js\\n<template>\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch\\n},\\n\\n...OTHER_CODE...\\n```\\n\\n앱 실행\\n\\n```sh\\nyarn serve\\n```\\n\\n방법 2:\\n\\n리포지토리를 복제하여 애플리케이션을 시작한 경우이 단계를 완료하려면 5 단계로 전환하기 만하면됩니다\\n\\n```sh\\ngit checkout step-5\\nyarn serve\\n```\\n\\n결과적으로 브라우저에이 사진이 표시됩니다\\n\\n![screen4](../images/build-iot-dapps/screen4.png)\\n\\n### 6 단계. 데모\\n\\n이 데모에서는 dApp을 통해 시작 및 중지 할 수있는 자동차가 있습니다. 자동차는 여행 중에 통나무를 수집하고 정지 한 후 체인에 저장합니다. 여기서는 별도로 시도한 두 모듈을 함께 사용합니다.\\n\\n로봇 (자동차)의 동작을 모방하기 위해 Robot 클래스를 작성합니다.이 로봇의 계정으로 `Alice` 키를 사용합니다. `Robot` 클래스는 `NewLaunch` 이벤트를 감시하여 스스로 켜고 끕니다. 전원을 켠 후 데이터를 로그에 수집하기 시작하며 데이터 측면에서는 타임 스탬프 일뿐입니다. 그리고 종료 후에는이 로그를 `데이터 로그` 모듈에 저장합니다.\\n\\n방법 1 :\\n\\n`src/utils/robot.js` 파일을 생성합니다. https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/robot.js 파일의 전체 코드.\\n\\n시각화를 위해 시작 버튼, 자동차 애니메이션 및 로그 출력이있는 `Demo.vue` 구성 요소를 만듭니다.\\n\\n`src/components/Demo.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Demo</h2>\\n    <template v-if=\\\"robot\\\">\\n      <h3>Robot: {{ robot.address }}</h3>\\n      <p v-if=\\\"robot.state\\\">Driver: {{ robot.driver }}</p>\\n      <button @click=\\\"run\\\" :disabled=\\\"isWrite\\\">\\n        <template v-if=\\\"!robot.state\\\">run</template>\\n        <template v-else>stop</template>\\n      </button>\\n      <div class=\\\"road\\\">\\n        <div\\n          class=\\\"robot\\\"\\n          :class=\\\"[robot.state ? 'robot-play' : 'robot-stop']\\\"\\n        ></div>\\n      </div>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n        <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n          <b>{{ item[0] | dateFormat }}</b>\\n          <pre>{{ item[1] | dataFormat }}</pre>\\n        </div>\\n      </div>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n  height: 500px;\\n  overflow-y: auto;\\n}\\n.log .row {\\n  margin: 10px;\\n  border-bottom: 1px solid #eee;\\n}\\n.road {\\n  width: 1000px;\\n  margin: 20px auto;\\n  background-color: #eee;\\n  padding: 20px 0;\\n  border: 5px solid #a5a5a5;\\n  border-left: 0;\\n  border-right: 0;\\n  position: relative;\\n}\\n.road::before {\\n  content: \\\" \\\";\\n  width: 1000px;\\n  border-top: 5px dashed #a5a5a5;\\n  position: absolute;\\n  top: 50%;\\n  left: 0;\\n}\\n@keyframes move {\\n  from {\\n    transform: translateX(0);\\n  }\\n  to {\\n    transform: translateX(100%);\\n  }\\n}\\n.robot {\\n  height: 100px;\\n  width: 100px;\\n  color: #fff;\\n  font-weight: bold;\\n  font-style: 14px;\\n  animation: move 30s linear infinite;\\n  border-radius: 0 10px 10px 0;\\n  background: url(\\\"../images/build-iot-dapps/car.png\\\") no-repeat 0 0;\\n  background-size: cover;\\n}\\n.robot-play {\\n  animation-play-state: running;\\n}\\n.robot-stop {\\n  animation-play-state: paused;\\n}\\n</style>\\n```\\n\\n구성 요소 코드. 여기에서 `Robot` 클래스의 인스턴스와 시작 / 중지 기능을 만들어야합니다.\\n\\n`src/components/Demo.vue`\\n```js\\n...OTHER_CODE...\\n\\n<script>\\nimport { u8aToString } from \\\"@polkadot/util\\\";\\nimport Robot from \\\"../utils/robot\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      isWrite: false,\\n      error: \\\"\\\",\\n      robot: null,\\n      log: []\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return JSON.parse(u8aToString(v));\\n    }\\n  },\\n  async created() {\\n    this.robot = new Robot(\\\"//Alice\\\", this.api);\\n    await this.robot.subscribeLog(r => {\\n      this.log = r.reverse().map(item => {\\n        return [item[0], item[1]];\\n      });\\n    });\\n  },\\n  destroyed() {\\n    this.robot.destroy();\\n  },\\n  methods: {\\n    async run() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot.account.address, !this.robot.state)\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Demo.vue\\n\\n`src/images/build-iot-dapps/car.png`, `src/assets/car.png` 에 다른 차 사진을 추가해 보겠습니다. 예 https://github.com/airalab/example-robonomics-dapp/blob/master/src/assets/car.png\\n\\n표시를 위해 `App.vue`에 새 구성 요소 추가\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n      <button @click=\\\"tab = 'demo'\\\" :class=\\\"{ active: tab === 'demo' }\\\">\\n        demo\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\nimport Demo from \\\"./components/Demo\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch,\\n  Demo\\n},\\n\\n...OTHER_CODE...\\n```\\n\\n앱 실행\\n\\n```sh\\nyarn serve\\n```\\n\\n방법 2:\\n\\n리포지토리를 복제하여 애플리케이션을 시작한 경우이 단계를 완료하려면 6 단계로 전환하면됩니다.\\n\\n```sh\\ngit checkout step-6\\nyarn serve\\n```\\n\\n결과적으로 브라우저에이 사진이 표시됩니다\\n\\n![screen5](../images/build-iot-dapps/screen5.png)\\n\\n이것으로 강의를 마칩니다.\\n\\n감사합니다!\"}},{\"node\":{\"id\":\"39610b5684ca73d193df95540df80f6b\",\"title\":\"Connect Vacuum Cleaner\",\"path\":\"/docs/ko/vacuum-connect/\",\"content\":\"\\n## Connect to Home Assistant\\n\\nYou need your vacuum to be connected to Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your vacuum (it must be in connecting mode via a long press of the power button) and follow instructions in the app. For more details look at the user manual of your vacuum.\\n\\nOpen Home Assistant web page with this address:\\n```\\nhttp://<raspberry_address>:8123\\n```\\n\\nGo to `Integrations` tab, press `Add integration` and choose `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Vacuum (Robot vacuum in this example):\\n\\n![vacuum](../images/home-assistant/vacuum_int.png)\\n\\nAfter that you can connect your device to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"ad36c86c1c13e7810317d81e66944a09\",\"title\":\"How to participate in the Wiki translation\",\"path\":\"/docs/ko/translate-wiki/\",\"content\":\"\\nEveryone can contribute to Robonomics. If you want to contribute to the translation of the documentation, you are on the right track: this article will tell you how to do it.\\n\\n## Editing an article\\n\\nIf support for your language has already been added to the site, follow these steps:\\n\\n1. Click the \\\"Edit this page\\\" button on the article you would like to translate. Each article is duplicated in a supported language, even if it has not yet been translated from English.\\n2. Edit by sticking to the existing markup. You can read the article [How to edit WIKI](/docs/en/edit-wiki)\\n3. Submit [PR](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) with the changes you have made.\\n\\n## Adding a new language\\n\\nIf the language you would like to translate the article into has not yet been added, request it from the Robonomics root team by, [creating Issue](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) on GitHub.\\n\\nWhen we add support for the requested language to the site, we will close the Issue, commenting on it if necessary. You will be notified accordingly. This means you can translate pages (they will already be duplicated in English in a folder like `/docs/locale`)\\n\\n## Notes\\n* If you see a way to improve an existing translation of an article, you can also use the PR or Issue on GitHub to request changes\\n* If you make a significant contribution to the translation, you can participate in the rewards program\\n\"}},{\"node\":{\"id\":\"07afc4bf3abb6fb1874a63b5f9c386df\",\"title\":\"How the technical committee is fast-tracking the democracy proposals\",\"path\":\"/docs/ko/technical-committee-fast-track/\",\"content\":\"\\nNote: The screenshots contained in this article were taken using v1.9.0 of Robonomics node implementation, launched in **dev** mode.\\n\\nThe Robonomics Technical Committee can use the **fast-track** function to speed up the proposals enacting in the Democracy module.\\n\\nIf you want to learn more about how Polkadot ecosystem Governance works, then we strongly recommend reading [this article](https://polkadot.network/blog/polkadot-governance/) on the Polkadot blog.\\n\\nThere are six members who make up the Technical Committee for the Robonomics parachain. For our example, let's create the same setup in our dev mode environment:\\n![Techcomm membership](../images/technical-committee-fast-track/techcomm_membership.png)\\n\\nBriefly, the process of fast-tracking a proposal involves a few steps:\\n1. Creating the proposal preimage\\n2. Creating the proposal using the created preimage hash\\n3. Technical committee votes on the created proposal\\n4. Initiating proposal fast-tracking \\n5. Technical committee votes regarding fast-tracking the proposal\\n6. Voting on enacted proposal in the Democracy pallet\\n\\nFor example, let's set the free balance for the account *4EnEc9ZD1jpA1H3HpVzr1v6SGGYGrue2k9Ny5KzFHhti5xQv* to 10 XRT\\n\\n## 1. Creating the proposal preimage\\nOpen the **Governance -> Democracy** page and click the **Submit preimage** button, and then input the required parameters:\\n![Creating preimage](../images/technical-committee-fast-track/creating_preimage.png)\\n\\nAfter all fields are filled, then we need to save generated preimage hash (*0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b* in this example). As we will need it in the next step.\\n\\nAfter saving the preimage hash we can click the **Submit preimage** button in this window and sign the transaction:\\n![Sign submitting preimage](../images/technical-committee-fast-track/sign_submitting_preimage.png)\\n\\n\\n## 2. Creating proposal using created preimage hash\\nOpen the **Governance -> Tech. comm.** page and go to the **Proposals** tab:\\n![Techcomm proposals interface](../images/technical-committee-fast-track/techcomm_proposals_interface.png)\\n\\nThen click **\\\"Submit proposal\\\"** button and create *democracy.externalProposeMajority(0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b)* using your technical committee account and the preimage hash from earlier:\\n![Create techcomm proposal 1](../images/technical-committee-fast-track/create_techcomm_proposal_1.png)\\n\\nAfter signing transaction, the proposal will appear on this page:\\n![Created techcomm proposal 1](../images/technical-committee-fast-track/created_techcomm_proposal_1.png)\\n\\n## 3. Technical committee voting for created proposal\\nOn this step the majority of the technical committee members need to vote **Aye** in this poll. For example:\\n![First vote result](../images/technical-committee-fast-track/first_vote_result.png)\\n\\nThen we can decide to close this vote/poll using the **Close** button. After this action the proposal will appear on the **Democracy** page on the **external** table. You may wonder how can you see the **Fast track** button. This button appears and is active ONLY if we used the **democracy.externalProposeMajority** function:\\n![Created democracy proposal](../images/technical-committee-fast-track/created_democracy_proposal.png)\\n\\n\\n## 4. Initiating proposal fast-tracking\\nGo to the **Governance -> Democracy** page and click on the **Fast track** button. In this newly opened window set the required parameters and click **Fast track**.\\n![Fast track interface](../images/technical-committee-fast-track/fast_track_interface.png)\\n\\nAfter this, the fast-track proposal should now appear on the Technical Committee proposals page:\\n![Techcomm fast-track proposal](../images/technical-committee-fast-track/techcomm_fasttrack_proposal.png)\\n\\n\\n## 5. Technical committee voting for fast-track the proposal\\nNow the technical committee need to vote unanimously for fast-tracking the earlier created proposal. It means that all six members need to vote **Aye**:\\n![Fast-track vote result](../images/technical-committee-fast-track/fasttrack_vote_result.png)\\n\\nAfter this anyone can **Close** this voting, and the proposal will be enacted and moved from **external** table to active **referenda**:\\n![Democracy enacted proposal](../images/technical-committee-fast-track/democracy_enacted_proposal.png)\\n\\n\\n## 6. Voting on enacted proposal in Democracy\\nNow at least one account needs to vote **Aye** on the referenda:\\n![Voting for enacted proposal](../images/technical-committee-fast-track/voting_for_enacted_proposal.png)\\n\\nAs a result we'll get the active referenda with one positive vote on it:\\n![Positive voted referenda](../images/technical-committee-fast-track/positive_voted_referenda.png)\\n\\nAfter the voting period ends, this democracy proposal will be executed. In current example this will be happen in block #3351. Let's wait for this block and check it:\\n![Result](../images/technical-committee-fast-track/result.png)\\n\"}},{\"node\":{\"id\":\"6f2bc01d78533be2f98c69de497b8d92\",\"title\":\"How to Send Launch with Subscription\",\"path\":\"/docs/ko/subscription-launch/\",\"content\":\"\\nIf your address is in devices of any subscription you can send extrinsics with no fee. Lets try to send `launch`.\\n\\nGo to `Developer/Extrinsics`, choose your account (`MAIN` in the picture) and `rws -> call`. Then in `subscriptionID` field write the subscription's owner address (`SUBSCRIPTION OWNER` in the picture) and in the next field choose `launch -> launch`. In the `robot` field write the address you want to send `launch` transaction to(`LIGHTBULB (EXTENTION)` in the picture) and choose the parameter `Yes` or `No`. Then submit transaction:\\n\\n![launch](../images/dev-node/launch.png)\\n\\n\\nNow go to `Network/Explorer` and in the `Recent Events` you will see two events `rws.NewCall` and `launch.NewLaunch`:\\n\\n![events](../images/dev-node/events.png)\"}},{\"node\":{\"id\":\"fa2c3d51048013e98915984eba766605\",\"title\":\"Try It Out\",\"path\":\"/docs/ko/spot-try-it-out/\",\"content\":\"\\nWith this tutorial you will be able to see in simulation what real Spot did.\\n\\n## Requirements\\n\\n* ROS melodic desktop (installation instructions [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n\\n## Install package\\n\\nCreate workspace and clone packages:\\n```bash\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/src\\ngit clone https://github.com/clearpathrobotics/spot_ros.git\\ngit clone https://github.com/ros/geometry2 --branch 0.6.5\\n```\\nOpen the `view_model.launch` file:\\n```bash\\nnano ~/catkin_ws/src/spot_ros/spot_viz/launch/view_model.launch\\n```\\n\\nAnd set `use_sim_time` parameter to `true`, file must look like this:\\n```xml\\n<launch>\\n  <param name=\\\"/use_sim_time\\\" value=\\\"true\\\"/>\\n  <include file=\\\"$(find spot_description)/launch/description.launch\\\"/>\\n\\n  <node name=\\\"joint_state_publisher_gui\\\" pkg=\\\"joint_state_publisher_gui\\\" type=\\\"joint_state_publisher_gui\\\" />\\n\\n  <node name=\\\"rviz\\\" pkg=\\\"rviz\\\" type=\\\"rviz\\\" args=\\\"-d $(find spot_viz)/rviz/model.rviz\\\" />\\n</launch>\\n```\\n\\nThen install dependencies:\\n```bash\\ncd ~/catkin_ws/\\nrosdep install --from-paths src --ignore-src -y\\ncatkin_make\\n```\\n\\n## Run\\n\\nGet example rosbag file:\\n```bash\\nwget -O spot_rosbag.bag https://gateway.ipfs.io/ipfs/QmTDrfMy7Zs7uDLN3KPBC1UYqXNMXBKEwX7ggVmJKAm7Ef\\n```\\n\\nRun rviz with the Spot model:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_model.launch\\n``` \\nThen in a new terminal:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_robot.launch\\n``` \\n![spot_viz](../images/spot/spot.jpg)\\n\\n\\nPlay rosbag file and you will see the robot move:\\n```bash\\nrosbag play spot_rosbag.bag\\n```\\n![spot_viz](../images/spot/spot2.jpg)\"}},{\"node\":{\"id\":\"26f456841079ad985a455ba5e980ef26\",\"title\":\"Troubleshooting\",\"path\":\"/docs/ko/spot-troubleshooting/\",\"content\":\"\\n### Admin socket already exists \\n\\nIf you can't run yggdrasil with this error:\\n```bash\\nAdmin socket /var/run/yggdrasil.sock already exists and is in use by another process\\n```\\nTry to remove file yggdrasil.sock and run it again:\\n```bash\\nsudo rm /var/run/yggdrasil.sock\\n```\\n\\n### Can't get lease\\n\\nIf you can't get lease with this error:\\n```python\\nGeneric exception during check-in:\\nNo lease for resource \\\"body\\\"\\n    (resuming check-in)\\n```\\nOr this error:\\n```python\\nGeneric exception during check-in:\\nbosdyn.api.RetainLeaseResponse (LeaseUseError): \\n    (resuming check-in)\\n```\\n\\nYou need to acquire lease (if you have already done it, try again):\\n```python\\nlease = lease_client.acquire()\\n```\\n\"}},{\"node\":{\"id\":\"4d1bfc8b9b88ffa0f3db265cadc44ed9\",\"title\":\"Lesson 5. Robot service. Camera calibration and \\\"Spot check\\\" procedure\",\"path\":\"/docs/ko/spot-lesson5/\",\"content\":\"\\nIn this lesson you will learn what should you do if you just got the robot: the first run and network setup. Also you will learn how to run the calibration process that should be run monthly.\\n\\n## The challenge\\n\\nCreate and execute Python script implements behaviors described.\\n\\n1. Run \\\"spot check\\\" and save the result of the calibration in a `/home/student/result` directory as a text file.\\n2. Run camera calibration procedure.\\n\\n## Theory\\n\\n### First Run\\n\\nLook at [Startup Procedure](https://support.bostondynamics.com/s/article/Startup-Procedure) page in Documentation.\\n\\n### Networking\\n\\nSpot offers a variety of networking options to support a diverse set of applications and environments. Options include:\\n\\n* Spot as a connected peer. Physicall connection to Spot.\\n\\n* Spot as a WiFi access point. \\n\\n* Spot as a WiFi client. Spot can join an existing WiFi network, and applications can also join the same WiFi network to talk to Spot.\\n\\nFor more information look at [Networking page](https://dev.bostondynamics.com/docs/concepts/networking).\\n\\nSpot Core is connected to the Spot via payload port. Spot Core can be connected to the Internet with Wi-Fi dongle. The setup instructions you can find at [Spot Core Cockpit](https://dev.bostondynamics.com/docs/payload/spot_core_cockpit.html?highlight=spot%20check) page.\\n\\n### Calibration\\n\\nSpot Check is a full calibration of the robot. Also you can run the camera calibration \\n\\n* [run_spot_check](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L164) runs full spot check routine. The robot should be sitting on flat ground when this routine is started. This routine calibrates robot joints and checks camera health.\\n\\n* [run_camera_calibration](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L204). Run full camera calibration routine for robot. This function blocks until calibration has completed. This function should be called once the robot is powered on and standing with his back to the calibration stand at a distance of 1 meter. Calibation process takes about 20 minutes.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"07b5c33ed8a1fe06f977cd155b825708\",\"title\":\"Lesson 4. GraphNav service. Mapping and navigating on the map\",\"path\":\"/docs/ko/spot-lesson4/\",\"content\":\"\\nIn the fourth lesson you will learn how to record and play autonomous missions with GraphNav service.\\n\\n## The challenge\\n\\nThis lesson you can solve the challenge without writing your own Python script.\\n\\n1. Record a map avioding obstacles. You can use WASD remote control tool. Save your mission in `/home/student/result`.\\n2. Move Spot through recorded waypoints. You can use GraphNav service command line tool.\\n\\n## Theory\\n\\nThe Spot SDK includes APIs, client libraries, and examples that support the development of autonomous navigation behaviors for the Spot robot. Collectively, this service is referred to as GraphNav. Maps are recorded and saved and later can be replayed with any robot in your fleet. During the map recording process, you can assign actions and API callbacks to waypoints along the map route.\\n\\nRead [GraphNav Tech Summary](https://dev.bostondynamics.com/docs/concepts/autonomy/graphnav_tech_summary) to learn how it works. [Initialisation](https://dev.bostondynamics.com/docs/concepts/autonomy/initialization) is also important part, it will be usefull in this lesson.\\n\\n> You can view recorded maps with [View Map](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_view_map) example. For that you need to copy the map to your computer:\\n> ```bash\\n> scp -r student@strelka.ygg.merklebot.com:<path_to_the_map_on_spot> <path_to_the_map_to_download>\\n> ```\\n> Also you need [install spot packages](https://github.com/boston-dynamics/spot-sdk/blob/master/docs/python/quickstart.md#install-spot-python-packages).\\n\\nStudy [recording and playing missions](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_command_line) examples in order to use it to record the map and playback the mission recorded.\\nUse [wasd](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/wasd) example to move robot while recording the map.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\\nYou can run remote control tool from examples directory.\\n\\n```console\\ncd ~/spot-sdk/python/examples/wasd\\npython3 wasd.py --username <SPOT_AUTH_USERNAME> --password <SPOT_AUTH_PASSWORD> <SPOT_ADDRESS>\\n```\\n\\nGraphNav command line tool is located at `~/spot-sdk/python/examples/graph_nav_command_line`.\\n\"}},{\"node\":{\"id\":\"f3c73450ed4b03593728a43e794be02c\",\"title\":\"Lesson 3. Find and follow an object, navigate between them\",\"path\":\"/docs/ko/spot-lesson3/\",\"content\":\"\\nIn the third lesson you will learn how to find World Objects and go to them.\\n\\n## The challenge\\n\\nYou start with Spot in the place with some fiducials (a mark on the object) around. Create and execute Python script detects at least two fiducials and moves Spot to each of them within 1 m.\\n\\n## Theory\\n\\nSpot has the World Object Service that provides a way to track and store objects detected in the world around Spot. A world object is considered a higher-level item in the scene that has some amount of semantic information associated with it. More information you can find in [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services#world-object) tab in Spot SDK documentation.\\n\\nUsing world object service you can find fiducials near the Spot. \\n\\n> Spot can find objects around faster if he stands.\\n\\nIn the task you will need find fiducials' coordinates and go to them. You already know how to move to the local coordinates from the [Lesson 2](/docs/en/spot-lesson2.md). The example of how to find a fiducial and it's coordinates is in [fiducial_follow example](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/examples/fiducial_follow/fiducial_follow.py).\\n\\nIn your script, firstly, you need to find fiducial object with World Object Service:\\n\\n```python\\nfiducial_objects = world_object_client.list_world_objects(\\n            object_type=[world_object_pb2.WORLD_OBJECT_APRILTAG]).world_objects\\n```\\n\\nThen get fiducial coordinates in a visual frame:\\n\\n```python\\nfiducial = fiducial_objects[0]\\nvision_tform_fiducial = get_a_tform_b(fiducial.transforms_snapshot, VISION_FRAME_NAME,fiducial.apriltag_properties.frame_name_fiducial.to_proto()\\n```\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"8abc5bf04cd55bad76b8a8241dd17b6a\",\"title\":\"Lesson 2. Remote controlled and programmed motion\",\"path\":\"/docs/ko/spot-lesson2/\",\"content\":\"\\nIn the second lesson you will learn how to use Spot Command services and walk with Spot.\\n\\n## The challenge\\n\\nYou have a list of points with their local coordinates in the `/home/student/lessons` directory. Spot should go through these points. The origin of the local coordinates is in the place where Spot was turned on. On each point Spot should make one of the motions from the following list, then go to the next point. \\n\\nThe list of moves:\\n* To turn around himself\\n* To lie down in pose to change battery\\n* To nod\\n* To change the stance of robot's legs\\n* To go sideways to the next point\\n\\nCreate and execute a Python script that implements behavior described.\\n\\n> You can find Spot local coordinates with:\\n> ```python\\n> get_vision_tform_body(robot_state_client.get_robot_state().kinematic_state.transforms_snapshot)\\n> ```\\n\\n## Theory\\n\\nYou can control Spot with `Robot Command Service`. Firstly you need to build a command to supply it to the command service.\\nSpot SDK has a `RobotCommandBuilder` class for it.\\nFull list of methods and its descriprions you can find [here](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/bosdyn-client/src/bosdyn/client/robot_command.py#L593). \\n\\nIn this lesson you may need to use:\\n\\n* Stand Command\\n\\n```python\\ndef stand_command(params=None, body_height=0.0, \\n                footprint_R_body=geometry.EulerZXY())\\n```\\n\\n* Go to point\\n\\n```python\\ndef synchro_se2_trajectory_point_command(goal_x, goal_y, goal_heading,      \\n                                    frame_name, params=None,\\n                                    body_height=0.0,\\n                                    locomotion_hint=spot_command_pb2.HINT_AUTO,\\n                                    build_on_command=None)\\n```\\n\\nCheck usage example [here](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/frame_trajectory_command/frame_trajectory_command.py).\\n\\n* Velocity Command\\n\\n```python\\ndef synchro_velocity_command(v_x, v_y, v_rot, params=None, body_height=0.0,\\n                            locomotion_hint=spot_command_pb2.HINT_AUTO, \\n                            frame_name=BODY_FRAME_NAME)\\n```\\n\\n* Stance Command\\n\\n```python\\ndef stance_command(se2_frame_name, pos_fl_rt_frame, pos_fr_rt_frame, \\n                        pos_hl_rt_frame,\\n                        pos_hr_rt_frame, accuracy=0.05, \\n                        params=None, body_height=0.0,\\n                        footprint_R_body=geometry.EulerZXY(), \\n                        build_on_command=None)\\n```\\n\\nThe example of use is [here](https://github.com/boston-dynamics/spot-sdk/blob/91ed30607264e795699995d6d7834ba0c8a94d36/python/examples/stance/stance_in_place.py)\\n\\n* Pose to change battery\\n\\n```python\\ndef battery_change_pose_command(dir_hint=1)\\n```\\n\\nExample of building and running velocity command:\\n\\n```python\\nfrom bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder\\nimport time\\n\\ncommand_client = robot.ensure_client(RobotCommandClient.default_service_name)\\ncmd = RobotCommandBuilder.velocity_command(0.5, 0, 0.5)\\ncommand_client.robot_command(cmd, end_time_secs=time.time() + 2)\\n```\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"3a5be9bd87e84c588c01928038357802\",\"title\":\"Lesson 1. Emergency stop, initialization, body position control\",\"path\":\"/docs/ko/spot-lesson1/\",\"content\":\"\\nWelcome to the first lesson!\\n\\nDuring this lesson you will learn how to authorize yourself as a user, get motor power control and send basic commands to Spot.\\n\\nWatch our introductory video if you haven't seen it already:\\n\\nhttps://youtu.be/qdk7BjWJprc\\n\\n## The challenge\\n\\nCreate a Python script controls robot body position. Run your script on Spot to let it execute a sequence of motions:\\n\\n1. Stand-up,\\n2. Trace your initials with it's face (one letter, at least 3 points),\\n3. Sit-down.\\n\\n## Theory\\n\\nRead [Understanding Spot Programming](https://dev.bostondynamics.com/docs/python/understanding_spot_programming) page in Spot SDK documentation.\\nYou need to understand what is `E-Stop` and how make initialization in your Python script in order to to let the robot execute commands.\\n\\nYou can find more detailed information for this lesson in [Base Services](https://dev.bostondynamics.com/docs/concepts/base_services), [Geometry and Frames](https://dev.bostondynamics.com/docs/concepts/geometry_and_frames), [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services) and [E-Stop](https://dev.bostondynamics.com/docs/concepts/estop_service) sections of the Spot SDK documentation.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to SpotCORE by SSH from the terminal,\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Create a script can authenticate in Spot, acquire control (lease) and power on the robot.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file. Spot address is `192.168.50.3`.\\n\\n> In [Taking ownership of Spot (Leases)](https://dev.bostondynamics.com/docs/python/understanding_spot_programming#taking-ownership-of-spot-leases) section use `lease = lease_client.acquire()` before `lease_keep_alive = bosdyn.client.lease.LeaseKeepAlive(lease_client)`\\n\\n3. Try your script with stand-up and sit-down commands. Ensure robot moves as expected,\\n\\n> Make sure you run your script by Python 3 with `python3` command. Command `python` refers to an obsolete Python 2 interpreter.\\n\\n4. Add body position control to your script. Experiment with `bosdyn.geometry.EulerZXY` robot command argument builder in order to identify what yaw, roll and pitch parameters you need to set to solve the challenge. The range of Pitch, Yaw and Roll is from -0.5 to 0.5.\\n\"}},{\"node\":{\"id\":\"f66f5d60bf7722cc13c1865c1b008aa2\",\"title\":\"Lesson 0. Configure and test connection to Spot\",\"path\":\"/docs/ko/spot-lesson0/\",\"content\":\"\\nLet's start establishing connection to the robot.\\nOur goal is to get answers from Spot to our [ping](https://en.wikipedia.org/wiki/Ping_(networking_utility)) signals.\\nWe use Yggdrasil Network to expose Spot to the internet, that means we will need to configure Yggdrasil Network support on your computer first.\\n\\n## 1. Yggdrasil Installation \\n\\nYggdrasil is an early-stage implementation of a fully end-to-end encrypted IPv6 network. Before startitng the lessons you need to install it on your computer.\\n\\n### For Linux: \\nInstallation instructions [here](https://yggdrasil-network.github.io/installation-linux-deb.html).\\n\\n### For MacOS: \\nDownload .pkg file from [here](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4.0-macos-amd64.pkg).\\n\\nLocate the downloaded file in Finder. Right-click it and click Open. Step through the installer as usual.\\n\\n### For Windows:\\nDownload .msi file for [x64 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x64.msi) or for [x32 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x86.msi) and run it with double click.\\n\\n## 2. Open configuration file\\n\\nYou need to add a list of peers (public nodes) to configuration file so that you will be able to connect to Spot. \\n\\n### For MacOS and Linux:\\nFor that, edit the `yggdrasil.conf` file with this command in a terminal:\\n\\n```bash\\nsudo nano /etc/yggdrasil.conf\\n```\\n\\n### For Windows:\\nRun `updateconfig.bat` in `C:/Program Files/Yggdrasil`. \\n\\nThen in `C:/ProgramData/Yggdrasil` open `yggdrasil.conf` with any text editor.\\n\\n> `ProgramData` is a hidden folder, so you need to show hidden data.\\n\\n## 3. Write peers\\n\\nIn the file that you opened find line `Peers:` (it is at the beginning of the file) add 5-6 peers geografically near to you (write them inside the brackets). You can find list of available peers [here](https://github.com/yggdrasil-network/public-peers) or add peers from example below. Example in yggdrasil.conf:\\n\\n```bash\\n  Peers:\\n  [\\n    tcp://213.188.199.150:10010\\n    tcp://213.188.210.9:10010\\n    tcp://[2a09:8280:1::3:312]:10010\\n    tcp://[2a09:8280:1::a:2e2]:10010\\n    tcp://46.151.26.194:60575\\n    tcp://ygg-ru.cofob.ru:18000\\n    tcp://ygg.tomasgl.ru:61933\\n    tls://185.22.60.71:8443\\n    tcp://51.15.118.10:62486\\n    tls://ygg.loskiq.dev:17314\\n    tls://longseason.1200bps.xyz:13122\\n  ]\\n  ```\\nCheck if the peers online in [Puplic Peers](https://publicpeers.neilalexander.dev/).\\n\\n## 4. Save and close configuration file\\n\\n### For Linux and MacOS:\\n\\nPress `Ctrl+x`, then press `y` to save changes and press `Enter`.\\n\\n### For Windows:\\n\\nSave and close file.\\n\\n## 5. Restart service\\n\\n### For Linux:\\n\\nThen restart Yggdrasil using this command:\\n\\n```bash\\nsystemctl restart yggdrasil\\n```\\n### For macOS:\\n\\nUnload the service and run Yggdrasil with changed config file:\\n\\n```bash\\nsudo launchctl unload /Library/LaunchDaemons/yggdrasil.plist\\nsudo yggdrasil -useconffile /etc/yggdrasil.conf\\n```\\n> You will need to do that before every lesson.\\n\\n### For Windows:\\n\\nPress win + r and type `services.msc`, find Yggdrasil service, open it and restart (press Stop and Start).\\n\\n![win-service](../images/spot/spot-windows.jpg)\\n\\n## 6. Check Connection\\n\\nCheck if Yggdrasil works well.\\n\\nFor that try to ping Spot address:\\n```bash\\nping strelka.ygg.khassanov.xyz\\n```\\n> To open terminal in Windows press `Win+R`, type `cmd` and press `Enter`.\\n\\n> On MacOS use `ping6` instead of `ping`.\\n\\nIf you can't ping Spot or you had any errors during the Yggdrasil setup look in [Troubleshooting page](/docs/spot-troubleshooting). If you can't find the solution there, please email spot@robonomics.network.\\n\\n## 7. Create ssh key\\n\\nYou will connect to Spot via ssh, so you need to create ssh keys which you will use in booking lessons.\\n\\nRun following command in the terminal:\\n```bash\\nssh-keygen -t rsa\\n```\\n> SSH Client is available by default only in Windows 10, so if you use older versions you need to install it. For example you can use [PuTTY](https://www.putty.org/).\\n\\nRemember the path to your key (by default it is `/home/<user>/.ssh/id_rsa.pub` or `C:\\\\Users\\\\<user>\\\\.ssh\\\\id_rsa.pub`).\\n\"}},{\"node\":{\"id\":\"f505e47797c44c31806b363ea2042673\",\"title\":\"Setup SLS Gateway\",\"path\":\"/docs/ko/sls-setup/\",\"content\":\"\\nYou can use [SLS Gateway from Robonomics](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01) instead of Xiaomi/Aqara gateways. It works only in your local network and don't send any data to external servers, so you can control all data about your home.\\n\\n1. Ensure that the switches on the back of the gateway are properly positioned. Switches 5 (RX Zigbee to ESP) and 6 (TX Zigbee to ESP) must be in the ON position, the others must be off. \\n\\n2. Connect the type C power cable. The indicator light in the center should turn green.\\n\\n3. The first time it starts up, the gateway will begin distributing Wi-Fi with the SSID 'zgw****' to set up the SLS gateway connection. Connect to this network. Keep in mind that the signal may be quite weak, so it is best to keep the SLS Gateway closer to your computer. \\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). Configure the SLS Gateway to connect to your Wi-Fi by entering the user / pass. After that the gateway's Wi-Fi will shut down. \\n\\n5. Find the local IP of the SLS gateway to access the web interface. You can use the command 'arp -a' or 'nmap'. The resulting link should look like this: 'http://192.168.xxx.xxx'.\\n\\n6. Go to Setting/Hardware and make sure that the settings look like this. Correct the settings if necessary and reboot the gateway:\\n\\n![sls-hardware](../images/home-assistant/sls-hardware.jpg)\\n\\n7. Configure automatically adding devices to Home Assistant. Go to `Zigbee/Config` then tick `Home Assistant MQTT Discovery` and `Clear States`:\\n\\n![sls-hass](../images/home-assistant/sls-hass.png)\\n\\n8. Connect your devices by going to Zigbee/Join. Press the Enable Join button to connect and put your sensors in pairing mode. \\n\\nAfter that connect it to Home Assistant with the following [guide](/docs/sls-gateway-connect)\"}},{\"node\":{\"id\":\"ed94f1ec48d168b801d1f209e0ca522c\",\"title\":\"Connect SLS Gateway to Home Assistant\",\"path\":\"/docs/ko/sls-gateway-connect/\",\"content\":\"\\n## MQTT Brocker\\n\\nFirst, you need to run MQTT brocker on your raspberry with Home Assistant. Connect to it under `ubuntu` login. Then install [Mosquitto Brocker](https://mosquitto.org/):\\n\\n```bash\\nsudo apt update -y && sudo apt install mosquitto mosquitto-clients -y\\n```\\nConfigure username (you can use any username you want) and password (you will be asked to enter the password after the command):\\n```bash\\nsudo mosquitto_passwd -c /etc/mosquitto/passwd <username>\\n```\\nThen edit configuration file:\\n```bash\\nsudo nano /etc/mosquitto/mosquitto.conf\\n```\\nAdd the following at the end of the file:\\n```\\nlistener 1883\\nallow_anonymous false\\npassword_file /etc/mosquitto/passwd\\n```\\n\\nThen restart the service:\\n\\n```bash\\nsudo systemctl restart mosquitto\\n```\\n\\nAnd check the brocker status:\\n```bash\\nsystemctl status mosquitto\\n```\\n\\n![mosquitto](../images/home-assistant/mosquitto.png)\\n\\n## MQTT Integration\\n\\nThen you need to add MQTT integration to Home Assistant. Open web interface then go to `Configuration/Integrations` page and press `Add Integration` button. Find MQTT:\\n\\n![mqtt](../images/home-assistant/mqtt.png)\\n\\nPress on it and set up your brocker with address (localhost), port (1883) and your username and password, then press `submit`:\\n\\n![mqtt1](../images/home-assistant/mqtt1.png)\\n\\nThen press on three dots on MQTT integration and choose `System Options`:\\n\\n![mqtt_options](../images/home-assistant/mqtt_conf.png)\\n\\nAnd check if automatically adding new devices is enabled:\\n\\n![mqtt_dev](../images/home-assistant/add_dev.png)\\n\\n## MQTT on SLS Gateway\\n\\nAlso you need to configure MQTT on SLS Gateway. On your SLS Gateway go to `Settings/Link` -> `MQTT Setup`:\\n\\n![sls-mqtt](../images/home-assistant/sls-mqtt.png)\\n\\nAnd add your brocker address (address of the raspberry with Home Assistant in local network) and port (1883). Also write the topic name (you can choose any). Don't forget to tick `Enable` and `Retain states`:\\n\\n![sls-mqtt1](../images/home-assistant/sls-mqtt1.png)\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\"}},{\"node\":{\"id\":\"1c4d07cd6e236358375137ee4201b25e\",\"title\":\"Introduction\",\"path\":\"/docs/ko/sensors-network-introduction/\",\"content\":\"\\n## What is Sensors Robonomics Network?\\n\\nThe Sensors Robonomics Network is a civilian network of sensors to monitor air quality. Anyone can build their own sensor or use an off-the-shelf solution from the development team and set it up in their home. The sensors use open source software and component wiring diagrams. One of the main sensors used is the PM10 and PM2.5 fine particulate sensor.\\n\\n## What is PM10 and PM2.5?\\n\\nPM10 is a particle of a substance 10 microns or smaller, PM2.5 is a particle 2.5 microns in diameter or smaller. They are constantly floating in the air and do not settle due to their small size, for comparison, the thickness of a human hair is 100 microns. These particles can appear for a variety of reasons, including industrial processes involving the handling of bulk materials or the burning and processing of minerals. They are also emitted after forest fires and dust storms. In addition, they can come from conventional transport when burning fuel or from wear and tear on tires and pavement. Car tires are wiped out into fine crumbs and the wind blows them from the roads all over the city.\\n\\n## Why do we need to measure them?\\n\\nPM10 and PM2.5 are the most dangerous because their size allows them to penetrate the lungs, whereas larger particles tend to linger in the nose or throat. Larger PM10 particles irritate the airways, nose, throat, and eyes. Particles smaller than 2.5 microns can penetrate deep into the lungs and even enter the bloodstream. The effects of these particles on the human body can be devastating:\\n- poisoning by harmful substances entering the bloodstream\\n- allergic reactions\\n- bacterial and fungal infections\\n- cancer\\n- mucous membrane irritation\\n- exacerbation of respiratory symptoms\\n\\n## Why the Sensors Robonomics Network?\\n\\nIn Russia there are other public monitoring networks, such as [Breathe Moscow](https://breathe.moscow/), which are based on the German project [sensor.community](https://sensor.community/ru/). But they use the usual client-server architecture, which in this case is a drawback. Data from all sensors together with user requests go to one server, which cannot always handle such load. So there are situations when the map with data is not available at the most responsible moments. With Sensors Robonomics Network, sensors send data to several different servers, and any user can bring up the Sensors Connectivity server for their sensor and see it on the map. The map itself is not overloaded because it is a decentralized application (DApp) that works directly from your browser with the data that the servers send to the IPFS pub-sub channel.\\n\\n## Sources\\n\\nhttp://www.npi.gov.au/resource/particulate-matter-pm10-and-pm25\\n\\nhttps://habr.com/ru/company/tion/blog/396111/\"}},{\"node\":{\"id\":\"a181409e2368dfaca4fb61497cde6c2c\",\"title\":\"Sensors Connectivity\",\"path\":\"/docs/ko/sensors-connectivity-on-aira/\",\"content\":\"\\nThe Sensors Robonomics Network uses the sensors community module from Robonomics to receive and process data. This module allows any user to raise his own server to receive data from sensors and process it further. Now the developers have launched several such servers and any sensor can send data to them. Running several servers allows to avoid data loss in case of problems with one of them, because sensors from a non-working server will switch to a working one.\\n\\nSensors Connectivity schematic:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSensors Connectivity is a set of stations (station1, station2...), which receive various data, including data from sensors via http protocol. But also it can be sensors connected to the computer via USB or any other data source.\\n\\nData received from the stations are processed by Sensors Connectivity and passed to feeders (feeder1, feeder2...). Feeders send the processed data to the user. In our case the data is sent to the decentralized IPFS channel.\\n\\nMap [sensors.robonomics.network](https://sensors.robonomics.network/) is a decentralized application (DApp) running on your computer. It reads data from the IPFS channel and outputs them to the map. So there is no direct connection between the server collecting the data from the sensors and the map the user sees, the data transfer between them is done via IPFS pubsub, which reduces the load on the servers.\\n\\nIn addition, every once in a while, a file with data from the last time period is saved in IPFS, and the hash of that data is further written to the blockchain. Since IPFS is a content-addressable network, storing data in it guarantees that any change in the data will not go unnoticed, because the address of the desired file contains a hash of its content, which will change if any change in the data occurs. The blockchain is used to pass the hash on to the user, who can use it to retrieve the desired data from the IPFS (which is what happens when requesting to view the history on [sensors.robonomics.network](https://sensors.robonomics.network/)). Since the transaction made cannot be changed, we can be sure that it is the correct hash.\\n\\nThe source code for Sensors Connectivity is available at [link](https://github.com/airalab/sensors-connectivity). To see the data from your server on the map, you need to contact the development team at vm@multi-agent.io and send the ipfs id of your server. \\n\\n# Run your own Sensors Connectivity\\n\\n## Pre-requirements\\n\\nTo build a python package IPFS daemon should be installed. Assyming, you work with linux:\\n\\n```\\nwget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_linux-amd64.tar.gz\\ntar -xzf go-ipfs_v0.8.0_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh \\nipfs init\\n```\\nYou can get IPFS ID with the following command after running IPFS daemon (it is in the `ID` column):\\n\\n```console\\n$ ipfs id\\n{\\n\\t\\\"ID\\\": \\\"QmUZxw8jsRpSx5rWkTpJokPGKvWihTrt5rbRCFXzJ4eCAP\\\",\\n\\t\\\"PublicKey\\\": \\\"CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC/uMV3rLM/C+LOh2DGPo3chr+VM+vyYMKi...\\n    ...\\n```\\n\\n## Installation as PyPi package\\n\\n```\\npip3 install py-sr25519-bindings\\npip3 install sensors-connectivity\\n```\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config is set, you can run the service: (in another terminal)\\n\\n```\\nsensors_connectivity \\\"path/to/your/config/file\\\"\\n```\\n\\nYou will be able to see logs in your console and in `~/.logs`.\\n\\n## Build from source\\n### Requirements\\n\\nTo build a python package fron source [poetry](https://python-poetry.org/docs/#osx--linux--bashonwindows-install-instructions) should be also installed. Assyming, you work with linux:\\n\\n```\\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -\\n```\\n\\n### Get a Package And Installing dependencies\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npoetry install\\n```\\n\\n### Documentation\\n\\nTo prepare a sensor for the work with the package follow instructions on [Robonomics Wiki](/docs/connect-sensor-to-robonomics/).\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\nMake a copy of `default.json` and fill it using description from the article.\\n\\nYou also can set a logging file. The default file for logs is `logging.py`, which uses `console` and `file` handler by default. Pay attention for the `file` handler. The template is stored in `connectivity/config/logging_template.py`. You can cpecify the path (`filename`), where your logs will be stored in (do not forget to create this directory if it doesn't exist). Default path for logs is `~/.logs`. You can figure any other handlers from the [library](https://docs.python.org/3.8/library/logging.html).\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config and log files are setted, you can run the service: (in another terminal)\\n\\n```\\npoetry run sensors_connectivity \\\"path/to/your/config/file\\\"  \\n```\\n\\nIf your log file is setted with `console` handler, you will be able to see logs in your console.\\n\\n### Example of logs:\\n\\n```\\n2022-02-17 19:30:51,248 - INFO - Getting data from the stations...\\n2022-02-17 19:30:51,443 - INFO - airalab-http-v0.8.0: [[], [{MAC: c8e2650f254e, Uptime: 0:00:14.010502, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:30:51,443 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:07,517 - INFO - Frontier Datalog: Data sent to Robonomics datalog and included in block 0x04baf3d81c6d31ec6f3ca3e515b9a6920666ee17cbd66f57130eaa000bad2cd4\\n2022-02-17 19:31:07,519 - INFO - RobonomicsFeeder: {\\\"0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a\\\": {\\\"model\\\": 2, \\\"geo\\\": \\\"53.518475,49.397178000000004\\\", \\\"measurement\\\": {\\\"airtemp\\\": -8.0, \\\"windang\\\": 45.0, \\\"windspeed\\\": 0.13, \\\"windspeedmax\\\": 0.13, \\\"pm10\\\": \\\"\\\", \\\"pm25\\\": \\\"\\\", \\\"timestamp\\\": 1645113602.0}}}\\n2022-02-17 19:31:07,523 - INFO - Checking data base...\\n127.0.0.1 - - [17/Feb/2022 19:31:13] \\\"POST / HTTP/1.1\\\" 200 -\\n2022-02-17 19:31:21,248 - INFO - Getting data from the stations...\\n2022-02-17 19:31:21,429 - INFO - airalab-http-v0.8.0: [[{MAC: c8e2650f254e, Uptime: 0:00:43.818101, M: {Public: 133b761496539ab5d1140e94f644e2ef92c7ac32446dc782bfe1a768379a669a, geo: (1,200), measurements: {'pm10': 27.58, 'pm25': 15.02, 'temperature': 22.93, 'pressure': 758.0687068706872, 'humidity': 39.44, 'timestamp': 1645115473}}}], [{MAC: c8e2650f254e, Uptime: 0:00:43.996539, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:31:21,444 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:51,249 - INFO - Getting data from the stations...\\n```\\n\\n## Troubleshooting\\n\\n### Python.h: No such file or directory\\n\\nIf during running `poetry install` comand you get such error, you need to install the header files and static libraries for python dev. Use your package manager for installation. For example, for `apt` you need to run\\n```\\nsudo apt install python3-dev\\n```\\n> Note:\\npython3-dev does not cover all versions for python3. The service needs at least python3.8, for that you may need to specify the version `sudo apt install python3.8-dev`.\\n\\n[Here](https://stackoverflow.com/a/21530768) you can find examples for other package managers.\\n\\n### Python versions mismatch\\n\\nIf during running `poetry install` comand you get `SolverProblemError`, which says \\\"The current project's Python requirement (3.6.9) is not compatible with some of the required packages Python requirement:..\\\", even though you have older version of python (e.g. python3.8), you may need to specify the python version poetry is using:\\n\\n```\\npoetry env use python3.8\\n```\\n\\n\"}},{\"node\":{\"id\":\"27f89965593bb58ca48d21b0b4e9fed0\",\"title\":\"How to contribute\",\"path\":\"/docs/ko/sensors-connectivity-contribution/\",\"content\":\"\\nIf you find any bugs or would like to propose an improvement, please, open a new issue in one of tre repositories, that you want to contribute.\\n\\n## Main Repositories\\n\\n- [sensors-connectivity](https://github.com/airalab/sensors-connectivity/issues) - Sensors Connectivity server\\n- [sensors-software](https://github.com/LoSk-p/sensors-software/issues) - firmware for the sensor\\n- [airrohr-firmware-flasher](https://github.com/LoSk-p/airrohr-firmware-flasher/issues) - application for microcontroller firmware\\n\"}},{\"node\":{\"id\":\"55922fa125b2d792e70714d6d7391917\",\"title\":\"Securely connect cloud AI to the factory floor\",\"path\":\"/docs/ko/securely-connect-cloud-ai-to-the-factory-floor/\",\"content\":\"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n![](../images/google-play-store.gif)\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n![](../images/Veracity_Protocol_Transaction.gif)\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n![](../images/Veracity_Protocol_Launch.gif)\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"}},{\"node\":{\"id\":\"9801283fe80ea3f02e312a739538c24a\",\"title\":\"How to Run Robonomics Dev Node\",\"path\":\"/docs/ko/run-dev-node/\",\"content\":\"\\nFor testing your applications on Robonomics you may want to need to run it in the dev mode.\\n\\nhttps://youtu.be/04GsVkZ7aVg\\n\\n## Run\\n\\n1. First, you need a binary file, download the archive with it from the latest [release](https://github.com/airalab/robonomics/releases).\\n\\n2. Unpack it and change permissions:\\n\\n```bash\\ntar xf robonomics-1.7.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n3. And run in the dev mode:\\n\\n```bash\\n./robonomics --dev\\n```\\nYou will see the following output:\\n\\n![robonomics](../images/dev-node/robonomics.png)\\n\\n## Get tokens\\n\\nNow you can connect to your local node through the [Polkadot Portal](https://polkadot.js.org/apps/#/explorer).\\n\\nChange the network to `Local Node` in the upper left corner and press `Switch`.\\n\\n![local_node](../images/dev-node/portal.png)\\n\\nThen go to `Accounts`:\\n\\n![accs](../images/dev-node/accs.png)\\n\\nYou can create a new account with the button `Add Account`.\\n\\n![add_acc](../images/dev-node/add_acc.png)\\n\\nDon't forget to save your seed phrase somewhere.\\n\\nAnd use one of existing accounts to send tokens to your new one. Choose for example Alice and press `Send`. Then choose your new account and write the amount of units you want to send and press `Make Transfer`:\\n\\n![send](../images/dev-node/send.png)\"}},{\"node\":{\"id\":\"8177ab729828e19978290965237c4e15\",\"title\":\"ROS-based Projects for Smart Spaces\",\"path\":\"/docs/ko/ros-smart-projects/\",\"content\":\"\\nThroughout its 15 years of development, the Robot Operating System framework was integrated with dozens of [various robotic devices](https://robots.ros.org/), and there are even more packages with algorithms and tools developed by the community. Truth be told, there are now so many projects, and the chaoticness of the description style of their repositories grew so much that it is currently quite problematic to find projects dedicated to a specific subject topic. \\n\\nHere, you’ll find a modest list of ROS-based projects that are dedicated to robots and IoT-devices that are meant for use in a home or office environment. This subject matter is one of the pillars of the Robonomics platform. Our goal is to try and bring these projects on track with Robonomics, from both a technical integration point of view and the perspective of an interesting application of these devices in a robot economy. Feel free to use this list in your search for ideas and inspiration.\\n\\nYou can check out some examples of ROS-projects integrated with Robonomics in the [Playground Overview page](https://wiki.robonomics.network/docs/en/playground-overview/). New projects, including those described here, will be added to the Wiki with time.\\n\\nAs of right now (**April 2021**), Robonomics is oriented towards ROS **Melodic** and **Noetic** versions. Older versions can also work, but there may be additional integration work needed. In the future, support for ROS version 2 will be added.\\n\\nThe main resources to search for ROS repositories and packages can be accessed [here](https://index.ros.org/).\\n\\n## Simulation\\n\\nBefore shifting our attention solely to devices, it’s worth remembering that for a large quantity of ROS projects, there exists an option to test them in a simulation. The most popular tool for the 3D modeling of various robots under ROS is the [Gazebo](http://gazebosim.org/) simulator and its offshoot project, [Ignition](https://index.ros.org/r/ros_ign/). Both simulators allow to model devices in various difficult indoor and outdoor environments, alter the model and environment itself, test control algorithms and debug before moving over to the real device. Also, this is an excellent tool for training and situations when a real device is absent.\\n\\nOverall, this is one of the best options for trying to integrate Robonomics with a ROS device without any expenditures at all. A real scenario would merely require slight code modifications. For Gazebo, Robonomics has a detailed guide that consists of two parts that cover [settings](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) and [integrations](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/) (using a drone as an example). The main challenge is in finding a ready model (for example, [here](https://github.com/osrf/gazebo_models)) for Gazebo or trying to create your own model using the [SDFormat](http://sdformat.org/) developed for simulators. \\n\\n## Single-board computers and other boards\\n\\nSuch boards act as a base component for connecting other devices to ROS, primarily sensors and recording devices (audio, photo, and video recorders, cameras, temperature, pressure, and substance concentration sensors.) because the concept of a smart space implies the creation of a [digital twin](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf) of infrastructure objects. Also, boards can act as the main computing device and controller for constructing a robotic mobile device. A list of boards that support ROS is presented below:\\n\\n| Name and link                                                                                         |                                    Description                                  | ROS version | Last update |\\n|:-----------------------------------------------------------------------------------------------------:|---------------------------------------------------------------------------------|:-----------:|:-----------:|\\n|  [Raspberry Pi](http://wiki.ros.org/ROSberryPi/Installing%20ROS%20Melodic%20on%20the%20Raspberry%20Pi)| single board computer; RaspPi versions 2, 3 and 4 are available                 |   melodic   |     2020    |\\n|    [Arduino](http://wiki.ros.org/rosserial_arduino)                                                   | single board computer                                                           |    noetic   |     2021    |\\n|    [Phidgets](http://wiki.ros.org/phidgets)                                                           | sets of boards, various sensors and devices: Ph sensor, LED, RFID, motor control|    noetic   |     2020    |\\n|   [Sense HAT](https://wiki.ros.org/sensehat_ros)                                                      | shield for RaspPi with a set of sensors and LED                                 |    noetic   |     2020    |\\n|     [Navio2](https://navio2.emlid.com/)                                                               | autopliot shield for RaspPi 2,3,4                                               |    noetic   |     2020    |\\n|     [OpenCR](http://wiki.ros.org/opencr)                                                              | robot controller                                                                |    noetic   |     2021    |\\n\\n## Smart home devices and household robots\\n\\nPresented here are ROS devices whose initial use was for smart homes or offices. The list varies widely, from vacuum cleaners and robotic assistance to home control systems.\\n\\n| Name and link                                             | Description                                                 |          ROS version          | Last update |\\n|:---------------------------------------------------------:|-------------------------------------------------------------|:-----------------------------:|:-----------:|\\n|  [Care-O-bot 4](http://wiki.ros.org/care-o-bot)           | household robot-assistant; a simulation is available        |            melodic            |     2021    |\\n|     [Kobuki](http://wiki.ros.org/kobuki)                  | mobile platform with different use cases (e.g. a waiter)    |            melodic            |     2020    |\\n|    [QTrobot](http://wiki.ros.org/Robots/qtrobot)          | humanoid social robot                                       | kinetic (melodic can be used) |     2020    |\\n|      [Nao](http://wiki.ros.org/nao)                       | humanoid robot; a simulation is available                   |            Melodic            |     2020    |\\n|     [TIAGo](http://wiki.ros.org/Robots/TIAGo)             | service robot with a manipulator; a simulation is available |            kinetic            |     2020    |\\n|     [Roomba](https://github.com/AutonomyLab/create_robot) | robot vacuum cleaner                                        |            melodic            |     2020    |\\n|    [OpenHAB](http://wiki.ros.org/iot_bridge)              | home automation system                                      |            kinetic            |     2017    |\\n|     [Sesame](https://index.ros.org/p/sesame_ros/)         | smart lock                                                  |            melodic            |     2021    |\\n\\n## Mobile platforms and manipulators\\n\\nFirst and foremost, ROS is known for supporting mobile robotics, from drones to industrial manipulators, for which many packages were created that realize simultaneous localization and mapping ([SLAM](http://wiki.ros.org/rtabmap_ros)), solve the direct and inverse task of kinematics, [trajectory planning](https://moveit.ros.org/), and etc. Mobile robotics are gradually penetrating into everyday life, which is why it is certainly interesting to test existing ROS-robots in their use within a smart space. The general list of ROS-based mobile platforms is rather large, which is why here we have selected those that are potentially convenient to operate in a home or office space. \\n\\n| Name and link                                             | Description                                | ROS version | Last update |\\n|:---------------------------------------------------------:|--------------------------------------------|:-----------:|:-----------:|\\n|   [turtlebot](http://wiki.ros.org/turtlebot3)             | mobile platform tailored for ROS           |    noetic   |     2020    |\\n|    [GoPiGo3](http://wiki.ros.org/Robots/gopigo3)          | mobile robot based on RaspPi               |   melodic   |     2020    |\\n|    [LoCoBot](http://wiki.ros.org/locobot)                 | mobile manipulator                         |   kinetic   |     2020    |\\n|   [ROSbot 2.0](http://wiki.ros.org/Robots/ROSbot-2.0)     | mobile platform; a simulation is available |    noetic   |     2021    |\\n|     [VOLTA](http://wiki.ros.org/Robots/Volta)             | mobile platform; a simulation is available |   melodic   |     2021    |\\n|    [evarobot](http://wiki.ros.org/Robots/evarobot)        | mobile platform; a simulation is available |    noetic   |     2020    |\\n|    [Freight](http://wiki.ros.org/Robots/freight)          | mobile platform; a simulation is available |   melodic   |     2021    |\\n|      [PR2](http://wiki.ros.org/Robots/PR2)                | mobile platform; a simulation is available |   melodic   |     2021    |\"}},{\"node\":{\"id\":\"6d910c2012ae1b03fc6c943ee1c752bb\",\"title\":\"Manual start of the Robonomics network, consisting of 3 nodes\",\"path\":\"/docs/ko/robonomics-test-network-manual/\",\"content\":\"\\n**Need to start Robonomics network of N (N> = 2) nodes**\\n\\n## Requirements\\n- Robonomics binary, download latest here: https://github.com/airalab/robonomics/releases/\\n- Subkey tool, download latest here: https://github.com/airalab/robonomics/releases/\\n- 3 servers with root shell. Their ip-addresses in the current instruction will be `165.227.171.127`, `159.89.25.75` and `159.89.30.50`\\n\\n## Introduction\\nIn this tutorial, we will first create all key files locally, and then upload them to their corresponding nodes. \\n\\n## Prepare directories\\nDownload 2 archives from the links above and open the folder with them in the terminal.\\nThen create a directory for the project, unpack the archives into it and go to the created folder:\\n```\\n$ mkdir robonomics_test_network\\n$ tar -xf ./robonomics-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ tar -xf ./subkey-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ cd ./robonomics_test_network/\\n```\\n\\nNext, create a separate **uploads** directory and the necessary subdirectories for each server. All files intended for uploading to a specific server will be stored in these subdirectories:\\n```\\n$ mkdir -p uploads/165.227.171.127/keystore && mkdir -p uploads/165.227.171.127/network\\n$ mkdir -p uploads/159.89.25.75/keystore && mkdir -p uploads/159.89.25.75/network\\n$ mkdir -p uploads/159.89.30.50/keystore && mkdir -p uploads/159.89.30.50/network\\n```\\n\\nAlso, create a **local** folder with **validators** and **sudo** folders, which will store the validators and sudo keys locally.\\n```\\n$ mkdir -p local/validators && mkdir -p local/sudo\\n```\\n\\n## Prepare spec.json\\nUsing the robonomics binary, generate a **spec.json** file, which will use as the basis:\\n```\\n$ ./robonomics build-spec --chain dev > uploads/spec.json\\n```\\n\\nNext, edit this file. At first correct the first three fields, make them look like this:\\n```\\n\\\"name\\\": \\\"Test Robonomics Network\\\",\\n\\\"id\\\": \\\"dev\\\",\\n\\\"chainType\\\": \\\"Live\\\",\\n```\\n\\n### bootNodes\\nThe **bootNodes** field is a list of strings of special format. For each of the bootnodes must write the corresponding string here.\\nTo do this, first create a key file for each bootnode using **subkey**:\\n```\\n$ ./subkey generate-node-key uploads/165.227.171.127/network/secret_ed25519  \\n12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\n$ ./subkey generate-node-key uploads/159.89.25.75/network/secret_ed25519\\n12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\n$ ./subkey generate-node-key uploads/159.89.30.50/network/secret_ed25519\\n12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\n```\\n\\nEach command creates a key file in the specified directory and outputs to stdout the string that will be needed to fill in the **bootNodes** field in the **spec.json** file. As a result, the **bootNodes** section should look like following example:\\n```\\n\\\"bootNodes\\\": [\\n\\\"/ip4/165.227.171.127/tcp/30333/p2p/12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\\",\\n\\\"/ip4/159.89.25.75/tcp/30333/p2p/12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\\",\\n\\\"/ip4/159.89.30.50/tcp/30333/p2p/12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\\"\\n],\\n```\\nThe next 3 fields (telemetryEndpoints, protocolId, properties) can be filled like this:\\n```\\n \\\"telemetryEndpoints\\\": [\\n     [\\n       \\\"/dns4/telemetry.polkadot.io/tcp/443/x-parity-wss/%2Fsubmit%2F\\\",\\n       0\\n     ]\\n ],\\n\\\"protocolId\\\": \\\"txrt\\\",\\n\\\"properties\\\": {\\n    \\\"ss58Format\\\": 32,\\n    \\\"tokenDecimals\\\": 9,\\n    \\\"tokenSymbol\\\": \\\"TXRT\\\"\\n},\\n```\\nFurther up to the **palletBalances** field leave unchanged.\\n\\n\\n### palletBalances\\nTo fill the palletBalances field create **the number of nodes + 1** (the last key is for **sudo**) keys. This can be done using **subkey**, in the file name must specify **SS58 Address** from the generated key, in the file content must specify **seed** phrase in quotes. \\n\\nExample creating one key.\\n - Generate key:\\n    ```\\n    $ ./subkey -n robonomics generate\\n    Secret phrase `display cargo domain april joy still bundle notice bridge pencil fat approve` is account:\\n      Network ID/version: substrate\\n      Secret seed:        0x0275ab9bce53e4359184f02112943162c708f483009e0b7b3ba63549c5c2e514\\n      Public key (hex):   0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      Account ID:         0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      SS58 Address:       4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n - Create key file:\\n    ```\\n    $ touch ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx && echo '\\\"display cargo domain april joy still bundle notice bridge pencil fat approve\\\"' | tee ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n  \\nCommand template for creating a validator key file:  \\n`touch ./local/validators/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/validators/**SS58_Address**`\\n\\nCommand template for creating a sudo key file:   \\n`touch ./local/sudo/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/sudo/**SS58_Address**`\\n\\nThree keys are stored in the **local/validators** folder and one in the **local/sudo** folder. As a result, the following content should appear in the **local** directory:\\n```\\n./local/\\n├── sudo\\n│   └── 4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\n└── validators\\n    ├── 4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ├── 4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\n    └── 4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\n```\\n\\nNow fill the palletBalances section in the spec.json file with these keys.\\nAs a result, it should look like this:\\n```\\n\\\"palletBalances\\\": {\\n  \\\"balances\\\": [\\n    [\\n      \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Generated validator 1 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Generated validator 2 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Generated validator 3 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\",    <-- Generated sudo key\\n      1000000000000000000\\n    ],\\n  ]\\n},\\n```\\nThe values that were previously presented in the palletBalances section must be deleted.\\n\\n### palletSession\\nNext step is the **palletSession** section in file **spec.json**. First let's describe its format. \\nThis section contains the \\\"keys\\\" field, that contains a list of three lists (equals of nodes count). Each of these lists looks like follows:\\n```\\n[\\n    \\\"%validator_SS58_address%\\\",\\n    \\\"%validator_SS58_address%\\\",\\n    {\\n        \\\"babe\\\": \\\"%sr25519_babe_SS58_address%\\\",\\n        \\\"im_online\\\": \\\"%sr25519_im_online_SS58_address%\\\"\\n        \\\"authority_discovery\\\": \\\"%sr25519_authority_discovery_SS58_address%\\\",\\n        \\\"grandpa\\\": \\\"%ed25519_grandpa_SS58_address%\\\",\\n    }\\n]\\n```\\n**%validator_SS58_address%** is the validator key that was generated for each node in the **palletBalances** section of this manual. Just copy it twice for each node.\\n\\nTo fill in the remaining 4 lines for each node, you need to create 4 key files for each node and store them in the **keystore** folders.\\nAs key files are generated, you can fill **palletSession**.\\n\\nEach key file must contain a **seed** phrase in quotes.\\nMaking of the name of each key file require separate consideration.\\nThe name of each key file is formed as **prefix** + **account_id without leading hexadecimal zero**.\\n\\nPrefixes matching:  \\n>      grandpa: '6772616e'  \\n>      babe: '62616265'\\n>      im_online: '696d6f6e'  \\n>      authority_discovery: '61756469'  \\n\\nAn example of creating keys for one node:\\n- Creating a **babe** (prefix *62616265*) key file.   \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  >  Secret phrase **cover once garment syrup income chair elder business diary frozen rack damage** is account:  \\n  >\\n  >  Network ID/version: `substrate`\\n  >\\n  >  Secret seed:        `0x90ddeee3a9a0c464572021d311c245eefc41f9a59c739faefda47efcf4755677`\\n  >\\n  >  Public key (hex):   `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  >\\n  >  Account ID:         `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  > \\n  >  SS58 Address:       `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`\\n  \\n ```\\n $ touch uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 && echo '\\\"cover once garment syrup income chair elder business diary frozen rack damage\\\"' | tee ./uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 \\n ```\\n This command creates a **babe** key file for the `165.227.171.127` node. To fill in **spec.json**, need to take from this output the value **SS58 Address**: `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`. This address need to insert instead of `%sr25519_babe_SS58_address%` in the above **palletSession** template.\\n   \\n **babe** key file creation command template:  \\n`touch ./uploads/[node_ip]/keystore/62616265+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/62616265+[Account_ID]`  \\n\\nAs you can see, the name of the babe key file is the sum of two substrings: `babe prefix ('62616265')`, and the `account_id` of the generated key, without the leading zero (`fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`). \\n  Note that the keys `babe, im_online, authority_discovery` are generated with the indication `--sr25519`.  \\n  **grandpa** key have to generate with the indication `--ed25519`.\\n \\n\\n- Creating an **im_online** (prefix *696d6f6e*) key file.  \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  > Secret phrase **envelope truly balance turkey undo casual waste skill average ordinary gun split** is account:\\n  >\\n  >   Network ID/version: `substrate`\\n  > \\n  >   Secret seed:        `0x8a19df08feeff9f1fa3581902ca22a305252aea32e284d32f10e990d00bb8926`\\n  > \\n  >   Public key (hex):   `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   Account ID:         `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   SS58 Address:       `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt`\\n   \\n  ```\\n  $ touch uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09 && echo '\\\"envelope truly balance turkey undo casual waste skill average ordinary gun split\\\"' | tee uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n  ```\\n  **im_online** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID]`\\n  \\n  **spec.json**: `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt` need to insert instead of `%sr25519_im_online_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating an **authority_discovery** (prefix *61756469*) key file.\\n   ```\\n   $ ./subkey --sr25519 -n robonomics generate\\n   ```\\n   > Secret phrase **boy harsh because omit equip atom apart spring undo explain walnut crystal** is account:\\n   >\\n   > Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0x27838c9ea0524353da3717862ef0ecef123f40e81b73bb5ef377d12b47d1c543`\\n   > \\n   >   Public key (hex):   `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   > \\n   >   Account ID:         `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   >  \\n   >   SS58 Address:       `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t`\\n   \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07 && echo '\\\"boy harsh because omit equip atom apart spring undo explain walnut crystal\\\"' | tee uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n   ```\\n  **authority_discovery** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/61756469+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/61756469+[Account_ID]` \\n  \\n   **spec.json**: `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t` need to insert instead of `%sr25519_authority_discovery_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating a **grandpa** (prefix *6772616e*) key file.\\n   ```\\n   $ ./subkey --ed25519 -n robonomics generate\\n   ```\\n   > Secret phrase **squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle** is account:\\n   > \\n   >   Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0xef0a9f51a4da7b789c0a25d39b44428d4da7262cc3fe013d4383b45216e8b83e`\\n   >  \\n   >   Public key (hex):   `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   >  \\n   >   Account ID:         `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   > \\n   >   SS58 Address:       `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa`\\n    \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009 && echo '\\\"squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle\\\"' | tee uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n   ```\\n   **grandpa** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/6772616e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/6772616e+[Account_ID]`\\n   \\n   **spec.json**: `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa` need to insert instead of `%sr25519_grandpa_SS58_address%` in the above **palletSession** template.\\n   \\n   \\n**Now 4 key files have been created for one node. Need to repeat this actions for the remaining two nodes.**\\n\\nYou should get the following **uploads** directory structure after creating all the keys:\\n```\\n./uploads/\\n├── 165.227.171.127\\n│   ├── keystore\\n│   │   ├── 617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n│   │   ├── 62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43\\n│   │   ├── 6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n│   │   └── 696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n│   └── network\\n│       └── secret_ed25519\\n├── 159.89.25.75\\n│   ├── keystore\\n│   │   ├── 617564692ac9bd30c0168fa623cfd66abb4327992d900a652bcbb238b740bdde497a565f\\n│   │   ├── 626162657cd666bb540c41cb33896a34d7413ffb86fcef1eddddfcd4edb325166df6335d\\n│   │   ├── 6772616e084402349bc08ef90c2837e8e3f12ebe8bd4ab86809e9ee5f4f8ca26e73a0518\\n│   │   └── 696d6f6e6ed2d507c0283ae869ba6514975bd8765eb8e06abd22afc09e8f36ef3950a116\\n│   └── network\\n│       └── secret_ed25519\\n└── 159.89.30.50\\n|   ├── keystore\\n|   │   ├── 61756469f20a4e16a0ee79431d6f9a70c38892c7532ad1347c2226d43ef6ffe8966e9b30\\n|   │   ├── 62616265e695aa459dbfd42bea7ed3b87970f164f34b6fee4d5a831ffbecd89eb9769b26\\n|   │   ├── 6772616eadef59f896ea6b94bcd4519be8cc4b70263fc318cec1a3be14850bbc22117c34\\n|   │   └── 696d6f6e2cb4dc8f8a67f477da15045ca40ef3861a2a6b2034ae0c64a179b4431341ea2c\\n|   └── network\\n|       └── secret_ed25519\\n└── spec.json\\n```\\n\\nThe palletSession section should look like this:\\n```\\n\\\"palletSession\\\": {\\n    \\\"keys\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t\\\",\\n                \\\"babe\\\": \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",\\n                \\\"grandpa\\\": \\\"4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa\\\",\\n                \\\"im_online\\\": \\\"4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt\\\"\\n            }\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4F6daoG2gBXRLvbT4mVRajExZdZBHH7APmX3wDuLYJyzxHSS\\\",\\n                \\\"babe\\\": \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",\\n                \\\"grandpa\\\": \\\"4G3Ai6BGUjqtCoM2aTvWyR19gQ8WZiNnh1KFM47RyiYTwkE6\\\",\\n                \\\"im_online\\\": \\\"4FHA7gzKfSLvd8jP85JUCWV6RyeRLm331KHcjnynGx7TWm7D\\\"\\n            }\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address                        \\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4CqzJFkdSZg52PfV6Fd4gJ3vPLmRu1HGuPvNivjJ8dDWaz1a\\\",\\n                \\\"babe\\\": \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",\\n                \\\"grandpa\\\": \\\"4Cqi4rG3CzWRZairhZX4isT8qG2jyz9fGDXJMrP6uBYkrft5\\\",\\n                \\\"im_online\\\": \\\"4C7V6R59cZVbabExqgWvHVE1vj1E1cV42SZr8d8zZD3gmsqk\\\"\\n            }\\n        ]\\n    ]\\n},\\n```\\n\\n### palletStaking\\n**palletStaking** must be filled in as follows:\\n```\\n\\\"palletStaking\\\": {\\n    \\\"historyDepth\\\": 84,\\n    \\\"validatorCount\\\": 10,\\n    \\\"minimumValidatorCount\\\": 2,\\n    \\\"invulnerables\\\": [\\n        \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",     <-- Validator 1 SS58 Address\\n        \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",     <-- Validator 2 SS58 Address\\n        \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\"      <-- Validator 3 SS58 Address\\n    ],\\n    \\\"forceEra\\\": \\\"NotForcing\\\",\\n    \\\"slashRewardFraction\\\": 100000000,\\n    \\\"canceledPayout\\\": 0,\\n    \\\"stakers\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",  <-- Validator 1 SS58 Address\\n            \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",  <-- Validator 1 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",  <-- Validator 2 SS58 Address\\n            \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",  <-- Validator 2 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",   <-- Validator 3 SS58 Address\\n            \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",   <-- Validator 3 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ]\\n    ]\\n},\\n```\\nThe example specified in which fields what values should be substituted.\\n\\n### palletSudo\\nIn the rest of the **spec.json** file, you need to change only the contents of **palletSudo**, substituting the previously generated **sudo** address there:\\n```\\n            \\\"palletBabe\\\": {\\n                \\\"authorities\\\": []\\n            },\\n            \\\"palletGrandpa\\\": {\\n                \\\"authorities\\\": []  \\n            },\\n            \\\"palletImOnline\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletAuthorityDiscovery\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletTreasury\\\": {},\\n            \\\"palletElectionsPhragmen\\\": {\\n                \\\"members\\\": []\\n            },\\n            \\\"palletCollectiveInstance1\\\": {\\n                \\\"phantom\\\": null,\\n                \\\"members\\\": []\\n            },\\n            \\\"palletSudo\\\": {\\n                \\\"key\\\": \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\"   <-- sudo address\\n            }\\n        }\\n    }\\n}\\n```\\n\\n## systemd unit file\\nNow create systemd unit file:\\n```\\n$ touch ./uploads/robonomics.service\\n```\\n\\nAnd fill it like this:\\n```\\n[Unit]\\nDescription=robonomics\\nAfter=network.target\\n\\n[Service]\\nUser=root\\nGroup=root\\nType=users\\nWorkingDirectory=/root\\nRestart=on-failure\\nExecStart=/usr/bin/robonomics  --chain /etc/substrate/spec.json --name ${HOSTNAME} --validator\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\nAs you can see from the \\\"ExecStart\\\" line, the **robonomics** binary is stored in the **/usr/bin/** directory, and the **spec.json** file is stored in the **/etc/substrate/** directory.\\n\\n## Uploading files\\nThe following one-line command uploads all files to the required directories on the servers. It is important that there are no other folders in the **uploads** directory, except for the folders with the ip-addresses of the nodes:\\n```\\n$ \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n    ssh root@\\\"$IP\\\" \\\"mkdir -p /root/.local/share/robonomics/chains/dev\\\" && \\\\\\n    scp -r ./uploads/$IP/* root@$IP:/root/.local/share/robonomics/chains/dev/ && \\\\\\n    scp ./uploads/robonomics.service root@$IP:/etc/systemd/system/ && \\\\\\n    scp ./robonomics root@$IP:/usr/bin/ && \\\\\\n    ssh root@$IP \\\"mkdir -p /etc/substrate\\\" && \\\\\\n    scp ./uploads/spec.json root@$IP:/etc/substrate/ \\\\\\n; done\\n```\\n\\n## Network launch\\nNow connect to all nodes, enable and start the **robonomics.service** unit:\\n```\\n$  \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n   ssh root@$IP \\\"systemctl enable robonomics.service && systemctl start robonomics.service\\\" \\\\\\n; done\\n```\\nAfter starting the service on all three nodes, you can view the node logs using **journalctl**. \\nTo do this, you can connect to any existing server via ssh and run the following command:\\n```\\n$ journalctl -u robonomics.service -f\\n```\\n![Robonomics Chart](../images/robonomics-test-network-manual/result-journalctl.jpg \\\"Robonomics Network journalctl stdout\\\")\\n\"}},{\"node\":{\"id\":\"7fddb65d3ee32fae5da5cc00a7b07173\",\"title\":\"Robonomics + Prometheus + Grafana\",\"path\":\"/docs/ko/robonomics-prometheus-grafana/\",\"content\":\"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](../images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](../images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](../images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](../images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](../images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](../images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](../images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](../images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](../images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"}},{\"node\":{\"id\":\"19c8ab0b87ab0d8ca0afc684ba6d6cf8\",\"title\":\"Robonomics Liability\",\"path\":\"/docs/ko/robonomics-liability/\",\"content\":\"\\nThe package is responsible for receiving `New Liability` events (`listener` node) and playing topics from `objective` field (`executor` node).\\nThe launch file also include `ipfs_channel` node and `signer` node.\\n\\n## ROS Parameters\\n\\n### ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~web3_ws_provider\\n\\nWeb3 WebSocket provider address. The type is `string`, defaults to `ws://127.0.0.1:8546`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~enable_executor\\n\\nEnable or disable executor node. If it's `false`, no topics from objective would be published. The type is `boolean`, defaults to `true`\\n\\n### ~master_check_interval\\n\\nPeriod (in seconds) to check master for new topic publications. It's necessary for the Recorder, which records all the topics a CPS publishes. The type is `double`, defaults to `0.1`\\n\\n### ~recording_topics\\n\\nList of topics name separated by comma. It allows you to specify which topics would be recorded. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Subscribed topics\\n\\n### /liability/infochan/eth/signing/demand (robonomics_msgs/Demand)\\n\\n[robonomics_msgs/Demand](/docs/market-messages#demand) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/offer (robonomics_msgs/Offer)\\n\\n[robonomics_msgs/Offer](/docs/market-messages#offer) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/result (robonomics_msgs/Result)\\n\\n[robonomics_msgs/Result](/docs/market-messages#result) message to sign and send further to IPFS channel\\n\\n\\n## Published topics\\n\\n### /liability/infochan/incoming/demand (robonomics_msgs/Demand)\\n\\nContains a [robonomics_msgs/Demand](/docs/market-messages#demand) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/offer (robonomics_msgs/Offer)\\n\\nContains a [robonomics_msgs/Offer](/docs/market-messages#offer) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/result (robonomics_msgs/Result)\\n\\nContains a [robonomics_msgs/Result](/docs/market-messages#result) message which was read from IPFS channel\\n\\n### /liability/incoming (robonomics_liability/Liability)\\n\\nContains all the information about the last created [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)\\n\\n### /liability/ready (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)is ready for execution\\n\\n### /liability/complete (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg) has done its job\\n\\n### /liability/finalized (std_msgs/String)\\n\\nSignals when a liability has been finalized\\n\\n## Services\\n\\n### /liability/start (robonomics_liability/StartLiability)\\n\\nThe service tells executor to play topics from the objective. It's required to pass a liability address ([robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)), which you can get from `/liability/ready` topic\\n\\n### /liability/finish (robonomics_liability/FinishLiability)\\n\\nCPS should call the service after performing the task. The input is [robonomics_liability/FinishLiability](/docs/robonomics-liability-messages#robonomics_liabilityfinishiabilitysrv)\\n\\n### /liability/restart (robonomics_liability/StartLiability)\\n\\nThe service allows to restart a liability after the system shutdown. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/resume (robonomics_liability/StartLiability)\\n\\nThe service allows to resume a liability from the last timestamp available in the persistence store. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/read (robonomics_liability/ReadLiability)\\n\\nThe service returns all the data about a liability by its address. The input is [robonomics_liability/ReadLiability](/docs/robonomics-liability-messages#robonomics_liabilityreadliabilitysrv)\\n\"}},{\"node\":{\"id\":\"3ec7d86a994ca59cb836ef81b3868e03\",\"title\":\"Robonomics Liability Messages\",\"path\":\"/docs/ko/robonomics-liability-messages/\",\"content\":\"\\n## robonomics_liability/Liability.msg\\n\\n| Field        \\t| Type                                                                         \\t| Description                                    \\t|\\n|--------------\\t|------------------------------------------------------------------------------\\t|------------------------------------------------\\t|\\n| address      \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The Liability’s address                        \\t|\\n| model        \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model Identifier                \\t|\\n| objective    \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model parameters in rosbag file \\t|\\n| result       \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| Liability result hash                          \\t|\\n| promisee     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisee address                           \\t|\\n| promisor     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisor address (usually CPS)             \\t|\\n| lighthouse   \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The address of lighthouse your CPS works on    \\t|\\n| token        \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Operational token address                      \\t|\\n| cost         \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| CPS behavioral model implementation cost       \\t|\\n| validator    \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Observing network address                      \\t|\\n| validatorFee \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| Observing network commission                   \\t|\\n\\n## robonomics_liability/StartLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                                           |\\n|---------  |-----------------  |-----------------------------------------------------  |\\n| address   | std_msgs/String   | The address of Liability you are willing to execute   |\\n\\n**Response**\\n\\n| Field     | Type              | Description                               |\\n|---------  |-----------------  |------------------------------------------ |\\n| success   | std_msgs/Bool     | Weather or not the Liability was started  |\\n| msg       | std_msgs/String   | Status of launch                          |\\n\\n## robonomics_liability/FinishLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                           |\\n|---------  |-----------------  |------------------------------------   |\\n| address   | std_msgs/String   | The address of Liability to finish    |\\n| success   | std_msgs/Bool     | The status of execution               |\\n\\n**Response**\\n\\nThe response is empty\\n\\n## robonomics_liability/ReadLiability.srv\\n\\n**Request**\\n\\n| Field     | Type                                                                          | Description                   |\\n|---------  |------------------------------------------------------------------------------ |----------------------------   |\\n| address   | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)  | The address of a liability    |\\n\\n**Response**\\n\\n| Field         | Type                                                                  | Description           |\\n|-----------    |---------------------------------------------------------------------  |---------------------  |\\n| read          | std_msgs/Bool                                                         | Status of execution   |\\n| liability     | [robonomics_liability/Liability](#robonomics_liabilityliabilitymsg)   | Liability             |\\n\"}},{\"node\":{\"id\":\"aafc80c2bd6acdacde60302e13dda3ee\",\"title\":\"로노미크스-JS\",\"path\":\"/docs/ko/robonomics-js/\",\"content\":\"\\n[Robonomics-js](https://github.com/airalab/robonomics-js) 는 Robonomics 네트워크 작업을위한 간단한 자바 스크립트 라이브러리입니다.\\n\\n## 설치\\n\\n```\\nnpm install robonomics-js --save\\n```\\n\\n또는/나\\n\\n```\\nyarn add robonomics-js\\n```\\n\\n### 의존성\\n\\n* [Web3](https://github.com/ethereum/web3.js/) 버전 1.2.4\\n* [Ipfs](https://github.com/ipfs/js-ipfs) 버전 0.34.0\\n\\n\\n## 용법\\n\\nRobonomics 인스턴스를 만듦\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\n```\\n\\n### 옵션\\n\\n속성의 대상 :\\n\\n```\\noptions.web3\\n```\\n\\n[web3.js](https://github.com/ethereum/web3.js/)인스턴스 :\\n\\n```JavaScript\\n// metamask\\nconst options = {\\n  web3: new Web3(window.ethereum),\\n  ...\\n};\\n\\n// infura\\nconst options = {\\n  web3: new Web3(\\n    new Web3.providers.WebsocketProvider(\\n      \\\"wss://mainnet.infura.io/ws/v3/0b2f2a5026264b57b6d698b480332e89\\\"\\n    )\\n  ),\\n  ...\\n};\\n```\\n\\n```\\noptions.messageProvider\\n```\\n\\npubsub 지원과 함께 [js-ipfs](https://github.com/ipfs/js-ipfs) 노드를 사용하는 MessageProviderIpfs의 인스턴스입니다 \\n\\n```JavaScript\\nconst ipfs = new Ipfs({\\n  repo: 'robonomics-example',\\n  relay: {\\n    enabled: true,\\n    hop: {\\n      enabled: true\\n    }\\n  },\\n  EXPERIMENTAL: {\\n    pubsub: true\\n  },\\n  config: {\\n    Addresses: {\\n      Swarm: [\\n        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star',\\n        '/dns4/1.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/2.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/3.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/'\\n      ]\\n    },\\n    Bootstrap: [\\n      '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',\\n      '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',\\n      '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',\\n      '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',\\n      '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',\\n      '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',\\n      '/dns4/1.pubsub.aira.life/tcp/443/wss/ipfs/QmdfQmbmXt6sqjZyowxPUsmvBsgSGQjm4VXrV7WGy62dv8',\\n      '/dns4/2.pubsub.aira.life/tcp/443/wss/ipfs/QmPTFt7GJ2MfDuVYwJJTULr6EnsQtGVp8ahYn9NSyoxmd9',\\n      '/dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw'\\n    ]\\n  }\\n})\\n\\nconst options = {\\n  messageProvider: new MessageProviderIpfs(ipfs),\\n  ...\\n};\\n```\\n\\n```\\noptions.account\\n```\\n\\n이것은 메시지에 서명하는 데 사용되는 계정 개체입니다. 계정 주소 (잠금 해제해야 함) 또는 개인 키 (주어진 개인 키에서 주소가 복구 됨)를 지정해야합니다.\\n\\n옵션 `isSignPrefix`는 접두어를 추가해야하는지 여부를 알려줍니다. 디폴트 `true`입니다.\\n\\n```JavaScript\\nconst options = {\\n  account: {\\n    address: '0x0000000000000000000000000000000000000000',\\n    privateKey: '0x0000000000000000000000000000000000000000000000000000',\\n    isSignPrefix: true\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.ens\\n```\\n\\n이것은 `ens`계약 객체입니다. 이것은 필수가 아닙니다. 필요한 경우 네트워크가 메인 넷으로 설정되지 않은 경우 계약의 `address`를 지정할 수 있습니다. `suffix`는 사이드 체인의 경우 `sid`, 메인 넷의 경우 `eth`일 수 있습니다. `eth`가 디폴트입니다. `version`은 Robonomics Network의 버전입니다. 디폴트는 배포된 최신 버전입니다.\\n\\n```JavaScript\\nconst options = {\\n  ens: {\\n    address: '0x314159265dD8dbb310642f98f50C066173C1259b',\\n    suffix: 'eth',\\n    version: 5\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.lighthouse\\n```\\n\\n등대의 ENS 이름이며 필요하지 않습니다. 디폴트는 `airalab.lighthouse.5.robonomics.eth`입니다. `airalab`과 같이 이름의 첫부분 만 지정할수 있습니다.\\n\\n```JavaScript\\nconst options = {\\n  lighthouse: 'airalab.lighthouse.5.robonomics.eth',\\n  ...\\n};\\n```\\n\\n전체 초기화가 될때까지 기다려야합니다\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\nrobonomics.ready().then(() => {\\n  console.log('Robonomics instance ready')\\n})\\n```\\n\\n## API\\n\\n### 메시지\\n\\n#### 수요\\n\\n메시지 사양\\n\\n```JavaScript\\nconst demand = {\\n  // REQUIRED\\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost\\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED \\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  validatorFee: 0,                                              // validator fee \\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendDemand`\\n\\n수요 메시지에 서명하고 브로드캐스팅합니다. 책임은 약속으로 반환됩니다\\n\\n```JavaScript\\nrobonomics.sendDemand(demand).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onDemand`\\n\\n정의된 모델로 수요 메시지를 수신합니다. 모델이 null이면 모든 수요 메시지를 반환합니다.\\n\\n```JavaScript\\nrobonomics.onDemand(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### 공급\\n\\n메시지 사양\\n\\n```JavaScript\\nconst offer = {\\n  // REQUIRED \\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost \\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED\\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  lighthouseFee: 0,                                             // lighthouse fee\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendOffer`\\n\\n공급 메시지에 서명하고 브로드캐스팅합니다. 책임은 약속으로 반환됩니다\\n\\n```JavaScript\\nrobonomics.sendOffer(offer).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onOffer`\\n\\n정의된 모델로 공급 메시지를 수신합니다. 모델이 `null`이면 모든 공급 메시지를 반환합니다\\n\\n```JavaScript\\nrobonomics.onOffer(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### 결과\\n\\n메시지 사양\\n\\n```JavaScript\\nconst result = {\\n  // REQUIRED \\n  liability: \\\"0x0000000000000000000000000000000000000000\\\",  // liability contract address\\n  success: true,                                            // status of the task\\n  result: \\\"QmWXk8D1Fh5XFJvBodcWbwgyw9htjc6FJg8qi1YYEoPnrg\\\"  // ipfs hash of the rosbag log file\\n};\\n```\\n\\n`robonomics.sendResult`\\n\\n결과 메시지에 서명하고 브로드캐스팅합니다\\n\\n```JavaScript\\nrobonomics.sendResult(result).then(() => {\\n  console.log(\\\"ok\\\");\\n});\\n```\\n\\n`robonomics.onResult`\\n\\n결과 메시지를 수신합니다. 이 결과는 유효하지 않을 수 있습니다. 유효한 결과는 책임 계약에 저장됩니다\\n\\n```JavaScript\\nrobonomics.onResult(result => {\\n  console.log(result);\\n});\\n```\\n\\n### 스마트 계약\\n\\n#### 책임\\n\\n`liability.getInfo`\\n\\n계약의 속성 개체 반환합니다\\n\\n```JavaScript\\nliability.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    model,\\n    objective,\\n    result,\\n    token,\\n    cost,\\n    lighthouseFee,\\n    validatorFee,\\n    demandHash,\\n    offerHash,\\n    promisor,\\n    promisee,\\n    lighthouse,\\n    validator,\\n    isSuccess,\\n    isFinalized\\n  }\\n  */\\n});\\n```\\n\\n`liability.onResult`\\n\\n책임이 끝날 때까지 기다립니다. 결과를 반환합니다\\n\\n```JavaScript\\nliability.onResult().then(result => {\\n  console.log(result);\\n});\\n```\\n\\n#### 등대\\n\\n`robonomics.lighthouse.getInfo`\\n\\n계약의 속성 개체 반환합니다\\n\\n```JavaScript\\nrobonomics.lighthouse.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    minimalStake,\\n    timeoutInBlocks,\\n    keepAliveBlock,\\n    marker,\\n    quota\\n  }\\n  */\\n});\\n```\\n\\n`robonomics.lighthouse.getProviders`\\n\\n등대에있는 공급자 목록을 반환합니다\\n\\n```JavaScript\\nrobonomics.lighthouse.getProviders().then(list => {\\n  console.log(list);\\n});\\n```\\n\\n##### 새로운 등대 창조\\n\\n```JavaScript\\nconst minimalFreeze = 1000      // Wn\\nconst timeout = 25              // blocks\\nconst name = 'mylighthouse'     // lighthouse name\\nrobonomics.factory.methods.createLighthouse(minimalFreeze, timeout, name).send({ from: robonomics.account.address })\\n    .then((tx) => console.log(tx))\\n\\nrobonomics.factory.onLighthouse((lighthouse) => {\\n    console.log(lighthouse.name)\\n})\\n```\\n\\n##### 공급자되기\\n\\n사전에 `XRT`토큰에 대해 `approve`를 호출해야합니다.\\n\\n```JavaScript\\nconst name = \\\"mylighthouse\\\";    // lighthouse name\\nconst stake = 1000;             // Wn\\nrobonomics.lighthouse.methods\\n  .refill(stake)\\n  .send({ from: robonomics.account.address })\\n  .then(tx => console.log(tx));\\n```\\n\\n#### 토큰\\n\\n`robonomics.xrt.getInfo`\\n\\n토큰의 속성 개체 반환합니다\\n\\n```JavaScript\\nrobonomics.xrt.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    name,\\n    totalSupply,\\n    decimals,\\n    symbol\\n  }\\n  */\\n});\\n```\\n\\n##### 균형 확인\\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .balanceOf(robonomics.account.address)\\n  .call()\\n  .then(balance => console.log(balance));\\n```\\n\\n##### 허용량 확인\\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .allowance(robonomics.account.address, robonomics.factory.address)\\n  .call()\\n  .then(allowance => console.log(allowance));\\n```\\n\\n##### 승인\\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .approve(robonomics.lighthouse.address, 100)\\n  .send({\\n    from: robonomics.account.address\\n  })\\n  .then(tx => console.log(tx));\\n```\\n\\n## 링크\\n\\n- [Website](https://robonomics.network/)\\n- [Minimal template of dApp](https://github.com/airalab/vue-dapp-robonomics-template)\\n- [dApp example](https://codesandbox.io/s/robonomics-vue-template-ewuiw)\"}},{\"node\":{\"id\":\"951b346eea456c52de13ee9b91fdb63e\",\"title\":\"How Robonomics Network Works\",\"path\":\"/docs/ko/robonomics-how-it-works/\",\"content\":\"\\nIn this section we will discuss the Robonomics Network scenario.\\n\\nThere are few main parts in the Robonomics network:\\n\\n- IPFS for the messages exchanging\\n- the Ethereum blockchain for storing new liability contracts\\n- a provider that is responsible for matching messages\\n- an agent\\n\\nLet's have a look at the following diagram that describes the scenario without any additional details:\\n\\n![The main scenario of Robonomics Network](../images/robonomics_network_scenario.jpg \\\"The main scenario of Robonomics Network\\\")\\n\\nThere are three types of [messages](/docs/market-messages) in IPFS: Demand, Offer, Result.\\n\\n**Below there is the specification for a Demand message:**\\n\\n| Field         | Type                      | Description                                       | Example                                           |\\n|-------------- |-------------------------  |------------------------------------------------   |------------------------------------------------   |\\n| model         | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model Identifier                   | QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC    |\\n| objective     | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    | QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r    |\\n| token         | ethereum_common/Address   | Operational token address                         | 0xbD949595eE52346c225a19724084cE517B2cB735        |\\n| cost          | ethereum_common/UInt256   | CPS behavioral model implementation cost          | 1                                                 |\\n| lighthouse    | ethereum_common/Address   | Lighthouse address                                | 0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1       |\\n| validator     | ethereum_common/Address   | Observing network address                         | 0x0000000000000000000000000000000000000000        |\\n| validatorFee  | ethereum_common/UInt256   | Observing network commission                      | 0                                                 |\\n| deadline      | ethereum_common/UInt256   | Deadline block number                             | 6393332                                           |\\n| sender        | ethereum_common/Address   | Message sender address                            | 0x0000000000000000000000000000000000000000        |\\n| signature     | std_msgs/UInt8[]          | Sender’s digital signature                        | 0x23bc…c617                                       |\\n\\n<!--\\n=============== ============================================================== ================================================ ================================================\\n     Field                                   Type                                                Description                                        Example\\n=============== ============================================================== ================================================ ================================================\\n  model          :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model Identifier                  QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC\\n  objective      :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model parameters in rosbag file   QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r\\n  token          :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Operational token address                        0xbD949595eE52346c225a19724084cE517B2cB735\\n  cost           :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   CPS behavioral model implementation cost         1\\n  lighthouse     :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Lighthouse address                               0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1\\n  validator      :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Observing network address                        0x0000000000000000000000000000000000000000\\n  validatorFee   :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Observing network commission                     0\\n  deadline       :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Deadline block number                            6393332\\n  sender         :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Message sender address                           0x0000000000000000000000000000000000000000\\n  signature      std_msgs/UInt8[]                                               Sender's digital signature                       0x23bc...c617\\n=============== ============================================================== ================================================ ================================================\\n-->\\n\\nAn Offer message has the same fields but instead of `validatorFee` there is a `lighthouseFee` field. This field determines the amount of fee for a lighthouse.\\n\\nNow let's have a look at the following diagram and walk step by step from the moment of publishing messages to a liability finalization.\\n\\n![Robonomics Network detailed scenario](../images/robonomics_network_detailed_scenario.jpg \\\"Robonomics Network detailed scenario\\\")\\n\\nA liability contract is created only if the following fields match: `model`, `objective`, `token`, `cost`. A provider of Robonomics Network watches every message and finds those ones that have a match.\\nAfter the match is found the provider calls `createLiability(demand, offer)` method from the contract factory where `demand` and `offer` are serialized.\\n\\nBelow is the package diagram for the Robonomics communication stack:\\n\\n![Robonomics communication stack](../images/robonomics_network_communication_stack.jpg \\\"Robonomics communication stack\\\")\\n\\nThe factory deserializes arguments and recovers *promisee* and *promisor* addresses from signatures.\\n\\nNext step is token transfer. The factory transfers **cost** tokens from the *promisee* address and **validatorFee** and **lighthouseFee** from the *promisor* address to the new liability address.\\n\\n> - **You should approve sufficient amount of tokens for the factory.**\\n> - **It's not required to approve tokens from the *promisor* address if fees are null.**\\n\\nNow the factory emits a NewLiability event with the liability address. An agent gets the address, reads fields, perform a task and at the same time writes a log file in rosbag format.\\n\\nWhen the work is done the agent sends a Result message with the following fields: hash of the rosbag file, a success flag, a signature. If the **validator** field is not null it means that only validator is able to finalize the liability.\\n\\nAfter the successful liability finalization the agent gets **cost** tokens. Otherwise, the *promisee* gets tokens back.\"}},{\"node\":{\"id\":\"78c7ef325b8e9af4ef7d108f139c82b4\",\"title\":\"Robonomics DApp Overview\",\"path\":\"/docs/ko/robonomics-dapp-overview/\",\"content\":\"\\nYou can operate with Robonomics Network using the interface of [Robonomics Network Dapp (decentralized application)](https://dapp.robonomics.network/#/). It is available in browsers with [Metamask extension](https://metamask.io). On the first page you will see the statistics of the network:\\n\\n![Robonomics DApp's first page](../images/robonomics_dapp_first_page.jpg \\\"Robonomics DApp's first page\\\")\\n\\nLet's have a look at the bottom table \\\"Robonomics Telemetry\\\".\\n\\nEvery time an instance of AIRA is launched it broadcasts a piece of information about itself. Usually it takes some time for the Dapp to receive data from an instance of AIRA.\\n\\nHave a brief look at the page [\\\"AIRA installation\\\"](/docs/aira-installation) to understand where `IPNS` and `Address Eth` came from.\\n\\n## IPNS\\n\\nYou can treat it as a unique identifier of your instance in IPFS network. Under that name AIRA publishes metadata about itself.\\n\\n## Address Eth\\n\\nBy default AIRA generates new Ethereum address for you (it's [possible](/docs/aira-faq#how-to-change-ethereum-address-of-aira) to generate new one).\\n\\nIt's mainly used to sign all the outcoming messages.\\n\\n## Lighthouse\\n\\nIn Robonomics Network an agent must choose a lighthouse to work on. By default it's `airalab.lighthouse.5.robonomics.eth`.\\n\\nYou can choose existing one or create your own on [Lighthouses](https://dapp.robonomics.network/#/lighthouse) page.\\n\\n## Peers\\n\\nThe amount of IPFS pubsub [peers](/docs/aira-faq#how-to-check-the-quantity-of-ipfs-peers).\\n\\n## Date\\n\\nThe date and time of last update\\n\\n## Network\\n\\nRobonomics Network officially works in Ethereum Mainnet.\\nThere is also [Sidechain](https://github.com/airalab/airalab-sidechain) which is mostly for testing purpose.\\n\\n\\n\"}},{\"node\":{\"id\":\"158c2c0e90593b68b5ee842fe2160176\",\"title\":\"Contracts deployment\",\"path\":\"/docs/ko/robonomics-contracts-deployment/\",\"content\":\"\\nRobonomics network works on top of the existing Ethereum network. The protocol is implemented by smart contracts. A source code is on [Github](https://github.com/airalab/robonomics_contracts). Airalab team deploys new version of contracts and supports a current one. \\n\\nIn this lesson we are going to learn more about these contracts. To do this we will deploy our test copy. Also we are going to use these contracts in the future lessons. \\n\\nYou need a client running Ethereum node. You can use either one of existing network (e.g. Mainnet, Ropsten, Kovan) or your local one. For testing purpose we suggest to use this [docker container](https://github.com/f-o-a-m/cliquebait) \\n\\n    $ docker run --rm -d -p 9545:8545 -p 9546:8546 foamspace/cliquebait:latest\\n\\nNext step is obtain a copy of robonomics contracts source code:\\n\\n    $ git clone --recursive https://github.com/airalab/robonomics_contracts\\n\\nA file truffle.js contains available networks for migration. We will work with development network. When you are in `robonomics_contracts` directory install dependencies and run a migration:\\n\\n    npm install // to install dependencies\\n    truffle migrate --network development\\n\\nIt's time to learn how to create a new lighthouse. For more information about Robonomics network and Lighthouse in particular read [white paper](http://static.robonomics.network/docs/book-the-economy-of-robots-1-2017/robonomics.network-book-the-economy-of-robots-1-2017-en.pdf). Briefly lighthouse o distributes the running time of providers. Every lighthouse serves its own broadcast channel. Ask and Bid messages come into this channel. XRT tokens are used as a payment. \\n\\nWhen XRT contracts was deployed some tokens were issued on our account. Let's check the balance:\\n\\n    $ truffle --network development console\\n    > xrt = XRT.at(XRT.address)\\n    > xrt.balanceOf(web3.eth.accounts[0])\\n\\nAnd that's how we create a lighthouse:\\n\\n    > factory = LiabilityFactory.at(LiabilityFactory.address)\\n    > tx = factory.createLighthouse(1000, 10, \\\"test\\\")\\n    > tx.then(x => {laddress = x.logs[0].args.lighthouse})\\n    > l = LighthouseLib.at(laddress)\\n\\nInstead of deploying a lighthouse contract every time we need a new one, we ask a factory to do this job. A `l` variable contains lighthouse instance. The lighthouse should be able to spend our tokens. Let's make an approve and check everything went well:\\n\\n    > xrt.approve(l.address,1000)\\n    > xrt.allowance(web3.eth.accounts[0],l.address)\\n\\nAnd a very important step is become a worker:\\n\\n    > l.refill(1000)\\n\\nEach worker has to put a stake. In this case it's 1000 Wn.\\n\\nBelow is a table of our addresses:\\n\\n| Contract          | Address                                       | ENS name                          |\\n|------------------ |--------------------------------------------   |---------------------------------- |\\n| ENSRegistry       | 0x80c77a7de64a15450bb8cf45ece4fbb7bae6fb49    |                                   |\\n| XRT               | 0x673583a369eb3a830a5571208cf6eb7ce83987f8    | xrt.3.robonomics.eth              |\\n| LiabilityFactory  | 0x1b3190e00c1903266862af1f31714d4b81ef59b2    | factory.3.robonomics.eth          |\\n| Lighthouse        | 0xd2b78c032b6c8851a8b6cbf950caa02a77618d8e    | test.lighthouse.3.robonomics.eth  |\\n\"}},{\"node\":{\"id\":\"c14a7dc9cfc8b39256bf36caa864c26c\",\"title\":\"Robonomics Coffee\",\"path\":\"/docs/ko/robonomics-coffee/\",\"content\":\"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](../images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](../images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](../images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](../images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](../images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](../images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](../images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](../images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](../images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](../images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](../images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](../images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](../images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"}},{\"node\":{\"id\":\"e0f9dbee2b5b3ec0f2984fb9cd035cd8\",\"title\":\"Become a Provider\",\"path\":\"/docs/ko/robonomics-become-a-provider/\",\"content\":\"\\nThis page describes how to create a lighthouse and become a provider in the Robonomics network.\\n\\n## Prepare an address\\n\\nFirst of all, an Ethereum address is required. You must have access to a private key of the address. In case you don't have one, below are steps to create an address via [Parity](https://www.parity.io/ethereum/).\\n\\n```\\n$ sudo snap install parity\\n$ parity.ethkey generate random\\nsecret:  15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539\\npublic: 38b800bfd90d486c78c646da79bb94b9d038aca8aad221062ce1b148df7764bfef02f6b3cf931786b6997540b798ea226ae60bd201c222d8f702e408a1a5cbff\\naddress: c531fa8f141493df3da264a864bdcbec19695b4c\\n```\\n\\nThe `secret` field is a private key, you'll need it to run the provider client. Save it to a file:\\n\\n```\\n$ echo '0x15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539' > private.key\\n```\\n\\nThe next step is to deposit some ethers and XRT tokens to the address which is held in the `address` field.\\n\\n## Create a lighthouse\\n\\nGo to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse) and fill in a name in the right side:\\n\\n![The Right Side](../images/become_a_provider_1.jpg \\\"The Right Side\\\")\\n\\nClick on the `Create lighthouse and connect to the network` button and sign a transaction. After a while you should see:\\n\\n![Success of Creating a Lighthouse](../images/become_a_provider_2.jpg \\\"Success of Creating a Lighthouse\\\")\\n\\nNow it's time to put a stake. Select the new lighthouse and click `Connect to the network`:\\n\\n![Selecting the Lighthouse](../images/become_a_provider_3.jpg \\\"Selecting the Lighthouse\\\")\\n\\nOn this page in the `Provider` section click the `Approve` button, sign a transaction. When it's mined click the `Refill` button and do the same.\\n\\n## Install the client\\n\\nNow you need to install [robonomics-tools](https://github.com/airalab/robonomics-tools) at least 0.4.2 version. You can build from the source or do the following steps:\\n\\n**Make sure you have Nix and Stack installed:**\\n    \\n```\\n$ curl -sSL https://get.haskellstack.org/ | sh\\n$ curl https://nixos.org/nix/install | sh\\n```\\n\\n* Setup Airalab binary cache at [https://aira.cachix.org](https://aira.cachix.org/)\\n* Import Airalab channel:\\n\\n```\\n$ nix-channel --add http://aira.life/channels/aira-unstable/ aira\\n$ nix-channel --update\\n```\\n* Install from the binary cache:\\n\\n```\\n$ nix-env -iA aira.robonomics-tools\\n```\\n* Run the client:\\n\\n```\\n$ xrtd --lighthouse mobilerobotics.lighthouse.5.robonomics.eth --private $(cat private.key)\\n```\\n\\n**Get familiar with the `xrtd` options via `xrtd --help`.**\\n\\n## Test the provider\\n\\nTo test your provider go again to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse/) and connect to the just created lighthouse.\\n\\nAt the bottom you should see the `TEST LIGHTHOUSE` section.\\n\\nClick on the `Demand` button and then on the `Offer` one. You should see something similar to:\\n\\n![Demand and Offer messages](../images/provider_mobilerobotics_demand_offer.jpg \\\"Demand and Offer messages\\\")\\n\\nDon't forget to sign every message with the MetaMask extension.\\n\\nFinally you should see a new liability contract created:\\n\\n![Liability is created](../images/provider_mobilerobotics_liability.jpg \\\"Liability is created\\\")\\n\"}},{\"node\":{\"id\":\"4945a308f724ecca8e0a889cb3654ba8\",\"title\":\"Robonomics IO Launch\",\"path\":\"/docs/ko/rio-launch/\",\"content\":\"\\nA simple way to turn on and off an IoT device or a robot. Basically sending \\\"ON\\\" will result in `true` state for a device, anything else will result in `false`.\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Accounts on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Usage\\n\\nTo see the result of transaction first of all run `read` part:\\n\\n```\\n% ./robonomics io read launch\\n```\\n\\nNow let's turn a robot on:\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nThen you should see in the first terminal window:\\n\\n```\\n% ./robonomics io read launch\\n5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH >> 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL : true\\n```\\n\\nLet's describe all the accounts and options above.\\n\\n* `-r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL` means robot's address\\n* `-s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` private key of the account to launch from (must have tokens for a transaction)\\n* `5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH` address that launches a robot\\n* `true` turn it on\\n\\nIf we pass anything else but \\\"ON\\\" the state becomes `false`\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\\nand\\n\\n```\\n% ./robonomics io read launch --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"59e466102f0415b7e165fec5216f1a0a\",\"title\":\"Robonomics IO Overview\",\"path\":\"/docs/ko/rio-overview/\",\"content\":\"\\nThe [crate](https://crates.robonomics.network/robonomics_io/index.html) provides a convenient way to interact with blockchain and includes a set of tools. The latest release can be found [here](https://github.com/airalab/robonomics/releases)\\n\\n```\\n% ./robonomics io\\nrobonomics-io 0.21.0\\nRobonomics Framework I/O operations\\n\\nUSAGE:\\n    robonomics io [FLAGS] [OPTIONS] <SUBCOMMAND>\\n\\nFLAGS:\\n        --dev        Specify the development chain\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nOPTIONS:\\n    -d, --base-path <PATH>        Specify custom base path\\n        --chain <CHAIN_SPEC>      Specify the chain specification (one of dev, local, or staging)\\n    -l, --log <LOG_PATTERN>...    Sets a custom logging filter. Syntax is <target>=<level>, e.g. -lsync=debug\\n\\nSUBCOMMANDS:\\n    help     Prints this message or the help of the given subcommand(s)\\n    read     Read information from device\\n    write    Write information into device\\n```\\n\\n## The Pipeline Philosophy \\n\\nThe tool is designed in order to be included in a pipeline chain of processes. From Unix user experience everyone is familiar with commands like:\\n\\n```\\nps aux | grep robonomics\\n```\\n\\nIt means standard output produced by the `ps` program becomes standard input for the `grep` program. \\n\\nThe `robonomics io` consists of several subcommands with reading, writing abilities or both. It treats everything as a virtual or physical device ([everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file))\\n\\n## Read Overview\\n\\nIn general `read` means it reads data from a device or a network and prints it in `stdout`.\\n\\nHow to use it for:\\n\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io read\\nrobonomics-io-read 0.4.0\\nRead information from device\\n\\nUSAGE:\\n    robonomics io read <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    help      Prints this message or the help of the given subcommand(s)\\n    ipfs      Download data from IPFS storage\\n    launch    Robot launch request events\\n    pubsub    Subscribe for broadcasing data\\n    sds011    Nova SDS011 particle sensor\\n```\\n\\n## Write Overview\\n\\nUsually it writes data to blockchain or publishes to pubsub channel. \\n\\nHow to use it for:\\n\\n* [datalog](/docs/rio-datalog)\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io write\\nrobonomics-io-write 0.4.0\\nWrite information into device\\n\\nUSAGE:\\n    robonomics io write <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    datalog    Data blockchainization subsystem command\\n    help       Prints this message or the help of the given subcommand(s)\\n    ipfs       Upload data into IPFS storage\\n    launch     CPS launch subsystem command\\n    pubsub     Broadcast data into PubSub topic\\n```\\n\\n## Local Testnet\\n\\nFor testing purpose it's possible to run the development environment:\\n\\n```\\n% ./robonomics --dev --rpc-cors all\\n```\\n\\n`--rpc-cors all` allows the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) to be connected to local node. After launching the node, go to the dapp, click on Robonomics icon in the upper left corner, choose Development and put node's local address\\n\\n![Robonomics Dapp Connect to Local Node](../images/robonomics-dapp-connect-local.jpg \\\"Robonomics Dapp Connect to Local Node\\\")\\n\\nFinally click Switch and you should be connected to the local node. Check out Accounts tab. There you can create new accounts and transfer tokens.\\n\\n\"}},{\"node\":{\"id\":\"d407f7b1785fb95a243358651146e3f4\",\"title\":\"Robonomics IO IPFS\",\"path\":\"/docs/ko/rio-ipfs/\",\"content\":\"\\nIt serves downloading and uploading files from/to IPFS network\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Running [IPFS](https://ipfs.io/#install) daemon \\n\\n## Write\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\n## Read\\n\\n```\\n% echo QmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy | ./robonomics io read ipfs\\nHello Robonomics\\n```\\n\\n## Remote IPFS node\\n\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs --remote https://ipfs.infura.io:5001/\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\nThe same applies for `read`\\n\\n\"}},{\"node\":{\"id\":\"66d0d1db3ef99c9f6f915c7d17ca2f9f\",\"title\":\"Robonomics IO Datalog\",\"path\":\"/docs/ko/rio-datalog/\",\"content\":\"\\nDatalog module allows you to store any string on blockchain\\n\\nhttps://www.youtube.com/watch?v=rs67AMyd-gE\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Account on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Write\\n\\nAssuming local node is running:\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nwhere `0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` is a private key for the account with tokens.\\nIn this example the public key is 5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH. Let's go to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/)\\nand see what happened.\\n\\nIn the Dapp go to Developer -> Chain state. In the \\\"selected state query\\\" list choose datalog and below choose your account. Click plus button on the right and you should see the following:\\n\\n![Robonomics Chain State Datalog](../images/robonomics-dapp-chain-state-datalog.jpg \\\"Robonomics Chain State Datalog\\\")\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"742e7b0d7e45f11c90b9fe8fec66e7ca\",\"title\":\"Raspberry Setup\",\"path\":\"/docs/ko/raspberry-setup/\",\"content\":\"\\nFor both methods, the first thing you need to do is setup a Raspberry Pi.\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card and run the Imager program. From the menu, select 64-bit Ubuntu Server as the operating system and ensure to select your SD card from the storage dropdown, and then press `write`.\\n\\n![pi](../images/home-assistant/pi.png)\\n\\nOpen the SD card's storage from your computer and navigate inside the root folder of the card. The name of the folder should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Copy the below text and paste it into the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end (also you can use `arp -a`):\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\n\\nIn this example we can see that the Raspberry Pi's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\".\\n\\n## Home Assistant\\n\\nNow we need to install Home Assistant to the Raspberry Pi. Detailed instructions can be found [here](https://www.home-assistant.io/installation/linux#install-home-assistant-core). You need to install `Home Assistant Core`. It's actual version is 2021.11.5 and instruction assumes that we already have installed Python 3.9 or newer.\\n\\nUpdate your system and install necessary packages:\\n```bash\\nsudo apt-get update\\nsudo apt-get upgrade -y\\nsudo apt-get install -y python3 python3-dev python3-venv python3-pip libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 tzdata libcurl4-openssl-dev\\n```\\n\\nCreate user `homeassistant` and the directory for homeassistant core:\\n```bash\\nsudo useradd -rm homeassistant\\nsudo mkdir /srv/homeassistant\\nsudo chown homeassistant:homeassistant /srv/homeassistant\\n```\\n\\nNext up is to create and change to a virtual environment for Home Assistant Core. This will be done as the homeassistant account.\\n```bash\\nsudo -u homeassistant -H -s\\ncd /srv/homeassistant\\npython3.9 -m venv .\\nsource bin/activate\\n```\\n![terminal1](../images/home-assistant/terminal1.png)\\n\\nThen install required Python packages:\\n```bash\\npython3 -m pip install wheel\\npip3 install homeassistant==2021.11.5\\n```\\n\\nStart Home Assistant Core for the first time. This will complete the installation for you, automatically creating the `.homeassistant `configuration directory in the `/home/homeassistant` directory, and installing any basic dependencies:\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant$ hass\\n```\\n\\nYou can now reach your installation via the web interface on `http://%RASPBERRY_IP_ADDRESS%:8123`. \\nIn this example: `http://192.168.43.56:8123`\\n\\n> You don't need to connect you raspberry to the screen, you can open Web UI from any computer connected to your local network\\n\\nCreate user and finish setup (first setup is described [here](https://www.home-assistant.io/getting-started/onboarding/) in more details), then stop Home Assistant with `Ctrl+C`.\\n\\nAfter this installation process has been completed, from the `python_scripts` folder import some necessary scripts:\\n\\n```bash\\nmkdir python_scripts\\ncd python_scripts/\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/send_datalog.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/control.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/utils.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/create_config.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/encrypt.py\\n```\\n\\nTo use Robonomics you need account (instructions of how to create it are [here](/docs/create-account-in-dapp/)). Add mnemonic or raw seed from it in `config.config` file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\n\\nIn this format:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\n\\n## Substrate Interface\\n\\nTo pub data to Robonomics you need to install `substrate-interface` python package (you need to install RUST before) to your raspberry. \\n\\nInstall RUST:\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nsource $HOME/.cargo/env\\nrustup default nightly\\n```\\n\\nAnd install necessary python packages to the virtual environment:\\n```bash\\npip3 install pynacl==1.4.0 packaging pycurl\\npip3 install substrate-interface==1.1.2 --use-feature=2020-resolver\\npip3 install python-miio==0.5.8 --use-feature=2020-resolver\\n```\\nBe sure that you-re on virtual environment:\\n\\n![terminal1](../images/home-assistant/terminal2.png)\\n\\n## Systemd services\\n\\nNow change user (you can run under any user, which allows you to use sudo):\\n\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant/python_scripts$ exit\\n```\\n\\nCreate new service for home assistant start: \\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/home-assistant@homeassistant.service \\n```\\n\\nPaste the following:\\n\\n```\\n[Unit]\\nDescription=Home Assistant\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/hass -c \\\"/home/%i/.homeassistant\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nDo the same for robonomics control service:\\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/robonomics-control@homeassistant.service \\n```\\n\\nWith:\\n```\\n[Unit]\\nDescription=Robonomics Control\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/python3.9 \\\"/srv/%i/python_scripts/control.py\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nAnd enable both services:\\n```bash\\nubuntu@ubuntu:~$ sudo systemctl enable home-assistant@homeassistant.service\\nubuntu@ubuntu:~$ sudo systemctl enable robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\"}},{\"node\":{\"id\":\"14029e0dc3328f040502063d74ec6e52\",\"title\":\"Setup with Prepared Image\",\"path\":\"/docs/ko/raspberry-image/\",\"content\":\"## Image\\nWe prepared an image to make it easier to use the Home Assistant with Xiaomi Miio and Robonomics with the Raspberry Pi.\\n\\nYou can get it here: [download image](https://ipfs.io/ipfs/bafybeihzzqoyycflxzxlxy2aplkzxo537ggqatdlbr24b4dnlyrtpkp2eu)\\n\\nSHA256 checksum: `7ec5ea99d7e339b54cbeaaae58c8295411769d27732ec2b5464dbb495ba24120`\\n\\nWhat preinstalled in the image:\\n- Ubuntu Server 21.10 (3/4/400): 64-bit server OS for arm64 archtectures\\n- Python 3.9.7\\n- Home Assistant Core 2021.11.5\\n- rustc 1.59.0-nightly (efec54529 2021-12-04)\\n- substrate-interface 1.1.2\\n- python-miio 0.5.8\\n\\n## How To Use The Prepared Image\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Insert SD card into your PC and run the Imager program. In `Operating System` select `Use custom` and choose the previously downloaded `.img.gz` file. Then select your SD card in the `Storage` dropdown and click `WRITE`.\\n\\n![imager](../images/home-assistant/use_custom_image.png)\\n![imager](../images/home-assistant/imager_prep.png)\\n\\nAfter writing is comleted, open the SD card's files on your computer and navigate inside the root folder of the card. The name should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Write this to the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end:\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\nThere raspberry's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\". Then follow the instructions to change the password.\\n\\nThen you need to write the seed from your Robonomics account to config file. Open it:\\n```bash\\nsudo -u homeassistant -H -s\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add mnemonic:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\nThen restart Robonomics Control service:\\n```bash\\nsystemctl restart robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n\"}},{\"node\":{\"id\":\"8ed342c66d931eded4cc8128c1b4b98e\",\"title\":\"R&D Based on Robonomics Network\",\"path\":\"/docs/ko/r-and-d-based-on-robonomics-network/\",\"content\":\"\\nFor over 4 years, the Robonomics project participants completed 13 R&D projects in the process of writing the current version of the Robonomics platform, including:\\n\\n### Launching a drone under the control of a decentralized computer.\\n2016 - Successful field test of 3DR X8 drone compatibility with Drone Employee software.\\nBelow you can observe a workflow in which a person sends a Drone transaction through the Ethereum Blockchain.\\n\\nhttps://www.youtube.com/watch?v=V_3rcP2Duv0&t=1s\\n\\n### Management of a fleet of drones in a decentralized network.\\n[Distributed Sky](https://airmarket.io/wp-content/uploads/2018/09/Distributed-Sky-Whitepaper-v3.0.pdf) is the backbone of the Unmanned aircraft system traffic management (UTM). It uses a global network of computers to process and store identities, traffic and other sensitive information, and uses cryptography to make the UTM process secure and scalable.\\nBelow is the video of Drone Passport agent in action.\\n\\nhttps://www.youtube.com/watch?v=yxGTOkGkBJ8\\n\\n### Tokenization of data from IoT devices.\\n\\nThe 4th industrial revolution is flying the flag of CPSs’ total integration into mass production and rendering services. Machines do not engage in empty talk, they are honest in their work and can be an independent party supplying information, based on algorithmic analysis of which the network itself can emit new units of any value.\\nValues based on the labor of machines will be much more interesting for the new generation than other values, the emission of which is built on any other principle. More information available [here](https://blog.aira.life/tokenization-and-the-4th-industrial-revolution-3208022be747)\\n\\n### Digital markets for robots.\\n\\n### Industrial zone management with capital.\\n[The article](https://ieeexplore.ieee.org/abstract/document/8525391) presents the architecture of communication protocol for modern industrial processes and business based on cyber-physical systems - Industry 4.0. The main attention is paid to one of the key trends of this concept - to economical autonomous agents i.e. to robots or smart things, which are able to make decisions independently about their economic actions. Agents begin to fully participate in business processes, so it is important to automate the processes and ensure formal and secure communication between multiple heterogeneous agents, taking into account the economic component of the industry. The article shows how to organize economic interaction between agents using a peer-to-peer network based on decentralized Blockchain technology and smart contracts. More information about Industry 4.0 may be found in a video below.\\n\\nhttps://www.youtube.com/watch?v=yuxOF_z70us\\n\\n### Drones, sensors, and blockchain for monitoring the quality of water on the Volga.\\nAs part of [this river project](https://github.com/airalab/drone_on_volga), the drone offers its services through a web application allowing any user to request the service. Typically, the mission generates parameters such as drone position, travel speed, measured water quality parameters, and other minor requirements.\\nThe Robonomics network is used to communicate with the robot. With its help, the robot can offer its services, and citizens or government officials can order them by making a cryptocurrency payment through the website. The Robonomics network is built on the Ethereum blockchain platform and the IPFS protocol, which record the hash of sensor measurements in the public blockchain and thus protect historical data from possible falsification.\\nFascinating video about experiments with water drone is below.\\n\\nhttps://www.youtube.com/watch?v=Mtqm5y6Bolo\\n\\n### Civilian observatory networks.\\nIn August 2018 Airalab with support of Smart Distribution (Libelium distributor in Russia) [set up a measuring network in a living district in Tolyatti, Russia](https://www.libelium.com/libeliumworld/success-stories/preventing-asthsma-sensor-network-air-quality-pm10-dust-in-play-area/).\\nThe aim was to create the basis for the implementation of an air quality monitoring network in areas of special vulnerability (schools, playgrounds, nursing homes, hospitals, etc.) that can provide local authorities with information to take measures to protect their citizens.\\nAn example of using a sensor is shown in a video below. Also, source code may be found [here](https://github.com/airalab/sensors-connectivity).\\n\\nhttps://www.youtube.com/watch?v=shqey3tmNUk\\n\\n### Robot artist Gaka-chu.\\nModern technologies make human life more comfortable and more fun, freeing up time for reflection and experimentation.\\nIt was a series of reflections on the static nature of the industry that led the development team to the idea of ​​conducting an experiment showing the autonomous transformation of production for a specific type of product.\\nSuch an experiment became a [robot artist](https://github.com/airalab/robot_painter/) - a small, clumsy KUKA manipulator living in a large world of serious industrial robots. And his name is Gaka-chu. Why? Because of the love of drawing: \\\"gaka\\\" in Japanese is \\\"artist\\\". And \\\"chu\\\" was added for an inexplicable love for Pokemons.\\n\\nhttps://youtu.be/xSD_lsrAA0I\\n\\n### Issuance of green certificates based on the data from renewable energy sources.\\nThe conceptual goal of [DAO IPCI](https://ipci.io/ru/) is to provide a common space, common environment, tools and ecosystem that is universal, reliable, easy to use, allowing a variety of stakeholders, including businesses and people, to record quantitative impacts and quantitative commitments, invest in negative impact mitigation projects, offset the carbon footprint, acquire and trade mitigation results, join existing programs or launch new ones. Source code is provided [here](https://github.com/DAO-IPCI/DAO-IPCI).\\n\\nhttps://www.youtube.com/watch?v=q9plB0TjUnw&list=PLLepqB9oh7WvUVzbeaiwQojrip2tLPA6P\\n\\n### Roadspace negotiation for autonomous cars.\\nOur goal was to develop a [decentralized system](https://github.com/khssnv/mobi_grand_challenge) for road space negotiation where autonomous vehicles can pay for routes and right of way. We believe a market-based approach can be used to alleviate a traffic congestion problem.\\n\\nhttps://youtu.be/JFQTknMZOYg\\n\\n### Blockchain in the tasks of the chemical industry.\\nOriginally the following task was set: developing a [quality control system](https://github.com/Vourhey/chemistry-quality-control) for the production of a certain chemical product. Why is monitoring the quality so important here? The main active substance of this chemical product is chlorine dioxide. It is hazardous to health in high concentrations. And if the concentration is below normal, then this chemical product is useless.\\nAnd what does Blockchain have to do with it? Blockchain helps building trust to the manufacturing company. The consumer knows that no one can change the information in the Blockchain. That means that the manufacturing company can not forge the results of the audit.\\n\\n### Control of equipment maintenance process by supply chain participants based on IoT data.\\n\\n### Robot as a service in service robotics.\\nRobonomics is the ready-to-work and open-source platform which you can use to connect your robot as a service for end-users, they call it [‘Robot-as-a-Service’](https://blog.aira.life/how-can-you-hire-a-robot-176ba29da565). Robonomics support Web3 technologies that implement the exchange of technical and economic information between humans and machines. Robonomics is a purely technical and open source project.\\n\\nhttps://www.youtube.com/watch?v=IEgvXcj3nSo\"}},{\"node\":{\"id\":\"369b9e6aa1e7e53c5d9ece187c8b6be0\",\"title\":\"Playground Overview\",\"path\":\"/docs/ko/playground-overview/\",\"content\":\"\\nRobonomics allows to use robots as autonomous agents that receive commands from a human or another robot and do some useful work, storing a report of their actions in Blockchain. The interaction between the robot and the Robonomics platform is quite simple with a [Robonomics IO](/docs/rio-overview).\\n\\n## Robonomics ROS playground overview \\n\\nhttps://youtu.be/mKr352z8vio\\n\\n## What Robots You Can Control\\nThe playground section contains examples of connecting different robots to Robonomics which everyone can try to repeat step by step. In this section you can try to control:\\n* [an Unmanned Aerial Vehicle](/docs/iris-drone/)\\n* [a Mars Rover](/docs/connect-mars-curiosity-rover-under-robonomics-parachain-control/)\\n* [a Manipulator](/docs/kuka/)\\n* [an industrial Baxter Robot](/docs/baxter2/)\\n\\nSince all robots are available as simulation models, you don't need any special hardware. So you can try to connect the robot to Robonomics Network right now.\\n## How Do You Control the Robot\\nAll of our Demos are launched in a local network, however you can connect a robot to the live networks in the same way.\\n\\nAll Demos in this section follow a similar scenario. You [create an account](/docs/create-account-in-dapp/) for the robot and send him some units for paying transactions. Then the user sends an `ON/OFF` transaction to the robot's address, the robot receives it and starts working. After the job is done the telemetry is saved in IPFS and the file hash is sent to datalog. So at any time you can see how the robot performed its work.\\n## Connect Your Own Robot\\nIn addition you can create your own control package for any ROS-compatible device with [this](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) instruction.\\n\\n\"}},{\"node\":{\"id\":\"bd91052739c4d4a0a78e39abcef149f4\",\"title\":\"Market messages\",\"path\":\"/docs/ko/market-messages/\",\"content\":\"\\nMarket messages is used for exchange **Demand** and **Offer** information. It also used for delivery **Result** messages with liability execution reports.\\n\\n> This is spec for Robonomics `Generation 5`.\\n\\n- Currently for message delivery is used [IPFS PubSub](https://ipfs.io/blog/25-pubsub/) broadcaster.\\n- IPFS PubSub **topic** is set according to *Lighthouse [ENS](https://ens.domains/) name*.\\n\\n## Messages content\\n\\nRobonomics market message use [JSON](https://www.json.org/) data format.\\n\\n\\n### Demand\\n\\n| Field | ROS Type | Description |\\n|-------------- |-------------------------  |------------------------------------------------ |\\n| model | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model identifier |\\n| objective | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model parameters in rosbag file |\\n| token | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Operational token address |\\n| cost | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | CPS behavioral model execution cost |\\n| lighthouse | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Lighthouse contract address |\\n| validator | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Observing network address |\\n| validatorFee  | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Observing network fee |\\n| deadline | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Deadline block number |\\n| nonce | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Robonomics message counter |\\n| sender | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Message sender address |\\n| signature | std_msgs/UInt8[] | Sender’s Ethereum signature |\\n\\n### Offer\\n\\n| Field             | ROS Type                  | Description                                       |\\n|---------------    |-------------------------  |------------------------------------------------   |\\n| model             | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model identifier                   |\\n| objective         | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    |\\n| token             | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Operational token address                         |\\n| cost              | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | CPS behavioral model execution cost               |\\n| validator         | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Observing network address                         |\\n| lighthouse        | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Lighthouse contract address                       |\\n| lighthouseFee     | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Liability creation fee                            |\\n| deadline          | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Deadline block number                             |\\n| nonce             | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Robonomics message counter                        |\\n| sender            | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Message sender address                            |\\n| signature         | std_msgs/UInt8[]          | Sender’s Ethereum signature                       |\\n\\n### Result\\n\\n| Field         | ROS Type                  | Description                       |\\n|-----------    |-------------------------  |---------------------------------- |\\n| liability     | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Liability contract address        |\\n| result        | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | Liability result multihash        |\\n| success       | std_msgs/Bool             | Is liability executed successful  |\\n| signature     | std_msgs/UInt8[]          | Sender’s Ethereum signature       |\\n\\n## Messages signing\\n\\nBefore signing the messages is packed using [abi.encodePacked](https://solidity.readthedocs.io/en/latest/abi-spec.html#non-standard-packed-mode\\n) solidity finction and hashed by Keccak_256.\\n\\n```\\n   demandHash = keccak256(abi.encodePacked(\\n        _model\\n      , _objective\\n      , _token\\n      , _cost\\n      , _lighthouse\\n      , _validator\\n      , _validator_fee\\n      , _deadline\\n      , IFactory(factory).nonceOf(_sender)\\n      , _sender\\n      ));\\n```\\n\\n**`nonce` parameter is counted by factory smart contract and incremented for each created liability smart contract.**\\n\\nMessage hash are signed using Ethereum ``secp256k1`` [signature](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sign).\\n\"}},{\"node\":{\"id\":\"a6b903c0e3c5daed9b1913cde38989b4\",\"title\":\"Control Kuka manipulator with robonomics\",\"path\":\"/docs/ko/kuka/\",\"content\":\"\\nVideo with an example of work can be found here:\\n\\nhttps://youtu.be/z55HepXbHr8\\n\\n***\\n\\n## Requirements\\n* ROS melodic, Gazebo (installation instraction [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n* Some extra packages\\n```bash\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n* IPFS 0.4.22 (download from [here](https://www.npackd.org/p/ipfs/0.4.22) and install)\\n```bash\\ntar -xvzf go-ipfs_v0.4.22_linux-386.tar.gz\\ncd go-ipfs/\\nsudo bash install.sh\\nipfs init\\n```\\n* pip3\\n```bash\\nsudo apt-get install python3-pip\\n```\\n* ipfshttpclient\\n```bash\\npip3 install ipfshttpclient\\n```\\n* substrate-interface\\n```bash\\npip3 install substrate-interface\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n* IPFS browser extension (not necessary)\\n***\\n## Installation\\nInstall Kuka manipulator and control packages\\n```bash\\ncd catkin_wc/src/\\ngit clone https://github.com/orsalmon/kuka_manipulator_gazebo\\ngit clone https://github.com/LoSk-p/kuka_controller\\ncd ..\\ncatkin_make\\n```\\n***\\n## Running gazebo model\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch manipulator_gazebo manipulator_empty_world.launch\\n```\\nIn a new window\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun manipulator_gazebo move_arm_server\\n```\\n![model](../images/kuka-demo/1.png)\\n***\\n## Running robonomics\\nGo to the folder with robonomics file ad create a local robonomics network:\\n```bash\\n./robonomics --dev --tmp\\n```\\n\\n![robonomics](../images/kuka-demo/robonomics.png)\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node\\n\\n![local](../images/kuka-demo/local.png)\\n\\nThen go to Accounts and create `KUKA` account. Save account's mnemonic key, you will need it later. \\n\\n![acc](../images/kuka-demo/create_acc.png)\\n\\nSend some units to the new account from one of default accounts.\\n\\n![accs](../images/kuka-demo/send_money.png)\\n***\\n## Running ipfs\\nRun ipfs daemon:\\n```bash\\nipfs daemon\\n```\\n***\\n## Running control package\\nIn config directory in kuka_control package you need to create config file with this lines, where `<your_mnemonic>` is saved mnemonic seed:\\n```bash\\n{\\n    \\\"kuka_mnemonic\\\": \\\"<your_mnemonic>\\\",\\n    \\\"node\\\": \\\"ws://127.0.0.1:9944\\\"\\n}\\n```\\n\\nNow you can run control script:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun kuka_controller move_arm_client.py\\n```\\n![control](../images/kuka-demo/run.png)\\n\\n## Sending transaction\\nIn [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) go to `Developer/Extrinsics`, change `extrinsic` to `launch`. Chose your `KUKA` account in `robot` and change `param` to `Yes`. The press `Submit Transaction`\\n\\n![transaction](../images/kuka-demo/launch.png)\\n\\nIn the window with kuka_control package you will see:\\n\\n![done](../images/kuka-demo/res.png)\\n\\nThen go `Developer/Chain State` on the Robonomics portal, select `datalog` and `datalogItem((AccountId,u64)): RingBufferItem` in query and add `KUKA` datalog with button '+':\\n\\n![datalog](../images/kuka-demo/datalog.png)\\n\\nNow you can find robot's telemetry in IPFS via this link with your hash `https://gateway.ipfs.io/ipfs/<hash>`.\\n\\n## Troubleshooting\\n\\nIf `catkin_make` doesn't work with the message that it can't find MoveArm.h, try to remove last four lines in CMakeLists.txt in kuka_manipulator_gazebo package:\\n```\\ninclude_directories(include ${catkin_INCLUDE_DIRS})\\n\\nadd_executable(move_arm_server src/move_arm_server.cpp)\\ntarget_link_libraries(move_arm_server ${catkin_LIBRARIES})\\nadd_dependencies(move_arm_server beginner_tutorials_gencpp)\\n```\\nDo `catkin_make` without these lines, then returm them and do `catkin_make` again.\\n\"}},{\"node\":{\"id\":\"dc00175dc7f7d4511ee8cfe382b6e09a\",\"title\":\"Drone control with robonomics\",\"path\":\"/docs/ko/iris-drone/\",\"content\":\"\\n**Drone starts moving after transcation and store file with the coordinates in IPFS. The control script is based on the [GAAS demo script](https://github.com/generalized-intelligence/GAAS)**  \\n\\nhttps://youtu.be/4CwtGAX1OwM\\n\\n## Requirements\\n* dependencies for control:\\n``` sh\\nsudo apt install -y \\\\\\n\\tpython3-pip \\\\\\n\\tninja-build \\\\\\n\\texiftool \\\\\\n\\tpython-argparse \\\\\\n\\tpython-empy \\\\\\n\\tpython-toml \\\\\\n\\tpython-numpy \\\\\\n\\tpython-yaml \\\\\\n\\tpython-dev \\\\\\n\\tpython-pip \\\\\\n\\tninja-build \\\\\\n\\tprotobuf-compiler \\\\\\n\\tlibeigen3-dev \\\\\\n\\tgenromfs\\n```\\n```sh \\npip3 install \\\\\\n\\tpandas \\\\\\n\\tjinja2 \\\\\\n\\tpyserial \\\\\\n\\tcerberus \\\\\\n\\tpyulog \\\\\\n\\tnumpy \\\\\\n\\ttoml \\\\\\n\\tpyquaternion\\n```\\n* ROS Melodic + Gazebo [installation tutorial](http://wiki.ros.org/melodic/Installation)\\n* extra packages: \\n``` bash \\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\nsudo apt-get install python-jinja2\\nsudo apt-get install python-catkin-pkg\\nsudo apt-get install python3-catkin-pkg-modules\\n```\\n* IPFS verson 0.4.22\\n```bash\\nwget https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-amd64.tar.gz\\ntar -xvzf go-ipfs_v0.4.22_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh\\nipfs init\\n```\\n* ipfshttpclient\\n```sh\\npip3 install ipfshttpclient\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n## Environment Setup\\n```bash \\nsudo apt-get install ros-melodic-mavros ros-melodic-mavros-extras\\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\\nsudo ./install_geographiclib_datasets.sh\\ncd ~/catkin_ws/src\\ngit clone https://github.com/PX4/Firmware.git\\ncd Firmware\\ngit checkout v1.9.0\\nbash ./Tools/setup/ubuntu.sh\\n```\\n```bash\\ncd ~/catkin_ws/src\\ngit clone https://github.com/generalized-intelligence/GAAS.git\\ncp -r ~/catkin_ws/src/GAAS/simulator/models/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/models/\\ncp -r ~/catkin_ws/src/GAAS/simulator/worlds/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/worlds/\\ncp -r ~/catkin_ws/src/GAAS/simulator/posix-config/* ~/catkin_ws/src/Firmware/posix-configs/SITL/init/ekf2/\\n```\\n\\nModifying your `.bashrc` file, adding the following lines to the bottom:  \\n\\n`source ~/catkin_ws/devel/setup.bash `  \\n`source ~/catkin_ws/src/Firmware/Tools/setup_gazebo.bash ~/catkin_ws/src/Firmware/ ~/catkin_ws/src/Firmware/build posix_sitl_default `   \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware/Tools/sitl_gazebo`  \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models:~/catkin_ws/src/GAAS/simulator/models`  \\n\\n  \\n## Control Package Installation\\nIn a new Terminal:\\n```bash\\ncd catkin_ws/src\\ngit clone https://github.com/tubleronchik/robonomics_drone_sim.git\\ncd ..\\ncatkin build\\n```\\n## Robonomics Network\\nTo create a local robonomics network go to the folder with the robonomic binary file and run:  \\n`./robonomics --dev --rpc-cors all`  \\n\\nAdd robonomic's path to `config.py`\\n\\n![IPFS](../images/iris-drone-demo/IPFS.jpg)\\n\\nGo to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node.\\n![localNode](../images/iris-drone-demo/localNode.jpg)\\n\\nGo to **Accounts** and create **DRONE** and **EMPLOYER** accounts. Save the account names and keys and path to **robonomics** to `~/catkin_ws/src/drone_sim/src/config.py`. Transfer some money into the accounts.\\n\\n![accounts](../images/iris-drone-demo/addingAcc.jpg)\\n\\n## Running Simulation\\nRun IPFS daemon\\n```bash\\ncd go-ipfs\\nipfs daemon\\n```\\nIn another terminal launch the simulation:\\n```bash\\nroslaunch px4 mavros_posix_sitl.launch\\ncd ~/catkin_ws/src/robonomics_drone_sim/src\\npython3 takeoff.py\\n```\\nWaiting till \\\"Waiting for payment\\\" \\n\\n![launch](../images/iris-drone-demo/launch.jpg)\\n\\nTo send a transaction run in another window:\\n`echo \\\"ON\\\" | ./robonomics io write launch -r <drone_addres> -s <employer_key>` - where **<drone_address>** and **<employer_key>** should be replaced with the strings from `config.py` accordingly.\\n\\nAfter data was pushed to IPFS, go to the **Chain State** in [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/). Select **datalog** in query and add DRONE datalog using `+` button.\\n\\n![datalog](../images/iris-drone-demo/datalog.jpg)\\n\\nYou can find drone's telemetry running `https://gateway.ipfs.io/ipfs/<hash>` inserting the hash from above.\\n\\n![output](../images/iris-drone-demo/output.jpg)\\n\\nIt's important to remove `db` derictory before next launches using  \\n` rm -rf ~/.local/share/robonomics/chains/dev/db`\\n\"}},{\"node\":{\"id\":\"6d53543abd554cdb5d63553438269e4f\",\"title\":\"IPFS Common\",\"path\":\"/docs/ko/ipfs-common/\",\"content\":\"\\nThe package handle IPFS connections, provides useful services for working with IPFS Network. \\nIt's included in `robonomics_liability` launch file\\n\\n## ROS Parameters\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_file_providers\\n\\nA list of public nodes to pin result files. The type is `list of strings`, defaults to `[ipfs_public_providers]`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_swarm_connect_to\\n\\nA list of IPFS nodes to connect to. The type is `list of strings`, defaults to `[ipfs_swarm_connect_addresses]`\\n\\n## Subscribed topics\"}},{\"node\":{\"id\":\"55548af7707900f510e5e246cedfc0f8\",\"title\":\"IoT Sensors Connectivity\",\"path\":\"/docs/ko/iot-sensors-connectivity/\",\"content\":\"\\nRobonomics Network allows you to communicate with any sensor you wish and get data from the sensor all around the world. This data can be transferred to different destinations.\\n\\nOn this page you'll find step-by-step instructions to connect an ESP board to the connectivity server provided by AiraLab.\\n\\n## Requirements\\n\\n* ESP8266/ESP32 like board with WiFi\\n\\n## 1. Get the software\\n\\n### On Windows\\n\\nInstall [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\\n\\nInstall Ubuntu via Windows Store:\\n\\n![Windows Store](../images/windows_store.jpg \\\"Windows Store\\\")\\n\\nand clone the [package](https://github.com/airalab/sensors-connectivity)\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\n```\\n\\nThe next step is to install python and dependencies:\\n\\n```\\nsudo apt update && sudo apt install python3-pip\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n### On Ubuntu\\n\\n```\\nsudo apt update && sudo apt install python3-pip git\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n> You can ignore such warnings:\\n>\\n> ```\\n> The script ... is installed in '...' which is not on PATH.\\n> Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\n> ```\\n\\n### On NixOS\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\nnix build -f release.nix\\nsource result/setup.bash\\n```\\n\"}},{\"node\":{\"id\":\"ecca65167981bebf1002b6321cbe583e\",\"title\":\"IPFS Common Messages\",\"path\":\"/docs/ko/ipfs-common-messages/\",\"content\":\"\\n## ipfs_common/Filepath.msg\\n\\n| Field         | Type                  | Description           |\\n|------------   |-------------------    |--------------------   |\\n| filepath      | std_msgs/String       | A path to a file      |\\n\\n## ipfs_common/Multihash.msg\\n\\n| Field         | Type              | Description                               |\\n|-----------    |-----------------  |------------------------------------------ |\\n| multihash     | std_msgs/String   | A wrapper for model and objective fields  |\\n\\n## ipfs_common/IpfsDownloadFile.srv\\n\\n**Request**\\n\\n| Field         | Type                                                  | Description               |\\n|-------------- |---------------------------------------------------    |------------------------   |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of a file       |\\n| file          | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)       | Where to save the file    |\\n\\n**Response**\\n\\n| Field         | Type              | Description           |\\n|-----------    |-----------------  |---------------------  |\\n| success       | std_msgs/Bool     | Status of execution   |\\n| error_msg     | std_msgs/String   | Error message         |\\n\\n## ipfs_common/IpfsUploadFile.srv\\n\\n**Request**\\n\\n| Field     | Type                                              | Description                               |\\n|-------    |-------------------------------------------------  |---------------------------------------    |\\n| file      | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)   | Path to a file to be uploaded to IPFS     |\\n\\n**Response**\\n\\n| Field         | Type                                                  | Description                   |\\n|-------------- |---------------------------------------------------    |----------------------------   |\\n| success       | std_msgs/Bool                                         | Status of execution           |\\n| error_msg     | std_msgs/String                                       | Error message                 |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of uploaded file    |\\n\"}},{\"node\":{\"id\":\"8c837ff2e14effb4ec8abef05e5b3133\",\"title\":\"IoT Firmware Upload\",\"path\":\"/docs/ko/iot-firmware-upload/\",\"content\":\"\\nThere are few firmwares for ESP like boards:\\n\\n* [Ping](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/ping)\\n* [TCP](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/tcp)\\n* [Mobile GPS](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/mobile_gps)\\n\\nThere is a script to upload a firmware for each one, called `flash_firmware.py`. It's located in the root of the repository\\n\\n> **Requirements**\\n> In order to install all dependencies run in the root of the repository folder:\\n>\\n> ```\\n> pip install -r requirements.txt\\n> ```\\n>\\n> Python3 is required!\\n\\nUsually in order to upload a firmware to your board follow these steps:\\n\\n1. Assemble the board and connect it to PC\\n2. Edit a `config.yaml` in a corresponding folder (e.g. `boards/esp/tcp/config.yaml`)\\n3. Run `python flash_firmware.py -s PATH_TO_FOLDER -c PATH_TO_CONFIG` where `PATH_TO_FOLDER` is a path to the desired firmware (e.g. `boards/esp/ping`) and `PATH_TO_CONFIG` is a path to the configuration file (e.g. `boards/esp/ping/config.yaml`)\\n\\n\"}},{\"node\":{\"id\":\"b4777ef9436dc4bf287464df1d89e1b5\",\"title\":\"Interact with AIRA\",\"path\":\"/docs/ko/interact-with-aira/\",\"content\":\"\\nAt this point you should be familiar with a [DApp](/docs/get-weather-on-fuji-mountain/) and how to launch [AIRA image](/docs/aira-installation-on-vb/).\\nNow you are ready to do more complicated stuff like installing a package and interacting with it via DApp.\\n\\n> **Important:**\\n> Make sure you have covered previous lessons before you continue.\\n\\n\\n> **Tip:**\\n> During the lesson you will type a few commands in terminal. AIRA image doesn't support clipboard, so to make life easier have a look at [Connect via SSH](/docs/aira-connecting-via-ssh/) and log in via SSH to the VM.\\n\\nWalkthrough video:\\n\\nhttps://www.youtube.com/embed/QM06l07_wuA\\n\\n## Package installation\\n\\nAfter you launched AIRA and logged in using your terminal do the following:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nRun one by one commands above. After the last one you should see a link to DApp generated specifically for your instance.\\n\\n![Terminal with AIRA](../images/aira_hello_terminal.jpg \\\"Terminal with AIRA\\\")\\n\\nClick on the link, the DApp should be shown.\\n\\n## DApp \\n\\nConnect [MetaMask](http://metamask.io/) if prompted and click on the button\\n\\n![Request connection in Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Request connection in Robonomics Dapp\\\")\\n\\nSign the message as usual and wait for the result\\n\\n![Wait for Result of request](../images/aira_hello_dapp_2.jpg \\\"Wait for Result of request\\\")\\n\\nMeanwhile have a look at the terminal. You should see the greeting\\n\\n![AIRA greeting in terminal](../images/aira_hello_terminal_2.jpg \\\"AIRA greeting in terminal\\\")\\n\\nIn the end the greeting will appear in the DApp\\n\\n![Robonomics DApp Greeting for AIRA](../images/aira_hello_dapp_3.jpg \\\"Robonomics DApp Greeting for AIRA\\\")\\n\\n## Troubleshooting\\n\\n### You click \\\"Request current values\\\" but see no greeting\\n\\nProbably you have just launched AIRA and IPFS hasn't finished initialization. Wait a minute or so and try again.\\n\\n### I see response hash but the data doesn't appear\\n\\nAgain most probably the issue comes from IPFS connection. Click and the hash and you'll see the result. It's not necessary to download the file.\\n\\n## Home Task (optional)\\n\\nIf you are familiar with [Python](https://www.python.org/) change the shown text to something different and complete the lesson with your version of `hello_aira`\\n\\n- Make a fork of the [repository](https://github.com/vourhey/hello_aira)\\n- The output text is located [here](https://github.com/Vourhey/hello_aira/blob/master/scripts/hello_aira#L45)\\n\"}},{\"node\":{\"id\":\"75916d0c7d87f689264e9c0544a7f5b6\",\"title\":\"How to launch the Robonomics collator\",\"path\":\"/docs/ko/how-to-launch-the-robonomics-collator/\",\"content\":\"\\nNote: In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is maintained by developers, but anyone can support the project. Every additional full node of the blockchain helps it to be more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it could be [built from source](/docs/how-to-build-collator-node/).\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nBut we recommend that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need use *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can simply launch a collator directly in the command line to check for errors.\\nAfter that we strongly recommend to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](../images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](../images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with : `journalctl -u robonomics.service -f` \\n\\nNow the robonomics collator is launched it will sync with the Kusama Relay Chain, this can take up quite some time depending on your network speed and system specifications, so we recommend to download a Kusama snapshot and use it. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the robonomics service. You can find more info about snapshots and usage instructions on the followin page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](../images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](../images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\"}},{\"node\":{\"id\":\"37a93f7b7837a176d25ba5f7dfea0d07\",\"title\":\"How to build collator node from source\",\"path\":\"/docs/ko/how-to-build-collator-node/\",\"content\":\"\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](../images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v1.4.0:\\n\\n```\\n  rustup install nightly-2021-11-02\\n```\\n![Install nightly](../images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2021-11-02\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2021-11-02\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v1.4.0 robonomics-node\\n```\\n![Start build Robonomics](../images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](../images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"}},{\"node\":{\"id\":\"b82f99a314cdf9808f9f00330348063e\",\"title\":\"Passing dynamic parameters\",\"path\":\"/docs/ko/hardware-passing-dynamic-parameters/\",\"content\":\"\\nIn [previous](/docs/connect-simple-cps/) example we discussed how to create a simple CPS with Arduino. Our first CPS is able to do only one task: to blink a led. We suggest you to get through the first lesson. Now let's expand the example and teach our board to blink blue or red led depending on objective parameter.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_with_args).\\n\\n\\n## Arduino\\n\\nThe only difference in Arduino source code is instead of subscribing to one topic now we subscribe to `/blink_red` and `/blink_blue` topics\\n\\n```c\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void blinkRedCb(const std_msgs::Empty& msg) {\\n    blink(13, 500);\\n    blink(13, 500);\\n    blink(13, 500);\\n  }\\n\\n  void blinkBlueCb(const std_msgs::Empty& msg) {\\n    blink(12, 500);\\n    blink(12, 500);\\n    blink(12, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> subRed(\\\"blink_red\\\", &blinkRedCb);\\n  ros::Subscriber<std_msgs::Empty> subBlue(\\\"blink_blue\\\", &blinkBlueCb);\\n\\n  void setup()\\n  {\\n    pinMode(13, OUTPUT);\\n    pinMode(12, OUTPUT);\\n\\n    nh.initNode();\\n    nh.subscribe(subRed);\\n    nh.subscribe(subBlue);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n<!-- Here is the diagram of all connections:\\n\\n.. image:: ../img/6.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\n\\n## ROS\\n\\nWe can pass arguments via objective which points to rosbag file. Have a look at `blink.py` script. The main difference is `blink()` method:\\n\\n```python\\ndef blink(self, data):\\n  if data.data == \\\"blue\\\":\\n      rospy.loginfo(\\\"Blinking blue...\\\")\\n      self.blink_blue.publish(Empty())\\n\\n  if data.data == \\\"red\\\":\\n      rospy.loginfo(\\\"Blinking red...\\\")\\n      self.blink_red.publish(Empty())\\n\\n  rospy.wait_for_service('/liability/finish')\\n  fin = rospy.ServiceProxy('/liability/finish', FinishLiability)\\n  fin(FinishLiabilityRequest(address=self.liability, success=True))\\n  rospy.loginfo(\\\"Finished\\\")\\n```\\n\\nNow `/blink` topic has a `String` type. You can find prepared rosbags in `rosbag` folder.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh/). Do not forget to add `COM1` port in settings. Run the following command:\\n\\n```\\n$ rosrun arduino_with_args blink.py\\n```\\n\\nAlso we need to add rosbag files to IPFS:\\n\\n```\\n$ ipfs add rosbag/blink_blue.bag\\n$ ipfs add rosbag/blink_red.bag\\n```\\n\\n**Before the next step you should approve XRT tokens on the Factory.**\\n\\nThe last step is to build Dapp and launch. Take a look at the previous [lesson](/docs/connect-simple-cps/). To make Arduino blink the blue led send blue demand and blue offer messages. For the red one send corresponding messages.\\n\\nThat's it! Now you are able to pass dynamic parameters to your cyber-physical system agent!\"}},{\"node\":{\"id\":\"f34e32a27409170eb6dddfea5a3a4236\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/ko/home-assistant-begin/\",\"content\":\"There are instructions on how to connect your smart home devices to the Robonomics network. You need Robonomics [accounts](/docs/create-account-in-dapp/) for each device, they will publish encrypted data in datalog. Also you need user account that will send commands to devices end encrypt/decrypt data.\\n\\nIn this video you can see the example of connecting temperature sensor:\\n\\nhttps://youtu.be/iB2Z8HtERgs\\n\\n# Requirements\\n\\n* Raspberry Pi 4 or 3\\n* SD card and SD adapter\\n* Temperature sensor - [Keen Home RS-THP-MP-1.0](https://www.zigbee2mqtt.io/devices/RS-THP-MP-1.0.html) (or another [supported device](https://www.zigbee2mqtt.io/information/supported_devices.html))\\n\\n### Method 1 (with SLS Gateway)\\n* [Robonomics SLS Gateway](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01)\\n\\n### Method 2 (with zigbee2MQTT)\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\n### Method 3 (with Xiaomi Gateway)\\n* Xiaomi Gateway (one of [supported](https://www.home-assistant.io/integrations/xiaomi_miio#xiaomi-gateway))\\n* [Mi Home app](https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&hl=ru&gl=US) or HomeKit app\\n\\nAlso you can connect some devices directly through Mi Home app (for example, Vacuum Cleaner).\\n\\n# Setup\\n\\n1. First you need to [setup Raspberry Pi](/docs/raspberry-setup/) (also you can [use prepared image](/docs/raspberry-image/)).\\n2. Then you need to connect devices to Home Assistant:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n3. And [connect them to Robonomics Network](/docs/add-smart-device-to-robonomics/).\\n\"}},{\"node\":{\"id\":\"ebffe57b8749a95377e76c6bd1cf3384\",\"title\":\"Connect an Air Pollution Sensor\",\"path\":\"/docs/ko/hardware-connect-sensor/\",\"content\":\"\\nIn this lesson you are going to learn how to connect your sensor to the network and make it publish data. You will see how it is easy to become a member of a global sensor network!\\n\\nSource code is located [here](https://github.com/airalab/robonomics_tutorials/tree/master/sensor_city).\\n\\nIn this section we are not going to create a liability contract. Instead we will teach Arduino with sensors to publish the data by a request. All measurements will be published as a Result message.\\n\\n## Arduino\\n\\nLet's begin with an Arduino circuit. You need the following components:\\n\\n* Arduino Uno\\n* Optical Dust Sensor Sharp GP2Y1010AU0F\\n* Gas Sensor MQ-2\\n* Gas Sensor MQ-7\\n* Resistor 150 Ohm\\n* Capacitor 220 uF\\n* Wires\\n\\nConnect all parts as described below:\\n\\n<!-- .. image:: ../img/7.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\nA firmware for Arduino Uno is in `sensor_city/scetches` folder. In order to upload it to the board use [Arduino IDE](https://www.arduino.cc/en/Main/Software).\\n\\n<!-- .. image:: ../img/8.png\\n   :alt: Arduino IDE\\n   :align: center\\n -->\\n\\n## Aira\\n\\nThe following steps are performed in Aira client. You can download the latest image from [this page](https://github.com/airalab/aira/releases). It's convenient to [connect via SSH](/docs/aira-connecting-via-ssh/).\\n\\nAfter you have imported the image to VirtualBox, connect Arduino via USB to your PC and enable serial port forwarding. You should check `Enable Serial Port` and assign `/dev/ttyACM0` in `Path/Address`. Inside the virtual machine `/dev/ttyS0` refers to your external Arduino.\\n\\n<!-- .. image:: ../img/9.png\\n   :alt: Set a port\\n   :align: center -->\\n\\nFinally launch the image and run these command:\\n\\n```\\n$ roslaunch sensor_city publish_data.launch\\n```\\n\\n**Check out the source code to learn how it works under the hood!**\\n\\nNow Aira patiently waits for a signal to publish the measurements. Go to [Dapp](https://dev.aira.life/smart-city/#/) and click on `Broadcast signal`. You should see the data!\"}},{\"node\":{\"id\":\"1dcdc26b50c57c8502d7e561c29d206b\",\"title\":\"용어 사전\",\"path\":\"/docs/ko/glossary/\",\"content\":\"\\n## 에이전트\\n\\nRobonomics Network의 따라 에이전트는 IPFS 이나 블록체인 이나 네트워크의 두 인터페이스를 모두 사용하고 실제 작업을 수행하는 프로그램 모듈입니다. 일반적으로 ROS 패키지로 표시되며 실제 사이버 물리적 시스템을 Robonomics 네트워크에 연결할 수 있습니다 (반드시 그런 것은 아님).\\n\\n## 사이버-물리 시스템\\n\\n일반적으로 로봇이라고하는 물리적 메커니즘과 메커니즘의 동작을 제어하는 프로그램 알고리즘의 결합입니다.\\n\\n## DAPP\\n\\n분산 애플리케이션을위한 짧은 형식입니다. 일반적으로 에이전트와 상호 작용하는데 도움이되는 단일 페이지 웹 기반 애플리케이션입니다.\\n\\n## IPFS\\n\\n[공식 전보에 따르면](https://docs.ipfs.io/introduction/)  \\\"IPFS는 파일, 웹 사이트, 응용 프로그램 및 데이터를 저장하고 액세스하기위한 분산 시스템입니다\\\". 작동 방식에 대한 자세한 내용은 공식 웹 사이트를 참조하시기 바랍니다.\\n\\n## Lighthouse\\n\\n등대는 단일 방송 채널을 제공하는  업체의 실행 시간을 배포할 수있는 자율적인 워크 플로입니다.\\n\\n자세한 내용은 [Robonomics 백서](https://static.robonomics.network/docs/whitepaper/Robonomics-whitepaper-en.pdf) 섹션 5.2를 참조하시기 바랍니다..\\n\\n## 사이드 체인\\n\\nAiralab이 소유한 Proof-of-Authority 합의가있는 이더리움 기반 블록체인 네트워크입니다.\"}},{\"node\":{\"id\":\"4fa4ec657d7ea98af6d3de36f93f07db\",\"title\":\"Getting Started\",\"path\":\"/docs/ko/\",\"content\":\"\\n## What is Robonomics\\n\\nRobonomics platform provides tools for working with the robot economy network. Robonomics allow designers of smart cities and industry 4.0 zones to build trust among the [autonomous robots services](/docs/glossary#cyber-physical-system), provide [direct user access via dapp](/docs/glossary#dapp) for ordering products from autonomous factories and services of urban sensor networks. This in turn will allow us to put in place a decentralized system that globally monitors the activities of cyber physical systems.\\n\\nThe following chart describes what place Robonomics takes in the scenario:\\n\\n![Robonomics Chart](../images/robonomics_network_basic_scheme.jpg \\\"Robonomics Network scenario\\\")\\n\\nFind more in [Building dApps on Robonomics deck](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf)\\n\\n## Robonomics Network quick start\\n**For newcomer's convenience core Robonomics developers came up with a [6 lessons learning curve](https://wiki.robonomics.network/docs/en/wschool2021-intro/)!**\\n\\nYou'll explore the serverless IoT architecture! Robonomics Web Services (RWS) is the basic infrastructural service for Robotics and IoT on top of Polkadot && IPFS.\\n\\nCourse graduates can launch a local relay chain and control a ROS-compatible device through cross-chain transaction.\\n\\n**[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.**\\n\\n### Benefits for Robonomics Academy graduates\\n- Intership for best students   Become a Robonomics team member and contribute to the development of the chosen product.\\n- Active community && regular events   Become a part of the learner's community, discuss your use-cases with industry experts. Team-up and participate in hackathons!\\n- Certificate of completion   Add a certificate for completing the course on building DAPPs for IoT to your portfolio.\\n- Assistance in admission to the ITMO university. Whether you are a bachelor or master, you'll get assistance in your admission to the university.\\n- Funding && acceleration opportunities: 1)Apply for up to $50.000 Academia - support grant; 2)Participate in Robonomics builders acceleration program supported by Web3 Foundation; 3)Deploy your stand-alone DAPP on top of Robonomics; 4)Monetize it && get marketing support from Robonomics team.\\n\\n\\n## What the documentation contains\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"}},{\"node\":{\"id\":\"df4973c11867968897f3e033eac2cde2\",\"title\":\"DEMO \\\"Get Weather on Fuji Mountain\\\"\",\"path\":\"/docs/ko/get-weather-on-fuji-mountain/\",\"content\":\"\\n**Let's start from a quick example of what Robonomics is able to do within 5 minutes. Requirements: [Metamask extension](https://metamask.io/)**\\n\\nTo get the weather from sensor on Fuji Mountain, please, open the page of [Fuji Weather sensor](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/) in Robonomics dApp and follow instructions below.\\n\\nHere's a walkthrough video:\\n\\nhttps://www.youtube.com/embed/t098NlMELk4\\n\\n## 1. Open the Dapp\\n\\nIn case you don't have MetaMask extension you'll see the picture below. Go to the link provided above and install one.\\n\\n![\\\"Robonomics dApp if no MetaMask installed\\\"](../images/sensor-demo/sensor-demo-1.png \\\"Robonomics dApp if no MetaMask installed\\\")\\n\\n## 2. Allow connection to the extension\\n![\\\"Connection to Robonomics dApp via Metamask\\\"](../images/sensor-demo/sensor-demo-2.png \\\"Connection to Robonomics dApp via Metamask\\\")\\n\\n## 3. Press \\\"Request current values\\\"\\n![\\\"Request sensor's data in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-3.png \\\"Request sensor's data in Robonomics network via dApp\\\")\\n\\n## 4. Sign a message. No token or ether are needed\\n![\\\"Sign a message in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-4.png \\\"Sign a message in Robonomics network via dApp\\\")\\n\\n## 5. Wait until the agent collects the data and sends it back\\n![\\\"Wait for response of the agent in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-5.png \\\"Wait for response of the agent in Robonomics network via dApp\\\")\\n\\n## 6. Wait until the Dapp downloads the result file from IPFS\\n![\\\"Wait for IPFS file with results in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-6.png \\\"Wait for IPFS file with results in Robonomics network via dApp\\\")\\n\\n## 7. Look at the weather data on Fuji Mountain\\n![\\\"The results of sensor network in Robonomics via dApp\\\"](../images/sensor-demo/sensor-demo-7.png \\\"The results of sensor network in Robonomics via dApp\\\")\\n\\nJust now you have broadcasted a demand message and got a result from an autonomous agent! The result file is stored in IPFS, the result message is signed with the agent's private key.\\n\"}},{\"node\":{\"id\":\"a1fd3921031ce4c42636cb7794eace1c\",\"title\":\"How to Buy a Subscription\",\"path\":\"/docs/ko/get-subscription/\",\"content\":\"\\nhttps://youtu.be/EsUiG_4ZGcw\\n\\nWe will use [Robonomics dev node](/docs/run-dev-node) to try the subscription, but in the production network everything works the same. \\n\\nIn `Developer/Chain state` you can see auctions for subscriptions (to get a subscription you need to win a fast auction). Choose `rws` and `auctionQueue` and press `+` button, you will see IDs of available auctions:\\n\\n![queue](../images/dev-node/queue.png)\\n\\nYou can see an information about any subscription with `rws` `auction` and ID of auction (the auction's ID in the picture is 0):\\n\\n![auction](../images/dev-node/auction.png)\\n\\nIn the information about the auction you can see `winner` field, at the moment it is `null` so nobody has this subscription and we can get it. For that go to `Developer/Extrinsic`, choose your account and `rws -> bid`. Also set auction ID (0) and the amount of units to bid (more than 1000000000 Wn):\\n\\n![bid](../images/dev-node/bid.png)\\n\\nSubmit the transaction and check the information about the auction with ID 0 (in `Chain state` choose `rws -> auction` and ID 0):\\n\\n![win](../images/dev-node/auc_win.png)\\n\\nNow in `winner` field you will see your account address, it means that this account has the subscription 0. An auction starts with the first bid and lasts a few blocks, so if somebody bids more tokens than you in the next few blocks one will be the winner and one will take the subscription.\\n\\nNow you can add devices. Devices are accounts that are able to use this subscription and send extrinsics with no fee. To test it lets create a new account with no tokens and add it to devices. \\n\\nTo add devices choose `rws -> setDevices` in `Developer/Extrinsic`. Then press `Add Item` button and choose recently created account with no tokens:\\n\\n![set_devices](../images/dev-node/set_devices.png)\\n\\nSubmit the transaction. Now you can check the list of devices in `Chain state` with `rws -> devices`. There you will see the address of your account without tokens. Choose the account that has bought the subscription and press `+`:\\n\\n![devices](../images/dev-node/devices.png)\\n\\nNow you can try to [send launch](/docs/subscription-launch) extrinsic using the subscription.\"}},{\"node\":{\"id\":\"83b5ce1b04353c26a9ac22798ceb6d76\",\"title\":\"Gaka-Chu setup and software Installation\",\"path\":\"/docs/ko/gaka-chu/\",\"content\":\"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](../images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](../images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"}},{\"node\":{\"id\":\"c40597475d1db55db0b12dd66cb01056\",\"title\":\"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\"path\":\"/docs/ko/freertos-mqtt/\",\"content\":\"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](../images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](../images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](../images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](../images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](../images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"}},{\"node\":{\"id\":\"da19ca9210c605576b73fbdf990b963f\",\"title\":\"Ethereum Common\",\"path\":\"/docs/ko/ethereum-common/\",\"content\":\"\\nThe packages contains two launch files: `erc20.launch` and `signer.launch`. The last one is included in [Robonomics Liability](/docs/robonomics-liability).\\n\\nBelow is the description for `erc20` node which contains utils for convenient work with Ethereum accounts and XRT token.\\n\\n## ROS Parameters\\n\\n###  ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~erc20_token\\n\\nERC20 token to work with. Type is `string`, defaults to `xrt.5.robonomics.eth`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Published topics\\n\\n### /eth/event/transfer (ethereum_common/TransferEvent)\\n\\nThe event [ethereum_common/TransferEvent](/docs/ethereum-common-messages#ethereum_commontransfereventmsg) is emitted after the transfer of tokens was made\\n\\n### /eth/event/approval (ethereum_common/ApprovalEvent)\\n\\nThe event [ethereum_common/ApprovalEvent](/docs/ethereum-common-messages#ethereum_commonapprovaleventmsg) is emitted after the approval of tokens was made\\n\\n## Services\\n\\n### /eth/accounts (ethereum_common/Accounts)\\n\\nList of available Ethereum accounts. See [ethereum_common/Accounts](/docs/ethereum-common-messages#ethereum_commonaccountssrv)\\n\\n### /eth/account_eth_balance (ethereum_common/AccountBalance)\\n\\nReturns the balance of the given address in Wei. See [ethereum_common/AccountBalance](/docs/ethereum-common-messages#ethereum_commonaccountbalancesrv)\\n\\n### /eth/eth_balance (ethereum_common/Balance)\\n\\nReturns the balance of the default address. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/current_block (ethereum_common/BlockNumber)\\n\\nReturns current block number. See :ref:`Ethereum-common-BlockNumber.srv`\\n\\n### /eth/transfer (ethereum_common/Transfer)\\n\\nTransfers tokens from the default account to a given one. See :ref:`Ethereum-common-Transfer.srv`\\n\\n### /eth/transfer_from (ethereum_common/TransferFrom)\\n\\nTransfers tokens from a given account to another one. See :ref:`Ethereum-common-TransferFrom.srv`\\n\\n### /eth/approve (ethereum_common/Approve)\\n\\nApproves tokens from the default account to a given one. See :ref:`Ethereum-common-Approve.srv`\\n\\n### /eth/account_xrt_balance (ethereum_common/AccountBalance)\\n\\nReturns the XRT balance of a given account. See :ref:`Ethereum-common-AccountBalance.srv`\\n\\n### /eth/xrt_balance (ethereum_common/Balance)\\n\\nReturn the XRT balance of the default account. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/account_xrt_allowance (ethereum_common/AccountToAddressAllowance)\\n\\nReturns how much one account is allowed to spend from another account. See :ref:`Ethereum-common-AccountToAddressAllowance.srv`\\n\\n### /eth/xrt_allowance (ethereum_common/Allowance)\\n\\nReturns how much the Factory is allowed to spend from the default account. See :ref:`Ethereum-common-Allowance.srv`\"}},{\"node\":{\"id\":\"896fffddf0720823305d0c59bbbdcbd7\",\"title\":\"Ethereum Common Messages\",\"path\":\"/docs/ko/ethereum-common-messages/\",\"content\":\"\\n## ethereum_common/Address.msg\\n\\n| Field   \\t| Type            \\t| Description                    \\t|\\n|---------\\t|-----------------\\t|--------------------------------\\t|\\n| address \\t| std_msgs/String \\t| Address in Ethereum blockchain \\t|\\n\\n## ethereum_common/UInt256.msg\\n\\n| Field   \\t| Type            \\t| Description                \\t|\\n|---------\\t|-----------------\\t|----------------------------\\t|\\n| uint256 \\t| std_msgs/String \\t| A wrapper for big integers \\t|\\n\\n## ethereum_common/TransferEvent.msg\\n\\n| Field      \\t| Type                                                  \\t| Description      \\t|\\n|------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_from  \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Sender address   \\t|\\n| args_to    \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Receiver address \\t|\\n| args_value \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/ApprovalEvent.msg\\n\\n| Field        \\t| Type                                                  \\t| Description      \\t|\\n|--------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_owner   \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Owner address    \\t|\\n| args_spender \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Spender address  \\t|\\n| args_value   \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/AccountBalance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field   \\t| Type                                                  \\t| Description    \\t|\\n|---------\\t|-------------------------------------------------------\\t|----------------\\t|\\n| balance \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wei \\t|\\n\\n## ethereum_common/AccountToAddressAllowance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n| to      \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field  \\t| Type                                                  \\t| Description   \\t|\\n|--------\\t|-------------------------------------------------------\\t|---------------\\t|\\n| amount \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wn \\t|\\n\\n## ethereum_common/Accounts.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------- |-------------------------------------------------------    |----------------------------   |\\n| accounts  | [ethereum_common/Address[]](#ethereum_commonaddressmsg)     | List of available accounts    |\\n\\n## ethereum_common/Allowance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                                       |\\n|--------   |-------------------------------------------------------    |-----------------------------------------------    |\\n| amount    | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | Amount of XRT the Factory is allowed to spend     |\\n\\n## ethereum_common/Approve.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------  |-------------------------------------------------------    |-----------------------------  |\\n| spender   | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Who is allowed to spend       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | How much tokens are allowed   |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/Balance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                       |\\n|---------  |-------------------------------------------------------    |--------------------------------   |\\n| balance   | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The balance of default account    |\\n\\n## ethereum_common/BlockNumber.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type              | Description           |\\n|--------   |-----------------  |---------------------- |\\n| number    | std_msgs/Uint64   | Current block number  |\\n\\n## ethereum_common/Transfer.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Ethereum address      |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/TransferFrom.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| owner     | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Owner's address       |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Another account       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\"}},{\"node\":{\"id\":\"502c79588683b7f7ddbd7e51a46ce714\",\"title\":\"How to edit WIKI\",\"path\":\"/docs/ko/edit-wiki/\",\"content\":\"\\n**Robonomics WIKI is open source. Any corrections are welcome: fixing errors, typos, some unclear or outdated information, translation into any language. You'll need a [GitHub](https://github.com/) account.**\\n\\n## Edit existing doc\\n\\n1. Choose page\\n2. Click button \\\"Edit page\\\" marked with the Github logo on the page you want to edit\\n3. Clicking on the button will take you to the .md file.\\n4. Please, follow common rules for editing [Markdown files](https://en.wikipedia.org/wiki/Markdown), bearing in mind a few features of the WIKI stack:\\n\\n### Frontmatter\\nDocs in Robonomics WIKI contain frontmatter block. It must be at the top of the Markdown file, and must take the form of valid YAML set between triple-dashed lines. Between the triple-dashed lines, you can set or edit folowing options:\\n\\n```YAML\\n---\\ntitle: How to contribute # Title for the page, you do not need to duplicate it in text\\ncontributors: [positivecrash] # Main contributors (who actively curates this page). GitHub nickname required, without any additional symbols\\ntranslated: true # \\\"true\\\" if it has been translated in current language (see locale folder name of doc)\\n---\\n```\\n\\n### Images\\n1. Upload image in folder `/docs/images/url-of-your-doc`\\n* If image needs to be localized, insert all of them in one folder\\n* Use locale appendix in name of images if it's localized, e.g. `image_en.jpg`\\n* Make sure your image is web optimised and at the same time it looks good\\n2. Insert images standart way for Markdown files.\\n\\n### YouTube videos\\nYou can embed any YouTube video in doc by inserting share link as separate paragraph without any additional quotes or tags, e.g.: `https://youtu.be/kQaSwNYHJQ8`\\n\\n### Asciinema\\nRobonomics WIKI has support for Asciinema. To insert Asciinema, please, follow these instructions:\\n* Import component after frontmatter block `import Asciinema from '~/components/Asciinema.vue'`\\n* Insert as separate paragraph `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, where is vid is ID of specific asciicast\\n\\n> You can get the widget script for a specific asciicast by clicking on “Embed” link on asciicast page.\\n> It looks like this:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Asciinema docs](https://asciinema.org/docs/embedding)\\n\\nIn the example above vid is 14.\\n\\n## Add new doc\\n\\nIf you need to add new page in docs of Robonomics WIKI, please, follow these steps:\\n\\n1. Find the folder with the locale that matches the language of the article you are adding, e.g. `/docs/en/`\\n2. Create .md file, using in name latin characters and follow common rules for [url structure](https://developers.google.com/search/docs/advanced/guidelines/url-structure)\\n3. Edit file as described above\\n4. Duplicate file to other locale folders, even if you do not plan to translate them. Do not forget mark in frontmatter not translated pages as `translated: false`\\n5. Add doc in menu:\\n* Open file `/data/sidebar_docs.yaml`\\n* Decide where to place your doc\\n* If you want to create new section, provide title with locale appendix, using only locales your section is translated\\n* Add doc with link. The link must be only one, and must not contain locale characters. Correct is `/docs/url-of-your-doc`, not correct is `/docs/en/url-of-your-doc`\\n* Use valid YAML for `/data/sidebar_docs.yaml` and rely on the existing file structure\\n\\n## Submit Pull Request\\n\\n[Make pull request](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) for any content you changed including typos, translations, outdated information or broken links.\\n\\nDecisions about individual PRs made by Robonomics core team. Special grants in [XRT](https://robonomics.network/community#token) are also possible for extended contribution 🤖💙💛💚💎🍭🎉🔌\"}},{\"node\":{\"id\":\"1c16ac0d01787d21c01fb97f0c724c03\",\"title\":\"Digital Twins\",\"path\":\"/docs/ko/digital-twins/\",\"content\":\"\\n## Requirements\\n- `robonomics` [executable][ln1]\\n- Be familiar with [parachain.robonomics][ln2]\\n\\n## Digital Twins Schema\\n\\nDigital twins have the following structure:\\n\\n| DT id \\t| Topic Name \\t| Source    \\t|\\n|-------\\t|------------\\t|-----------\\t|\\n| 0     \\t| 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1     \\t| 0x00...001 \\t| 4GVi...Bn \\t|\\n|       \\t| 0x00...002 \\t| 4Hm...vLS \\t|\\n|       \\t| 0x00...... \\t| 4HQ...RQY \\t|\\n|       \\t| 0xFF...FFF \\t| 4Hw...CyK \\t|\\n| 2     \\t| 0x00...000 \\t| 4HJ...k3o \\t|\\n\\n Where:\\n* **DT id** - is unsigned integer unique number.\\n* **Topic name** - is 0x prefixed `H256 hex` or `ascii data` with 32 bytes length. For example: `0x1234....FF` and  `hello.parachain.robonomics.world`.\\n* **Source** - is Account address.\\n\\n## Create Digital Twin\\nGo to ***Developer -> Extrinsics*** and choose `digitalTwin.create()` extrinsic.\\n![digital Twin create][im1]\\n\\n Submit transaction and go to ***Network -> Explorer*** and in the **recent events** you will see information about digital twin.\\n ![digital Twin create info][im2]\\n\\n## Add DT Topic\\n\\nYou can create multiple topics for one digital twin. for creating topic you need go to ***Developer -> Extrinsics*** and choose `digitalTwin.setSource(id,topic,source)` extrinsic. Fill in the fields and submit transaction.\\n![DT topic fields][im3]\\n\\nAgain go to **Network -> Explorer*** and in the **recent events** you will see information about created topic.\\n![info about topic][im4]\\n\\nYou can create several topics for one twin.\\n![topics][im5]\\n\\n## Chain State\\n\\nYou can find all information about existing *digital twins in* ***Developer -> Chain state*** such as:\\n- Total number of Digital twins - total()\\n- Information about owner of digital twin - owner(u32)\\n- Information about topics in digital twin - digitalTwin(u32)\\n![chain info][im6]\\n\\n\\n[ln1]: <https://github.com/airalab/robonomics/releases>\\n[ln2]: </docs/create-account-in-dapp>\\n[im1]: <../images/digital-twin/twin-create.jpg>\\n[im2]: <../images/digital-twin/create-log.jpg>\\n[im3]: <../images/digital-twin/fields.jpg>\\n[im4]: <../images/digital-twin/topic.jpg>\\n[im5]: <../images/digital-twin/topics.jpg>\\n[im6]: <../images/digital-twin/chain-state.jpg>\\n\"}},{\"node\":{\"id\":\"2a39ede57c53a161e039f65128e3e5a7\",\"title\":\"Cross-chain Message\",\"path\":\"/docs/ko/cross-chain-messages/\",\"content\":\"\\nXCM (Cross-chain Message) allows sending messages between parachains. You can send launchXcm transaction to run/stop your robot or datalogXcm transaction to save data to blockchain.\\n\\nhttps://www.youtube.com/watch?v=a6XrqoaYhK8&feature=emb_logo\\n\\n## Create Account\\n\\nLets try to send message from Earth to Mars.\\nGo to [parachain.robonomics.network](https://parachain.robonomics.network/#/explorer) and choose `Airalab Rococo` testnet:\\n\\n![testnets](../images/cross-chain/testnet.jpg)\\n\\nIn `Network/Parachains` you will see two parachains with their id:\\n\\n![ids](../images/cross-chain/Parachains_id.jpg)\\n\\nThen go to Earth parachain and [create](https://wiki.robonomics.network/docs/create-account-in-dapp/) two accounts (for example `ROBOT` and `EMPLOYER`). In a new tab go to Mars parachain.\\n\\n## LaunchXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `EMPLOYER` account and launchXcm. Then write Mars parachain id (2000) and choose the `ROBOT` account:\\n\\n![launch](../images/cross-chain/launch.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nTo see your transaction in Mars parachain go to `Network/Explorer` and look at Recent Events.\\n\\n![recent_launch](../images/cross-chain/recent_launch.jpg)\\n\\n## DatalogXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `ROBOT` account and datalogXcm. Write Mars parachain id (2000) and the message:\\n\\n![datalog](../images/cross-chain/datalog.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nYou can see your transaction in Recent Events in Mars parachain:\\n\\n![recent_datalog](../images/cross-chain/recent_datalog.jpg)\\n\\n\\n\"}},{\"node\":{\"id\":\"cd94c40ea0c7a7ed12d5cbba45897878\",\"title\":\"Create digital identity run by Ethereum\",\"path\":\"/docs/ko/create-digital-identity-run-by-ethereum/\",\"content\":\"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](../images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](../images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](../images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](../images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](../images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](../images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"}},{\"node\":{\"id\":\"a09bf3b4ce9df39f246e84ea6bc64c97\",\"title\":\"Create Account for Robonomics Parachain\",\"path\":\"/docs/ko/create-account-in-dapp/\",\"content\":\"\\n**In order to interact and operate with Robonomics Parachain, developers and users need to create an account on the Polkadot / Substrate Portal. The account performs basic functions for the network: your public network address(the public key), the access control to the address and funds (the private key), sending transactions to the network, showing your tokens and their amount, etc. Below are two main ways to create an account for Robonomics Parachain.**\\n\\n## 1. Using Polkadot{.js} Browser Extension\\n\\nThe Polkadot Extension provides a mechanism to generate the account and interact with all Polkadot / Kusama projects including Robonomics Parachain. This is not the safest way to manage your account, but it is the most convenient in terms of security / usability balance.\\n\\n## 1.1. Install Browser Extension\\n\\nThe browser extension is available for [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) and [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=en) (plus Chromium-based browsers).\\n\\n![Browser Extension](../images/creating-an-account/1.1-polkadot-extension.png \\\"Browser Extension\\\")\\n\\n## 1.2. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. If this is the first time you entered the portal, it will request access to the browser extension, so allow access. \\n\\nOnce you've opened the app, take a look at the top left corner. The name of the network, its icon and the number of the last block are displayed there. Clicking on this area will open a list of all Polkadot / Kusama networks, including test networks and local nodes. You can switch between networks by selecting the required one and pressing the `Switch` button. **Make sure you are connected to Robonomics Parachain now**. \\n\\n![Robonomics Parachain app](../images/creating-an-account/1.2-robonomics-app.png \\\"Robonomics Parachain app\\\")\\n\\n## 1.3. Update Extension Metadata\\n\\nIt is very likely that the app will ask you to update the metadata for the extension to display the correct information about the chain you are connected to. Go to **Settings -> Metadata**, press `Update metadata` button and then, in the pop-up window, allow the extension to do it. \\n\\n![Updating metadata](../images/creating-an-account/1.3-metadata-update.png \\\"Updating metadata\\\")\\n\\n## 1.4. Create Account in Extension\\n\\nOpen the Polkadot{.js} browser extension. Click the big plus button or select `Create new account` from the small plus icon in the top right. You should see the following menu, with generated mnemonic seed in the form of twelve words and the address. \\n\\n![Account creation, step one](../images/creating-an-account/1.4-create-account-step-1.png \\\"Account creation, step one\\\")\\n\\nThe seed is your key to the account. Knowing the seed allows you (or anyone else who knows the seed) to get control on this account and even re-create it, if you forget the password. **It's very important to store it somewhere securely**, preferably on paper or other non-digital device, not in digital storage or on a computer. \\n\\nSave the seed and press `Next step`. You should see the following menu.\\n\\n![Account creation, step two](../images/creating-an-account/1.5-create-account-step-2.png \\\"Account creation, step two\\\")\\n\\n- *Network* allows you to choose which of the networks this account will be exclusively used for. You can use the same address on multiple networks, however, for privacy reasons, it is recommended that you create a new address for each network you use. \\nSelect the Robonomics network from the drop-down list. If you could not find the Robonomics network, then most likely you did not update the metadata, go back and do it.\\n\\n    - You will notice that the format of the address and the account icon will change — this is normal. Different network formats are merely other representations of the same public key. \\n\\n- *Name* is just account's name for your use only. It is not stored on the blockchain and will not be visible to other users. \\n\\n- *Password* is used to encrypt your account's information. You will need to re-enter it when signing transactions on the portal. Create one and remember it.\\n\\nAs a result, after creating an account, you will see it in the list of accounts in Polkadot{.js} extension. By clicking on three dots, you can rename the account, export it, remove it from the extension and change the network used for the account. \\n\\nAlso, the account will appear in the **Accounts -> Accounts** menu on the portal, where it will be noted that it was injected using the extension.\\n\\n![Successful account creation](../images/creating-an-account/1.6-account-injected.png \\\"Successful account creation\\\")\\n\\n\\n## 2. Directly on Robonomics Parachain App\\n\\nYou can use the user interface on the Polkadot / Substrate Portal to create an account, although this is not recommended as it is the less secure method for the account creation. It should be used when other methods are not applicable or for development and tests. \\n\\n## 2.1. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check at the top left corner that you are connected to Robonomics Parachain**.  \\n\\nGo to **Accounts -> Accounts** and press `Add account` button. \\n\\n![Robonomics Parachain App](../images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Robonomics Parachain App\\\")\\n\\n## 2.2. Create Account\\n\\nYou should see the following popup menu with account seed. \\n\\n![Generating account seed](../images/creating-an-account/2.2-robonomics-app-seed.png \\\"Generating account seed\\\")\\n\\nIt has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). Save the seed phrase securely and press `Next`.\\n\\nIn the next menu, you need to set the account name and password, similar to the extension instructions described above.\\n\\n![Generating account name and password](../images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Generating account name and password\\\")\\n\\nClicking on the `Next` button will take you to the last window. Click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n![Successful account creation](../images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Successful account creation\\\")\\n\\n## 3. Account Сreated Successfully \\n\\nNow you can fully operate with your fresh-created account. Send and receive tokens, messages, write datalog and more. Feel free to explore all the features of app. To copy your account's address simply click on its icon, address will be copied to clipboard. \\n\\nIf you would like to know more about Polkadot / Kusama accounts and additional ways to create them, more information can be found [here](https://wiki.polkadot.network/docs/learn-accounts) and [here](https://wiki.polkadot.network/docs/learn-account-generation).\\n\"}},{\"node\":{\"id\":\"6ba30379a47ad940d6450eaa4560bcc7\",\"title\":\"How to contribute\",\"path\":\"/docs/ko/contributing/\",\"content\":\"\\nRobonomics network is an open-source project built by core maintainers from Airalab and contributors. We want to make it easy for anyone to contribute. You may contribute to core, suggest changes, improve documentation or write a blog post. Please, read some rules and suggestions for contributing.\\n\\n## Main Airalab repositories \\n\\n- [aira](https://github.com/airalab/aira) - AIRA client for Robonomics network. \\n- [robonomics_comm](https://github.com/airalab/robonomics_comm) - Robonomics communication stack\\n- [robonomics_contracts](https://github.com/airalab/robonomics_contracts) - smart contracts of Robonomics network\\n\\n## Bugs and proposals for improvements\\n\\nIf you find a bug in AIRA client, Robonomics repositories, this documentation or would like to propose an improvement, please, open a new issue in the same repository, that you want to contribute.\\n\\n### Rules for reporting\\n\\nWhen opening a new issue, do not forget about a few basic rules for reporting:\\n\\n1. Choose exact repository, that you want to submit an issue.\\n\\n2. If you are reporting bug, make sure the bug was not already reported.\\n\\n3. Be sure to include title and clear description, as much relevant information as possible.\\n\\n4. Please prefix your issue with one of the following: `[BUG]`, `[PROPOSAL]`, `[QUESTION]`.\\n\\n\\n## Pull requests\\n\\nAny Airalab repository or this documentation may be subject to pull requests or changes by contributors where you believe you have something valuable to add or change. Please, do not forget about basic rules for contributors.\\n\\n### Rules for contributing\\n\\n1. Pull requests are preferred to issues, if you have some fixes, especially for small changes such as typos.\\n\\n2. Make sure the PR description clearly describes the problem and the solution. Include the relevant issue number if applicable.\\n\\n3. Please, do not fix whitespace, format code, or make a purely cosmetic patch.\\n\\n4. Please, attempt to adhere to the prevailing Markdown style, language, and layout.\\n\\n\\n\"}},{\"node\":{\"id\":\"89aaedb40d4ecc3d6dd6431cd5d84ced\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ko/connectivity-terminal-readme/\",\"content\":\"\\n# Sensors-Connectivity Terminal Readme\\n\\n## Connection\\n\\nTo connect to the server:\\n\\n```bash\\nssh <user>@<address>\\n```\\nWhere user and address are replaced with user, which connectivity service runs under, and address of the VM respectively.\\n\\n## Installation\\n\\nInstallation guide can be found on this [page](https://wiki.robonomics.network/docs/en/sensors-connectivity-on-aira/).\\n\\n\\n## Status checking \\n\\nAssuming you launch the code as a systemd service. Therefore, to check service status:\\n\\n```bash\\nsystemctl status connectivity.service\\n```\\nThere you will find all necessary information about the service, including path to the log files.\\n\\n## Logs\\n\\nGeneral path for log files is: ` ~/.ros/log/latest/connectivity-worker-1.log` where `connectivity-worker-1.log` is the last recordered file.\\n\\nFor watching logs in real time:\\n```bash\\ntail -f  <path>\\n```\\nWhere path should be replced with the log path. To look through the whole file simply open the log file in your favourite editor.\\n\\nIt can be useful to copy log files to your local machine:\\n\\n```bash\\nscp -rv <user>@<address>: <path-to-log-files> <path-in-your-local-machine>\\n```\"}},{\"node\":{\"id\":\"3811c9e3dce9df1d2ae535e428243e25\",\"title\":\"Connect the simplest CPS\",\"path\":\"/docs/ko/connect-simple-cps/\",\"content\":\"\\nIn this section we will build the simplest real cyber-physical system!\\n\\nWe will buy a \\\"wink\\\" from Arduino, e.g. make Arduino blink with its onboard led. The lesson is tested on Arduino Uno, but any other board with a led will do the job.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_blink).\\n\\n## Arduino\\n\\nThe firmware for the board is located in [arduino_blink/misc/arduino/arduino.ino](https://github.com/airalab/robonomics_tutorials/blob/master/arduino_blink/misc/arduino/arduino.ino). Use [Arduino IDE](https://www.arduino.cc/en/Main/Software) to load the code to your Arduino board.\\n\\nIn the code we subscribe for the ``/blink_led`` topic and set a callback. The type of the topic is ``Empty``, so the board waits until someone publishes to the topic and performs the LED blinking.\\n\\n```\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle  nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void messageCb( const std_msgs::Empty& toggle_msg){\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> sub(\\\"blink_led\\\", &messageCb );\\n\\n  void setup()\\n  {\\n    pinMode(LED_BUILTIN, OUTPUT);\\n    nh.initNode();\\n    nh.subscribe(sub);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n\\n## AIRA client\\n\\n> You can download the latest release from [here](https://github.com/airalab/aira/releases).\\n\\nSet up the COM port forwarding. You should forward your `/dev/ttyUSB0` or `/dev/ttyACM0` port (depending on the system) to `COM1`. In the client `/dev/ttyS0` will represent the board. After this launch the virtual machine.\\n\\n## ROS\\n\\nWhen new liability is created it goes to `/liability/ready` topic. We have to remember the address and call `/liability/start` service to get the data from objective.\\n\\n```\\n  def newliability(l):\\n    self.liability = l.address\\n    rospy.loginfo(\\\"Got new liability {}\\\".format(self.liability))\\n\\n    prefix = \\\"/liability/eth_\\\" + self.liability\\n    rospy.Subscriber(prefix + '/blink', Empty, self.blink)\\n\\n    rospy.wait_for_service(\\\"/liability/start\\\")\\n    rospy.ServiceProxy('/liability/start', StartLiability)(StartLiabilityRequest(address=self.liability))\\n  rospy.Subscriber(\\\"/liability/ready\\\", Liability, newliability)\\n```\\n\\nA message in the `/blink` topic come from the objective field. Have a look at [Basic usage](/docs/aira-basic-usage) page.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh). All tutorials are pre-installed. To launch the ros package run the following command:\\n\\n```\\n$ rosrun arduino_blink blink.py\\n```\\n\\nAlso we need to add a rosbag file to IPFS::\\n\\n```\\n$ ipfs add rosbag/blink.bag\\n```\\n\\n> Before the next step you should approve XRT tokens on the Factory.\\n\\nOn your host system build and launch an Dapp for the lesson:\\n\\n```\\n$ git clone https://github.com/airalab/robonomics_tutorials/\\n$ cd robonomics_tutorials/arduino_blink_dapp\\n$ npm i && npm run dev\\n```\\n\\nOpen [http://localhost:8000/](http://localhost:8000/) and press \\\"Demand\\\" then \\\"Offer\\\" buttons. Wait until a new liability is created and you should see the board blinking. Congratulations on the first agent!\\n\"}},{\"node\":{\"id\":\"3f962378485d2a6eb08295824613f265\",\"title\":\"Connect Sensor To Robonomics Network\",\"path\":\"/docs/ko/connect-sensor-to-robonomics/\",\"content\":\"\\n## Hardware\\n\\nUniversal board for air quality sensor, based on ESP8266 allows to use the following modules: NODEMCU v3, NODEMCU v2, WEMOS D1 MINI. The device is designed for 6 - 24 volt power supply, using DC-DC converter DC MINI560.\\n\\n![plata](../images/sensors-connectivity/plata.png)\\n\\nThis board allows you to connect PM sensors:\\n\\n- [SDS011](https://cdn-reichelt.de/documents/datenblatt/X200/SDS011-DATASHEET.pdf)\\n- PMS1003-6003\\n- [PMS7003/G7](http://www.plantower.com/en/content/?110.html)\\n- [SPS 30 PM Sensor](https://sensirion.com/products/catalog/SPS30/)\\n\\nI2C connectivity:\\n\\n- [BMP180](https://cdn-shop.adafruit.com/datasheets/BST-BMP180-DS000-09.pdf) - temperature and humidity\\n- [BME/P280](https://www.mouser.com/datasheet/2/783/BST-BME280-DS002-1509607.pdf) - temperature, humidity, atmospheric pressure\\n- [HTU21D](https://eu.mouser.com/ProductDetail/Measurement-Specialties/HTU21D?qs=tx5doIiTu8oixw1WN5Uy8A%3D%3D) - temperature and humidity\\n- SHT3x(I2C) - temperature and humidity\\n- [CCS811 VOC SENSOR](https://www.sciosense.com/wp-content/uploads/documents/Application-Note-Baseline-Save-and-Restore-on-CCS811.pdf) - volatile Organic Compounds, CO2 equivalent\\n- LCD1602/ 2004 / OLED SSD1306 / SH1106 - supported displays\\n\\nPossibility of connection via 1 Wire interface:\\n\\n- DTH22(AM2302) - temperature and humidity\\n- DS18B20 - temperature.\\n\\nThere is also a smaller MINI model with a trimmed down list of connectable devices. The source circuits for both models can be found at [full model](https://oshwlab.com/ludovich88/aira_sensor_rev0-1) and [MINI model](https://oshwlab.com/ludovich88/aira_sensor_d1_mini).\\n\\n> To obtain a ready-made board, contact the developers at vm@multi-agent.io.\\n\\nAfter receiving/assembling the sensor, all that remains is to flash and configure it.\\n\\n## Firmware\\n\\nOur firmware is based on the firmware from [Sensor.Community](https://github.com/opendata-stuttgart/sensors-software), with some sensors added and the data sending scheme changed. The source code can be found [at the link](https://github.com/LoSk-p/sensors-software/tree/master/airrohr-firmware). \\n\\nTo flash the sensor you can use `airrohr-flasher`. Download the executable for your operating system from [latest release](https://github.com/airalab/sensors-connectivity/releases).\\n\\n### For Linux\\n\\nFirst you need to add a user to the `dialout` group (for Ubuntu) to gain access to the USB port:\\n\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\n\\nAfter that, reboot the computer. Next, change the permissions of the file and run it:\\n\\n```bash\\nchmod +x airrohr-flasher-linux\\n./airrohr-flasher-linux\\n```\\n\\n### For Windows:\\nUnzip the flasher and double-click to run it. You will also need to install drivers for USB2serial (Windows 10 should start automatically):\\n\\n* Drivers for NodeMCU v3 (CH340): [Windows](http://www.wch.cn/downloads/file/5.html) ([2018/09/04 v3.4 mirror](https://d.inf.re/luftdaten/CH341SER.ZIP))\\n\\n### For MacOS.\\nDownload the flasher and run it. You will also need to install the drivers for USB2serial: \\n* Drivers for NodeMCU v3 (CH340): [macOS](http://www.wch.cn/downloads/file/178.html) ([2018/09/04 v1.4 mirror](https://d.inf.re/luftdaten/CH341SER_MAC.ZIP))\\n\\n---\\n\\nSelect the firmware (in English or Russian) and click `Upload`. Uploading the firmware will take some time.\\n\\n![flasher](../images/sensors-connectivity/7_flasher.jpg)\\n\\n## Setup\\n\\nAfter downloading the firmware, reboot the ESP (just disconnect and reconnect the USB).\\n\\nAfter a while after the reboot, ESP will create a Wi-Fi network called RobonomicsSensor-xxxxxxxxx. Connect to it from your phone or computer, then an authorization window will open (if it doesn't open in any browser go to 192.168.4.1). Select your Wi-Fi network from the list (or write it yourself if it's not on the list) and fill in the password field. Also write the coordinates of the place where the sensor will be installed in the field below:\\n\\n![guest](../images/sensors-connectivity/guest.jpg)\\n\\nClick `Save and restart`.\\n\\nThe board will connect to the specified Wi-Fi network and in a couple of minutes you will be able to see the data on [map](https://sensors.robonomics.network/#/):\\n\\n![map](../images/sensors-connectivity/14_map.jpg)\\n\\n## Advanced Setup\\n\\nFor a more detailed setup (you may need it to connect additional sensors or send data to your own server) you need to find the address of the sensor in your Wi-Fi network. To do this, you can use `airrohr-flasher` (your computer must be on the same network as the sensor is connected to). Start it and go to the `Discovery` tab, then press `Refresh`, wait a moment and your sensor address will appear.\\n\\n![addr](../images/sensors-connectivity/11_flaser2.jpg)\\n\\nDouble-click on this address (or type it into your browser), you will get to the sensor menu:\\n\\n![home](../images/sensors-connectivity/home.png)\\n\\nUnder the `Configuration` tab you can configure the sensors used:\\n\\n![sensors](../images/sensors-connectivity/sensors.png)\\n\\nAnd also set up sending to your own server. To do this, in the tab `APIs` uncheck `Robonomics` and check `Send to own API` and specify the server address and port (65 for sensors connectivity):\\n\\n![apis](../images/sensors-connectivity/apis_en.png)\\n\\nClick `Save and restart` to save the settings.\\n\\n\\n\"}},{\"node\":{\"id\":\"0bf960bccd15014e02fe06ab775ff988\",\"title\":\"Connect Mars Curiosity rover under Robonomics parachain control\",\"path\":\"/docs/ko/connect-mars-curiosity-rover-under-robonomics-parachain-control/\",\"content\":\"\\n**Let's see how Robonomics Parachain control allows to make Mars Curiosity rover move. Requirements:**\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n- IPFS up to [0.6.0](https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz)\\n- [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases). This tutorial tested fine on v1.1)\\n\\nHere is the video showing successful launch:\\n\\nhttps://www.youtube.com/watch?v=6BSOyRbmac8\\n\\n### 1. Set up a simulation\\nDownload Curiosity rover package:\\n```shell\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src\\ngit clone https://bitbucket.org/theconstructcore/curiosity_mars_rover/src/master/\\ncd ..\\ncatkin build\\n```\\nWe need to adjust starting conditions to make our rover spawn smoothly:\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/worlds` and change line 14 of the file` mars_curiosity.world` to \\n`<pose>0 0 8 0 0 0</pose>`\\n\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/launch` and change line 4 of the file `mars_curiosity_world.launch` to \\n`<arg name=\\\"paused\\\" default=\\\"false\\\"/>`\\n\\nDon't forget to add source command to `~/.bashrc`\\n`source /home/$USER/robonomics_ws/devel/setup.bash`\\n\\n\\n- Reboot console and launch the simulation:\\n\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\n![Mars rover](../images/curiosity-demo/rover.jpg?raw=true \\\"Mars rover\\\")\\n\\nNote: if the image is dark, e.g. shadowed, change `Camera` to `Orthorgraphic` in Gazebo toolbar.\\nThe simulation can be closed for a while.\\n\\n------------\\n\\n### 2. Download Robonomics controller package\\nTo download a controller package for Rover type in terminal:\\n```shell\\ncd ~/robonomics_ws/src\\ngit clone https://github.com/PaTara43/robonomics_sample_controller\\ncd robonomics_sample_controller\\npip3 install -r requirements.txt\\npip3 install rospkg\\ncd ..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3 # The controller supports python3\\n```\\n\\n------------\\n\\n### 3. Manage accounts in DAPP\\nSince we are testing, let us create a local robonomics network with robonomics binary file:\\n```shell\\n./robonomics --dev --tmp\\n```\\n\\n![Running node](../images/curiosity-demo/robonomics.jpg?raw=true \\\"Running node\\\")\\n\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node \\n\\n![Local node](../images/curiosity-demo/local_node.jpg?raw=true \\\"Local node\\\")\\n\\n\\nGo to Accounts and create **CURIOSITY** and **EMPLOYER** accounts.\\n\\n**Important**! Copy each account's address (to copy address click on account's icon) and Curiosity's account **mnemonic seed** (obtained while creating the account)\\nTransfer some money (units) to these accounts. You can read more about accounts in Robonomics [here](https://wiki.robonomics.network/docs/en/create-account-in-dapp/)\\n\\n![Account creation](../images/curiosity-demo/account_creation.jpg?raw=true \\\"Account creation\\\")\\n\\n\\nAdd these addresses, seed and node address (defaults to `ws://127.0.0.1:9944` for developer node) in `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. No quotes.\\n\\n------------\\n\\n\\n### 4. Start Robonomics\\n\\nBefore going further, make sure that you have installed [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion).\\n\\nIn a separate terminal launch IPFS:\\n```shell\\nifps init #you only need to do this once per IPFS installation\\nipfs daemon\\n```\\n\\nIn another separate terminal launch Curiosity simulation if it's not live:\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\nWait till it stays still\\n\\nIn another terminal launch the controller:\\n```shell\\nrosrun robonomics_sample_controller sample_controller.py\\n```\\n![Controller](../images/curiosity-demo/controller.jpg?raw=true \\\"Controller\\\")\\n\\n\\nNow you can send a transaction triggering the Rover to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/).\\nGo to `Developer->Extrinsics` and select Curiosity's employer account, `launch` extrinsic, Curiosity's account as a target account and `yes` as a parameter.\\nSubmit the extrinsic.\\n\\n![Extrinsic](../images/curiosity-demo/extrinsic.jpg?raw=true \\\"Extrinsic\\\")\\n\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter. The rover will move around and collect data for about a minute.\\nLater, when the job is done:\\n\\n![Job done](../images/curiosity-demo/job_done.jpg?raw=true \\\"Job done\\\")\\n\\n\\nOn the Robonomics portal go to `Developer -> Chain state` and obtain a `CURIOSITY` datalog using “+” button with selected `datalog -> RingBufferItem` as query: \\n\\n![Datalog](../images/curiosity-demo/datalog.jpg?raw=true \\\"Datalog\\\")\\n\\nNow the IPFS hash of the telemetry is saved in the blockchain. To see the data simply copy the hash and find it on a gateway:\\n\\n![Data in IPFS](../images/curiosity-demo/data_in_ipfs.jpg?raw=true \\\"Data in IPFS\\\")\\n\\n\\nThis telemetry is kept in a decentralized storage, and it's hash is stored in a blockchain!\\n\"}},{\"node\":{\"id\":\"a1851f7d728f55e55a9bde42a214e4a7\",\"title\":\"Connect any ROS-compatible robot under Robonomics parachain control. Part 2, IPFS\",\"path\":\"/docs/ko/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/\",\"content\":\"\\n**In this article we will continue using Robonomics tools to make a drone be controlled by a parachain. This time we will add sending data to IPFS and hash storing in chain options. Below is the instruction and code snippets. Requirements:**\\n- [**Part 1 of this tutorial**](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1)\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- IPFS 0.4.22 (download from [here](https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-386.tar.gz) and install)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n- Python dependencies:\\n```\\npip install cv_bridge ipfshttpclient\\n```\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=dliLb6GHgpo&feature=youtu.be\\n\\n\\n## 1. Add dependencies\\nIf we launch a simulation and look at the topic list (see previous tutorial), we will see, that there is one topic containing front camera data and using `sensor_msgs/Image` message type:\\n\\n![front_camera](../images/drone-demo/front_camera.jpg \\\"front_camera\\\")\\n\\nLet's try to take a picture every 1 second and after the flight publish these photos to IPFS. If you have completed the first tutorial, you don't need to download anything else. It's the `drone_sample_controller_pictures.py` script.\\n## 2. Manage accounts in DAPP\\nAs done in a previous tutorial, create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 3. Launch\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nIn another one launch ipfs daemon:\\n```\\nifps init # you only need to do this once\\nipfs daemon\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller_pictures.py\\n```\\nNow you can send a transaction triggering the drone to start flying and taking pictures. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying and taking pictures:\\n\\n![flying_picturing](../images/drone-demo/flying_picturing.jpg \\\"flying_picturing\\\")\\n\\nLater, when the job is done, on the Robonomics portal go to `Developer` -> `Chain state` and add a `DRONE` datalog using `“+”` button with selected `datalog` as state query. The IPFS hash of the telemetry has been saved in the blockchain. To see the data simply copy the hash and add it to the local [gateway](https://gateway.ipfs.io/ipfs/QmeYYwD4y4DgVVdAzhT7wW5vrvmbKPQj8wcV2pAzjbj886/docs/getting-started/) address `localhost:8080/ipfs/`:\\n\\n![Voila](../images/drone-demo/datalog.jpg \\\"Voila\\\")\\n\"}},{\"node\":{\"id\":\"18da56029b91c06db76f234e551b936f\",\"title\":\"Connect ROS-compatibale Drone To Robonomics Parachain. Part 1. Launch by Transaction\",\"path\":\"/docs/ko/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/\",\"content\":\"\\n**In this article we will show that with the help of Robonomics tools you can control any ROS-compatible device. We will find a random drone simulation package on the web and adjust it to run with Robonomics.**\\n**Requirements:**\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=fDpwhBasQ5o&feature=youtu.be\\n\\n## 1. Find a simulation\\nLet's surf the web. Google for `ROS drone simulator`. The first link will mostly likely show you the `tum_simulator` page on [http://wiki.ros.org/tum_simulator](http://wiki.ros.org/tum_simulator)\\n\\n![tum_simulator](../images/drone-demo/tum_simulator.jpg \\\"tum_simulator\\\")\\n\\nIt's pretty outdated, so we better find a fork for our system. Google for `tum_simulator Ubuntu 18 Gazebo 9 fork`. The first result is a GitHub [repo](https://github.com/tahsinkose/sjtu-drone) with an appropriate package. Dowload it\\n```\\nmkdir -p drone_simulator_ws/src\\ncd drone_simulator_ws/src\\ngit clone https://github.com/tahsinkose/sjtu-drone\\ncd ..\\ncatkin build\\n```\\nDon’t forget to add source command to `~/.bashrc`:\\n```\\necho \\\"source /home/$USER/drone_simulator_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource \\\"~/.bashrc\\\"\\n```\\nNow we can run the simulation to see what do we need to do to take the drone under parachain control.\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\n\\n## 2. Inspect ROS topics\\nWhen the simulation is runnung, in a new tab run the following command to see the list of topics used by the drone:\\n```\\nrostopic list\\n```\\nLet's take a look at `/cmd_vel`, `/drone/takeoff` and `/drone/land`:\\n```\\nrostopic info /cmd_vel\\nrostopic info /drone/takeoff\\nrostopic info /drone/land\\n```\\n\\n![topics_info](../images/drone-demo/topics_info.jpg \\\"topics_info\\\")\\n\\nAs may be seen, there should be messages of `Twist` and `Empty` types, they are parts of `std_msgs` and `geometry_msgs`, we'll use this in the controller. Shut the simulation for a while.\\n## 3. Download controller package\\nGlobally, the main difference from the casual ROS robot controller is a block of code, which checks all the transactions in the network using [Robonomics IO](https://wiki.robonomics.network/docs/rio-overview/). The package itself is available on GitHub. Download it and build the workspace:\\n```\\ncd ~/drone_simulator_ws/src\\ngit clone https://github.com/PaTara43/drone_simulator_controller\\ncd drone_simulator_controller/src\\nchmod +x *.py\\ncd ~/drone_simulator_ws/src\\ncatkin build\\n```\\n## 4. Manage accounts in DAPP\\nSince we are testing, let's create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 5. Launching the drone under parachain control\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller.py\\n```\\n\\n![launched_drone](../images/drone-demo/launched_drone.jpg \\\"launched_drone\\\")\\n\\nNow you can send a transaction triggering the drone to start flying. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying:\\n\\n![flying](../images/drone-demo/flying.jpg \\\"flying\\\")\\n\\nThat's how any ROS-compatible robot can be controlled by Robonomics parachain control. Proceed to [part 2](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2) to learn more\\n\"}},{\"node\":{\"id\":\"5f8aea5a83c03fbb4e81b1d5349697c1\",\"title\":\"Configuration Options Description\",\"path\":\"/docs/ko/configuration-options-description/\",\"content\":\"\\nBasically, you can think of the package as a black box with one input (sensor data) and many outputs.\\nFor now only SDS011 sensor is supported, but if you are familiar with Python it'd be easy to add other sensors as well.\\n\\nHave a look at [configuration](https://github.com/airalab/sensors-connectivity/blob/master/config/default.json) file:\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"port\\\": \\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\": 300,\\n      \\\"geo\\\": \\\"\\\",\\n      \\\"public_key\\\": \\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\nAt the moment it's possible to publish data to [Luftdaten](https://luftdaten.info/), [Robonomics Network](https://robonomics.network/) and [Datalog](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer).\\nThe last one is experimental!\\n\\n> DO NOT edit `config/default.json` file. Instead make a copy\\n\\nPlay around with the configuration!\\n\\nExplanation of options:\\n\\n| Field                         | Description                                                                                                                                                                                                                                           |\\n|------------------------------    |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |\\n| `general/publish_interval`         | integer number from 1 and above. Tells how often send measurements. Keep in mind that if measurements from sensors come less often than this number connectivity sends last data      |\\n| `general/db_path`                  |   path to the database (.db) file    |\\n| `comstation/enable`                | true/false. Enabling/disabling the station      |\\n| `comstation/port`                  | valid path to com port, for example `/dev/ttyUSB0`. It is where a sensor is connected to      |\\n| `comstation/work_period`           | integer from 0 to 1800. For SDS011 sensor 0 means continuous work. Recommended period is 300 seconds     |\\n| `comstation/geo`                   | `lat,lon` a string with two floats separated by a comma. It represents latitude and longitude of a sensor     |\\n| `comstation/public_key`            | Ed25519 verifying key in hex format. If not provided connectivity generates a new one      |\\n| `httpstation/enable`                | true/false. Enabling/disabling the station   |\\n| `httpstation/port`                  | what port listen to      |\\n| `mqttstation/enable`                | true/false. Enabling/disabling the station   |\\n|`mqttstation/host`                   | the hostname or IP address of the remote broker |\\n|`mqttstation/port`                   | the network port of the server host to connect to |\\n| `luftdaten/enable`                 | true/false. Whether or not publish data to [Luftdaten](https://devices.sensor.community/). Don't forget to register the sensor's mac address on the site         |\\n| `robonomics/enable`                | true/false. Whether or not publish data to IPFS topic according to Robonomics communication protocol      |\\n| `robonomics/ipfs_proveder`         | an endpoint for IPFS daemon. By default it's `/ip4/127.0.0.1/tcp/5001/http` that means local daemon. The endpoint must by in multiaddr format. For example for [Infura.io](https://infura.io/) it would be `/dns/ipfs.infura.io/tcp/5001/https`       |\\n| `robonomics/ipfs_topic`            | IPFS topic's name. If you want to use [DApp](https://sensors.robonomics.network) provided by Robonomics team leave it untouched                 |\\n| `datalog/enable`                   | true/false. Enable/Disable saving log to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)    |\\n| `datalog/suri`                     | a private key from robonomics parachain account  |\\n| `datalog/dump_interval`            | specify a period of time for collecting log in seconds                                      |\\n| `datalog/temporal_username`        | set username to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `detalog/temporal_password`        | set password to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `datalog/pinata_api`                | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) api key                      |\\n| `datalog/pinata_secret`            | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) secret api key                |\\n| `dev/sentry`                       | for development purpose. If you have a [Sentry.io](https://sentry.io/) account you can put sentry's credentials in here   |\\n| `frontier/enable`                  | true/false. Whether or not publish telemetry to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)   |\\n| `frontier/suri`                    | a private key from robonomics parachain account                                                       |\\n| `trackagro/enable`                 | true/false. Enabling/disabling the station from [TrackAgro](https://tmeteo.docs.apiary.io/#)          |\\n| `trackagro/token`                  | authorization token for [TrackAgro](https://tmeteo.docs.apiary.io/#)                                  |\\n\\n## Scenario #1: Connect SDS011 to serial port\\n\\nThe easiest and the most straightforward way to connect your sensor to the network is using the serial port\\n\\nConnect you SDS011 sensor to a USB port, let's assume it got `/dev/ttyUSB0` address\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #2: Connect SDS011 via HTTP\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n> Do not forget to open the port in system firewall\\n>\\n> On NixOS you can do:\\n> ```\\n> networking.firewall.allowedTCPPorts = [ 31313 ];\\n> ```\\n\\n## Scenario #3: Connect SDS011 via MQTT\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #4: Connect Multiple Sensors and Publish to Datalog\\n\\n### Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": true\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n\\n\"}},{\"node\":{\"id\":\"097873aa746f47f5441a1dbfd03bf2b0\",\"title\":\"Community\",\"path\":\"/docs/ko/community/\",\"content\":\"\\n**Here you can learn how to get involved in the Robonomics Network Community.**\\n\\nThere are many ways to contribute to Robonomics Network: you can contribute directly based on your skills and professional background, you can attend an event, join the conversation online or watch for our latest news and release.\\n\\n## For Developers\\n\\n- [Robonomics' code base and new releases on GitHub](https://github.com/airalab)\\n- [Ask your technical question on Riot](https://riot.im/app/#/room/#robonomics:matrix.org)\\n\\n## For Researchers & Academics\\n\\n- [Read Robonomics White Paper and our scientific articles](https://robonomics.network/community/#science)\\n\\nIf you have a background in mathematics, cryptography, or economics you might be interested for collaboration with us, write us to [research@aira.life](mailto:research@aira.life)\\n\\n## For All, even non-technical\\n\\n- [Get familiar with Robonomics services and statistics in dApp - open in browser with Metamask](https://dapp.robonomics.network)\\n- [Read our blog](https://blog.aira.life)\\n- [Stay tuned by following us on Twitter](https://twitter.com/AIRA_Robonomics)\\n\\nIf you are not a developer or a researcher, you can start with other suggestions for getting involeved in Robonomics Network Community. If you want to organize a meetup in your city, write content about Robonomics, translate Robonomics content into your native language, write to [community@aira.life](mailto:community@aira.life)\\n\"}},{\"node\":{\"id\":\"0538f8c0c730fbb707cff01cc9d68427\",\"title\":\"Changing Exodus Bridge Receiving Address\",\"path\":\"/docs/ko/changing-exodus-receiving-address/\",\"content\":\"\\r\\nThis article will provide guidance on how you can change your Robonomics parachain receiving address in the event that you have input the wrong receiving address in the [Exodus bridge dapp](https://dapp.robonomics.network/#/exodus)\\r\\n\\r\\nPlease be aware that the process of changing the receiving address is not something that will be able to be carried out indefinitely, in fact the intervention of the development team is only possible during the early stages of the Robonomics parachain development, and eventually it will not be possible for the development team to conduct this kind of operation. **Please always ensure that you input the correct parachain address (i.e. one you have the seed phrase for) into the Exodus bridging application**.\\r\\n\\r\\n*Please be informed that the currently, if you input the wrong Robonomics parachain account address into the Exodus bridge dapp, then the process will be carried out as follows:*\\r\\n\\r\\n1. Complete the process as described in this article (i.e. signing the message & raising a GitHub issue).\\r\\n2. Bridged $XRT will be sent to the account originally input into the Exodus bridge dapp (i.e. the incorrect account).\\r\\n3. If no transactions are made on the incorrect account for 1 month, then the Robonomics team will transfer the $XRT tokens to the new address stipulated in the message (which you will sign as per the instructions below).\\r\\n\\r\\nOf course, the utmost priority for the Robonomics team is to ensure only valid changes of address are executed, as such you need to sign a message **from the Ethereum account which you originally deposited the $XRT tokens into the Exodus dapp**. We recommend that you utilize a site such as [MyCrypto](https://app.mycrypto.com/sign-message) to create this message (the following images will show how to conduct this process on MyCrypto).\\r\\n\\r\\nSelect the icon which corresponds to your web3 wallet, in our case we will choose MetaMask.\\r\\n\\r\\n![MyCrypto.com-Landing-Page](https://i.imgur.com/fyJyBG0.png)\\r\\n\\r\\nNow, click on the \\\"Connect to MetaMask\\\" button as shown above, and select the correct account (the account which you previously **sent $XRT tokens from**).\\r\\n\\r\\n![Page-after-selecing-metamask](https://i.imgur.com/1rd6izf.png)\\r\\n\\r\\nNow, we get the option to input a message, you shall follow the below template when inputting the message into this section, otherwise the process will not work. **These addresses relate to the Robonomics parachain addresses**.\\r\\n\\r\\n>Wrong target address: **WRONG_ADDRESS**. Right target address: **RIGHT_ADDRESS**\\r\\n\\r\\nSo, your message will look something like the message below (please make sure you input your own address, and not the one shown below). The message should all be on 1 line, don't use any line breaks (i.e. pressing enter). Afterwards, press the \\\"Sign Message\\\" button located under the message text.\\r\\n\\r\\n![example-of-how-the-message-should-look](https://i.imgur.com/jb1YqLs.png)\\r\\n\\r\\nNow you should get a notification on your web 3 wallet, click \\\"Sign\\\".\\r\\n\\r\\n![Example-metamask-notification](https://i.imgur.com/GTHEYTs.png)\\r\\n\\r\\nOnce signed, wait a few moments and then the MyCrypto page should change, and a signature shall appear.\\r\\n\\r\\n![signature-generated-from-signed-message](https://i.imgur.com/JemAEPm.png)\\r\\n\\r\\nNext, you need to head on over to the [Robonomics GitHub page](https://github.com/airalab/robonomics/issues/new), and open a new issue. The issue should have the title \\\"Robonomics exodus: a request to change the target address\\\", and the body / comment of the issue shall be the signature generated by MyCrypto. Afterwards, click \\\"Submit new issue\\\", and the Robonomics team will handle your issue and leave a reply to your issue regarding the status of your request.\\r\\n\\r\\n![example-of-GitHub-issue](https://i.imgur.com/6ZHSFRw.png)\"}},{\"node\":{\"id\":\"d5c957828da2c5e6c69a12b16249b60b\",\"title\":\"Offsetting Service\",\"path\":\"/docs/ko/carbon-footprint-service/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"}},{\"node\":{\"id\":\"899f206a9c105cc06004d095e951018a\",\"title\":\"Connect sensor\",\"path\":\"/docs/ko/carbon-footprint-sensor/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"}},{\"node\":{\"id\":\"ed8ee8e0064203bbfc0be4b0c1d6ee6e\",\"title\":\"Say \\\"Hello Baxter!\\\" with robonomics\",\"path\":\"/docs/ko/baxter2/\",\"content\":\"Example of how it works:\\n\\nhttps://youtu.be/2Dvuv0ZE2Bw\\n\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```sh\\nsudo apt-get install ros-melodic-qt-build ros-melodic-driver-common ros-melodic-gazebo-ros-control ros-melodic-gazebo-ros-pkgs ros-melodic-ros-control ros-melodic-control-toolbox ros-melodic-realtime-tools ros-melodic-ros-controllers ros-melodic-xacro python-wstool ros-melodic-tf-conversions ros-melodic-kdl-parser python-wstool python-catkin-tools qt4-default\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```sh\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node (binary file) (download latest [release][db4] here)\\n - Create __Baxter__ and __Employer__ accounts  on **Robonomics Portal**  \\n (you can find tutorial [\\\"Create an Account on Robonomics Portal\\\"][db8] here).\\n - IPFS browser extension (not necessary)\\n\\n## 0. install CV Bridge extension for python3\\n\\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n## 1. Download simulation and controller packages\\nWe will need to create 2 workspaces - one for main Baxter's packages and other for main control programme.\\nFirst workspace. It's main control programme. It will run under python3.\\n\\n```sh\\ncd ~\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src/\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\npip3 install -r requirements.txt\\n```\\nSecond workspace. There will be all Baxter's packages. Simulation is very old, so it could run only under python2.\\n```shell\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src/\\nwstool init .\\nwstool merge https://raw.githubusercontent.com/RethinkRobotics/baxter_simulator/master/baxter_simulator.rosinstall\\nwstool update\\n```\\nThese packages were created for ROS indigo. We have to change some files to run them on ROS melodic.\\nWe will use **patch** files.\\n```sh\\npatch ./baxter_simulator/baxter_sim_io/include/baxter_sim_io/qnode.hpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/qnode_patch\\npatch ./baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/arm_patch\\npatch ./baxter_interface/src/baxter_interface/robot_enable.py ~/robonomics_ws/src/Baxter_simulation_controller/patch/interface_patch\\n```\\nAnd let's build  all our packages:  \\nFirst build Baxter's packages\\n```sh\\ncd ../\\ncatkin build\\n```\\nThen return to first workspace and build it too:\\n```sh\\ncd ~/Baxter_simulation_controller/\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\necho \\\"source /home/$USER/robonomics_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```  \\n\\n\\n## 2. Start simulation\\n### Let's start our simulation:\\nAt first go to `robot_ws` and copy and edit baxter.sh\\n```sh\\ncd ~/robot_ws/\\ncp src/baxter/baxter.sh .\\n```\\nFind your local ip address with command:\\n```\\nip a\\n```\\n![ip_a][im14]\\n\\nEdit the following values in `baxter.sh` :\\n```\\nnano baxter.sh\\n```\\n\\n- your_ip - put your local ip address. See `ip a`\\n- ros_version - for example \\\"melodic\\\"\\n\\n![baxtersh][im15]\\n\\nRun the baxter shell script with sim specified:\\n```sh\\n./baxter.sh sim\\nroslaunch baxter_gazebo baxter_world.launch\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp\\n```\\n![robonomics][im3]\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts.\\n\\nYou can find The manual \\\"Create an Account on Robonomics Portal\\\" [here][db8]\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\n\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n![create account2][im16]\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robonomics_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same portal [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nWhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL:  \\n#### gateway.ipfs.io/ipfs/< put your hash here>\\n\\n\\n\\nThat's all!\\n\\n![result1][im12]\\n![result2][im13]\\n\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/ip_a.png>\\n[im15]: <../images/baxter_demo/baxter_sh.jpg>\\n[im16]: <../images/baxter_demo/create_account2.jpg>\\n[db8]: <https://wiki.robonomics.network/docs/create-account-in-dapp/>\"}},{\"node\":{\"id\":\"0309f74dc27e010a1944f98500f8c36e\",\"title\":\"Control Baxter robot with robonomics\",\"path\":\"/docs/ko/baxter/\",\"content\":\"\\nExample of how it works:\\n\\nhttps://www.youtube.com/watch?v=JivTDhDJLHo\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-melodic-cv-bridge\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```shell\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node download latest [release][db4] here (last tested release v1.1)\\n - IPFS browser extension (not necessary)\\n## 0. install CV Bridge extension for python3\\n \\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\n\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n\\n## 1. Download simulation and controller packages\\nDownload packages:\\n```sh\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\ngit checkout old_version\\npip3 install -r requirements.txt\\ncd ../..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n## 2. Start simulation\\nLet's start gazebo world and put our baxter in it:\\n```sh\\nroslaunch gazebo_ros empty_world.launch\\n```\\n![empty world][im1]\\n\\nOpen one more window in terminal:\\n```sh\\nrosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp --rpc-cors all\\n```\\n![robonomics][im3]\\n\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts (__Robot__ is not necessary)\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n\\n![create account2][im14]\\n\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robot_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nwhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL: gateway.ipfs.io/ipfs/< put your hash here >\\n\\n![ipfs][im11]\\n\\nClick  __View on Gateway__ and that's all!\\n\\n![result1][im12]\\n\\n![result2][im13]\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/create_account2.jpg>\"}},{\"node\":{\"id\":\"9b002045bea5b2e0df214d36402244f5\",\"title\":\"AIRA Overview\",\"path\":\"/docs/ko/aira-overview/\",\"content\":\"\\n## Introduction\\n\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It implements the standard of economic interaction between human-robot and robot-robot. AIRA makes it possible to connect a variety of different robots under decentralized computer's control (currently supported Ethereum and Polkadot/Substrate).\\n\\nBasically it is the client for Robonomics Network developed by [Airalab](https://aira.life).\\n\\nAIRA is NixOS based operating system and officially supports the following architectures: x86, Raspberry Pi 3 B+ and Raspberry Pi 4.\\n\\nThe most simple way to get familiar with AIRA is to try installing AIRA as a [virtual machine](/docs/aira-installation-on-vb/).\\n\\nAIRA comes with a few preinstalled and configured services to help you focus on [agent](/docs/glossary#agent) development.\\n\\nMeanwhile it's highly customizable, but it's recommended to understand [NixOS](http://nixos.org/) and [Nix](https://nixos.org/nix/) language.\\n\\n## What's included? \\n\\nThe following services are included in the default distribution:\\n\\n* [Robonomics communication stack](https://github.com/airalab/robonomics_comm)\\n* [IPFS](https://ipfs.io/)\\n* OpenSSH\\n* [cjdns](https://github.com/cjdelisle/cjdns)\\n* [Yggdrasil-go](https://yggdrasil-network.github.io/)\\n\\nBesides at the first launch AIRA [generates](/docs/aira-installation-on-vb#launch-the-machine) for you new Ethereum address and IPNS identifier.\\n\\nIt's possible to use AIRA as a virtual machine or install as a main operating system. Also you can install only the services you need.\\n\"}},{\"node\":{\"id\":\"bea7142b9a0cea195eec2c21d7c17eb2\",\"title\":\"AIRA Installation\",\"path\":\"/docs/ko/aira-installation/\",\"content\":\"\\n- [**How to launch AIRA on VirtualBox**](/docs/aira-installation-on-vb/)\\n\\n- **The installation on Raspberry Pi** is as simple as writing an image of AIRA on SD card using `dd` or [Etcher](https://www.balena.io/etcher/), for example.\\n\\n\\n\"}},{\"node\":{\"id\":\"604d0bf3c0d238df556398b6e3af77c0\",\"title\":\"AIRA Installation on VirtualBox\",\"path\":\"/docs/ko/aira-installation-on-vb/\",\"content\":\"\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It is the client for Robonomics Network developed by [Airalab](https://aira.life). It is an operating system based on [NixOS](https://nixos.org/). With AIRA you can  turn any cyber-physical system in an economic agent, where robots operate as a services for the reasonable payments. [More theory about AIRA here](/docs/aira-overview).\\n\\nIt's possible to install AIRA on a x86_64 PC. Also there are images for Raspberry Pi 3 and 4 supported by the team.\\n\\nThe best way to try AIRA is to start from installing it as a virtual machine on [VirtualBox](https://www.virtualbox.org/).\\n\\n## Requirements\\n\\n* VirtualBox\\n* [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2Gb of RAM for the machine\\n* 40Gb of free disk space\\n\\n## Obtain the image\\n\\nAIRA has [stable](https://aira.life/channels/aira-stable/) and [unstable](https://aira.life/channels/aira-unstable/) channels.\\n\\nTo get stable image download the file with `.ova` extension.\\n\\tThe link for stable image is [here](https://releases.aira.life/channels/aira/stable/862-aira-stable/nixos-20.03pre-git-x86_64-linux.ova)\\n\\nDon't forget to compare checksum of the downloaded image with the last column `SHA-256 hash` on the [download page](https://aira.life/channels/aira-stable/). It must be equal to the output of the following command (it is an example, please check the name of downloaded by you .ova file first):\\n\\n```\\nsha256sum nixos-20.03pre-git-x86_64-linux.ova\\n```\\n\\nYou may wish to check out the walkthrough video:\\n\\nhttps://www.youtube.com/embed/cDcaypYPBhI\\n\\n## Troubleshooting\\n\\nIf you have fresh installed VirtualBox, you need to install the [extension](https://www.virtualbox.org/wiki/Downloads) pack or disable USB 2.0 controller.\\n\\nAlso VirtualBox may show a warning about `Display settings`. Consider switching `Graphics Controller` in settings of the VM to `VMSVGA`.\\n\\n## Import to VirtualBox\\n\\nOpen VirtualBox and press `Ctrl+I` or go to `File > Import Applicance...`\\n\\n![AIRA import VB image](../images/aira-installation/aira_import_vb_image.jpg \\\"AIRA import VB image\\\")\\n\\nAt this moment the next step is not necessary but it will help you to connect to the VM via SSH easily.\\n\\nFirst add `Host-Only` adapter in VirtualBox menu `File > Host Network Manager...` or by pressing `Ctrl+H`\\n\\n![Host Only](../images/aira-installation/host_only_adapter.jpg \\\"Host Only\\\")\\n\\nThen go to the image's settings, Network and add the second network adapter\\n\\n![Second adapter](../images/aira-installation/add_second_adapter.jpg \\\"Second adapter\\\")\\n\\nFor more details look at the standalone [lesson](/docs/aira-connecting-via-ssh/).\\n\\nOptionally you can increase the amount of video memory and switch `Graphics Controller` to `VMSVGA`.\\n\\n## Launch the machine\\n\\nFinally press Start and you'll see AIRA welcoming you with generated Ethereum address and IPFS identifier\\n\\n![AIRA image ready, Welcome screen](../images/aira-installation/aira_image_ready.jpg \\\"AIRA image ready, Welcome screen\\\")\\n\\nAt the very first initialization AIRA generates new Ethereum address and IPNS identifier for you.\\n\\n\"}},{\"node\":{\"id\":\"9646c5bc0b11b61a736c4bd35c395220\",\"title\":\"Frequently Asked Questions about AIRA\",\"path\":\"/docs/ko/aira-faq/\",\"content\":\"\\n## How to see logs from main services?\\n\\nIPFS in real time:\\n\\n    journalctl -u ipfs -f\\n\\nand Liability::\\n\\n    journalctl -u liability -f\\n\\n## How to check the quantity of IPFS peers?\\n\\n    ipfs pubsub peers \\n\\n## IPFS can't connect to the daemon, what should I do?\\n\\nTry to specify `--api` option\\n\\n    ipfs swarm peers --api=/ip4/127.0.0.1/tcp/5001/\\n\\n## How to change ethereum address of AIRA?\\n\\nDelete `keyfile` and `keyfile-psk` in `/var/lib/liability` and restart the service\\n\\n```\\nsystemctl restart liability\\n```\\n\\n## IPFS daemon doesn't start\\n\\nThe error mostly occurs on single-board computers like Raspberry Pi or LattePanda after unexpected electricity lost.\\n\\nUsually the file `/var/lib/ipfs/api` is corrupted and one may see error:\\n\\n```\\nError: Failed to parse '/var/lib/ipfs/api' file.\\n  error: failed to parse multiaddr \\\"\\\": empty multiaddr\\nIf you're sure go-ipfs isn't running, you can just delete it.\\nOtherwise check:\\n  ps aux | grep ipfs\\n```\\n\\nYou can delete `/var/lib/ipfs/api` file and restart the service\\n\\n\"}},{\"node\":{\"id\":\"daec21266f652e624e30fa9df74f5d83\",\"title\":\"Connecting AIRA via SSH\",\"path\":\"/docs/ko/aira-connecting-via-ssh/\",\"content\":\"\\nIt is more convenient to work with virtual machine via ssh connection. In this section we will configure VM.\\n\\n> **It's required to have your ssh public key on Github. In case you don't have one, please follow the [link](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\nBelow is the walkthrough video:\\n\\nhttps://www.youtube.com/embed/R6waDG5iwm0\\n\\n## Add Host Adapter\\n\\nGo to `File` -> `Host Network Manager...` or press `Ctrl+H`\\n\\n![VirtualBox Network Manager](../images/virtualbox_network_manager.png \\\"VirtualBox Network Manager\\\")\\n\\nClick `Create` button.\\n\\n## Add the Second Adapter to the VM\\n\\nSelect imported VM and click `Settings`. Go to `Network` tab and enable the second adapter\\n\\n![Add Second Adapter](../images/add_second_adapter_to_vm.png \\\"Add Second Adapter\\\")\\n\\n## Populate Authorized Keys\\n\\nLaunch the VM and run the following command replacing `<username>` with your Github user name:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nFind out the VM's IP address by running:\\n\\n```\\nip a\\n```\\n\\nYou should look for an address which starts with `192.168.xx.xx`\\n\\n## Log in via SSH\\n\\nNow open your terminal and log in via SSH as usual using the address from the previous step:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n\"}},{\"node\":{\"id\":\"7b8f632af3191830fa42b4b5ffcf1248\",\"title\":\"Basic usage of AIRA\",\"path\":\"/docs/ko/aira-basic-usage/\",\"content\":\"\\nTo get familiar with AIRA, let's see what is under the hood.\\n\\nOnce you launch the client several ros nodes will already be on the run. Here's a list of robonomics communication stack nodes:\\n\\n```bash\\n$ rosnode list\\n/eth/erc20_token\\n/eth/eth_node\\n/graph/aira_graph\\n/liability/executor\\n/liability/infochan/eth/signer\\n/liability/infochan/ipfs_channel\\n/liability/persistence\\n/liability/listener\\n/rosout\\n```\\n\\n- `/eth/erc20_token`, `/eth/eth_node` - proved services for Ethereum blockchain and ERC20 tokens\\n- `/graph/aira_graph` - service node for exploring other AIRA instances\\n- `/liability/executor` - gets rosbag file from IPFS and plays it\\n- `/liability/infochan/ipfs_channel` - is responsible for offer, demand and result messages. It catches messages from the channel and sends signed messages back\\n- `/liability/infochan/eth/signer` - offers services for signing offer, demand and result messages\\n- `/liability/listener` - watches for a new liability contracts. When the event is received the node calls executor node\\n- `/liability/persistence` - helps to store incoming liabilities and restart them after shutdown\\n\\nAnd here's a list of robonomics stack topics.\\n\\n```bash\\n$ rostopic list\\n/eth/event/approval\\n/eth/event/transfer\\n/graph/greetings\\n/liability/complete\\n/liability/finalized\\n/liability/incoming\\n/liability/infochan/eth/sending/demand\\n/liability/infochan/eth/sending/offer\\n/liability/infochan/eth/sending/result\\n/liability/infochan/eth/signing/demand\\n/liability/infochan/eth/signing/offer\\n/liability/infochan/eth/signing/result\\n/liability/infochan/incoming/demand\\n/liability/infochan/incoming/offer\\n/liability/infochan/incoming/result\\n/liability/persistence/add\\n/liability/persistence/del\\n/liability/persistence/update_timestamp\\n/liability/ready\\n/liability/result\\n/rosout\\n/rosout_agg\\n```\\n\\nThe most important topics for us are:\\n\\n- `/liability/incoming` - when a new liability is created, this topic publishes Ethereum address of the contract\\n- `/liability/result` - this topic is for publishing results. But don't publish a result directly to this topic! Use a service instead\\n- `/liability/infochan/incoming/*` - a CPS gets information about offer, demand or result from corresponding topics\\n- `/liability/infochan/eth/signing/*` - a CPS sends offer, demand or result messages to corresponding topics\\n\\nFor the details check out the [API page](/docs/robonomics-liability/).\\n\\nLet's start with greetings - say hello to AIRA!\\n\\nYou should just launch a pre-installed package `hello_aira`:\\n\\n```\\n$ rosrun hello_aira hello_aira\\n```\\n\\nWe've launched our agent. It will wait for a demand message. Now it's time to send the message. Go to [dapp](https://airalab.github.io/robonomics_tutorials/) and press Order.\\nNow go back to the console and see the result!\"}},{\"node\":{\"id\":\"4a6abdd2d800e2c577865bf646652fae\",\"title\":\"Agent development examples\",\"path\":\"/docs/ko/agent-development-examples/\",\"content\":\"\\nUseful pieces of code and a few scenarios. All source code is [here](https://github.com/vourhey/robonomics_tutorials).\\n\\n1. [Broadcast Demand](https://github.com/Vourhey/robonomics_tutorials/tree/master/01_broadcast_demand/)\\n2. [Broadcast Offer](https://github.com/Vourhey/robonomics_tutorials/tree/master/02_broadcast_offer/)\\n3. [Trader](https://github.com/Vourhey/robonomics_tutorials/tree/master/03_trader/)\\n4. [Trader with ACL](https://github.com/Vourhey/robonomics_tutorials/tree/master/04_trader_with_acl/)\\n5. [Open Sensor Data](https://github.com/Vourhey/robonomics_tutorials/tree/master/05_open_sensor_data/)\\n\\n\"}},{\"node\":{\"id\":\"2dfa88e19a8f0210b9fde5dd192c5627\",\"title\":\"Add Device to Robonomics\",\"path\":\"/docs/ko/add-smart-device-to-robonomics/\",\"content\":\"For each device you need separate [Robonomics accounts](/docs/create-account-in-dapp/). After you've added your devices, you need to add them in a `config.config` file with their seeds. Firstly in `Configuration/Entities` tab in your Home Assistant find entity ids of your devices:\\n\\n![entity_id](../images/home-assistant/entity_id.png)\\n\\nOpen the configuration file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add there information of your devices in the following format:\\n\\n```\\n[device_name]\\nIDS = ['entity_id1', 'entity_id2']\\nSEED = word word word\\n```\\nWhere `device_name` is the name of your device (you can choose any name), `IDS` are entity ids of the data from the device (it may be one or more ids) and `SEED` is a mnemonic or raw seed from robonomics account to this device.\\n\\nAfter you fill the configuration file you need to get access token from Home Assistant. For that open your `profile` in the lower left corner:\\n\\n![profile](../images/home-assistant/profile.png)\\n\\nIn the end of the page find `Long-Lived Access Tokens` and press `create token`. Save it somewhere, you will not be able to see it again.\\n\\n![token](../images/home-assistant/token.png)\\n\\nNow run `create_config.py` script with your token:\\n\\n```bash\\ncd /srv/homeassistant\\nsource bin/activate\\npython3 python_scripts/create_config.py --token <access_token>\\n```\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\\n\\nYou can add the data from sensors to your homepage like in `Home Assistant setup` in the description to [Method 1](/docs/zigbee2-mqtt/).\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. Data looks like this:\\n\\n![datalog_data](../images/home-assistant/datalog_data.png)\\n\\nYou can decrypt it with script `decrypt.py`, run it with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"a1e74dac1839b0cf0702d15570e9da34\",\"title\":\"Connect Sensors with Zigbee2MQTT\",\"path\":\"/docs/ja/zigbee2-mqtt/\",\"content\":\"\\n## Mosquitto MQTT broker\\n\\nFor this method, you neet to install MQTT broker to the Raspberry Pi:\\n\\n```bash\\nsudo apt update\\nsudo apt install mosquitto mosquitto-clients\\n```\\nThe Mosquitto program will run automatically after installation.\\n\\n## Zigbee2MQTT setup\\n\\nIf you have the JetHome USB JetStick Z2 it will already have the necessary firmware so you don't need to flash it. However, if you have another adapter the first thing you need to flash it with zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nThen we need to install the ziqbee2mqtt software on the  Raspberry PI. Connect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\nInstall zigbee2MQTT:\\n```bash\\n# Setup Node.js repository\\nsudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\\n\\n# NOTE 1: If you see the message below please follow: https://gist.github.com/Koenkk/11fe6d4845f5275a2a8791d04ea223cb.\\n# ## You appear to be running on ARMv6 hardware. Unfortunately this is not currently supported by the NodeSource Linux distributions. Please use the 'linux-armv6l' binary tarballs available directly from nodejs.org for Node.js 4 and later.\\n# IMPORTANT: In this case instead of the apt-get install mentioned below; do: sudo apt-get install -y git make g++ gcc\\n\\n# NOTE 2: On x86, Node.js 10 may not work. It's recommended to install an unofficial Node.js 14 build which can be found here: https://unofficial-builds.nodejs.org/download/release/ (e.g. v14.16.0)\\n\\n# Install Node.js;\\nsudo apt-get install -y nodejs git make g++ gcc\\n\\n# Verify that the correct nodejs and npm (automatically installed with nodejs)\\n# version has been installed\\nnode --version  # Should output v10.X, v12.X, v14.X or v15.X\\nnpm --version  # Should output 6.X or 7.X\\n\\n# Clone Zigbee2MQTT repository\\nsudo git clone https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\nsudo chown -R ubuntu:ubuntu /opt/zigbee2mqtt\\n\\n# Install dependencies (as user \\\"ubuntu\\\")\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\nThen you need to configure it. Open configuration file:\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\nAnd paste this:\\n```\\npermit_join: true\\nmqtt:\\n  # MQTT base topic for Zigbee2MQTT MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n```\\nNow you can run zigbee2mqtt:\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n## Pairing device\\n\\nThen you need to pair your sensor. For that just long press the power button until it starts to blink (zigbee2MQTT must be launched). After sensor connects you will see the message like:\\n```\\nZigbee2MQTT:info  2019-11-09T12:19:56: Successfully interviewed '0x00158d0001dc126a', device has successfully been paired\\n```\\n> Remember this number `0x00158d0001dc126a` it will be the topic name for your sensor's data.\\nThen open configuration file again and set `permit_join: false`.\\n\\nThen lets make a service. Create the file:\\n```bash\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\nAdd the following to this file:\\n```\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\n# Or use StandardOutput=null if you don't want Zigbee2MQTT messages filling syslog, for more options see systemd.exec(5)\\nStandardError=inherit\\nRestart=always\\nUser=pi\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nVerify that the configuration works:\\n\\n```bash\\nsudo systemctl start zigbee2mqtt\\n```\\n\\n```bash\\nsystemctl status zigbee2mqtt.service\\n```\\n\\nOutput should look like:\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\nNow that everything works, we want systemctl to start Zigbee2MQTT automatically on boot, this can be done by executing:\\n\\n```bash\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n## Home Assistant Setup\\n\\nOpen Home Assistant configuration file:\\n\\n```bash\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add the following to setup MQTT broker and sensor (replace `topic_name` with the topic name from previous step):\\n\\n```\\n# MQTT broker setup\\nmqtt:\\n  broker: localhost\\n  port: 1883\\n\\n# Sensor setup\\nsensor:\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Humidity\\\"\\n    unit_of_measurement: '%'\\n    value_template: \\\"{{ value_json.humidity }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Temperature\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.temperature }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Pressure\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.pressure }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Battery\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.battery }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Link Quality\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.linkquality }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Voltage\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.voltage }}\\\"\\n\\n# Trigger on receiving data\\nautomation:\\n  - alias: \\\"send_datalog_climate\\\"\\n    trigger:\\n      platform: mqtt\\n      topic: \\\"zigbee2mqtt/0x00158d0006bcd022\\\"\\n    action:\\n      service: shell_command.send_datalog_climate\\n\\n# Shell command that will run on the trigger\\nshell_command:\\n  send_datalog_climate: 'python3 python_scripts/send_datalog.py temperature={{ states(\\\"sensor.mqtt_climate_temperature\\\")  }} humidity={{ states(\\\"sensor.mqtt_climate_humidity\\\") }} pressure={{ states(\\\"sensor.mqtt_pressure\\\") }} battery={{ states(\\\"sensor.mqtt_climate_battery\\\") }} linkquality={{ states(\\\"sensor.mqtt_climate_link_quality\\\") }} voltage={{ states(\\\"sensor.mqtt_climate_voltage\\\") }}'\\n```\\n\\nThen start Home Assistant with new configuration:\\n\\n```bash\\ncd /srv/homeassistant\\nhass\\n```\\n\\nTo see the sensor data in Home Assistant you need to add it. For that open the browser on your computer and go to:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nPress on three dots on the right side and choose `Edit Dashboard`\\n\\n![edit_dashboard](../images/home-assistant/dashboard.png)\\n\\nThen press `Add Card`\\n\\n![card](../images/home-assistant/card.png)\\n\\nGo to `By Entity` and tick all sensors that you need\\n\\n![sensors](../images/home-assistant/sensors.png)\\n\\nPress continue and you will be able to see sensor data at the homepage (you may see `unknown` before sensor send new data)\\n\\nIn a similar way you can add card for Robonomics Service. With this you can start or stop the servise or send current measurements with `run action` button.\\n\\n![action](../images/home-assistant/datalog.png)\\n\\nYou homepage will look like this\\n\\n![home](../images/home-assistant/home.png)\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. You can decrypt the data with script [decrypt.py](https://github.com/airalab/robonomics-smarthome/blob/main/python_scripts/decrypt.py), download it:\\n\\n```bash\\ncd /srv/homeassistant/python_scripts\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\n```\\nAnd run with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"b957888574de5dd0026e30ed2a7fd0f9\",\"title\":\"Connect Sensors with Xiaomi Gateway\",\"path\":\"/docs/ja/xiaomi-gateway/\",\"content\":\"\\nYou need your Xiaomi gateway along with all the sensors to be connected to the Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your hub (it must be in connecting mode which is achieved via a long press of the power button) and follow instructions in the app. After you add the gateway, you need to add sensors: press on your gateway, then go to `Child device` and press `+`. Find required device and follow the instructions on the screen. For more details refer to the user manual of your Xiaomi Gateway hub.\\n\\n## Add Gateway to Home Assistant\\nBe sure that you're logged in you raspberry as `homeassistant` user, if not do the following:\\n```bash\\nsudo -u homeassistant -H -s\\n```\\n\\nIn your Home Assistant:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations` and press `Add Intagration`. There you need to Find `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Hub (Aqara Hub in this example):\\n\\n![hub](../images/home-assistant/hub.png)\\n\\nPress `Submit` and you will be able to see your gateway in Integrations page.\\n\\n## Add Gateway to Home Assistant using Homekit Controller integration\\n\\nYou can also connect your hub to Aqara Home app on ios and then add it to Home Assistant through Homekit Controller integration. \\n\\nAdd your hub to the app using `add device` or `+` button. Right after your hub added to Aqara Home app you will be proposed to bind it with your Homekit account. \\n\\n![homekit](../images/home-assistant/homekit.png)\\n\\nWhen you see a menu like the picture, open your Home Assistant page:\\n\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations`. Here you can find your device discovered and click `Configure` button to add it by Homekit Controller integration. You have to enter pairing code of your device, which you can find on the sticker on your device.\\n\\n![configure1](../images/home-assistant/configure1.png)\\n\\n![configure2](../images/home-assistant/configure2.png)\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"41eff665bf4ae4c80baf994069206948\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ja/xcm-robobank/\",\"content\":\"\\n\\nMain goal of this project is simplification of parachain runtime development, when cross-chain messages are used. \\nAllows to develop runtime code with integration tests with high repeatablility and simple usage.\\nAutomates building, construction of pre-set network configuration (f.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and running tests, sending messages, using call to runtime, constructed and composed in Python.\\n\\nXCM Testsuite is used for testing production cycle for Robobank - the set of Substrate pallets, allowing robots to register in external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside Robonomics network with all needed infrastructure, but, in the same time, offer their services in any external parachain.\\n\\nVideo example is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe demo scenary main steps are:\\n- launch relay chain and two parachains in pack of 6 processes\\n- setup XCM messages channels between parachains\\n- register a robot in both parachains\\n- create order for this robot in client parachain (reserving payment for completion of order)\\n- send XCM message to Robonomica\\n- creating \\\"mirrored\\\" order record in Robonomica parachain\\n- accept order by robot in Robonomica\\n- send XCM message about order acceptance back to client parachain\\n- accept order in client parachain (reserving penalty fee for no-completion of order until deadline)\\n- complete order by robot in Robonomica\\n- send XCM message about order completion to client parachain\\n- settle all payments (client payment is transfered to robot, as well as penalty fee)\\n- close order\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nContains code of runtime pallets being tested.\\nAs in original node code of parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] First build can take a lot of time, up to several hours on weak machines\\n\\n[NOTE] Script works with FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains\\n\\n[NOTE] By default script re-creates same environment every launch, by removing all previous states. this behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for relay chain and for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (f.e. 4 validators of some stable Rococo revision)\\n    - collators for parachain-100 (f.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (f.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing to study any chain using frontend apps (explorer, DApp)\\n - keep printing all output of all chains to console\\n\\n[WARNING] After launch, wait until a network is up, make sure that blocks finalization started, and parachains are registered. These processes require approximately 5 min (50 blocks x 6 sec ).\\n\\n## Checking if all works \\n\\nUse standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, consensus started off, we can proceed to run test cases (in a new terminal)\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to relay.\\nWhen relay receives message it will transfer 15 tokens from `para 100` account to the Charlie's.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to `sibling 200` one.\\nBefore that, it endows `subl 100` account with 1000 tokens and  establish a channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace balances and authorities with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit code. The above command will rebuild project and update collator node before start.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent version of software. For this change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\"}},{\"node\":{\"id\":\"bbf9e1cf1565e2440f446715fadbd97e\",\"title\":\"Lesson 4, 実践でのRobonomics parachain\",\"path\":\"/docs/ja/wschool2021-robonomics-parachain-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\nRobonomics parachainは、Polkadotエコシステム上の汎用parachainではありません。Robonomicsの目的は、機械の経済を構築することであり、その目的をスコープとしたRobonomics parachainは、PolkadotエコシステムをIoT、スマートシティ、インダストリー4.0のコンセプトと統合するのに役立ちます。\\n\\n## Requirements\\n\\n* Dockerは[こちらでインストール](https://docs.docker.com/engine/install/)してください。\\n* Polkadot-launchは[こちらでインストール](https://github.com/paritytech/polkadot-launch#install)してください。\\n\\n## Relay chainの起動\\n\\nRelay chainはPolkadotの核となるもので、すべての子parachainに [共有のセキュリティ](https://wiki.polkadot.network/docs/en/learn-security)を提供し、メッセージパッシングの仕組みを実装しています。\\nここでは、Rococo (polkadot testnet) リレーチェーンのローカルインスタンスを、2つのロボノミクスベースのパラチェーンを子として起動してみましょう。用意された [Docker image tag: \\\"winter-school-2\\\"](https://hub.docker.com/layers/robonomics/robonomics/winter-school-2/images/sha256-92f4795262f3ded3e6a153999d2777c4009106a7d37fd29969ebf1c3a262dc85?context=explore) を使いますが、例題のソースコードはすべて[RobonomicsのGitHub](https://github.com/airalab/robonomics/tree/master/scripts/polkadot-launch)にあります。\\n\\n<Asciinema vid=\\\"419Jrg22ziFfMFPZlh2WtiLvg\\\"/>\\n\\n時間がかかるかもしれませんが、我慢してください。結果として、ポートに3つのチェーンインスタンスができるはずです。\\n\\n* `9944` - local rococo relay chain.\\n* `9988` - robonomics parachain with `id=100`\\n* `9989` - robonomics parachain with `id=200`\\n\\nリモートサーバを使用する場合は、ローカルマシンでいくつかの ssh トンネルを作成する必要があります。\\n```\\nssh -f -N -L 9944:127.0.0.1:9944 root@REMOTE_SERVER_IP\\nssh -f -N -L 9988:127.0.0.1:9988 root@REMOTE_SERVER_IP\\nssh -f -N -L 9989:127.0.0.1:9989 root@REMOTE_SERVER_IP\\n```\\nその後、あなたは、 https://parachain.robonomics.network/ で `ws://127.0.0.1:9944`と `ws://127.0.0.1:9988`と `ws://127.0.0.1:9989` を使うことができます。\\n\\n![relay](../images/ws_lesson4/upcoming.jpg)\\n\\n少し前のparachainは登録しておくべきです。\\n\\n![relay2](../images/ws_lesson4/parachains.jpg)\\n\\nそして、ブロックの生産を開始する。\\n\\n![relay3](../images/ws_lesson4/parachains2.jpg)\\n\\n次のステップとして、parachain間でメッセージをやり取りするためのHRMPチャネルを作成しましょう。relaychainのページにある`sudo`モジュールコールを使ってみます。\\n\\n![hrmp](../images/ws_lesson4/hrmp.jpg)\\n\\nチャネルができると、XCMコールが使えるようになります。`datalogXcm`パレット（`datalog`パレットのXCM版）を使ってみましょう。\\n\\n![datalogXcmSend](../images/ws_lesson4/datalogXcmSend.jpg)\\n\\n第2パラダイムのメッセージの結果として、`datalog` パレットが呼び出され、データがチェーンに書き込まれます。\\n\\n![datalogXcmRecv](../images/ws_lesson4/datalogXcmRecv.jpg)\\n\\n\\n結果として、この例は、XCMが標準的なRobonomicsパレットのクロスチェーン使用に対して、どのように使用できるかを示しています。\"}},{\"node\":{\"id\":\"b8722d50ca16de4db896fffa11c203a9\",\"title\":\"Lesson 3, Robonomics IOの実践\",\"path\":\"/docs/ja/wschool2021-robonomics-io-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\n## 必要なもの\\n\\n* Dockerが必要です、最初に[install](https://docs.docker.com/engine/install/)してください。\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) センサーは*オプション*です。\\n\\n### SDS011の確認 (オプション)\\n\\nSDS011センサーを接続した場合、それが`/dev`に表示され、正しいアクセス権を持っていることを確認してください。\\n\\n<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>\\n\\n## クイックスタート\\n\\nDockerのインストールが完了したら、公式リポジトリから[robonomicsのdockerイメージ](https://hub.docker.com/r/robonomics/robonomics)を起動します。このレッスンでは `winter-school `タグを使用します。\\n\\n<Asciinema vid=\\\"wM43jozIVfcRmt52ENrJ6yPlH\\\"/>\\n\\nDockerイメージの準備ができたら、`robonomics io`コマンド（SDS011デバイスを持っている場合はoptionで指定）を使ってデータを読み込んでみましょう。\\n\\n<Asciinema vid=\\\"iztt22tKGaV8wq3cMXY1oUEYv\\\"/>\\n\\nSDS011センサーがない場合は、`vsds011.sh`を使って同じDockerコンテナ内にある仮想のSDS011センサーを自由に使うことができます。続くコマンドの中では、物理的なセンサーの代わりに透過的に使用してください。\\n\\n\\n<Asciinema vid=\\\"GCkSiJBA1DgpLAAHiMhIOSpgG\\\"/>\\n\\nRobonomics IO サブシステムには2種類のコマンドがあります:\\n\\n* `read` - 読み込みアクセスをサポートするデバイスからデータを取得する。\\n* `write` - 書き込みアクセスをサポートするデバイスにデータを書き込む。\\n\\nデバイスによっては両方をサポートしているものもあり、その場合には両方のコマンドの引数にデバイスが表示されます。\\n\\n> 例えば、仮想デバイス `ipfs` は、ハッシュによる IPFS からのデータの`read`(読み取り)と、IPFS へのデータの`write`(書き込み)をサポートしています。\\n\\nサポートされているデバイスの全リストは、引数なしで `robonomics io read`または `robonomics io write` を実行することで得られます。\\n\\n## IPFSへのアクセス\\n次のステップでは、IPFSデーモンの起動が必要です。そのためには、`ipfs init`を実行し、専用のターミナルタブでデーモンを起動します。\\n\\n<Asciinema vid=\\\"ir6ziXSBUDrRltTmNxg7sdXVY\\\"/>\\n\\nデーモンが起動すると、別のタブでdockerイメージを接続し、`robonomics io`を使ってデータを読み書きできるようになります。\\n\\n<Asciinema vid=\\\"ZtwcmpB9Lhum2Sc221QmNwHG4\\\"/>\\n\\nSDS011センサーのデータをIPFSに転送するには、コンソールの`｜`(パイプ)シンボルを使います。実際にやってみましょう。\\n\\n\\n<Asciinema vid=\\\"XS0QESWG7f8ELsQe1bGQllb9O\\\"/>\\n\\nSDS011からのJSONデータがIPFS書き込みの入力として転送され、その結果が標準出力に出力されます。\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs\\n```\\n\\nこの方法を使えば `robonomics io`ツールのプリミティブな読み取りと書き込みを組み合わせるだけで、簡単なプログラムを簡単に作ることができます。\\n\\n\\n```bash\\nrobonomics io read sds011 | gz | robonomics io write pubsub my-sensor-data\\n```\\n\\n## Robonomics のデータログ\\n\\n> Robonomics[Datalog](https://crates.robonomics.network/pallet_robonomics_datalog/index.html) のターゲットはデータのブロックチェーン化です。このパレットは、カスタムデータをブロックチェーンに保存して、将来変更できないようにする機能を提供します。\\n\\nこのレッスンの最後の部分では、robonomicsノードを実行する必要があります。ブロックタイムが短く、あらかじめ設定された口座にすでに残高が分散されているため、開発モードが好まれます。同じコンテナ内の別のターミナルタブで起動してみましょう。\\n\\n<Asciinema vid=\\\"QnN9l0sdaZZOyK9ah0DntvCXt\\\"/>\\n\\n\\nまた、`datalog`デバイスの引数としてprivateなシード値が必要です。このシード値は、取引に署名するために使用され、アカウントを送信者として提示します。組み込まれている`robonomics key`コマンドを使って生成してみましょう。\\n\\n\\n<Asciinema vid=\\\"4Cdfl9F0GgjNWv1c1ZcTBBktF\\\"/>\\n\\n生成したアドレスとシード値は安全な場所に保存しておいてください。\\n\\n現在、アドレスの残高はゼロで、ネットワークはこのアドレスからの取引の送信を許可していません。この問題を解決するために、`Alice`アカウントからトークンを送金しましょう。https://parachain.robonomics.network の Robonomics Portal を使って、 `ws://127.0.0.1:9944`というアドレスのローカルノードに接続してみましょう。\\n\\n\\n![portal transfer](../images/ws_lesson3/tran.jpg)\\n\\n\\nそして、任意のデータをブロックチェーンに保存するために、`datalog`デバイスを使用することができます。`-s`keyは、アカウントの秘密シード値を設定するために使用されます。取引を行うためには、口座の残高がゼロでないことが必要です。\\n\\n<Asciinema vid=\\\"FzERH9TmFB8oRuas8ZU202Pv8\\\"/>\\n\\nすべてが正しく行われていれば、Robonomicsポータルの`Explorer`ページに`Datalog`イベントが表示されます。\\n\\n\\n![portal datalog](../images/ws_lesson3/datalog.jpg)\\n\\n\\n最後のステップは少し複雑ですが、このレッスンのすべての知識を使ってみるのもいいでしょう。SDS011センサー（またはファイル）からデータを収集し、それをIPFSに格納し、`datalog`トランザクションを送信してブロックチェーンにハッシュを保存する簡単なプログラムを作ってみましょう。\\n\\n\\n```\\nSDS011 -> IPFS -> Blockchain\\n```\\n\\nRobonomics IOを使って簡単に実装できますので、やってみましょう。\\n\\n\\n<Asciinema vid=\\\"MTpiawGo8DKEn081OozbYb5mU\\\"/>\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n\\n\\nうまくいけば、IPFSのハッシュを含む`Datalog`イベントが提示されるはずです。\\n\\n![portal datalog complex](../images/ws_lesson3/datalog_complex.jpg)\\n\"}},{\"node\":{\"id\":\"adc6f102aafce66839070b2b89175612\",\"title\":\"Lesson 2, RobonomicsのAIRA概要\",\"path\":\"/docs/ja/wschool2021-robonomics-github-overview/\",\"content\":\"\\n## Step 1: VirtualBox上にAIRAをインストール\\n\\nhttps://youtu.be/ISKilRfY3Ow\\n\\n参考\\n- [Robotics × Blockchainの準備~AIRAのインストール~](https://zenn.dev/kii/articles/aira-install)\\n  - 日本語翻訳者担当がこちらのチュートリアルを試した際に書いた記事\\n## Step 2: SSHによるAIRAへの接続\\n\\nhttps://youtu.be/W0rOcRA2sEc\\n\\n## Step 3: AIRAとやりとり\\n\\nhttps://youtu.be/fhRTF2mddfU\\n\"}},{\"node\":{\"id\":\"5c25db9a6812a9895efd3ac8d1fd8b0b\",\"title\":\"ロボノミクスウィンタースクール2021 紹介\",\"path\":\"/docs/ja/wschool2021-intro/\",\"content\":\"\\nロボノミクスウィンタースクール2021は、 2/10~2/24に**オンライン**で開催される。参加費は**無料**です。\\n\\n\\nテキストレッスンはこのWikiで、\\nビデオレッスンは[YouTube channel](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ)で、 \\nお知らせは[Twitter account](https://twitter.com/AIRA_Robonomics)でと、\\n様々な方法で**レッスン**をオンラインで公開しています。\\n\\nビデオレッスンとテキストレッスンは同じではありませんのでご注意ください。最初は、2つの言語バージョンを公開する予定です。英語とロシア語です。\\n\\n私たちと一緒にレッスンを進め、[Discord](https://discord.gg/5UWNGNaAUf)で**議論し、質問しましょう。**\\n\\n## オープニングセレモニーを見よう\\n\\nhttps://youtu.be/kQaSwNYHJQ8\\n\\n## 基本的な情報\\n\\n私たちのウェブサイト上の[ウィンタースクールについてのページ](https://robonomics.network/blog/winter-robonomics-school/)を見てください。スケジュール、パートナー情報、リンクなどの基本的な情報をまとめています。\\n\\n\\n\\n## 便利な関連リンク！\\n\\nロボノミクスウィンタースクール2021をフォローするために、どのようなリンクがあるのか、繰り返し説明します。\\n\\n- [ウェブサイトの概要](https://robonomics.network/blog/winter-robonomics-school/)\\n- テキストレッスン用のWiki、 あなたは今ここにいるよ 🤓\\n- [ビデオレッスン](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ)\\n- [Twitterでの速報](https://twitter.com/AIRA_Robonomics)\\n- [Discordでの質問、議論、クイズ](https://discord.gg/5UWNGNaAUf)\\n\\n**Robonomicsの学習を始めよう!**\\n\"}},{\"node\":{\"id\":\"5aeba103b56518ed2e6f8fbb9c80f44d\",\"title\":\"Lesson 5, コネクティビティ\",\"path\":\"/docs/ja/wschool2021-connectivity-service/\",\"content\":\"\\n## 複数のパイとしてのIoT\\n\\n* Device Software\\n    * FreeRTOS\\n    * ESP/Arduino\\n    * シングルボードコンピュータ (RPi、LattePandaなど)\\n* Connectivity\\n    * IoT Hub\\n    * IoT Manager\\n* Analytics Services\\n    * AWS\\n    * Google Cloud IoT Core\\n    * ThingsBoard\\n\\nふつう、ほとんどの方はセンサーやサーバーには興味がなく、データ分析に興味があります。それを手に入れるためには、どのデバイスを使うか、どのように連携するか、どこに接続するかを決める必要があります\\n\\n\\n## Device Software\\n\\n家庭用のウェザーステーションを例に考えてみましょう。大気汚染（SDS011）、温度、湿度（BME）のデータを収集する必要があります。ESP8266マイクロコントローラは、このタスクを処理することができます。\\n\\n必要なもの:\\n\\n* センサーからのデータを正しく読み取ることができる\\n* 固有の識別子を持つこと\\n* データを既知のサーバに転送する\\n* データのデジタル署名を行う（オプション）\\n\\n現在のファームウェアは[こちら](https://github.com/LoSk-p/sensors-software/tree/366b19bf447a5fc19220ef89eab0f2440f8db1c2)\\nからご覧いただけます。\\n\\n## Connectivityって何?\\n\\nIoTの世界で、Connectivityとは、さまざまなIoTデバイスをインターネットに接続し、データを送信したり、デバイスを制御したりすることを指します。\\n\\nよく知られているアーキテクチャのソリューションは、大きく3つのグループに分けられます。\\n\\n* 完全に分散化されたもの。たとえば、デバイスをメッシュネットワークで接続する。ハードウェア要件が高いため、広域ネットワークには適さない\\n* 集中型。たとえば、AWSなど。単一のエントリーポイントと接続の容易さを提供するが、サーバーに問題が発生した場合の障害リスクが高い\\n* ハイブリッド。たとえば、 [Robonomics Connectivity](https://github.com/airalab/sensors-connectivity)。ローカルネットワーク上のデバイスにアドレスを提供し、分散したIPFSメッセージチャネルにデータを公開する\\n\\n## AWS と Robonomics Connectivityの比較\\n\\n| 管理サービス \\t| AWS                               \\t|               Robonomics              \\t|\\n|---------------------\\t|-----------------------------------\\t|---------------------------------------\\t|\\n| トランザクションのタイプ    \\t| テクニカル                         \\t| テクニカル、経済的                \\t|\\n| セキュリティ            \\t| IT会社によるクラウド管理          \\t| Polkadot ,Ethereum                 \\t|\\n| プロトコル            \\t| HTTPS, MQTT                       \\t| IPFS, Robonomics                      \\t|\\n| エコシステム           \\t| private                           \\t| shared                                \\t|\\n| DeFiへのアクセス      \\t| No                                \\t| Yes                                   \\t|\\n| コスト               \\t| Pushing data - $1-2 a sensor      \\t| Pushing data - $0                     \\t|\\n|                     \\t| Shadow         - from $10 a month \\t| Digital Twin    - $0,01 a transaction \\t|\\n\\n## Aira上にConnectivityをインストール\\n\\nhttps://www.youtube.com/watch?v=JbBNMHAzJKM\\n\\n### 必要なもの\\n\\n* [VirtualBox 6.1](https://www.virtualbox.org/wiki/Downloads)以上\\n* [Aira OS ova image](https://static.aira.life/ova/airaos-21.03_robonomics-winter-school.ova)\\n\\n[この記事を参考に](/docs/aira-installation-on-vb/)AiraのイメージをVirtualBoxに取り込みます。\\n\\nSSHでの[接続設定](/docs/aira-connecting-via-ssh/)\\n\\nすべての準備が整い、SSHでのログインに成功したら、メインパッケージをクローンしてビルドしましょう。\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\ngit checkout v0.9\\nnix build -f release.nix\\n```\\n\\n\\nそれでは、後で使えるようにデフォルトの設定ファイルのコピーを作成しましょう。すべてのオプションについて知りたい方は[こちらの記事](/docs/configuration-options-description/) をご覧ください。次に、パッケージを `roslaunch` で起動します。\\n```\\ncp config/default.json config/my.json\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n## センサーをコネクティビティに接続\\n\\nhttps://www.youtube.com/watch?v=yxqxBk-6bpI\\n\\n### 必要なもの\\n\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) センサー\\n* [Yarn Packet Manager](https://yarnpkg.com/getting-started/install)\\n\\nそれでは、実際にセンサーを接続し、USBポートを仮想マシンに転送し、マップを設定して、自分の測定結果を見てみましょう。\\n\\nまず、Aira OSが起動している場合は停止し、対応するUSBデバイスを追加します。\\n\\n![VB USB Forwarding](../images/vb_forward_usb.jpg)\\n\\n仮想マシンを起動し、SSHで接続し、仮想マシンのUSBデバイスに合わせて`comstation/port`オプションを設定します。また、`comstation`を有効にして、緯度と経度を設定します。最終的に `config/my.json` は以下のようになります。\\n\\n```\\n{\\n   \\\"general\\\":{\\n      \\\"publish_interval\\\":30\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":0,\\n      \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"connectivity.robonomics.network\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\":{\\n      \\\"enable\\\":false\\n   },\\n   \\\"robonomics\\\":{\\n      \\\"enable\\\":true,\\n      \\\"ipfs_provider\\\":\\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\":\\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\":{\\n      \\\"enable\\\":false,\\n      \\\"path\\\":\\\"\\\",\\n      \\\"suri\\\":\\\"\\\",\\n      \\\"remote\\\":\\\"wss://substrate.ipci.io\\\",\\n      \\\"dump_interval\\\":3600,\\n      \\\"temporal_username\\\":\\\"\\\",\\n      \\\"temporal_password\\\":\\\"\\\"\\n   },\\n   \\\"dev\\\":{\\n      \\\"sentry\\\":\\\"\\\"\\n   }\\n}\\n```\\n\\n> 本物のセンサーがない場合は、`sensers-connectivity/utils/virtual-sensor.py` スクリプトを使ってエミュレートすることができます。\\n>\\n> 設定ファイルを以下のように変更することで、`HTTPStation`を有効にし、`COMStation`を無効にします。\\n\\n> ```\\n> {\\n>    \\\"general\\\":{\\n>       \\\"publish_interval\\\":30\\n>    },\\n>    \\\"comstation\\\":{\\n>       \\\"enable\\\":false,\\n>       \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n>       \\\"work_period\\\":0,\\n>       \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n>       \\\"public_key\\\":\\\"\\\"\\n>    },\\n>    \\\"httpstation\\\":{\\n>       \\\"enable\\\":true,\\n>       \\\"port\\\":8001\\n>    },\\n>    ...\\n> }\\n> ```\\n>\\n> そして、VM内の専用端末で`utils/virtual-sensor.py`を起動します。\\n\\nファイルを保存し、`sensers-connectivity`フォルダからconnectivityを起動します。\\n```\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\nコンソール出力に最初の測定値が表示されます。\\n\\nVMの中であなたのIPFS IDを探します。イメージを起動した直後、または `ipfs id` コマンドで表示されます。これは後で必要になります。\\n\\nそれでは、マップの独自のインスタンスをセットアップしましょう。ラップトップ（VMではない）で[このリポジトリ](https://github.com/airalab/sensors.robonomics.network)をクローンし、アプリをビルドします。\\n```\\ngit clone https://github.com/airalab/sensors.robonomics.network\\ncd sensors.robonomics.network\\nyarn install\\n```\\n\\n`src/agents.json` ファイルを編集し、IPFS ID を入力します。たとえば、以下のようになります。\\n```\\n[\\n  \\\"12D3KooWSCFAD3Lpew1HijniE6oFTuo4jsMwHzF87wNnXkpCRYWn\\\"\\n]\\n```\\n\\nマップを起動します。\\n\\n```\\nyarn serve\\n```\\n\\n[http://localhost:8080/](http://localhost:8080/)または yarn が教えてくれたアドレスに行き、センサーを探します。\\n\\n## 実践編\\n\\n### 軌道 1. ESP + SDS011 センサーを点滅させる\\n\\n必要なもの:\\n\\n* ESP8266\\n* 少なくともこの中から1つのセンサー SDS011, BME280, HTU21D\\n\\n[このインストラクション](https://wiki.robonomics.network/docs/connect-sensor-to-robonomics/) を使って、センサーをRobonomics Connectivityに接続します。\\n\\nセンサーが[地図](https://sensors.robonomics.network/#/)上に表示されることを確認します。 \\n\\n### 軌道 2. Connectivityの起動\\n\\n必要なもの:\\n\\n* ROS\\n* Python\\n* Nix (optional)\\n\\n[sensors-connectivity](https://github.com/airalab/sensors-connectivity#get-a-package-and-build)の構築と起動\\n\\n> ビルド方法、インストール方法は [こちら](https://wiki.robonomics.network/docs/iot-sensors-connectivity/) 設定方法は [こちら](https://wiki.robonomics.network/docs/configuration-options-description/)\\n\\nパッケージの全体像です。\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nたとえば、乱数発生器などの新しいステーションや、画面に文字列を表示するなどの新しいフィーダーを実装することが提案されています。\\n\\n `IStation` のInterfaceは[こちら](https://github.com/airalab/sensors-connectivity/blob/master/src/stations/istation.py#L73).\\n\\n `IFeeder` のInterfaceは[こちら](https://github.com/airalab/sensors-connectivity/blob/master/src/feeders/ifeeder.py#L5)\\n\\n\"}},{\"node\":{\"id\":\"b5c495fc456f59b073a64f93052498a1\",\"title\":\"Lesson 1, ユーザーアプリにロボットを繋ぐ\",\"path\":\"/docs/ja/wschool2021-connect-robotics-to-user-app/\",\"content\":\"\\nhttps://youtu.be/NOQxyojvaao\\n\\n- [Wiki上の参考チュートリアル](https://wiki.robonomics.network/docs/get-weather-on-fuji-mountain/)\\n- [Dapp](https://dapp.robonomics.network/#/)\\n\"}},{\"node\":{\"id\":\"8a3a94c1f0b4791fb118a9637c89559f\",\"title\":\"Lesson 6.2, Dapp インターフェースの構築\",\"path\":\"/docs/ja/wschool2021-build-dapp-interface/\",\"content\":\"\\n![Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot](../images/build-dapp-interface/sum.gif \\\"Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot\\\")\\n\\n## はじめに\\n\\nこのチュートリアルは前回の続きで、すでにシンプルなアプリケーションを構築し、アカウントとノードの接続、トランザクションの送信など、アプリの重要な機能に焦点を当てていました。今度は、このアプリケーションのために、**ユーザーフレンドリーなインターフェースを構築**します。\\n\\n## 前提条件\\n\\nこのチュートリアルは、**HTML、CSS、JavaScript**に少し慣れていて、これらのスキルを分散型アプリケーションに適用する方法を学びたい方を対象としています。\\n\\n\\nアプリのインターフェイスを構築するために、自分にとって快適なJavaScriptフレームワークを選ぶことができますし、フレームワークなしでインターフェイスを構築することもできます。Robonomics2021では、スケーラブルで使いやすい[Vue.js](https://vuejs.org) を使用しています。\\n\\n## このチュートリアルのための設定\\n\\nこのステップから始めて、**実際にやってみて学びたい**という方は、以下のTo-Doリストに従って、前のレッスンで作成したdappを起動してください。\\n\\n1.あなたのOSに合ったRobonomics v0.22のローカルノードを[リリースページ](https://github.com/airalab/robonomics/releases/tag/v0.22.0) からダウンロードしてください。もしあなたのシステムが最新のリリースにない場合は、過去のリリースから最新のバージョンを探してください。\\n\\n2.ターミナルで `./robonomics --dev --tmp` と入力して、ロボノミクスノードを開発者モードで起動します。\\n\\n3.ChromeまたはFirefox用のPolkadot Extensionをダウンロードしてください。[Polkadot Extension](https://polkadot.js.org/extension/)\\n\\n4. [このリポジトリ](https://github.com/vol4tim/example-robonomics-dapp/)をクローンします。\\n\\n5. [Yarn](https://yarnpkg.com)をインストールします。\\n\\n6. [@vue/cli](https://cli.vuejs.org/guide/installation.html)をインストールします。\\n\\n7. ターミナルで コマンドを実行して、dappの開発を開始します。\\n```shell\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n\\n**ブラウザにこのような画面が表示されるはずです。:**\\n\\n![Dapp Start](../images/build-dapp-interface/dapp-start.png \\\"Dapp Start\\\")\\n\\n\\n<details>\\n\\n  <summary>起動のためのいくつかの追加のヒント</summary>\\n\\n  - **ノードが起動している**ことを確認します:\\n    ![Example of running a Robonomics node](../images/build-dapp-interface/robonomics-node-launch.png \\\"Example of running Robonomics node\\\")\\n\\n  - **macOS**の場合、**アクセス権**を変更する必要があるかもしれません`chmod +x robonomics`\\n  - **Polkadot Extensionへのアクセスが許可**されていることを確認してください:\\n    ![Polkadot Extension giving access](../images/build-dapp-interface/polkadot-permission.png \\\"Polkadot Extension giving access\\\")\\n\\n  - 実行中のノードのログにエラーがあり、dappが正しくロードされていない場合、devチェーンのデータベースを削除してみてください: `sudo rm -rf <YOUR LOCAL PATH>/robonomics/chains/dev/db/` そしてノードを再起動してください。それでもだめな場合は、マシンを再起動してください。\\n\\n\\n</details>\\n\\n## コードの確認\\n\\nUIを変更するために、何をどこで修正すればよいかを明確にするために、dappの構造を確認してみましょう。\\n\\n```\\n.\\n├── public/\\n│   ├── favicon.ico           # dappのアイコンです\\n│   └── index.html            #  テンプレートファイル（アプリのアイコンのリンク、JavaScript、CSSファイルを注入します\\n├── src/\\n│   ├── assets/               # 画像やグローバルスタイルのフォルダ\\n│   ├── components/           # コンポーネントを格納するフォルダ\\n│   │   ├── Datalog.vue       # dapp内のDatalogタブ\\n│   │   ├── Demo.vue          #  dappの中のDemoタブ\\n│   │   ├── Launch.vue        # dappの中のLaunchタブ\\n│   ├── utils/                # アプリ用の重要な機能が入ったフォルダ (このチュートリアルでは api.js を触ります)\\n│   ├── App.vue               # アプリのルートであり、ページ全体のHTML、CSS、JSを含む。実際にはVueコンポーネントでもあります\\n│   ├── main.js               # アプリのエントリーファイル、ここでグローバルスタイルをインポートします\\n├── ...                       # 設定ファイルや依存関係のファイルがありますが、通常は変更しません\\n├── README.md                 # ここには、アプリの説明を書くことができます。\\n\\n```\\n\\n> **このチュートリアルのコードは、[このリポジトリ](https://github.com/positivecrash/wscool21-ui-dapp)にあります。**\\n\\n## CSS-IN-JS VS. グローバルスタイルシート\\n\\nこのチュートリアルでは、UIコンポーネントの安定したライブラリがなくても、小さなdappのインターフェースをゼロから変更する方法を紹介します。そこで、さまざまなVueコンポーネントをインポートして作成するだけでなく、独自のスタイルも作成します。\\n\\n\\nもしあなたのアプリケーションが大きかったり、プロジェクトにたくさんのdappsがある場合は、UIをより整理して効率的にするために、将来的にはあなたのプロジェクトに特化したコンポーネントのライブラリを探した方がいいでしょう（[例えば、コンポーネントを整理するためのツール](https://storybook.js.org)があります）。また、標準的なインターフェイスのテーマで良いのであれば、[サードパーティ製のUIライブラリ](https://vuetifyjs.com/)を利用することもできます。\\n## 最初のインポート、どこから始めるか\\n\\n\\nこのアプリのための特別なデザインはありませんが、[ブランドブック](https://static.robonomics.network/assets/Robonomics-Visual-Identity.pdf)があり、[タイポグラフィ、フォント、ボタンのスタイルなどが確立](https://robonomics.network/community#assets)されています。そこで、まずは以下のcssファイルをグローバルにインポートします。\\n```\\n...\\n├── src/\\n│   ├── assets/\\n│   │   ├── styles/\\n│   │   │   ├── reset.css         # 目的は、ブラウザの不整合を減らすことです。\\n│   │   │   ├── variables.css     # 色、フォント名、スペース値など、再利用する特定の値を含む\\n│   │   │   ├── typography.css    #  dapp全体のグローバルなタイポグラフィ\\n│   │   │   ├── animation.css     # dapp全体で使われるキーフレームアニメーション\\n...\\n\\n```\\n\\nこれらのファイルの内容は、あなたの認識に合うのであれば、代わりにApp.vueに書くことができます。しかし、この例では、App.vueを少しでもわかりやすくするために、いくつかのCSSファイルをグローバルにインポートすることをお勧めします。\\n\\n\\nこれらのCSSファイルをアプリにインポートするには、**main.js**ファイルを編集します:\\n\\n![VueアプリにグローバルなCSSをインポートする](../images/build-dapp-interface/import-css-vue-1.png \\\"Import global CSS in Vue app\\\")\\n\\n```JS\\nimport './assets/styles/reset.css'\\nimport './assets/styles/variables.css'\\nimport './assets/styles/typography.css'\\nimport './assets/styles/animation.css'\\n```\\n\\n**dappでフォントが変更されているかどうかを確認:**\\n\\n![Dapp Interface changing step 1](../images/build-dapp-interface/dapp-1.png \\\"Dapp Interface changing step 1\\\")\\n\\n\\n## レイアウトの変更とタイトルの装飾\\n\\n\\nアプリケーションのレイアウトを変更してみましょう。先に述べたように、App.vueに直接スタイルを書くこともできますが、今回の例では、このプロセスを分けて考えたいと思います。\\n\\n- **App.vue**の`<style>`タグからスタイルをコメントまたは削除する\\n\\n- このアプリケーションのstylesフォルダにcssファイル**app.css**を作成し、**main.js**にインポートします。\\n\\n```JS\\nimport './assets/styles/app.css'\\n```\\n\\n<details>\\n\\n<summary>app.cssにアプリの最初の基本スタイルを記述します。:</summary>\\n\\n```css\\n#app {\\n  display: grid;\\n  grid-template-rows: auto 1fr;\\n  align-items: stretch;\\n\\n  text-align: center;\\n}\\n\\nbody {\\n  background-color: var(--color-gray-light);\\n}\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>アプリのタイトルを変更する [app.vue]</summary>\\n\\n```html\\n<div class=\\\"top\\\">\\n    <h1>dApp Robonomics Demo</h1>\\n    <i>Winter School 2021</i>\\n    <img class=\\\"label\\\" alt=\\\"\\\" src=\\\"./assets/images/robonomics-winter-school-2021-logo.png\\\"/>\\n</div>\\n```\\n\\n</details>\\n\\n\\n\\n<details>\\n\\n<summary>タイトル用のスタイルを書く [app.css]</summary>\\n\\n```css\\n.top {\\n  position: relative;\\n  padding-top: var(--space);\\n  padding-bottom: calc(var(--space)*2);\\n\\n  border-bottom: 2px solid var(--color-dark);\\n  background-color: var(--color-light);\\n}\\n\\n.top h1 {\\n  font-size: 1.8rem;\\n}\\n\\n.top i {\\n  display: block;\\n}\\n\\n.top .loader-label {\\n  display: block;\\n  margin: calc(var(--space)/3) auto;\\n  max-width: 150px;\\n\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.5s FadeIn 0.3s ease forwards, 0.5s ScaleDown 0.1s ease forwards;\\n}\\n\\n.top .label {\\n  position: absolute;\\n  width: 100px;\\n  bottom: -50px;\\n  left: calc(50% - 50px);\\n  display: block;\\n\\n  transform: translateY(1rem);\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.7s FadeIn 0.5s ease forwards, 1s ScaleUp 0.5s ease forwards;\\n}\\n```\\n\\n</details>\\n\\n- ロボノミクスウィンタースクール2021のロゴが入ったファイルを、**./src/assets/images**フォルダに置く。\\n\\n**次のような画面が表示されます:**\\n![Dapp Interface changing step 2](../images/build-dapp-interface/dapp-2.png \\\"Dapp Interface changing step 2\\\")\\n\\n## dappのデータに合わせてスタイルを定義する\\n\\nここで、アプリのコンテンツを`<div>`要素で囲みます。また、アプリの状態（ロードされている、されていない）に応じて、異なるスタイルが必要です。\\n\\n- **App.vue**を開いて、ラッピング要素を書きます。:\\n```html\\n<div class=\\\"content\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n- `<script>`で定義されている変数`load`を見つけます。\\n- オブジェクトを`v-bind:class`に渡して、クラスを動的に切り替えます（私は短縮版の`:class`を使っています）。\\n\\n```html\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\nこのようにして、取得したデータに応じてアプリのスタイルを簡単に切り替えることができます。このクラスの使い方は以下の通りです。\\n\\n## dappのデータに応じてビューを定義する\\n\\nアプリのローダを変更しましょう。\\n- この目的のために、別のRobonomicsプロジェクトからコンポーネントをインポートします。\\n\\n\\n<details>\\n\\n<summary>./src/components/AnimatedRobonomicsLogo.vue</summary>\\n\\n```HTML\\n<template>\\n  <div class=\\\"logo-animated\\\" :style=\\\"{transform: 'scale('+scale+')'}\\\">\\n      <svg version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" width=\\\"196.9px\\\" height=\\\"170.3px\\\" viewBox=\\\"0 0 196.9 170.3\\\" style=\\\"enable-background:new 0 0 196.9 170.3;\\\" xml:space=\\\"preserve\\\">\\n\\t\\t<g transform=\\\"translate(2530 155)\\\">\\n            <path class=\\\"line\\\" d=\\\"M-2523.4,7.9l184.2,0.5l-91.7-158.1L-2523.4,7.9z\\\"/>\\n\\n            <circle class=\\\"dot\\\" cx=\\\"-2339.7\\\" cy=\\\"8.7\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2523.4\\\" cy=\\\"8.2\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2430.8\\\" cy=\\\"-148.4\\\" r=\\\"6.6\\\"/>\\n            \\n            <path class=\\\"triangle-1\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-45.8-79L-2477.3-18.3z\\\"/>\\n            <path class=\\\"triangle-2\\\" d=\\\"M-2431.2-18.1l46,0.1l-45.8-79L-2431.2-18.1z\\\"/>\\n            <path class=\\\"triangle-3\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-46-20.3L-2477.3-18.3z\\\"/>\\n          </g>\\n\\t</svg>\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style scoped>\\n    /*\\n    Global styles required:\\n    FadeIn - keyframe animation from animation: .css\\n    all --color- variables from variables.css\\n    */\\n\\n    .logo-animated {\\n        transform-origin: 0 0;\\n    }\\n\\n    .logo-animated .dot {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 1s FadeIn 0.3s ease forwards;\\n    }\\n\\n    .logo-animated .line {\\n        fill: transparent;\\n        stroke: var(--color-blue);\\n        stroke-miterlimit:10;\\n        stroke-dasharray: 700;\\n        stroke-dashoffset: 700;\\n        animation: 1s DrawSvgPath 0.5s ease-in-out forwards; \\n    }\\n\\n    .logo-animated .triangle-1 {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-1 0.1s linear infinite;\\n    }\\n\\n    .triangle-2 {\\n        fill: var(--color-violet-light);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-2 0.1s linear infinite;\\n    }\\n\\n    .triangle-3 {\\n        fill: var(--color-violet-mid);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-3 0.1s linear infinite;\\n    }\\n\\n\\n    @keyframes DrawSvgPath\\n        {\\n        to {\\n            stroke-dashoffset: 0;\\n        }\\n        }\\n\\n    @keyframes logo-triangle-1\\n    {\\n        0% { fill: var(--color-blue); }\\n        25% { fill: var(--color-blue); }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-violet-light); }\\n        100% { fill: var(--color-blue); }\\n    }\\n\\n    @keyframes logo-triangle-2\\n    {\\n        0% { fill: var(--color-violet-light); }\\n        25% { fill: #E0BDED; }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-blue); }\\n        100% { fill: var(--color-violet-light); }\\n    }\\n\\n    @keyframes logo-triangle-3\\n    {\\n        0% { fill: var(--color-violet-mid); }\\n        25% { fill: var(--color-violet-light); }\\n        50% { fill: var(--color-violet-light); }\\n        75% { fill: var(--color-violet-dark); }\\n        100% { fill: var(--color-violet-mid); }\\n    }\\n</style>\\n```\\n\\n</details>\\n\\n- このコンポーネントを**App.vue**に登録します。\\n```JS\\nexport default {\\n  components: {\\n    Loader: () => import(\\\"./components/AnimatedRobonomicsLogo\\\")\\n  }\\n}\\n```\\n- 既に知られている変数`load`を使って、条件付きのVueディレクティブ`v-if`で挿入します。\\n```HTML\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <Loader v-if=\\\"load\\\" />\\n  <template v-else>\\n    <!-- ここがロードされたDAPのメインコンテンツになります -->\\n  </template>\\n</div>\\n```\\n- ブラウザで結果を見てみましょう。いくつかの問題がありますが、これから修正していきます:\\n\\n1. ローダーがタイトルまでポップアップしています（中央にあるべきです）。以下の行を**app.css**に挿入してみましょう。\\n\\n```css\\nbody, html, #app {\\n  height: 100%;\\n  position: relative;\\n}\\n```\\n2. 通信速度が速すぎると、一瞬、ローダーが点滅するだけになります。混乱してしまうかもしれません。そこで、アプリからの応答にタイムアウトを設定してみましょう。そのためには、**api.js**を開き、関数`initAccount`の中に以下のコードを見つけます:\\n\\n```JS\\nconst timeout = new Promise(resolve => {\\n  setTimeout(resolve, 300);\\n});\\n```\\n`300`の代わりに`1700`を設定して、結果を確認します:\\n\\n![Dappインターフェース変更ステップ3](../images/build-dapp-interface/dapp-3.gif \\\"Dappインターフェース変更ステップ3\\\")\\n\\n\\n## 再利用可能なコンポーネントの使用\\n\\nコンポーネントを登録して使用する方法は、前回のLoaderの項ですでに見ていますが、今回はもっと注意深く注目してみたいと思います。\\n\\nAccountの部分を変えてみましょう。ここでは、自分で書いたコンポーネント（ボックス、ボタン、アイコン）とサードパーティのコンポーネント（[Vue Polkadot Libraryのもの](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon )）を使います。\\n\\n### ボックスの追加\\n\\n<details>\\n\\n<summary>./src/components/Box.vueファイルにBoxコンポーネントを作成します。</summary>\\n\\n```HTML\\n<template>\\n    <section class=\\\"box\\\" :class=\\\"classList\\\">\\n        <slot />\\n    </section>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    classList: {\\n      type: String\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .box {\\n        background-color: var(--color-light);\\n        border: 1px solid var(--color-dark);\\n        padding: calc(var(--space)*0.5) var(--space);\\n        box-shadow: 2px 2px 0 var(--color-dark);\\n        margin-bottom: calc(var(--space)*1.5);\\n    }\\n</style>\\n```\\n</details>\\n\\nこれで、Dappの中で何度も使うことができます。これをAccountセクションの例で見てみましょう:\\n\\n- コンポーネントを登録 (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Box: () => import(\\\"./components/Box\\\")\\n  }\\n}\\n```\\n\\n- これをAccountセクションに使用し、prop `classList`で追加のクラスを渡します:\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }} |\\n  <button @click=\\\"faucet\\\">\\n    faucet\\n  </button>\\n</Box>\\n```\\n\\n**結果の確認:**\\n![Dapp Interface changing step 4](../images/build-dapp-interface/dapp-4.png \\\"Dapp Interface changing step 4\\\")\\n\\n### ボタンの追加\\n\\n追加したボックス内のボタンに気づかないこともあるかもしれません。このアプリにはボタンが1つしかないわけではないので、修正してボタン用のコンポーネントを追加しましょう。\\n\\n<details>\\n\\n<summary>./src/components/Button.vueファイルにButtonコンポーネントを作成します。</summary>\\n\\n```HTML\\n<template>\\n  <button type=\\\"button\\\" :class=\\\"classList\\\" @click=\\\"onClick\\\" :disabled=\\\"disabled\\\" class=\\\"inline-block\\\">\\n    {{ label }}\\n  </button>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  components: {\\n    Icon: () => import(\\\"./Icon\\\")\\n  },\\n\\n  props: {\\n    label: {\\n      type: String,\\n    },\\n    type: {\\n      type: String,\\n      default: 'primary',\\n      validator: function (value) {\\n        return ['primary', 'secondary'].indexOf(value) !== -1;\\n      }\\n    },\\n    disabled: {\\n      type: Boolean,\\n      default: false,\\n    },\\n    size: {\\n      type: String,\\n      default: 'medium',\\n      validator: function (value) {\\n        return ['small', 'medium', 'large'].indexOf(value) !== -1;\\n      }\\n    }\\n  },\\n\\n  computed: {\\n    classList() {\\n      return {\\n        'button': true,\\n        [`${this.type}`]: true,\\n        [`button__${this.size}`]: true,\\n      };\\n    },\\n  },\\n\\n  methods: {\\n    onClick() {\\n      this.$emit('onClick');\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .button {\\n        appearance: none;\\n        -webkit-appearance: none;\\n        outline: 0;\\n        border: 0;\\n\\n        transition: 0.1s all linear;\\n\\n        padding: .15rem 0.6rem;\\n        border-width: 1px;\\n        border-style: solid;\\n        border-radius: .25rem;\\n  \\n        cursor: pointer;\\n\\n        font-family: var(--font-family);\\n        font-size: calc(var(--font-size)*0.9);\\n        line-height: 1;\\n        font-weight: 500;\\n\\n        text-transform: uppercase;\\n        letter-spacing: 1px;\\n    }   \\n\\n    .button:not([disabled]):hover {\\n    filter: saturate(1.5);\\n    }\\n\\n    .button[disabled] {\\n        cursor: default;\\n        opacity: 0.6;\\n    }\\n\\n    button.primary {\\n        border-color: var(--color-green);\\n        background-color: var(--color-green);\\n        color: var(--color-light);\\n    }\\n\\n    button.secondary {\\n        border-color: var(--color-blue);\\n        color: var(--color-blue);\\n    }\\n\\n    button.secondary:not([disabled]):hover {\\n        background-color: var(--color-blue);\\n        color: var(--color-light);\\n    }\\n\\n    .button__small {\\n        font-size: .85rem;\\n        padding: .1rem 0.45rem;\\n    }\\n\\n    .button__large {\\n        font-size: 1.2rem;\\n        padding: .5rem 1.7rem;\\n    }\\n\\n</style>\\n```\\n</details>\\n\\n\\n- コンポーネントの登録 (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Button: () => import(\\\"./components/Button\\\")\\n  }\\n}\\n```\\n\\n- `Button`コンポーネントで定義されたプロップを持つ`Faucet`ボタンに使用します。\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }}\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n</Box>\\n```\\n\\n**次のようなビューが得られます:**\\n![Dapp Interface changing step 5](../images/build-dapp-interface/dapp-5.png \\\"Dapp Interface changing step 5\\\")\\n\\nButtonコンポーネントでは、`@onClick`でpropからクリックイベントを発火していますので、faucet機能が正しく動作しているかどうか（クリックで残高が変化するはず）に注目します。\\n\\n\\n![Dapp Interface changing step 6](../images/build-dapp-interface/dapp-6.gif \\\"Dapp Interface changing step 6\\\")\\n\\n### アイコンの追加\\n\\nこのボタンにアイコンを追加して、インターフェイスのこの要素に注目させましょう。ユーザーは、このボタンをユニット化してクリックしないと、Dappを正しく操作できないからです。\\n\\nこの目的のために、アイコンのためのVueライブラリを使用することができますが、私はアイコンを持つ独自のコンポーネントを作成します。\\n\\n- [アイコンの大きなオンライン・アーカイブ](https://www.flaticon.com)で適切なアイコンを見つけました。\\n- .svgファイルをダウンロードして、ベクター・グラフィックス・エディターで編集し、適切なサイズにします。\\n\\n- Icon.vueコンポーネントにsvgをテキストとして挿入しました。\\n\\n<details>\\n\\n<summary>これで、Icon.vueコンポーネントの出来上がりです。</summary>\\n\\n```JS\\n<template>\\n  <div class=\\\"icon inline-block\\\" :class=\\\"classList\\\">\\n    <svg v-if=\\\"icon == 'faucet'\\\" class=\\\"icon-fill\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" :width=\\\"SvgWidth(20)\\\"  viewBox=\\\"0 0 20 24.9\\\" style=\\\"enable-background:new 0 0 20 24.9;\\\" xml:space=\\\"preserve\\\">\\n      <path d=\\\"M2.7,24.9c0.2,0,2.4,0,2.4-2.4c0-2-2.2-5.2-2.2-5.2s-2.5,3.3-2.5,5.3C0.4,24.6,2.4,24.9,2.7,24.9z M20,10.8V7.2V3.1h-2.6v2.6h-3.1V1.5h2.6c0.4,0,0.8-0.3,0.8-0.8S17.3,0,16.9,0h-6.7C9.8,0,9.5,0.3,9.5,0.8s0.3,0.8,0.8,0.8h2.6v4.1H7.9c-4.7,0-6.2,3.2-6.3,4.8c0,0,0,0.1,0,0.1v2.8H0v2.1h6.2v-2.1H4.6v-2.7c0-0.3,0.4-1.9,3.3-1.9h9.6v2.1L20,10.8L20,10.8z\\\"/>\\n    </svg>\\n\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n  props: {\\n    icon: {\\n      type: String\\n    },\\n    classList: {\\n      type: String\\n    },\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n  methods: {\\n    SvgWidth(SvgWidth) {\\n      return `${SvgWidth * this.scale}px`;\\n    }\\n  }\\n};\\n</script>\\n\\n<style>\\n.icon {\\n    line-height: 1;\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\nこれをボタンで使うには、Buttonコンポーネントを編集します。\\n\\nIconを**Button.vue**にインポートします:\\n\\n```JS\\ncomponents: {\\n    Icon: () => import(\\\"./Icon\\\")\\n}\\n```\\n\\npropを登録:\\n\\n```JS\\nprops: {\\n  icon: {\\n    type: String,\\n    default: 'none'\\n  }\\n}\\n```\\n\\nアイコンをボタンに追加します（`v-if`条件で異なるテンプレートを指定できます）。\\n\\n```HTML\\n<template v-if=\\\"icon != 'none'\\\">\\n  <Icon :icon=\\\"icon\\\" />\\n  <span v-if=\\\"label != ''\\\" class=\\\"inline-block\\\">{{ label }}</span>\\n</template>\\n<template v-if=\\\"icon == 'none' & label != ''\\\">\\n  {{ label }}\\n</template>\\n```\\n\\nスタイルを追加:\\n\\n```CSS\\n.button .icon-fill path {\\n  fill: var(--color-light);\\n}\\n\\n.button > *:not(:last-child) {\\n  margin-right: calc(var(--space)/2);\\n}\\n\\n```\\n\\n**App.vue**でアイコンプロップをボタンに追加:\\n\\n```HTML\\n<Button label=\\\"Faucet\\\" size=\\\"large\\\" icon=\\\"faucet\\\" @onClick=\\\"faucet\\\" />\\n```\\n\\n**確認:**\\n\\n![Dapp Interface changing step 7](../images/build-dapp-interface/dapp-7.png \\\"Dapp Interface changing step 7\\\")\\n\\n### ポルカドットのアバターを追加する\\n\\n- インストール [@vue-polkadot/vue-identicon](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon)\\n\\n- App.vueにインポート:\\n```JS\\ncomponents: {\\n    Identicon: () => import(\\\"@vue-polkadot/vue-identicon\\\")\\n}\\n```\\n\\n- `Account`という単語の代わりにアバターを挿入し、ドキュメントにしたがってpropsを渡し、value propとして`account`データを使用します:\\n\\n```HTML\\n<Identicon\\n  :value=\\\"account\\\"\\n  :theme=\\\"'polkadot'\\\"\\n  :size=\\\"40\\\"\\n  :class=\\\"'inline-block'\\\"\\n/>\\n```\\n\\n**確認:**\\n\\n![Dapp Interface changing step 8](../images/build-dapp-interface/dapp-8.png \\\"Dapp Interface changing step 8\\\")\\n\\n## 見やすいようにデータを操作する\\n\\nアカウントのアドレスをカットしてみましょう:\\n\\n- 変数`account`をcomputedプロパティでラップします。\\n\\n```JS\\ncomputed: {\\n  AccountAddress() {\\n    return this.account.slice(0, 6) + \\\"...\\\" + this.account.slice(-4);\\n  }\\n}\\n```\\n\\n- テンプレート内の変数 `account` を `AccountAddress` に置き換えてください。\\n\\n**確認:**\\n\\n![Dapp Interface changing step 9](../images/build-dapp-interface/dapp-9.png \\\"Dapp Interface changing step 9\\\")\\n\\n## CSS magic\\n\\nアカウントセクションをもう少し可愛くしてみましょう:\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n              \\n  <div class=\\\"account__address\\\">\\n    <Identicon\\n      :value=\\\"account\\\"\\n      :theme=\\\"'polkadot'\\\"\\n      :size=\\\"40\\\"\\n      :class=\\\"'inline-block'\\\"\\n    />\\n\\n    <code class=\\\"inline-block\\\">{{ AccountAddress }}</code>\\n  </div>\\n  \\n  <div class=\\\"account__balance\\\">{{ balance }}</div>\\n\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n  \\n</Box>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.account {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  align-items: center;\\n  justify-items: stretch;\\n  column-gap: var(--space);\\n}\\n\\n.account__balance {\\n    font-size: 150%;\\n    font-weight: 500;\\n    font-family: var(--font-family-code);\\n    white-space: nowrap;\\n}\\n\\n.account__address > *:not(:last-child) {\\n    margin-right: calc(var(--space)/2);\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 10](../images/build-dapp-interface/dapp-10.gif \\\"Dapp Interface changing step 10\\\")\\n\\nタブのスタイルを編集しましょう:\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.tabs {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  margin-top: calc(var(--space)*2.5);\\n}\\n\\n.tabs button {\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  border-width: 0 0 1px;\\n  font-family: var(--font-family);\\n  font-size: calc(var(--font-size)*1.5);\\n  font-weight: 300;\\n  cursor: pointer;\\n  transition: 0.2s all linear;\\n}\\n\\n.tabs button:not(.active) {\\n  opacity: 0.5;\\n  border-color: var(--color-gray)\\n}\\n\\n.tabs-content {\\n  padding-top: var(--space);\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>テンプレートの変更は最小限に</summary>\\n\\n```HTML\\n<div class=\\\"tabs-content\\\">\\n  <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" /> \\n</div>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 11](../images/build-dapp-interface/dapp-11.gif \\\"Dapp Interface changing step 11\\\")\\n\\n> このチュートリアルの完成したコードは、[このリポジトリ](https://github.com/positivecrash/wscool21-ui-dapp)にあることを覚えておいてください。そして、次のステップに進みましょう :)\\n\\n## Datalog\\n\\nまず、dapp で既に知られている UI 要素であるボタンを修正することから始めましょう（`Faucet`で行ったのと同じですが、異なるプロップを使用しています）。\\n\\n次に、これらの要素を`<fieldset>`で囲み、意味ごとに分離します。そして、fieldsetとinputの要素に自分のスタイルを書きます。\\n\\n<details>\\n\\n<summary>Datalog.vueのテンプレート:</summary>\\n\\n```HTML\\n<div class=\\\"tools\\\">\\n  <fieldset>\\n    <Button label=\\\"Read data\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"read\\\" />\\n  </fieldset>\\n\\n  <fieldset>\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" class=\\\"large\\\" />\\n    <Button label=\\\"Write\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"write\\\" />\\n  </fieldset>\\n</div>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>app.cssのinput要素のスタイル - グローバルなものになるはず:</summary>\\n\\n```CSS\\ninput, select{\\n  padding: .3rem 0.6rem;\\n  border: 1px solid var(--color-gray);\\n  background-color: var(--color-light);\\n  border-radius: var(--radius);\\n  font-size: var(--font-size);\\n  font-family: var(--font-family-code);\\n  border-radius: .25rem;\\n  transition: 0.2s ease all;\\n}\\n\\ninput:focus {\\n  border-color: var(--color-dark);\\n}\\n\\ninput.large, select.large {\\n  font-size: 1.2rem;\\n  padding: .35rem 1rem;\\n}\\n\\n\\n.tools *, .tools fieldset:not(:last-child):after {\\n  display: inline-block;\\n  vertical-align: middle;\\n  vertical-align: -moz-middle-with-baseline;\\n  vertical-align: -webkit-baseline-middle;\\n}\\n\\n.tools fieldset {\\n  border: 0;\\n}\\n\\n.tools fieldset:not(:last-child):after {\\n  content: \\\"•\\\";\\n}\\n\\n.tools fieldset > *,  .tools > * {\\n  margin-right: calc(var(--space)/2)\\n}\\n```\\n\\n</details>\\n\\n**アップデート後にすべてが問題なく動作することを確認してみましょう。:**\\n\\n![Dapp Interface changing step 12](../images/build-dapp-interface/dapp-12.gif \\\"Dapp Interface changing step 12\\\")\\n\\ndappの中にはdatalogセクションがあるので、そのためのコンポーネントを作ります。\\n\\n<details>\\n\\n<summary>新しいコンポーネントDatalogSection.vueのコードは以下のとおりです。</summary>\\n\\n```HTML\\n<template>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <h4 class=\\\"log-title\\\">Datalog</h4>\\n\\n        <div class=\\\"log-content\\\">\\n\\n          <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n\\n          <details v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"box\\\" :open=\\\"k === 0\\\">\\n              <summary>{{ item[0] }}</summary>\\n              <pre>{{ item[1] }}</pre>\\n          </details>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    log: {\\n      type: Array\\n    }\\n  },\\n\\n}\\n\\n</script>\\n\\n<style>\\n\\n.log {\\n  text-align: left;\\n  margin: var(--space) auto;\\n  width: 100%;\\n}\\n\\n.log-content {\\n  border: 1px solid var(--color-gray);\\n  max-height: 500px;\\n  overflow-y: auto;\\n  padding: var(--space);\\n  background-color: var(--color-gray-middark);\\n  outline: 1px solid #fff;\\n  box-shadow: 0 0 60px 20px #fff inset;\\n}\\n\\n.log-title {\\n  color: var(--color-gray-dark);\\n  font-weight: 300;\\n  font-family: var(--font-family-code);\\n\\n  border-bottom: 1px solid var(--color-gray);\\n}\\n\\n.log .box {\\n  margin-bottom: var(--space);\\n}\\n\\ndetails {\\n  transition: 0.2s all ease;\\n}\\n\\ndetails summary {\\n  cursor: pointer;\\n}\\n\\ndetails.box {\\n  padding-top: 0;\\n  padding-bottom: 0;\\n}\\n\\ndetails.box[open] {\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box:focus {\\n  box-shadow: 0 0 5px var(--color-gray)\\n}\\n\\ndetails.box summary {\\n  padding-top: calc(var(--space)*0.5);\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box[open] summary {\\n  border-bottom: 1px solid var(--color-dark);\\n  margin-bottom: calc(var(--space)*0.5);\\n  font-weight: 500;\\n}\\n\\n.log details.box summary {\\n  font-family: var(--font-family-code);\\n}\\n\\n</style>\\n```\\n\\n</details>\\n\\n\\nここで注意しなければならないのは、prop `log`を配列として渡していることです。この多次元配列にはエントリーのログが含まれていて、すべてのエントリーにはタイトル（dappのすべてのログには日付を書いています）とコンテンツがあると仮定しています。**Datalog.vue**と**Launch.vue**のコンポーネントで配列を再フォーマットする必要があります。\\n\\n次に**Datalog.vue**を編集します。ログを取得するFindメソッドを編集します:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n}\\n```\\n\\n次に、**Datalog.vue**でデータをフォーマットして、**DatalogSection.vue**にログの配列を渡す必要があります。そこで、ログの配列をマッピングしてみましょう:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray().map((item) => {\\n    return [new Date(Number(item[0])).toLocaleString(), u8aToString(item[1])]\\n  });\\n}\\n```\\n\\nこのコードはもう必要ありません。:\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return u8aToString(v);\\n  }\\n}\\n```\\n\\n**DatalogタブのDatalogセクションを確認してみましょう:**\\n\\n![Dapp Interface changing step 13](../images/build-dapp-interface/dapp-13.gif \\\"Dapp Interface changing step 13\\\")\\n\\n## 起動\\n\\nこのステップでは、ほとんどの改善点がすでに完了しているので、テンプレートに適用するだけです。ButtonとDatalogコンポーネントをインポートし、過剰なタイトルを削除します:\\n\\n![Dapp Interface changing step 14](../images/build-dapp-interface/dapp-14.gif \\\"Dapp Interface changing step 14\\\")\\n\\n`select`コントロール要素を`checkbox`に置き換えてみましょう。\\n\\nこれの代わりに:\\n```HTML\\n<select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n  <option value=\\\"ON\\\">ON</option>\\n  <option value=\\\"OFF\\\">OFF</option>\\n</select>\\n```\\n\\nこれを書く:\\n```HTML\\n<div class=\\\"toggler inline-block\\\">\\n  <input v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\" type=\\\"checkbox\\\" id=\\\"robot-switch\\\" />\\n  <label for=\\\"robot-switch\\\"><span></span></label>\\n</div>\\n```\\n\\n<details>\\n\\n<summary>Styles in app.css:</summary>\\n\\n```CSS\\n.toggler input { display: none; }\\n.toggler label {\\n  position: relative;\\n  display: block;\\n  width: 60px;\\n  height: 40px;\\n  border-radius: 4px;\\n  font-weight: 500;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  cursor: pointer;\\n  background-color: var(--color-gray);\\n  color: var(--color-light);\\n  text-align: center;\\n}\\n\\n.toggler label:before {\\n  content: 'Off';\\n  width: 100%;\\n  text-align: center;\\n  line-height: 40px;\\n}\\n\\n.toggler label:after {\\n  content: '';\\n  display: block;\\n  width: 6px;\\n  height: 100%;\\n  border-radius: 10px;\\n  background-color: var(--color-gray-dark);\\n\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  z-index: 10;\\n\\n  transition: 0.3s ease-out all;\\n}\\n\\n.toggler input:checked + label {\\n  background-color: var(--color-green);\\n}\\n\\n.toggler input:checked + label:before {\\n  content: 'On';\\n}\\n\\n.toggler input:checked + label:after {\\n  transform: translateX(54px);\\n  background-color: #007038;\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 15](../images/build-dapp-interface/dapp-15.gif \\\"Dapp Interface changing step 15\\\")\\n\\nインターフェイスについて明確にしておきたいことがあります。これらの要素を使って、いくつかのデバイスを開始します。それをイメージしてみましょう。ここではドローンを選んだので、`item.parameter`に応じてクラスを切り替えます。\\n\\n`data`に新しいプロパティを作成します:\\n```JS\\ndata() {\\n  status: false\\n}\\n```\\n\\nボタンがクリックされ、ブロックにtxが送られた後、`parameter`の値を`status`に代入します:\\n```JS\\nmethods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n            this.status = this.parameter; // new line here\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n```\\n\\n**Launch.vue**にドローンのスタイルを書きます。このコンポーネントだけにスタイルを適用するために、`<style>`タグの`スコープ`を忘れないように。\\n\\n<details>\\n\\n<summary>drone用のCSS:</summary>\\n\\n```CSS\\n<style scoped>\\n.tools {\\n  position: relative;\\n  padding-left: 120px;\\n  text-align: left;\\n  display: inline-block;\\n}\\n\\n.launch-drone {\\n  position: absolute;\\n  width: 100px;\\n  left: 0;\\n  filter: grayscale(1);\\n  transition: 1s all ease-in;\\n}\\n\\n.launch-drone.on {\\n  filter: grayscale(0);\\n  animation: DroneLaunch 10s linear infinite;\\n}\\n\\n@keyframes DroneLaunch {\\n  0%, 20%, 40%, 60%, 80%, 100% {\\n    transform: translateY(0);\\n  }\\n  10%, 30%, 50%, 70%, 90% {\\n    transform: translateY(-20%);\\n  }\\n}\\n</style>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 16](../images/build-dapp-interface/dapp-16.gif \\\"Dapp Interface changing step 16\\\")\\n\\nそれでは、**DatalogSection.vue**コンポーネントを追加しましょう。\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\nログの配列を再構築:\\n\\n```JS\\nthis.log.push({\\n  sender,\\n  robot,\\n  parameter\\n});\\n```\\n\\n\\n `[[\\\"entry 1 date\\\", \\\"entry 1 content\\\"], [\\\"entry 2 date\\\", \\\"entry 2 content\\\"]]`のような構造の場合:\\n\\n```JS\\nthis.log.push([new Date().toLocaleString(), {\\n  sender,\\n  robot,\\n  parameter\\n}]);\\n```\\n\\nテンプレートからコードを置き換えます:\\n\\n```HTML\\n<div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    sender: <b>{{ item.sender }}</b>\\n    <br />\\n    robot: <b>{{ item.robot }}</b>\\n    <br />\\n    parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n  </div>\\n</div>\\n```\\n\\nこちらに置き換え:\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n**確認:**\\n![Dapp Interface changing step 17](../images/build-dapp-interface/dapp-17.gif \\\"Dapp Interface changing step 17\\\")\\n\\n時々、いくつかのエラーが出ることがあります。接続がうまくいかなかったり、何か他のことが起こる可能性があります。そこで、Dappの中にエラーメッセージ付きのフォールバックを用意しました。\\n\\n```HTML\\n<div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n```\\n\\nインターフェースでは、エラーはこのようになっています。:\\n\\n![Dapp Interface changing step 18](../images/build-dapp-interface/dapp-18.png \\\"Dapp Interface changing step 18\\\")\\n\\n**app.css**に`.error`のスタイルを追加します:\\n\\n```CSS\\n.error {\\n  font-weight: 400;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  color: var(--color-red);\\n}\\n```\\n\\nそして、`.tools`の部分と他のコンテンツの間のスペースを、**app.css**でも下から修正します。\\n\\n```CSS\\n.tools {\\n  margin-bottom: var(--space);\\n}\\n```\\n\\n以下のようになります:\\n\\n![Dapp Interface changing step 19](../images/build-dapp-interface/dapp-19.png \\\"Dapp Interface changing step 19\\\")\\n\\nこのページでは、ボタンを「primary」にしています。技術的には問題ありませんが、上記のユーザーエクスペリエンスからすると、これは問題ありません。画面上に複数のプライマリ・ボタンを使用しない方が良いでしょう。そこで、**Launch.vue**に`type=\\\"secondary \\\"`のプロパティを持つ`ボタン`を追加して、この問題を解決しましょう。\\n\\n![Dapp Interface changing step 20](../images/build-dapp-interface/dapp-20.png \\\"Dapp Interface changing step 20\\\")\\n\\n良い感じ、次はノードの問題を解決して、デモのステップに進みましょう。\\n\\n## デモ\\n\\nはじめに、タブを入れ替えて、最も関連性の高いものに注意を払うようにしたいのですが、これは練習のために行う最初のステップではありません。**App.vue**でタブを反転させます。\\n\\nデフォルトのデータの入れ替えも忘れずに:\\n\\n```JS\\ndata() {\\n    return {\\n      ...\\n      tab: \\\"demo\\\"\\n    };\\n},\\n```\\n\\n![Dapp Interface changing step 21](../images/build-dapp-interface/dapp-21.png \\\"Dapp Interface changing step 21\\\")\\n\\nいつものように、すでにあるものを変更することから始めましょう。\\n\\n- 前のステップで行ったように、タイトル`<h2>Demo</h2>`を削除します。\\n- データログ、ボタン、アカウントアドレスなど、すでに学んだUI要素を見つけます。しかし、そうはいきません。ここでは、データログだけを変更します。\\n\\n**Demo.vue**にコンポーネントを追加します:\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\nログには生のデータが入っているので、前のステップのようにコンポーネントで描画しやすいデータを渡すために、ログで配列を再構成する必要があります。`async created() `の中の`return [item[0], item[1]];`という行を探して、次のように置き換えます。\\n\\n```JS\\nreturn [new Date(Number(item[0])).toLocaleString(), JSON.parse(u8aToString(item[1]))];\\n```\\n\\n使用していないコードをログから削除します。:\\n\\n```HTML\\n<div v-if=\\\"log\\\" class=\\\"log\\\">\\n  <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    <b>{{ item[0] | dateFormat }}</b>\\n    <pre>{{ item[1] | dataFormat }}</pre>\\n  </div>\\n</div>\\n```\\n\\nこちらも:\\n\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return JSON.parse(u8aToString(v));\\n  }\\n},\\n```\\n\\n**確認:**\\n![Dapp Interface changing step 22](../images/build-dapp-interface/dapp-22.png \\\"Dapp Interface changing step 22\\\")\\n\\n今回のロボット起動のデモ例をカスタマイズするには、自由にアイデアを出すことができます。個人的にはこの街から始めました。\\n\\n![Dapp Interface changing step 23](../images/build-dapp-interface/dapp-23.gif \\\"Dapp Interface changing step 23\\\")\\n\\n混乱しないように全体のコードは示しませんが、概略的には次のようなものになります。\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back\\\"></div>\\n  <div class=\\\"demo-city\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n</div>\\n```\\n\\n`.demo.play`という要素の中に、街を後ろに動かしたり、車を前に動かしたりするスタイルを書いています。\\n\\nこの作業をしているうちに、サイバーパンクの街を実現することを思いつきました。特別な作業なしで、車はタクシーになり、ドライバーは乗客になり、インターフェイスにはAIロボットのホログラムが乗客を迎えてくれるようになりました（これらはすべて、CSSとグラフィックの調整とトリックに過ぎません）\\n\\n**Cyberpunk cityデモのコード:**\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back-1\\\"></div>\\n  <div class=\\\"demo-back-2\\\"></div>\\n  <div class=\\\"demo-city-1\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n\\n  <div class=\\\"demo-data\\\">\\n    <div class=\\\"demo-data-driver inline-block\\\">\\n      <img alt=\\\"Driver's avatar\\\" src=\\\"../assets/images/cabman.png\\\" v-if=\\\"robot.state\\\"/>\\n    </div>\\n    <div class=\\\"demo-data-lines inline-block\\\">\\n      <div class=\\\"demo-data-line\\\">\\n          <div>Robot</div>\\n          <div>[ {{ addressShort(robot.address) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-line\\\" v-if=\\\"robot.state\\\">\\n          <div>Passenger</div>\\n          <div>[ {{ addressShort(robot.driver) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-welcome\\\" v-if=\\\"robot.state\\\">\\n          <span>Hello, passenger. </span>\\n          <span>I've linked to the vehicle. </span>\\n          <span>Your ride begins, congrats! </span>\\n      </div>\\n    </div>\\n\\n  </div>\\n\\n  <Button :label=\\\"robot.state ? 'stop' : 'run'\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" @onClick=\\\"run\\\" />\\n</div>\\n```\\n\\n</details>\\n\\n短縮されるべきハッシュアドレスが複数あるので、メソッドを追加しました。\\n```JS\\nmethods: {\\n  addressShort(address) {\\n    return address.slice(0, 6) + \\\"...\\\" + address.slice(-4);\\n  }\\n}\\n```\\n\\nButtonコンポーネントの登録も忘れずに\\n\\n```JS\\ncomponents: {\\n  Button: () => import(\\\"./Button\\\")\\n}\\n```\\n\\n<details>\\n\\n<summary>Styles</summary>\\n\\n```CSS\\n<style scoped>\\n.demo {\\n    --h: 120px;\\n    --color-yellow: #F2F209;\\n\\n    background-color: #AFCCD3;\\n\\n    background: linear-gradient(#010123, #4baac7);\\n\\n    position: relative;\\n    height: 500px;\\n    overflow: hidden;\\n\\n    border-width: 2px 2px 2px 15px;\\n    border-style: solid;\\n    border-color: var(--color-yellow);\\n    \\n}\\n\\n.demo:before {\\n    content: '[ Delamain cabs rental DEMO ]';\\n    background-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    padding: .5rem 1rem;\\n\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 300;\\n\\n    border-width: 0 6px 2px 0;\\n    border-style: solid;\\n    border-color: #7B186E;\\n}\\n\\ndiv[class^=demo-back-], div[class^=demo-city-] {\\n    position: absolute;\\n    left: 0;\\n    width: 100%;\\n    z-index: 2;\\n}\\n\\ndiv[class^=demo-back-]{\\n    border-top: 1px solid #364444;\\n}\\n\\ndiv[class^=demo-city-] {\\n    background-repeat: repeat-x;\\n    background-size: cover;\\n    background-position: 100% 0;\\n\\n    height: 300px;\\n    bottom: var(--h);\\n\\n    animation: 50s MoveCity infinite linear 1.5s;\\n}\\n\\ndiv.demo-back-1 {\\n    background-color: #060236;\\n    background: linear-gradient(#7B186E, #060236);\\n    height: var(--h);\\n    bottom: 0;\\n}\\n\\ndiv.demo-back-2 {\\n    background-color: #c515ae;\\n    border-width: 2px 0;\\n    border-style: solid;\\n    border-color: #69045c;\\n\\n    height: 20px;\\n    bottom: var(--h);\\n    z-index: 10;\\n}\\n\\ndiv.demo-city-1 {\\n    background-image: url(../assets/images/city-1.png);\\n}\\n\\n.demo-car {\\n    background-image: url(../assets/images/car.png);\\n    background-size: contain;\\n    background-repeat: no-repeat;\\n    background-position: 100% 0;\\n\\n    width: calc(508px * 0.5);\\n    height: calc(257px * 0.5);\\n    position: absolute;\\n    bottom: calc(var(--h) + 4px);\\n    z-index: 10;\\n\\n    transform: translateX(-100px);\\n    animation: MoveCar 50s infinite 1.5s linear;\\n}\\n\\n.demo.play div[class^=demo-city-], .demo.play .demo-car { animation-play-state: running; }\\n.demo.stop div[class^=demo-city-], .demo.stop .demo-car { animation-play-state: paused; }\\n\\n.demo.play .demo-car {\\n    background-image: url(../assets/images/car-ride.png);\\n}\\n\\n\\n.demo button {\\n    background-color: var(--color-yellow);\\n    border-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    bottom: 30px;\\n    right: 30px;\\n    z-index: 1000;\\n}\\n\\n.demo-data {\\n    position: absolute;\\n    bottom: 30px;\\n    left: 30px;\\n    z-index: 1000;\\n\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    padding: .5rem;\\n    font-family: var(--font-family-code);\\n\\n    transition: 0.2s all ease;\\n}\\n\\n.demo-data-lines {\\n    max-width: 400px;\\n}\\n\\n.demo-data-line {\\n    display: grid;\\n    grid-template-columns: 100px auto;\\n    gap: .5rem;\\n    text-align: left;\\n}\\n\\n.demo-data-line div:first-child {\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 700;\\n}\\n\\n.demo-data-driver {\\n    margin-right: 1rem;\\n}\\n\\n.demo-data-driver img {\\n    display: block;\\n    max-width: 100px;\\n\\n    visibility: hidden;\\n    opacity: 0;\\n    animation: FadeInBlink .3s cubic-bezier(0.075, 0.82, 0.165, 1) 0.6s forwards;\\n}\\n\\n.demo-data-welcome {\\n    text-align: left;\\n    padding-top: .5rem;\\n}\\n\\n.demo-data-welcome span {\\n    visibility: hidden;\\n    opacity: 0;\\n\\n    animation-name: FadeIn;\\n    animation-timing-function: cubic-bezier(0.075, 0.82, 0.165, 1);\\n    animation-duration: 0.6s;\\n    animation-fill-mode: forwards;\\n}\\n\\n.demo-data-welcome span:nth-child(1) { animation-delay: 1.5s; }\\n.demo-data-welcome span:nth-child(2) { animation-delay: 2.5s; }\\n.demo-data-welcome span:nth-child(3) { animation-delay: 3.2s; }\\n\\n\\n@keyframes MoveCity\\n{\\n  100% {\\n    background-position: -1000px 0;\\n  }\\n}\\n\\n@keyframes MoveCar\\n{\\n    0% {\\n        transform: translateX(-100px);\\n    }\\n    100% {\\n        transform: translateX(960px);\\n    }\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n**結果:**\\n\\n![Dapp Interface changing step 25](../images/build-dapp-interface/dapp-25.gif \\\"Dapp Interface changing step 25\\\")\\n\\n## Conclusion\\n\\nおめでとうございます！これで、Dappのデザインを変更し、アプリケーションのインターフェイスの構築を開始する方法がわかりました。\\n\\n### Checkout links\\n\\n- [このチュートリアルの全コード](https://github.com/positivecrash/wscool21-ui-dapp)\\n- [Discordで話し合う](https://discord.gg/5UWNGNaAUf)\\n- [ロボノミクスウィンタースクール2021のスケジュールと概要を見る](https://robonomics.network/blog/winter-robonomics-school/)\\n- [Github of contributor](https://github.com/positivecrash)\\n\\n### 実践\\n\\nもし時間が余っていたり、スキルを練習したい場合は、このデモで行える改善アイデアがあります:\\n\\n- UIを狭い画面に適応させ、モバイルフレンドリーなdappにする\\n- dappの**_variables.scss**ファイルとテンプレートファイルを編集して、「ライト/ダーク」モードを追加する\\n- アドレスに「クリップボードにコピー」ボタンを追加\\n- 繊細なポップアップを作成して、ユーザーに変更を通知する（例：「Faucet」ボタンをクリックした後にユニットを受け取ったというメッセージをポップアップで表示したり、「起動」セクションで発生したエラーをポップアップで移動させることができます）。\\n\\n\\n質問や結果の共有は[Discord](https://discord.gg/5UWNGNaAUf)で行ってください。メッセージに `@positivecrash`をつけてください。\\n\\n\\n\\n\\n\\n\\n\"}},{\"node\":{\"id\":\"b30810c63d9d7e89c50523daf6d2024e\",\"title\":\"Lesson 6.1, エンドユーザー向けのIoT Dappsの構築\",\"path\":\"/docs/ja/wschool2021-build-dapp-for-end-users/\",\"content\":\"\\n## 準備\\n\\n### Robonomicsノードの立ち上げ\\n\\ndAppの開発とテストには、ローカルのRobonomicsノードを使用します。そのためには、コンパイル済みのバイナリファイル https://github.com/airalab/robonomics/releases をダウンロードする必要があります。私はUbuntuを使用するので、適切なバージョンをダウンロードします。\\n\\nアーカイブを解凍\\n```sh\\nwget https://github.com/airalab/robonomics/releases/download/v0.24.0/robonomics-ubuntu-0.24.0-x86_64.tar.xz\\ntar -xvf robonomics-ubuntu-0.24.0-x86_64.tar.xz\\nchmod +x robonomics\\n```\\n\\nこれでノードを開発モードで起動できるようになりました。これには --dev フラグを使います。\\n```sh\\n./robonomics --dev --tmp\\n```\\n\\n> トラブルシューティング\\n```sh\\n./robonomics purge-chain --dev\\n```\\n\\n### ブラウザ拡張\\n\\nブラウザに鍵を保存するために、`polkadot{.js}`という拡張機能があります。dAppでは、これを使ってトランザクションに署名します。\\n\\nこの拡張機能は現在、`Google chrome` と `Firefox` で利用可能です。https://polkadot.js.org/extension/ \\n\\n拡張機能をインストールしたら、新しいアカウントを作成します。 \\n![screen1](../images/build-iot-dapps/screen1.png)\\n\\n> 最初のステップが完了しました。\\n\\n## DApp 開発\\n\\n### Step 1\\n\\n> ここでは、vue.jsのフレームワークを使ってdAppを書きますが、好きなもの・できるものを使っても構いません。\\n\\nvue.jsで起動アプリを作ってdAppの開発を始めましょう ここでは、2つの方法で行うことができます。\\n\\n方法 1:\\n\\n`Vue cli`コンソールユーティリティを使用する。これを行うには、`Vue cli`をインストールする必要があります。https://cli.vuejs.org/guide/installation.html \\nAlso we will need `yarn`. Install it from [here](https://yarnpkg.com)\\n\\nインストールが完了したら、ターミナルで次のコマンドを実行します。\\n\\n\\n```sh\\nvue create mydapp\\n```\\n\\nセットアップウィザードのいくつかの質問に答えます。ここでは、Vue 2バージョンを使用するので、デフォルトのバージョン`Default ([Vue 2] babel, eslint)`のままにしておきます。\\n\\n\\n方法 2:\\n\\n例のために準備されたgitリポジトリをクローンして、step-1にチェックアウトする。\\n\\n```sh\\ngit clone https://github.com/airalab/example-robonomics-dapp.git mydapp\\ncd mydapp\\ngit checkout step-1\\n```\\n\\nその結果、起動アプリケーションがインストールされたディレクトリが作成され、起動してブラウザで開くことができるようになります。\\n\\n\\n```sh\\nyarn\\nyarn serve\\n```\\n\\n### Step 2. polkadot.jsを使い始める\\n\\n#### 依存関係のインストール\\n\\nロボノミクスチェーンにdAppを接続するために、`@polkadot/api`ライブラリがあります。また、キーを持つ拡張機能とdAppを連動させるためには、`@polkadot/extension-dapp`ライブラリがあります。これらをアプリケーションにインストールする必要があります。このライブラリの使い方の詳細は、ドキュメント https://polkadot.js.org/docs/ に記載されています。\\n\\n方法 1:\\n\\n```sh\\nyarn add @polkadot/api @polkadot/extension-dapp\\n```\\n\\nまた、mjs拡張をサポートするために、vue.config.jsファイルを追加する必要があります。\\n\\n`vue.config.js`\\n```js\\nmodule.exports = {\\n  publicPath: \\\"\\\",\\n  configureWebpack: {\\n    resolve: {\\n      extensions: [\\\"*\\\", \\\".mjs\\\", \\\".js\\\", \\\".vue\\\", \\\".json\\\", \\\".gql\\\", \\\".graphql\\\"]\\n    },\\n    module: {\\n      rules: [\\n        {\\n          test: /\\\\.mjs$/,\\n          include: /node_modules/,\\n          type: \\\"javascript/auto\\\"\\n        }\\n      ]\\n    }\\n  }\\n};\\n```\\n\\n#### Robonomicsへの接続\\n\\nまず、Robonomicsノードに接続するためのパラメータを記述した設定ファイルを作成しましょう。デモのリポジトリには、このファイル`config.template.json`の例があります。\\n\\n`src/config.json`\\n```json\\n{\\n  \\\"endpoint\\\": \\\"ws://localhost:9944\\\",\\n  \\\"types\\\": {\\n    \\\"Record\\\": \\\"Vec<u8>\\\",\\n    \\\"Parameter\\\": \\\"Bool\\\",\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\"\\n  }\\n}\\n```\\n\\nこのファイルでは、接続先のノードとカスタムタイプを指定しています。\\n\\n\\n次に、実行中のノードに接続するためのスクリプトを書きます。\\n\\n`src/utils/api.js`\\n```js\\nimport { ApiPromise, WsProvider } from \\\"@polkadot/api\\\";\\nimport config from \\\"../config.json\\\";\\n\\nlet api;\\nexport async function initApi() {\\n  const provider = new WsProvider(config.endpoint);\\n  api = await ApiPromise.create({\\n    provider,\\n    types: config.types\\n  });\\n  return api;\\n}\\n\\nexport function getApi() {\\n  return api;\\n}\\n```\\n\\n拡張機能のキーを使ってトランザクションに署名できるように、拡張機能への接続用の関数と、アカウントを初期化するための関数の2つを追加しましょう。\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport {\\n  web3Accounts,\\n  web3Enable,\\n  web3FromAddress\\n} from \\\"@polkadot/extension-dapp\\\";\\n\\nasync function getExtension() {\\n  const extensions = await web3Enable(\\\"demo\\\");\\n  if (extensions.length === 0) throw new Error(\\\"no extension\\\");\\n  return extensions[0];\\n}\\n\\nexport async function initAccount(index = 0) {\\n  const timeout = new Promise(resolve => {\\n    setTimeout(resolve, 300);\\n  });\\n  await timeout;\\n  await getExtension();\\n  const accounts = await web3Accounts();\\n  if (accounts.length > 0) {\\n    const injector = await web3FromAddress(accounts[index].address);\\n    api.setSigner(injector.signer);\\n    return accounts[index].address;\\n  }\\n  throw new Error(\\\"no accounts\\\");\\n}\\n\\n...OTHER_CODE...\\n```\\n\\n口座の残高はゼロですが、ちょっとした資金が必要になります。そこで、別のfaucet関数を作る必要があります。Robonomicsを --dev フラグで起動したところ、残高の多いアリスアカウントがあるので、そこから資金を要求します。\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport { Keyring } from \\\"@polkadot/keyring\\\";\\n\\nexport function getBalance(account, cb) {\\n  api.query.system.account(account, ({ data: { free: currentFree } }) => {\\n    cb(currentFree);\\n  });\\n}\\n\\nexport const keyring = new Keyring({ type: \\\"sr25519\\\" });\\n\\nexport async function faucet(address) {\\n  keyring.setSS58Format(api.registry.chainSS58);\\n  const account = keyring.addFromUri(\\\"//Alice\\\");\\n  const tx = api.tx.balances.transfer(address, 1000000000000000);\\n  await tx.signAndSend(account);\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nフルバージョンのスクリプト  https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/api.js\\n\\nアプリの実行\\n\\n```sh\\nyarn serve\\n```\\n\\n方法 2:\\n\\nリポジトリをクローンしてアプリケーションを開始した場合、このステップを完了するためには、ステップ2に切り替えて残りの依存関係をインストールするだけで十分です。\\n\\n```sh\\ngit checkout step-2\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n### Step 3. vueをコンポーネントに接続\\n\\n#### 接続\\n\\n接続用のスクリプトはすでに書いてあります。あとはそれをインターフェイス上で使います。書かれた`initApi`関数を、ルートコンポーネントの`App.vue`で呼び出すだけで十分です。そして、ユーザーが接続を待っている間に、小さなローダーを表示します（今のところ、省略記号の形で）。\\n\\n方法 1:\\n\\nコンポーネントのテンプレートとベーススタイル。\\n\\n`src/App.vue`\\n```js\\n<template>\\n  <div id=\\\"app\\\">\\n    <h1>Robonomics dApp</h1>\\n    <div v-if=\\\"load\\\">...</div>\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api\\\">\\n        connected\\n      </template>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style>\\n#app {\\n  font-family: Avenir, Helvetica, Arial, sans-serif;\\n  -webkit-font-smoothing: antialiased;\\n  -moz-osx-font-smoothing: grayscale;\\n  text-align: center;\\n  color: #2c3e50;\\n  margin-top: 60px;\\n}\\nbutton {\\n  font-size: 14px;\\n  padding: 5px 12px;\\n}\\nbutton:hover {\\n  cursor: pointer;\\n}\\ninput {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nselect {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nbutton:focus,\\ninput:focus {\\n  outline: none;\\n}\\n.error {\\n  color: rgb(151, 31, 31);\\n  font-weight: bold;\\n  text-align: center;\\n  margin: 10px 0;\\n}\\n</style>\\n```\\n\\n`initApi`関数が呼び出されるコンポーネントコードがあります。\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi } from \\\"./utils/api\\\";\\n\\nexport default {\\n  name: \\\"App\\\",\\n  data() {\\n    return {\\n      load: false,\\n      api: null,\\n      error: null\\n    };\\n  },\\n  created() {\\n    this.init();\\n  },\\n  methods: {\\n    async init() {\\n      try {\\n        this.load = true;\\n        this.api = await initApi();\\n        this.load = false;\\n      } catch (error) {\\n        this.error = error.message;\\n        this.load = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\n#### アカウントの残高表示\\n\\nこれで、アカウントを使用し、残高を追加してインターフェイスに表示できるようになりました。\\n\\n適切なマークアップをテンプレートに追加しましょう。\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n  ...OTHER_CODE...\\n\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api && account\\\">\\n        <p>\\n          Account: <b>{{ account }}</b> {{ balance }} |\\n          <button @click=\\\"faucet\\\">\\n            faucet\\n          </button>\\n        </p>\\n      </template>\\n    </template>\\n\\n  ...OTHER_CODE...\\n\\n</template>\\n```\\n\\nアカウントアドレスと残高の新しいフィールドを追加しよう\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\ndata() {\\n  return {\\n\\n    ...OTHER_CODE...\\n\\n    account: null,\\n    balance: 0,\\n\\n    ...OTHER_CODE...\\n\\n  };\\n}\\n\\n...OTHER_CODE...\\n```\\n\\n`init`関数にアカウントの初期化を追加し、その残高を取得する必要があります。\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi, initAccount, getBalance, faucet } from \\\"./utils/api\\\";\\nimport { formatBalance } from \\\"@polkadot/util\\\";\\n\\n...OTHER_CODE...\\n\\nasync init() {\\n\\n  ...OTHER_CODE...\\n\\n  this.api = await initApi();\\n  this.account = await initAccount();\\n  getBalance(this.account, balance => {\\n    this.balance = formatBalance(balance);\\n  });\\n\\n  ...OTHER_CODE...\\n\\n}\\n\\n...OTHER_CODE...\\n</script>\\n```\\n\\nあとは、ボタンをクリックすると、残高が補充される機能を追加します。\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\n  methods: {\\n    faucet() {\\n      faucet(this.account);\\n    },\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/step-3/src/App.vue\\n\\nアプリの実行\\n\\n```sh\\nyarn serve\\n```\\n\\n方法 2:\\n\\nリポジトリをクローンした状態でアプリケーションを起動した場合、このステップを完了するには、ステップ3に切り替えるだけです。\\n\\n```sh\\ngit checkout step-3\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen2](../images/build-iot-dapps/screen2.png)\\n\\n### Step 4. データログ\\n\\nチェーン内の任意のデータを保存したり読み出したりするには、`datalog`モジュールを使用します。\\n\\nこのモジュールの使い方の例として、`Datalog.vue`コンポーネントを作ってみましょう。\\n\\n方法 1:\\n\\n\\nマークアップでは、ブロックでデータを読むための`read`ボタンを用意し、そこに日付の形式でリストを表示し、データそのものを表示するようにします。そして、文字列の形で任意のデータを入力できるテキスト入力のあるフォームと、`write`ボタンを用意します。\\n\\n`src/components/Datalog.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Datalog</h2>\\n    <button @click=\\\"read\\\">read</button> |\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" />\\n    <button @click=\\\"write\\\" :disabled=\\\"isWrite\\\">write</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n      <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        date: <b>{{ item[0] | dateFormat }}</b>\\n        <br />\\n        data: <b>{{ item[1] | dataFormat }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nコンポーネントコードです。ここでは、トランザクションを送信する際の主なポイントは、データを転送し、アカウントで署名する関数を、apiを介して呼び出すことです。\\n`this.api.tx.datalog.record(stringToHex(this.data)).signAsync(this.account);`\\n\\n`src/components/Datalog.vue`\\n```js\\n<script>\\nimport { stringToHex, u8aToString } from \\\"@polkadot/util\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      data: \\\"data string\\\",\\n      log: null,\\n      isWrite: false,\\n      error: \\\"\\\"\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return u8aToString(v);\\n    }\\n  },\\n  methods: {\\n    async read() {\\n      this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n    },\\n    async write() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.datalog\\n          .record(stringToHex(this.data))\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.read();\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Datalog.vue\\n\\nコンポーネントを切り替えるには、`App.vue`にコンポーネントの出力を追加します。\\n\\n`src/App.vue`\\n```js\\n...OTHER_CODE...\\n\\n<template v-else-if=\\\"api && account\\\">\\n  <p>\\n    Account: <b>{{ account }}</b> {{ balance }} |\\n    <button @click=\\\"faucet\\\">faucet</button>\\n  </p>\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\n\\n...OTHER_CODE...\\n\\nexport default {\\n  name: \\\"App\\\",\\n  components: {\\n    Datalog\\n  },\\n  data() {\\n    return {\\n      tab: \\\"datalog\\\"\\n\\n...OTHER_CODE...\\n</script>\\n\\n<style>\\n...OTHER_CODE...\\n\\n.tabs button {\\n  font-size: 14px;\\n  padding: 10px 20px;\\n  font-weight: bold;\\n  background: #ececec;\\n  border: 1px solid #aaa;\\n}\\n.tabs button:hover {\\n  background: #bfbfbf;\\n}\\n.tabs button:last-child {\\n  border-left: none;\\n}\\n.tabs button.active {\\n  background: #ced5e2;\\n}\\n</style>\\n```\\n\\nアプリの実行\\n\\n```sh\\nyarn serve\\n```\\n\\n方法 2:\\n\\nリポジトリをクローンした状態でアプリケーションを開始した場合、このステップを完了するには、ステップ4に切り替えるだけです。\\n\\n```sh\\ngit checkout step-4\\nyarn serve\\n```\\n\\nその結果、ブラウザには次のような画像が表示されます。\\n\\n![screen3](../images/build-iot-dapps/screen3.png)\\n\\n### Step 5. 起動\\n\\nこの関数は、ロボットの起動と停止に使用されます。このモジュールの使い方を説明するために、`Launch.vue`コンポーネントを書いてみましょう。\\n\\n\\n方法 1:\\n\\nコンポーネントのテンプレートには、ロボットのアドレス、ON/OFFクリッカー、送信用ボタンを指定するフォームを用意します。\\n\\n`src/components/Launch.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Launch</h2>\\n    <input v-model=\\\"robot\\\" :disabled=\\\"isWrite\\\" placeholder=\\\"Robot address\\\" />\\n    <select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n      <option value=\\\"ON\\\">ON</option>\\n      <option value=\\\"OFF\\\">OFF</option>\\n    </select>\\n    <button @click=\\\"launch\\\" :disabled=\\\"isWrite\\\">launch</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        sender: <b>{{ item.sender }}</b>\\n        <br />\\n        robot: <b>{{ item.robot }}</b>\\n        <br />\\n        parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nこのコードは`Datalog.vue`コンポーネントのように見えます。違いは読み方だけです。ロボットはイベントを通じてコマンドを受け取ります。\\n\\n`src/components/Launch.vue`\\n```js\\n<script>\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      robot: this.account,\\n      parameter: \\\"ON\\\",\\n      log: [],\\n      isWrite: false,\\n      error: \\\"\\\",\\n      unsubscribe: null\\n    };\\n  },\\n  async created() {\\n    this.unsubscribe = await this.api.query.system.events(events => {\\n      events.forEach(record => {\\n        const { event } = record;\\n        if (event.section === \\\"launch\\\" && event.method === \\\"NewLaunch\\\") {\\n          const sender = event.data[0].toString();\\n          const robot = event.data[1].toString();\\n          const parameter = event.data[2].toHuman();\\n          this.log.push({\\n            sender,\\n            robot,\\n            parameter\\n          });\\n        }\\n      });\\n    });\\n  },\\n  destroyed() {\\n    if (this.unsubscribe) {\\n      this.unsubscribe();\\n    }\\n  },\\n  methods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Launch.vue\\n\\n\\n表示のために、`App.vue`に新しいコンポーネントを追加します。\\n\\n`src/App.vue`\\n```js\\n<template>\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nアプリの実行\\n\\n```sh\\nyarn serve\\n```\\n\\n方法 2:\\n\\nリポジトリをクローンした状態でアプリケーションを起動した場合、このステップを完了するには、ステップ5に切り替えるだけです。\\n\\n```sh\\ngit checkout step-5\\nyarn serve\\n```\\n\\nその結果、ブラウザには次のような画像が表示されます。\\n\\n![screen4](../images/build-iot-dapps/screen4.png)\\n\\n### Step 6. デモ\\n\\nこのデモでは、dAppを介して起動・停止できる車を用意します。車は走行中にログを収集し、停車後にはチェーンに保存します。ここでは、別々に試した2つのモジュールを組み合わせて使用します。\\n\\nロボット(車)の動作をエミュレートするために、Robotクラスを書きます。このロボットのアカウントとして`Alice`キーを使います。`Robot`クラスは、`NewLaunch`イベントを監視して、自分の電源を入れたり切ったりします。電源を入れた後は、ログにデータを集め始めます。そして、シャットダウンの後、このログを`datalog`モジュールに保存します。\\n\\n方法 1:\\n\\n`src/utils/robot.js`というファイルを作成します。ファイルのフルコード https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/robot.js\\n\\nビジュアル化のために、`Demo.vue`コンポーネントを作成し、スタートボタン、車のアニメーション、ログ出力を行います。\\n\\n`src/components/Demo.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Demo</h2>\\n    <template v-if=\\\"robot\\\">\\n      <h3>Robot: {{ robot.address }}</h3>\\n      <p v-if=\\\"robot.state\\\">Driver: {{ robot.driver }}</p>\\n      <button @click=\\\"run\\\" :disabled=\\\"isWrite\\\">\\n        <template v-if=\\\"!robot.state\\\">run</template>\\n        <template v-else>stop</template>\\n      </button>\\n      <div class=\\\"road\\\">\\n        <div\\n          class=\\\"robot\\\"\\n          :class=\\\"[robot.state ? 'robot-play' : 'robot-stop']\\\"\\n        ></div>\\n      </div>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n        <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n          <b>{{ item[0] | dateFormat }}</b>\\n          <pre>{{ item[1] | dataFormat }}</pre>\\n        </div>\\n      </div>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n  height: 500px;\\n  overflow-y: auto;\\n}\\n.log .row {\\n  margin: 10px;\\n  border-bottom: 1px solid #eee;\\n}\\n.road {\\n  width: 1000px;\\n  margin: 20px auto;\\n  background-color: #eee;\\n  padding: 20px 0;\\n  border: 5px solid #a5a5a5;\\n  border-left: 0;\\n  border-right: 0;\\n  position: relative;\\n}\\n.road::before {\\n  content: \\\" \\\";\\n  width: 1000px;\\n  border-top: 5px dashed #a5a5a5;\\n  position: absolute;\\n  top: 50%;\\n  left: 0;\\n}\\n@keyframes move {\\n  from {\\n    transform: translateX(0);\\n  }\\n  to {\\n    transform: translateX(100%);\\n  }\\n}\\n.robot {\\n  height: 100px;\\n  width: 100px;\\n  color: #fff;\\n  font-weight: bold;\\n  font-style: 14px;\\n  animation: move 30s linear infinite;\\n  border-radius: 0 10px 10px 0;\\n  background: url(\\\"../images/build-iot-dapps/car.png\\\") no-repeat 0 0;\\n  background-size: cover;\\n}\\n.robot-play {\\n  animation-play-state: running;\\n}\\n.robot-stop {\\n  animation-play-state: paused;\\n}\\n</style>\\n```\\n\\nコンポーネントのコードです。ここでは、`Robot`クラスのインスタンスと、launch/stop関数を作成する必要があります。\\n\\n`src/components/Demo.vue`\\n```js\\n...OTHER_CODE...\\n\\n<script>\\nimport { u8aToString } from \\\"@polkadot/util\\\";\\nimport Robot from \\\"../utils/robot\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      isWrite: false,\\n      error: \\\"\\\",\\n      robot: null,\\n      log: []\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return JSON.parse(u8aToString(v));\\n    }\\n  },\\n  async created() {\\n    this.robot = new Robot(\\\"//Alice\\\", this.api);\\n    await this.robot.subscribeLog(r => {\\n      this.log = r.reverse().map(item => {\\n        return [item[0], item[1]];\\n      });\\n    });\\n  },\\n  destroyed() {\\n    this.robot.destroy();\\n  },\\n  methods: {\\n    async run() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot.account.address, !this.robot.state)\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Demo.vue\\n\\n車の写真をもう一枚、`src/images/build-iot-dapps/car.png`and `src/assets/car.png` に追加してみましょう。 例 https://github.com/airalab/example-robonomics-dapp/blob/master/src/assets/car.png\\n\\n表示のために、`App.vue`に新しいコンポーネントを追加します。\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n      <button @click=\\\"tab = 'demo'\\\" :class=\\\"{ active: tab === 'demo' }\\\">\\n        demo\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\nimport Demo from \\\"./components/Demo\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch,\\n  Demo\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nアプリの実行\\n\\n```sh\\nyarn serve\\n```\\n\\n方法 2:\\n\\nリポジトリをクローンした状態でアプリケーションを起動した場合、このステップを完了するには、ステップ6に切り替えるだけです。\\n\\n```sh\\ngit checkout step-6\\nyarn serve\\n```\\n\\nその結果、ブラウザには次のような画像が表示されます。\\n\\n![screen5](../images/build-iot-dapps/screen5.png)\\n\\n以上で、今回のレッスンは終了です。\\n\\nありがとうございました！\\n\"}},{\"node\":{\"id\":\"e3ea0df890c882410228612560435594\",\"title\":\"Connect Vacuum Cleaner\",\"path\":\"/docs/ja/vacuum-connect/\",\"content\":\"\\n## Connect to Home Assistant\\n\\nYou need your vacuum to be connected to Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your vacuum (it must be in connecting mode via a long press of the power button) and follow instructions in the app. For more details look at the user manual of your vacuum.\\n\\nOpen Home Assistant web page with this address:\\n```\\nhttp://<raspberry_address>:8123\\n```\\n\\nGo to `Integrations` tab, press `Add integration` and choose `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Vacuum (Robot vacuum in this example):\\n\\n![vacuum](../images/home-assistant/vacuum_int.png)\\n\\nAfter that you can connect your device to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"80ccb4f341a17f6a47d4d5e9d68db89b\",\"title\":\"Troubleshooting\",\"path\":\"/docs/ja/troubleshooting/\",\"content\":\"\\n## Can't create HRMP channel\\n\\nIt's not possible to create HRMP channel.\\n#### Solution\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n\\\"Address\\\": \\\"MultiAddress\\\",\\n\\\"LookupSource\\\": \\\"MultiAddress\\\",\\n\\\"AccountInfo\\\": \\\"AccountInfoWithRefCount\\\"\\n}\\n```\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n## Couldn't send XCM call with datalogXcm\\n If you try to send message between parachains and get error like this:\\n\\n![error_4lesson][im1]\\n\\n#### Solution\\n\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\n![XCM][im2]\\n\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n\\n\\n [im1]: <../images/troubleshooting/lesson4_error.jpg>\\n [im2]: <../images/troubleshooting/XCM.jpg>\\n\"}},{\"node\":{\"id\":\"6543f54abeff24a7c604d04382ccd008\",\"title\":\"How to participate in the Wiki translation\",\"path\":\"/docs/ja/translate-wiki/\",\"content\":\"\\nEveryone can contribute to Robonomics. If you want to contribute to the translation of the documentation, you are on the right track: this article will tell you how to do it.\\n\\n## Editing an article\\n\\nIf support for your language has already been added to the site, follow these steps:\\n\\n1. Click the \\\"Edit this page\\\" button on the article you would like to translate. Each article is duplicated in a supported language, even if it has not yet been translated from English.\\n2. Edit by sticking to the existing markup. You can read the article [How to edit WIKI](/docs/en/edit-wiki)\\n3. Submit [PR](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) with the changes you have made.\\n\\n## Adding a new language\\n\\nIf the language you would like to translate the article into has not yet been added, request it from the Robonomics root team by, [creating Issue](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) on GitHub.\\n\\nWhen we add support for the requested language to the site, we will close the Issue, commenting on it if necessary. You will be notified accordingly. This means you can translate pages (they will already be duplicated in English in a folder like `/docs/locale`)\\n\\n## Notes\\n* If you see a way to improve an existing translation of an article, you can also use the PR or Issue on GitHub to request changes\\n* If you make a significant contribution to the translation, you can participate in the rewards program\\n\"}},{\"node\":{\"id\":\"5da35c4a85d0e48401c93a1bdf2674fd\",\"title\":\"How the technical committee is fast-tracking the democracy proposals\",\"path\":\"/docs/ja/technical-committee-fast-track/\",\"content\":\"\\nNote: The screenshots contained in this article were taken using v1.9.0 of Robonomics node implementation, launched in **dev** mode.\\n\\nThe Robonomics Technical Committee can use the **fast-track** function to speed up the proposals enacting in the Democracy module.\\n\\nIf you want to learn more about how Polkadot ecosystem Governance works, then we strongly recommend reading [this article](https://polkadot.network/blog/polkadot-governance/) on the Polkadot blog.\\n\\nThere are six members who make up the Technical Committee for the Robonomics parachain. For our example, let's create the same setup in our dev mode environment:\\n![Techcomm membership](../images/technical-committee-fast-track/techcomm_membership.png)\\n\\nBriefly, the process of fast-tracking a proposal involves a few steps:\\n1. Creating the proposal preimage\\n2. Creating the proposal using the created preimage hash\\n3. Technical committee votes on the created proposal\\n4. Initiating proposal fast-tracking \\n5. Technical committee votes regarding fast-tracking the proposal\\n6. Voting on enacted proposal in the Democracy pallet\\n\\nFor example, let's set the free balance for the account *4EnEc9ZD1jpA1H3HpVzr1v6SGGYGrue2k9Ny5KzFHhti5xQv* to 10 XRT\\n\\n## 1. Creating the proposal preimage\\nOpen the **Governance -> Democracy** page and click the **Submit preimage** button, and then input the required parameters:\\n![Creating preimage](../images/technical-committee-fast-track/creating_preimage.png)\\n\\nAfter all fields are filled, then we need to save generated preimage hash (*0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b* in this example). As we will need it in the next step.\\n\\nAfter saving the preimage hash we can click the **Submit preimage** button in this window and sign the transaction:\\n![Sign submitting preimage](../images/technical-committee-fast-track/sign_submitting_preimage.png)\\n\\n\\n## 2. Creating proposal using created preimage hash\\nOpen the **Governance -> Tech. comm.** page and go to the **Proposals** tab:\\n![Techcomm proposals interface](../images/technical-committee-fast-track/techcomm_proposals_interface.png)\\n\\nThen click **\\\"Submit proposal\\\"** button and create *democracy.externalProposeMajority(0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b)* using your technical committee account and the preimage hash from earlier:\\n![Create techcomm proposal 1](../images/technical-committee-fast-track/create_techcomm_proposal_1.png)\\n\\nAfter signing transaction, the proposal will appear on this page:\\n![Created techcomm proposal 1](../images/technical-committee-fast-track/created_techcomm_proposal_1.png)\\n\\n## 3. Technical committee voting for created proposal\\nOn this step the majority of the technical committee members need to vote **Aye** in this poll. For example:\\n![First vote result](../images/technical-committee-fast-track/first_vote_result.png)\\n\\nThen we can decide to close this vote/poll using the **Close** button. After this action the proposal will appear on the **Democracy** page on the **external** table. You may wonder how can you see the **Fast track** button. This button appears and is active ONLY if we used the **democracy.externalProposeMajority** function:\\n![Created democracy proposal](../images/technical-committee-fast-track/created_democracy_proposal.png)\\n\\n\\n## 4. Initiating proposal fast-tracking\\nGo to the **Governance -> Democracy** page and click on the **Fast track** button. In this newly opened window set the required parameters and click **Fast track**.\\n![Fast track interface](../images/technical-committee-fast-track/fast_track_interface.png)\\n\\nAfter this, the fast-track proposal should now appear on the Technical Committee proposals page:\\n![Techcomm fast-track proposal](../images/technical-committee-fast-track/techcomm_fasttrack_proposal.png)\\n\\n\\n## 5. Technical committee voting for fast-track the proposal\\nNow the technical committee need to vote unanimously for fast-tracking the earlier created proposal. It means that all six members need to vote **Aye**:\\n![Fast-track vote result](../images/technical-committee-fast-track/fasttrack_vote_result.png)\\n\\nAfter this anyone can **Close** this voting, and the proposal will be enacted and moved from **external** table to active **referenda**:\\n![Democracy enacted proposal](../images/technical-committee-fast-track/democracy_enacted_proposal.png)\\n\\n\\n## 6. Voting on enacted proposal in Democracy\\nNow at least one account needs to vote **Aye** on the referenda:\\n![Voting for enacted proposal](../images/technical-committee-fast-track/voting_for_enacted_proposal.png)\\n\\nAs a result we'll get the active referenda with one positive vote on it:\\n![Positive voted referenda](../images/technical-committee-fast-track/positive_voted_referenda.png)\\n\\nAfter the voting period ends, this democracy proposal will be executed. In current example this will be happen in block #3351. Let's wait for this block and check it:\\n![Result](../images/technical-committee-fast-track/result.png)\\n\"}},{\"node\":{\"id\":\"799ccfa37a5bb5249f5e8e6e667aa5db\",\"title\":\"How to Send Launch with Subscription\",\"path\":\"/docs/ja/subscription-launch/\",\"content\":\"\\nIf your address is in devices of any subscription you can send extrinsics with no fee. Lets try to send `launch`.\\n\\nGo to `Developer/Extrinsics`, choose your account (`MAIN` in the picture) and `rws -> call`. Then in `subscriptionID` field write the subscription's owner address (`SUBSCRIPTION OWNER` in the picture) and in the next field choose `launch -> launch`. In the `robot` field write the address you want to send `launch` transaction to(`LIGHTBULB (EXTENTION)` in the picture) and choose the parameter `Yes` or `No`. Then submit transaction:\\n\\n![launch](../images/dev-node/launch.png)\\n\\n\\nNow go to `Network/Explorer` and in the `Recent Events` you will see two events `rws.NewCall` and `launch.NewLaunch`:\\n\\n![events](../images/dev-node/events.png)\"}},{\"node\":{\"id\":\"33ca47fd64e5c42e97605026ef8c226b\",\"title\":\"Try It Out\",\"path\":\"/docs/ja/spot-try-it-out/\",\"content\":\"\\nWith this tutorial you will be able to see in simulation what real Spot did.\\n\\n## Requirements\\n\\n* ROS melodic desktop (installation instructions [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n\\n## Install package\\n\\nCreate workspace and clone packages:\\n```bash\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/src\\ngit clone https://github.com/clearpathrobotics/spot_ros.git\\ngit clone https://github.com/ros/geometry2 --branch 0.6.5\\n```\\nOpen the `view_model.launch` file:\\n```bash\\nnano ~/catkin_ws/src/spot_ros/spot_viz/launch/view_model.launch\\n```\\n\\nAnd set `use_sim_time` parameter to `true`, file must look like this:\\n```xml\\n<launch>\\n  <param name=\\\"/use_sim_time\\\" value=\\\"true\\\"/>\\n  <include file=\\\"$(find spot_description)/launch/description.launch\\\"/>\\n\\n  <node name=\\\"joint_state_publisher_gui\\\" pkg=\\\"joint_state_publisher_gui\\\" type=\\\"joint_state_publisher_gui\\\" />\\n\\n  <node name=\\\"rviz\\\" pkg=\\\"rviz\\\" type=\\\"rviz\\\" args=\\\"-d $(find spot_viz)/rviz/model.rviz\\\" />\\n</launch>\\n```\\n\\nThen install dependencies:\\n```bash\\ncd ~/catkin_ws/\\nrosdep install --from-paths src --ignore-src -y\\ncatkin_make\\n```\\n\\n## Run\\n\\nGet example rosbag file:\\n```bash\\nwget -O spot_rosbag.bag https://gateway.ipfs.io/ipfs/QmTDrfMy7Zs7uDLN3KPBC1UYqXNMXBKEwX7ggVmJKAm7Ef\\n```\\n\\nRun rviz with the Spot model:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_model.launch\\n``` \\nThen in a new terminal:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_robot.launch\\n``` \\n![spot_viz](../images/spot/spot.jpg)\\n\\n\\nPlay rosbag file and you will see the robot move:\\n```bash\\nrosbag play spot_rosbag.bag\\n```\\n![spot_viz](../images/spot/spot2.jpg)\"}},{\"node\":{\"id\":\"6c57f1336f15f62a3c0ea3c703a1b2b3\",\"title\":\"Troubleshooting\",\"path\":\"/docs/ja/spot-troubleshooting/\",\"content\":\"\\n### Admin socket already exists \\n\\nIf you can't run yggdrasil with this error:\\n```bash\\nAdmin socket /var/run/yggdrasil.sock already exists and is in use by another process\\n```\\nTry to remove file yggdrasil.sock and run it again:\\n```bash\\nsudo rm /var/run/yggdrasil.sock\\n```\\n\\n### Can't get lease\\n\\nIf you can't get lease with this error:\\n```python\\nGeneric exception during check-in:\\nNo lease for resource \\\"body\\\"\\n    (resuming check-in)\\n```\\nOr this error:\\n```python\\nGeneric exception during check-in:\\nbosdyn.api.RetainLeaseResponse (LeaseUseError): \\n    (resuming check-in)\\n```\\n\\nYou need to acquire lease (if you have already done it, try again):\\n```python\\nlease = lease_client.acquire()\\n```\\n\"}},{\"node\":{\"id\":\"1012f1a3df758d423a9176287422c212\",\"title\":\"Lesson 5. Robot service. Camera calibration and \\\"Spot check\\\" procedure\",\"path\":\"/docs/ja/spot-lesson5/\",\"content\":\"\\nIn this lesson you will learn what should you do if you just got the robot: the first run and network setup. Also you will learn how to run the calibration process that should be run monthly.\\n\\n## The challenge\\n\\nCreate and execute Python script implements behaviors described.\\n\\n1. Run \\\"spot check\\\" and save the result of the calibration in a `/home/student/result` directory as a text file.\\n2. Run camera calibration procedure.\\n\\n## Theory\\n\\n### First Run\\n\\nLook at [Startup Procedure](https://support.bostondynamics.com/s/article/Startup-Procedure) page in Documentation.\\n\\n### Networking\\n\\nSpot offers a variety of networking options to support a diverse set of applications and environments. Options include:\\n\\n* Spot as a connected peer. Physicall connection to Spot.\\n\\n* Spot as a WiFi access point. \\n\\n* Spot as a WiFi client. Spot can join an existing WiFi network, and applications can also join the same WiFi network to talk to Spot.\\n\\nFor more information look at [Networking page](https://dev.bostondynamics.com/docs/concepts/networking).\\n\\nSpot Core is connected to the Spot via payload port. Spot Core can be connected to the Internet with Wi-Fi dongle. The setup instructions you can find at [Spot Core Cockpit](https://dev.bostondynamics.com/docs/payload/spot_core_cockpit.html?highlight=spot%20check) page.\\n\\n### Calibration\\n\\nSpot Check is a full calibration of the robot. Also you can run the camera calibration \\n\\n* [run_spot_check](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L164) runs full spot check routine. The robot should be sitting on flat ground when this routine is started. This routine calibrates robot joints and checks camera health.\\n\\n* [run_camera_calibration](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L204). Run full camera calibration routine for robot. This function blocks until calibration has completed. This function should be called once the robot is powered on and standing with his back to the calibration stand at a distance of 1 meter. Calibation process takes about 20 minutes.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"36d585ddce1bc130fe0a51fa5576653f\",\"title\":\"Lesson 4. GraphNav service. Mapping and navigating on the map\",\"path\":\"/docs/ja/spot-lesson4/\",\"content\":\"\\nIn the fourth lesson you will learn how to record and play autonomous missions with GraphNav service.\\n\\n## The challenge\\n\\nThis lesson you can solve the challenge without writing your own Python script.\\n\\n1. Record a map avioding obstacles. You can use WASD remote control tool. Save your mission in `/home/student/result`.\\n2. Move Spot through recorded waypoints. You can use GraphNav service command line tool.\\n\\n## Theory\\n\\nThe Spot SDK includes APIs, client libraries, and examples that support the development of autonomous navigation behaviors for the Spot robot. Collectively, this service is referred to as GraphNav. Maps are recorded and saved and later can be replayed with any robot in your fleet. During the map recording process, you can assign actions and API callbacks to waypoints along the map route.\\n\\nRead [GraphNav Tech Summary](https://dev.bostondynamics.com/docs/concepts/autonomy/graphnav_tech_summary) to learn how it works. [Initialisation](https://dev.bostondynamics.com/docs/concepts/autonomy/initialization) is also important part, it will be usefull in this lesson.\\n\\n> You can view recorded maps with [View Map](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_view_map) example. For that you need to copy the map to your computer:\\n> ```bash\\n> scp -r student@strelka.ygg.merklebot.com:<path_to_the_map_on_spot> <path_to_the_map_to_download>\\n> ```\\n> Also you need [install spot packages](https://github.com/boston-dynamics/spot-sdk/blob/master/docs/python/quickstart.md#install-spot-python-packages).\\n\\nStudy [recording and playing missions](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_command_line) examples in order to use it to record the map and playback the mission recorded.\\nUse [wasd](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/wasd) example to move robot while recording the map.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\\nYou can run remote control tool from examples directory.\\n\\n```console\\ncd ~/spot-sdk/python/examples/wasd\\npython3 wasd.py --username <SPOT_AUTH_USERNAME> --password <SPOT_AUTH_PASSWORD> <SPOT_ADDRESS>\\n```\\n\\nGraphNav command line tool is located at `~/spot-sdk/python/examples/graph_nav_command_line`.\\n\"}},{\"node\":{\"id\":\"6d3ebee35fc9bcc627313ea801e6c830\",\"title\":\"Lesson 3. Find and follow an object, navigate between them\",\"path\":\"/docs/ja/spot-lesson3/\",\"content\":\"\\nIn the third lesson you will learn how to find World Objects and go to them.\\n\\n## The challenge\\n\\nYou start with Spot in the place with some fiducials (a mark on the object) around. Create and execute Python script detects at least two fiducials and moves Spot to each of them within 1 m.\\n\\n## Theory\\n\\nSpot has the World Object Service that provides a way to track and store objects detected in the world around Spot. A world object is considered a higher-level item in the scene that has some amount of semantic information associated with it. More information you can find in [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services#world-object) tab in Spot SDK documentation.\\n\\nUsing world object service you can find fiducials near the Spot. \\n\\n> Spot can find objects around faster if he stands.\\n\\nIn the task you will need find fiducials' coordinates and go to them. You already know how to move to the local coordinates from the [Lesson 2](/docs/en/spot-lesson2.md). The example of how to find a fiducial and it's coordinates is in [fiducial_follow example](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/examples/fiducial_follow/fiducial_follow.py).\\n\\nIn your script, firstly, you need to find fiducial object with World Object Service:\\n\\n```python\\nfiducial_objects = world_object_client.list_world_objects(\\n            object_type=[world_object_pb2.WORLD_OBJECT_APRILTAG]).world_objects\\n```\\n\\nThen get fiducial coordinates in a visual frame:\\n\\n```python\\nfiducial = fiducial_objects[0]\\nvision_tform_fiducial = get_a_tform_b(fiducial.transforms_snapshot, VISION_FRAME_NAME,fiducial.apriltag_properties.frame_name_fiducial.to_proto()\\n```\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"5e1479f6809276640c8249745dba47d3\",\"title\":\"Lesson 2. Remote controlled and programmed motion\",\"path\":\"/docs/ja/spot-lesson2/\",\"content\":\"\\nIn the second lesson you will learn how to use Spot Command services and walk with Spot.\\n\\n## The challenge\\n\\nYou have a list of points with their local coordinates in the `/home/student/lessons` directory. Spot should go through these points. The origin of the local coordinates is in the place where Spot was turned on. On each point Spot should make one of the motions from the following list, then go to the next point. \\n\\nThe list of moves:\\n* To turn around himself\\n* To lie down in pose to change battery\\n* To nod\\n* To change the stance of robot's legs\\n* To go sideways to the next point\\n\\nCreate and execute a Python script that implements behavior described.\\n\\n> You can find Spot local coordinates with:\\n> ```python\\n> get_vision_tform_body(robot_state_client.get_robot_state().kinematic_state.transforms_snapshot)\\n> ```\\n\\n## Theory\\n\\nYou can control Spot with `Robot Command Service`. Firstly you need to build a command to supply it to the command service.\\nSpot SDK has a `RobotCommandBuilder` class for it.\\nFull list of methods and its descriprions you can find [here](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/bosdyn-client/src/bosdyn/client/robot_command.py#L593). \\n\\nIn this lesson you may need to use:\\n\\n* Stand Command\\n\\n```python\\ndef stand_command(params=None, body_height=0.0, \\n                footprint_R_body=geometry.EulerZXY())\\n```\\n\\n* Go to point\\n\\n```python\\ndef synchro_se2_trajectory_point_command(goal_x, goal_y, goal_heading,      \\n                                    frame_name, params=None,\\n                                    body_height=0.0,\\n                                    locomotion_hint=spot_command_pb2.HINT_AUTO,\\n                                    build_on_command=None)\\n```\\n\\nCheck usage example [here](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/frame_trajectory_command/frame_trajectory_command.py).\\n\\n* Velocity Command\\n\\n```python\\ndef synchro_velocity_command(v_x, v_y, v_rot, params=None, body_height=0.0,\\n                            locomotion_hint=spot_command_pb2.HINT_AUTO, \\n                            frame_name=BODY_FRAME_NAME)\\n```\\n\\n* Stance Command\\n\\n```python\\ndef stance_command(se2_frame_name, pos_fl_rt_frame, pos_fr_rt_frame, \\n                        pos_hl_rt_frame,\\n                        pos_hr_rt_frame, accuracy=0.05, \\n                        params=None, body_height=0.0,\\n                        footprint_R_body=geometry.EulerZXY(), \\n                        build_on_command=None)\\n```\\n\\nThe example of use is [here](https://github.com/boston-dynamics/spot-sdk/blob/91ed30607264e795699995d6d7834ba0c8a94d36/python/examples/stance/stance_in_place.py)\\n\\n* Pose to change battery\\n\\n```python\\ndef battery_change_pose_command(dir_hint=1)\\n```\\n\\nExample of building and running velocity command:\\n\\n```python\\nfrom bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder\\nimport time\\n\\ncommand_client = robot.ensure_client(RobotCommandClient.default_service_name)\\ncmd = RobotCommandBuilder.velocity_command(0.5, 0, 0.5)\\ncommand_client.robot_command(cmd, end_time_secs=time.time() + 2)\\n```\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"07794d4be6027d35b90f65dafa9a1955\",\"title\":\"Lesson 1. Emergency stop, initialization, body position control\",\"path\":\"/docs/ja/spot-lesson1/\",\"content\":\"\\nWelcome to the first lesson!\\n\\nDuring this lesson you will learn how to authorize yourself as a user, get motor power control and send basic commands to Spot.\\n\\nWatch our introductory video if you haven't seen it already:\\n\\nhttps://youtu.be/qdk7BjWJprc\\n\\n## The challenge\\n\\nCreate a Python script controls robot body position. Run your script on Spot to let it execute a sequence of motions:\\n\\n1. Stand-up,\\n2. Trace your initials with it's face (one letter, at least 3 points),\\n3. Sit-down.\\n\\n## Theory\\n\\nRead [Understanding Spot Programming](https://dev.bostondynamics.com/docs/python/understanding_spot_programming) page in Spot SDK documentation.\\nYou need to understand what is `E-Stop` and how make initialization in your Python script in order to to let the robot execute commands.\\n\\nYou can find more detailed information for this lesson in [Base Services](https://dev.bostondynamics.com/docs/concepts/base_services), [Geometry and Frames](https://dev.bostondynamics.com/docs/concepts/geometry_and_frames), [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services) and [E-Stop](https://dev.bostondynamics.com/docs/concepts/estop_service) sections of the Spot SDK documentation.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to SpotCORE by SSH from the terminal,\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Create a script can authenticate in Spot, acquire control (lease) and power on the robot.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file. Spot address is `192.168.50.3`.\\n\\n> In [Taking ownership of Spot (Leases)](https://dev.bostondynamics.com/docs/python/understanding_spot_programming#taking-ownership-of-spot-leases) section use `lease = lease_client.acquire()` before `lease_keep_alive = bosdyn.client.lease.LeaseKeepAlive(lease_client)`\\n\\n3. Try your script with stand-up and sit-down commands. Ensure robot moves as expected,\\n\\n> Make sure you run your script by Python 3 with `python3` command. Command `python` refers to an obsolete Python 2 interpreter.\\n\\n4. Add body position control to your script. Experiment with `bosdyn.geometry.EulerZXY` robot command argument builder in order to identify what yaw, roll and pitch parameters you need to set to solve the challenge. The range of Pitch, Yaw and Roll is from -0.5 to 0.5.\\n\"}},{\"node\":{\"id\":\"372c948eff53bb232101e7efcd193bf4\",\"title\":\"Lesson 0. Configure and test connection to Spot\",\"path\":\"/docs/ja/spot-lesson0/\",\"content\":\"\\nLet's start establishing connection to the robot.\\nOur goal is to get answers from Spot to our [ping](https://en.wikipedia.org/wiki/Ping_(networking_utility)) signals.\\nWe use Yggdrasil Network to expose Spot to the internet, that means we will need to configure Yggdrasil Network support on your computer first.\\n\\n## 1. Yggdrasil Installation \\n\\nYggdrasil is an early-stage implementation of a fully end-to-end encrypted IPv6 network. Before startitng the lessons you need to install it on your computer.\\n\\n### For Linux: \\nInstallation instructions [here](https://yggdrasil-network.github.io/installation-linux-deb.html).\\n\\n### For MacOS: \\nDownload .pkg file from [here](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4.0-macos-amd64.pkg).\\n\\nLocate the downloaded file in Finder. Right-click it and click Open. Step through the installer as usual.\\n\\n### For Windows:\\nDownload .msi file for [x64 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x64.msi) or for [x32 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x86.msi) and run it with double click.\\n\\n## 2. Open configuration file\\n\\nYou need to add a list of peers (public nodes) to configuration file so that you will be able to connect to Spot. \\n\\n### For MacOS and Linux:\\nFor that, edit the `yggdrasil.conf` file with this command in a terminal:\\n\\n```bash\\nsudo nano /etc/yggdrasil.conf\\n```\\n\\n### For Windows:\\nRun `updateconfig.bat` in `C:/Program Files/Yggdrasil`. \\n\\nThen in `C:/ProgramData/Yggdrasil` open `yggdrasil.conf` with any text editor.\\n\\n> `ProgramData` is a hidden folder, so you need to show hidden data.\\n\\n## 3. Write peers\\n\\nIn the file that you opened find line `Peers:` (it is at the beginning of the file) add 5-6 peers geografically near to you (write them inside the brackets). You can find list of available peers [here](https://github.com/yggdrasil-network/public-peers) or add peers from example below. Example in yggdrasil.conf:\\n\\n```bash\\n  Peers:\\n  [\\n    tcp://213.188.199.150:10010\\n    tcp://213.188.210.9:10010\\n    tcp://[2a09:8280:1::3:312]:10010\\n    tcp://[2a09:8280:1::a:2e2]:10010\\n    tcp://46.151.26.194:60575\\n    tcp://ygg-ru.cofob.ru:18000\\n    tcp://ygg.tomasgl.ru:61933\\n    tls://185.22.60.71:8443\\n    tcp://51.15.118.10:62486\\n    tls://ygg.loskiq.dev:17314\\n    tls://longseason.1200bps.xyz:13122\\n  ]\\n  ```\\nCheck if the peers online in [Puplic Peers](https://publicpeers.neilalexander.dev/).\\n\\n## 4. Save and close configuration file\\n\\n### For Linux and MacOS:\\n\\nPress `Ctrl+x`, then press `y` to save changes and press `Enter`.\\n\\n### For Windows:\\n\\nSave and close file.\\n\\n## 5. Restart service\\n\\n### For Linux:\\n\\nThen restart Yggdrasil using this command:\\n\\n```bash\\nsystemctl restart yggdrasil\\n```\\n### For macOS:\\n\\nUnload the service and run Yggdrasil with changed config file:\\n\\n```bash\\nsudo launchctl unload /Library/LaunchDaemons/yggdrasil.plist\\nsudo yggdrasil -useconffile /etc/yggdrasil.conf\\n```\\n> You will need to do that before every lesson.\\n\\n### For Windows:\\n\\nPress win + r and type `services.msc`, find Yggdrasil service, open it and restart (press Stop and Start).\\n\\n![win-service](../images/spot/spot-windows.jpg)\\n\\n## 6. Check Connection\\n\\nCheck if Yggdrasil works well.\\n\\nFor that try to ping Spot address:\\n```bash\\nping strelka.ygg.khassanov.xyz\\n```\\n> To open terminal in Windows press `Win+R`, type `cmd` and press `Enter`.\\n\\n> On MacOS use `ping6` instead of `ping`.\\n\\nIf you can't ping Spot or you had any errors during the Yggdrasil setup look in [Troubleshooting page](/docs/spot-troubleshooting). If you can't find the solution there, please email spot@robonomics.network.\\n\\n## 7. Create ssh key\\n\\nYou will connect to Spot via ssh, so you need to create ssh keys which you will use in booking lessons.\\n\\nRun following command in the terminal:\\n```bash\\nssh-keygen -t rsa\\n```\\n> SSH Client is available by default only in Windows 10, so if you use older versions you need to install it. For example you can use [PuTTY](https://www.putty.org/).\\n\\nRemember the path to your key (by default it is `/home/<user>/.ssh/id_rsa.pub` or `C:\\\\Users\\\\<user>\\\\.ssh\\\\id_rsa.pub`).\\n\"}},{\"node\":{\"id\":\"155ae5bed35abc84449faa669c4a26a6\",\"title\":\"Setup SLS Gateway\",\"path\":\"/docs/ja/sls-setup/\",\"content\":\"\\nYou can use [SLS Gateway from Robonomics](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01) instead of Xiaomi/Aqara gateways. It works only in your local network and don't send any data to external servers, so you can control all data about your home.\\n\\n1. Ensure that the switches on the back of the gateway are properly positioned. Switches 5 (RX Zigbee to ESP) and 6 (TX Zigbee to ESP) must be in the ON position, the others must be off. \\n\\n2. Connect the type C power cable. The indicator light in the center should turn green.\\n\\n3. The first time it starts up, the gateway will begin distributing Wi-Fi with the SSID 'zgw****' to set up the SLS gateway connection. Connect to this network. Keep in mind that the signal may be quite weak, so it is best to keep the SLS Gateway closer to your computer. \\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). Configure the SLS Gateway to connect to your Wi-Fi by entering the user / pass. After that the gateway's Wi-Fi will shut down. \\n\\n5. Find the local IP of the SLS gateway to access the web interface. You can use the command 'arp -a' or 'nmap'. The resulting link should look like this: 'http://192.168.xxx.xxx'.\\n\\n6. Go to Setting/Hardware and make sure that the settings look like this. Correct the settings if necessary and reboot the gateway:\\n\\n![sls-hardware](../images/home-assistant/sls-hardware.jpg)\\n\\n7. Configure automatically adding devices to Home Assistant. Go to `Zigbee/Config` then tick `Home Assistant MQTT Discovery` and `Clear States`:\\n\\n![sls-hass](../images/home-assistant/sls-hass.png)\\n\\n8. Connect your devices by going to Zigbee/Join. Press the Enable Join button to connect and put your sensors in pairing mode. \\n\\nAfter that connect it to Home Assistant with the following [guide](/docs/sls-gateway-connect)\"}},{\"node\":{\"id\":\"725905bc74a260969fef1d5a8d196d2a\",\"title\":\"Connect SLS Gateway to Home Assistant\",\"path\":\"/docs/ja/sls-gateway-connect/\",\"content\":\"\\n## MQTT Brocker\\n\\nFirst, you need to run MQTT brocker on your raspberry with Home Assistant. Connect to it under `ubuntu` login. Then install [Mosquitto Brocker](https://mosquitto.org/):\\n\\n```bash\\nsudo apt update -y && sudo apt install mosquitto mosquitto-clients -y\\n```\\nConfigure username (you can use any username you want) and password (you will be asked to enter the password after the command):\\n```bash\\nsudo mosquitto_passwd -c /etc/mosquitto/passwd <username>\\n```\\nThen edit configuration file:\\n```bash\\nsudo nano /etc/mosquitto/mosquitto.conf\\n```\\nAdd the following at the end of the file:\\n```\\nlistener 1883\\nallow_anonymous false\\npassword_file /etc/mosquitto/passwd\\n```\\n\\nThen restart the service:\\n\\n```bash\\nsudo systemctl restart mosquitto\\n```\\n\\nAnd check the brocker status:\\n```bash\\nsystemctl status mosquitto\\n```\\n\\n![mosquitto](../images/home-assistant/mosquitto.png)\\n\\n## MQTT Integration\\n\\nThen you need to add MQTT integration to Home Assistant. Open web interface then go to `Configuration/Integrations` page and press `Add Integration` button. Find MQTT:\\n\\n![mqtt](../images/home-assistant/mqtt.png)\\n\\nPress on it and set up your brocker with address (localhost), port (1883) and your username and password, then press `submit`:\\n\\n![mqtt1](../images/home-assistant/mqtt1.png)\\n\\nThen press on three dots on MQTT integration and choose `System Options`:\\n\\n![mqtt_options](../images/home-assistant/mqtt_conf.png)\\n\\nAnd check if automatically adding new devices is enabled:\\n\\n![mqtt_dev](../images/home-assistant/add_dev.png)\\n\\n## MQTT on SLS Gateway\\n\\nAlso you need to configure MQTT on SLS Gateway. On your SLS Gateway go to `Settings/Link` -> `MQTT Setup`:\\n\\n![sls-mqtt](../images/home-assistant/sls-mqtt.png)\\n\\nAnd add your brocker address (address of the raspberry with Home Assistant in local network) and port (1883). Also write the topic name (you can choose any). Don't forget to tick `Enable` and `Retain states`:\\n\\n![sls-mqtt1](../images/home-assistant/sls-mqtt1.png)\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\"}},{\"node\":{\"id\":\"bb6ab533f2bd8a81d74d084499090d93\",\"title\":\"Introduction\",\"path\":\"/docs/ja/sensors-network-introduction/\",\"content\":\"\\n## What is Sensors Robonomics Network?\\n\\nThe Sensors Robonomics Network is a civilian network of sensors to monitor air quality. Anyone can build their own sensor or use an off-the-shelf solution from the development team and set it up in their home. The sensors use open source software and component wiring diagrams. One of the main sensors used is the PM10 and PM2.5 fine particulate sensor.\\n\\n## What is PM10 and PM2.5?\\n\\nPM10 is a particle of a substance 10 microns or smaller, PM2.5 is a particle 2.5 microns in diameter or smaller. They are constantly floating in the air and do not settle due to their small size, for comparison, the thickness of a human hair is 100 microns. These particles can appear for a variety of reasons, including industrial processes involving the handling of bulk materials or the burning and processing of minerals. They are also emitted after forest fires and dust storms. In addition, they can come from conventional transport when burning fuel or from wear and tear on tires and pavement. Car tires are wiped out into fine crumbs and the wind blows them from the roads all over the city.\\n\\n## Why do we need to measure them?\\n\\nPM10 and PM2.5 are the most dangerous because their size allows them to penetrate the lungs, whereas larger particles tend to linger in the nose or throat. Larger PM10 particles irritate the airways, nose, throat, and eyes. Particles smaller than 2.5 microns can penetrate deep into the lungs and even enter the bloodstream. The effects of these particles on the human body can be devastating:\\n- poisoning by harmful substances entering the bloodstream\\n- allergic reactions\\n- bacterial and fungal infections\\n- cancer\\n- mucous membrane irritation\\n- exacerbation of respiratory symptoms\\n\\n## Why the Sensors Robonomics Network?\\n\\nIn Russia there are other public monitoring networks, such as [Breathe Moscow](https://breathe.moscow/), which are based on the German project [sensor.community](https://sensor.community/ru/). But they use the usual client-server architecture, which in this case is a drawback. Data from all sensors together with user requests go to one server, which cannot always handle such load. So there are situations when the map with data is not available at the most responsible moments. With Sensors Robonomics Network, sensors send data to several different servers, and any user can bring up the Sensors Connectivity server for their sensor and see it on the map. The map itself is not overloaded because it is a decentralized application (DApp) that works directly from your browser with the data that the servers send to the IPFS pub-sub channel.\\n\\n## Sources\\n\\nhttp://www.npi.gov.au/resource/particulate-matter-pm10-and-pm25\\n\\nhttps://habr.com/ru/company/tion/blog/396111/\"}},{\"node\":{\"id\":\"eb5eba22af7f4cb3f0986b4649531572\",\"title\":\"Sensors Connectivity\",\"path\":\"/docs/ja/sensors-connectivity-on-aira/\",\"content\":\"\\nThe Sensors Robonomics Network uses the sensors community module from Robonomics to receive and process data. This module allows any user to raise his own server to receive data from sensors and process it further. Now the developers have launched several such servers and any sensor can send data to them. Running several servers allows to avoid data loss in case of problems with one of them, because sensors from a non-working server will switch to a working one.\\n\\nSensors Connectivity schematic:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSensors Connectivity is a set of stations (station1, station2...), which receive various data, including data from sensors via http protocol. But also it can be sensors connected to the computer via USB or any other data source.\\n\\nData received from the stations are processed by Sensors Connectivity and passed to feeders (feeder1, feeder2...). Feeders send the processed data to the user. In our case the data is sent to the decentralized IPFS channel.\\n\\nMap [sensors.robonomics.network](https://sensors.robonomics.network/) is a decentralized application (DApp) running on your computer. It reads data from the IPFS channel and outputs them to the map. So there is no direct connection between the server collecting the data from the sensors and the map the user sees, the data transfer between them is done via IPFS pubsub, which reduces the load on the servers.\\n\\nIn addition, every once in a while, a file with data from the last time period is saved in IPFS, and the hash of that data is further written to the blockchain. Since IPFS is a content-addressable network, storing data in it guarantees that any change in the data will not go unnoticed, because the address of the desired file contains a hash of its content, which will change if any change in the data occurs. The blockchain is used to pass the hash on to the user, who can use it to retrieve the desired data from the IPFS (which is what happens when requesting to view the history on [sensors.robonomics.network](https://sensors.robonomics.network/)). Since the transaction made cannot be changed, we can be sure that it is the correct hash.\\n\\nThe source code for Sensors Connectivity is available at [link](https://github.com/airalab/sensors-connectivity). To see the data from your server on the map, you need to contact the development team at vm@multi-agent.io and send the ipfs id of your server. \\n\\n# Run your own Sensors Connectivity\\n\\n## Pre-requirements\\n\\nTo build a python package IPFS daemon should be installed. Assyming, you work with linux:\\n\\n```\\nwget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_linux-amd64.tar.gz\\ntar -xzf go-ipfs_v0.8.0_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh \\nipfs init\\n```\\nYou can get IPFS ID with the following command after running IPFS daemon (it is in the `ID` column):\\n\\n```console\\n$ ipfs id\\n{\\n\\t\\\"ID\\\": \\\"QmUZxw8jsRpSx5rWkTpJokPGKvWihTrt5rbRCFXzJ4eCAP\\\",\\n\\t\\\"PublicKey\\\": \\\"CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC/uMV3rLM/C+LOh2DGPo3chr+VM+vyYMKi...\\n    ...\\n```\\n\\n## Installation as PyPi package\\n\\n```\\npip3 install py-sr25519-bindings\\npip3 install sensors-connectivity\\n```\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config is set, you can run the service: (in another terminal)\\n\\n```\\nsensors_connectivity \\\"path/to/your/config/file\\\"\\n```\\n\\nYou will be able to see logs in your console and in `~/.logs`.\\n\\n## Build from source\\n### Requirements\\n\\nTo build a python package fron source [poetry](https://python-poetry.org/docs/#osx--linux--bashonwindows-install-instructions) should be also installed. Assyming, you work with linux:\\n\\n```\\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -\\n```\\n\\n### Get a Package And Installing dependencies\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npoetry install\\n```\\n\\n### Documentation\\n\\nTo prepare a sensor for the work with the package follow instructions on [Robonomics Wiki](/docs/connect-sensor-to-robonomics/).\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\nMake a copy of `default.json` and fill it using description from the article.\\n\\nYou also can set a logging file. The default file for logs is `logging.py`, which uses `console` and `file` handler by default. Pay attention for the `file` handler. The template is stored in `connectivity/config/logging_template.py`. You can cpecify the path (`filename`), where your logs will be stored in (do not forget to create this directory if it doesn't exist). Default path for logs is `~/.logs`. You can figure any other handlers from the [library](https://docs.python.org/3.8/library/logging.html).\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config and log files are setted, you can run the service: (in another terminal)\\n\\n```\\npoetry run sensors_connectivity \\\"path/to/your/config/file\\\"  \\n```\\n\\nIf your log file is setted with `console` handler, you will be able to see logs in your console.\\n\\n### Example of logs:\\n\\n```\\n2022-02-17 19:30:51,248 - INFO - Getting data from the stations...\\n2022-02-17 19:30:51,443 - INFO - airalab-http-v0.8.0: [[], [{MAC: c8e2650f254e, Uptime: 0:00:14.010502, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:30:51,443 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:07,517 - INFO - Frontier Datalog: Data sent to Robonomics datalog and included in block 0x04baf3d81c6d31ec6f3ca3e515b9a6920666ee17cbd66f57130eaa000bad2cd4\\n2022-02-17 19:31:07,519 - INFO - RobonomicsFeeder: {\\\"0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a\\\": {\\\"model\\\": 2, \\\"geo\\\": \\\"53.518475,49.397178000000004\\\", \\\"measurement\\\": {\\\"airtemp\\\": -8.0, \\\"windang\\\": 45.0, \\\"windspeed\\\": 0.13, \\\"windspeedmax\\\": 0.13, \\\"pm10\\\": \\\"\\\", \\\"pm25\\\": \\\"\\\", \\\"timestamp\\\": 1645113602.0}}}\\n2022-02-17 19:31:07,523 - INFO - Checking data base...\\n127.0.0.1 - - [17/Feb/2022 19:31:13] \\\"POST / HTTP/1.1\\\" 200 -\\n2022-02-17 19:31:21,248 - INFO - Getting data from the stations...\\n2022-02-17 19:31:21,429 - INFO - airalab-http-v0.8.0: [[{MAC: c8e2650f254e, Uptime: 0:00:43.818101, M: {Public: 133b761496539ab5d1140e94f644e2ef92c7ac32446dc782bfe1a768379a669a, geo: (1,200), measurements: {'pm10': 27.58, 'pm25': 15.02, 'temperature': 22.93, 'pressure': 758.0687068706872, 'humidity': 39.44, 'timestamp': 1645115473}}}], [{MAC: c8e2650f254e, Uptime: 0:00:43.996539, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:31:21,444 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:51,249 - INFO - Getting data from the stations...\\n```\\n\\n## Troubleshooting\\n\\n### Python.h: No such file or directory\\n\\nIf during running `poetry install` comand you get such error, you need to install the header files and static libraries for python dev. Use your package manager for installation. For example, for `apt` you need to run\\n```\\nsudo apt install python3-dev\\n```\\n> Note:\\npython3-dev does not cover all versions for python3. The service needs at least python3.8, for that you may need to specify the version `sudo apt install python3.8-dev`.\\n\\n[Here](https://stackoverflow.com/a/21530768) you can find examples for other package managers.\\n\\n### Python versions mismatch\\n\\nIf during running `poetry install` comand you get `SolverProblemError`, which says \\\"The current project's Python requirement (3.6.9) is not compatible with some of the required packages Python requirement:..\\\", even though you have older version of python (e.g. python3.8), you may need to specify the python version poetry is using:\\n\\n```\\npoetry env use python3.8\\n```\\n\\n\"}},{\"node\":{\"id\":\"b2a9e15cdec3794959508e0af45f4d7d\",\"title\":\"How to contribute\",\"path\":\"/docs/ja/sensors-connectivity-contribution/\",\"content\":\"\\nIf you find any bugs or would like to propose an improvement, please, open a new issue in one of tre repositories, that you want to contribute.\\n\\n## Main Repositories\\n\\n- [sensors-connectivity](https://github.com/airalab/sensors-connectivity/issues) - Sensors Connectivity server\\n- [sensors-software](https://github.com/LoSk-p/sensors-software/issues) - firmware for the sensor\\n- [airrohr-firmware-flasher](https://github.com/LoSk-p/airrohr-firmware-flasher/issues) - application for microcontroller firmware\\n\"}},{\"node\":{\"id\":\"6d8f0cef23e5c039e8a39f0a0d6415e6\",\"title\":\"ROS-based Projects for Smart Spaces\",\"path\":\"/docs/ja/ros-smart-projects/\",\"content\":\"\\nThroughout its 15 years of development, the Robot Operating System framework was integrated with dozens of [various robotic devices](https://robots.ros.org/), and there are even more packages with algorithms and tools developed by the community. Truth be told, there are now so many projects, and the chaoticness of the description style of their repositories grew so much that it is currently quite problematic to find projects dedicated to a specific subject topic. \\n\\nHere, you’ll find a modest list of ROS-based projects that are dedicated to robots and IoT-devices that are meant for use in a home or office environment. This subject matter is one of the pillars of the Robonomics platform. Our goal is to try and bring these projects on track with Robonomics, from both a technical integration point of view and the perspective of an interesting application of these devices in a robot economy. Feel free to use this list in your search for ideas and inspiration.\\n\\nYou can check out some examples of ROS-projects integrated with Robonomics in the [Playground Overview page](https://wiki.robonomics.network/docs/en/playground-overview/). New projects, including those described here, will be added to the Wiki with time.\\n\\nAs of right now (**April 2021**), Robonomics is oriented towards ROS **Melodic** and **Noetic** versions. Older versions can also work, but there may be additional integration work needed. In the future, support for ROS version 2 will be added.\\n\\nThe main resources to search for ROS repositories and packages can be accessed [here](https://index.ros.org/).\\n\\n## Simulation\\n\\nBefore shifting our attention solely to devices, it’s worth remembering that for a large quantity of ROS projects, there exists an option to test them in a simulation. The most popular tool for the 3D modeling of various robots under ROS is the [Gazebo](http://gazebosim.org/) simulator and its offshoot project, [Ignition](https://index.ros.org/r/ros_ign/). Both simulators allow to model devices in various difficult indoor and outdoor environments, alter the model and environment itself, test control algorithms and debug before moving over to the real device. Also, this is an excellent tool for training and situations when a real device is absent.\\n\\nOverall, this is one of the best options for trying to integrate Robonomics with a ROS device without any expenditures at all. A real scenario would merely require slight code modifications. For Gazebo, Robonomics has a detailed guide that consists of two parts that cover [settings](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) and [integrations](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/) (using a drone as an example). The main challenge is in finding a ready model (for example, [here](https://github.com/osrf/gazebo_models)) for Gazebo or trying to create your own model using the [SDFormat](http://sdformat.org/) developed for simulators. \\n\\n## Single-board computers and other boards\\n\\nSuch boards act as a base component for connecting other devices to ROS, primarily sensors and recording devices (audio, photo, and video recorders, cameras, temperature, pressure, and substance concentration sensors.) because the concept of a smart space implies the creation of a [digital twin](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf) of infrastructure objects. Also, boards can act as the main computing device and controller for constructing a robotic mobile device. A list of boards that support ROS is presented below:\\n\\n| Name and link                                                                                         |                                    Description                                  | ROS version | Last update |\\n|:-----------------------------------------------------------------------------------------------------:|---------------------------------------------------------------------------------|:-----------:|:-----------:|\\n|  [Raspberry Pi](http://wiki.ros.org/ROSberryPi/Installing%20ROS%20Melodic%20on%20the%20Raspberry%20Pi)| single board computer; RaspPi versions 2, 3 and 4 are available                 |   melodic   |     2020    |\\n|    [Arduino](http://wiki.ros.org/rosserial_arduino)                                                   | single board computer                                                           |    noetic   |     2021    |\\n|    [Phidgets](http://wiki.ros.org/phidgets)                                                           | sets of boards, various sensors and devices: Ph sensor, LED, RFID, motor control|    noetic   |     2020    |\\n|   [Sense HAT](https://wiki.ros.org/sensehat_ros)                                                      | shield for RaspPi with a set of sensors and LED                                 |    noetic   |     2020    |\\n|     [Navio2](https://navio2.emlid.com/)                                                               | autopliot shield for RaspPi 2,3,4                                               |    noetic   |     2020    |\\n|     [OpenCR](http://wiki.ros.org/opencr)                                                              | robot controller                                                                |    noetic   |     2021    |\\n\\n## Smart home devices and household robots\\n\\nPresented here are ROS devices whose initial use was for smart homes or offices. The list varies widely, from vacuum cleaners and robotic assistance to home control systems.\\n\\n| Name and link                                             | Description                                                 |          ROS version          | Last update |\\n|:---------------------------------------------------------:|-------------------------------------------------------------|:-----------------------------:|:-----------:|\\n|  [Care-O-bot 4](http://wiki.ros.org/care-o-bot)           | household robot-assistant; a simulation is available        |            melodic            |     2021    |\\n|     [Kobuki](http://wiki.ros.org/kobuki)                  | mobile platform with different use cases (e.g. a waiter)    |            melodic            |     2020    |\\n|    [QTrobot](http://wiki.ros.org/Robots/qtrobot)          | humanoid social robot                                       | kinetic (melodic can be used) |     2020    |\\n|      [Nao](http://wiki.ros.org/nao)                       | humanoid robot; a simulation is available                   |            Melodic            |     2020    |\\n|     [TIAGo](http://wiki.ros.org/Robots/TIAGo)             | service robot with a manipulator; a simulation is available |            kinetic            |     2020    |\\n|     [Roomba](https://github.com/AutonomyLab/create_robot) | robot vacuum cleaner                                        |            melodic            |     2020    |\\n|    [OpenHAB](http://wiki.ros.org/iot_bridge)              | home automation system                                      |            kinetic            |     2017    |\\n|     [Sesame](https://index.ros.org/p/sesame_ros/)         | smart lock                                                  |            melodic            |     2021    |\\n\\n## Mobile platforms and manipulators\\n\\nFirst and foremost, ROS is known for supporting mobile robotics, from drones to industrial manipulators, for which many packages were created that realize simultaneous localization and mapping ([SLAM](http://wiki.ros.org/rtabmap_ros)), solve the direct and inverse task of kinematics, [trajectory planning](https://moveit.ros.org/), and etc. Mobile robotics are gradually penetrating into everyday life, which is why it is certainly interesting to test existing ROS-robots in their use within a smart space. The general list of ROS-based mobile platforms is rather large, which is why here we have selected those that are potentially convenient to operate in a home or office space. \\n\\n| Name and link                                             | Description                                | ROS version | Last update |\\n|:---------------------------------------------------------:|--------------------------------------------|:-----------:|:-----------:|\\n|   [turtlebot](http://wiki.ros.org/turtlebot3)             | mobile platform tailored for ROS           |    noetic   |     2020    |\\n|    [GoPiGo3](http://wiki.ros.org/Robots/gopigo3)          | mobile robot based on RaspPi               |   melodic   |     2020    |\\n|    [LoCoBot](http://wiki.ros.org/locobot)                 | mobile manipulator                         |   kinetic   |     2020    |\\n|   [ROSbot 2.0](http://wiki.ros.org/Robots/ROSbot-2.0)     | mobile platform; a simulation is available |    noetic   |     2021    |\\n|     [VOLTA](http://wiki.ros.org/Robots/Volta)             | mobile platform; a simulation is available |   melodic   |     2021    |\\n|    [evarobot](http://wiki.ros.org/Robots/evarobot)        | mobile platform; a simulation is available |    noetic   |     2020    |\\n|    [Freight](http://wiki.ros.org/Robots/freight)          | mobile platform; a simulation is available |   melodic   |     2021    |\\n|      [PR2](http://wiki.ros.org/Robots/PR2)                | mobile platform; a simulation is available |   melodic   |     2021    |\"}},{\"node\":{\"id\":\"ed644dc535b9427eb7202b9a4a2dbff2\",\"title\":\"Securely connect cloud AI to the factory floor\",\"path\":\"/docs/ja/securely-connect-cloud-ai-to-the-factory-floor/\",\"content\":\"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n![](../images/google-play-store.gif)\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n![](../images/Veracity_Protocol_Transaction.gif)\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n![](../images/Veracity_Protocol_Launch.gif)\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"}},{\"node\":{\"id\":\"ba5fc12415cace30016980beada2fc81\",\"title\":\"How to Run Robonomics Dev Node\",\"path\":\"/docs/ja/run-dev-node/\",\"content\":\"\\nFor testing your applications on Robonomics you may want to need to run it in the dev mode.\\n\\nhttps://youtu.be/04GsVkZ7aVg\\n\\n## Run\\n\\n1. First, you need a binary file, download the archive with it from the latest [release](https://github.com/airalab/robonomics/releases).\\n\\n2. Unpack it and change permissions:\\n\\n```bash\\ntar xf robonomics-1.7.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n3. And run in the dev mode:\\n\\n```bash\\n./robonomics --dev\\n```\\nYou will see the following output:\\n\\n![robonomics](../images/dev-node/robonomics.png)\\n\\n## Get tokens\\n\\nNow you can connect to your local node through the [Polkadot Portal](https://polkadot.js.org/apps/#/explorer).\\n\\nChange the network to `Local Node` in the upper left corner and press `Switch`.\\n\\n![local_node](../images/dev-node/portal.png)\\n\\nThen go to `Accounts`:\\n\\n![accs](../images/dev-node/accs.png)\\n\\nYou can create a new account with the button `Add Account`.\\n\\n![add_acc](../images/dev-node/add_acc.png)\\n\\nDon't forget to save your seed phrase somewhere.\\n\\nAnd use one of existing accounts to send tokens to your new one. Choose for example Alice and press `Send`. Then choose your new account and write the amount of units you want to send and press `Make Transfer`:\\n\\n![send](../images/dev-node/send.png)\"}},{\"node\":{\"id\":\"e2eb77d4e210bce8d94fe7c0e8b6bad7\",\"title\":\"Manual start of the Robonomics network, consisting of 3 nodes\",\"path\":\"/docs/ja/robonomics-test-network-manual/\",\"content\":\"\\n**Need to start Robonomics network of N (N> = 2) nodes**\\n\\n## Requirements\\n- Robonomics binary, download latest here: https://github.com/airalab/robonomics/releases/\\n- Subkey tool, download latest here: https://github.com/airalab/robonomics/releases/\\n- 3 servers with root shell. Their ip-addresses in the current instruction will be `165.227.171.127`, `159.89.25.75` and `159.89.30.50`\\n\\n## Introduction\\nIn this tutorial, we will first create all key files locally, and then upload them to their corresponding nodes. \\n\\n## Prepare directories\\nDownload 2 archives from the links above and open the folder with them in the terminal.\\nThen create a directory for the project, unpack the archives into it and go to the created folder:\\n```\\n$ mkdir robonomics_test_network\\n$ tar -xf ./robonomics-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ tar -xf ./subkey-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ cd ./robonomics_test_network/\\n```\\n\\nNext, create a separate **uploads** directory and the necessary subdirectories for each server. All files intended for uploading to a specific server will be stored in these subdirectories:\\n```\\n$ mkdir -p uploads/165.227.171.127/keystore && mkdir -p uploads/165.227.171.127/network\\n$ mkdir -p uploads/159.89.25.75/keystore && mkdir -p uploads/159.89.25.75/network\\n$ mkdir -p uploads/159.89.30.50/keystore && mkdir -p uploads/159.89.30.50/network\\n```\\n\\nAlso, create a **local** folder with **validators** and **sudo** folders, which will store the validators and sudo keys locally.\\n```\\n$ mkdir -p local/validators && mkdir -p local/sudo\\n```\\n\\n## Prepare spec.json\\nUsing the robonomics binary, generate a **spec.json** file, which will use as the basis:\\n```\\n$ ./robonomics build-spec --chain dev > uploads/spec.json\\n```\\n\\nNext, edit this file. At first correct the first three fields, make them look like this:\\n```\\n\\\"name\\\": \\\"Test Robonomics Network\\\",\\n\\\"id\\\": \\\"dev\\\",\\n\\\"chainType\\\": \\\"Live\\\",\\n```\\n\\n### bootNodes\\nThe **bootNodes** field is a list of strings of special format. For each of the bootnodes must write the corresponding string here.\\nTo do this, first create a key file for each bootnode using **subkey**:\\n```\\n$ ./subkey generate-node-key uploads/165.227.171.127/network/secret_ed25519  \\n12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\n$ ./subkey generate-node-key uploads/159.89.25.75/network/secret_ed25519\\n12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\n$ ./subkey generate-node-key uploads/159.89.30.50/network/secret_ed25519\\n12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\n```\\n\\nEach command creates a key file in the specified directory and outputs to stdout the string that will be needed to fill in the **bootNodes** field in the **spec.json** file. As a result, the **bootNodes** section should look like following example:\\n```\\n\\\"bootNodes\\\": [\\n\\\"/ip4/165.227.171.127/tcp/30333/p2p/12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\\",\\n\\\"/ip4/159.89.25.75/tcp/30333/p2p/12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\\",\\n\\\"/ip4/159.89.30.50/tcp/30333/p2p/12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\\"\\n],\\n```\\nThe next 3 fields (telemetryEndpoints, protocolId, properties) can be filled like this:\\n```\\n \\\"telemetryEndpoints\\\": [\\n     [\\n       \\\"/dns4/telemetry.polkadot.io/tcp/443/x-parity-wss/%2Fsubmit%2F\\\",\\n       0\\n     ]\\n ],\\n\\\"protocolId\\\": \\\"txrt\\\",\\n\\\"properties\\\": {\\n    \\\"ss58Format\\\": 32,\\n    \\\"tokenDecimals\\\": 9,\\n    \\\"tokenSymbol\\\": \\\"TXRT\\\"\\n},\\n```\\nFurther up to the **palletBalances** field leave unchanged.\\n\\n\\n### palletBalances\\nTo fill the palletBalances field create **the number of nodes + 1** (the last key is for **sudo**) keys. This can be done using **subkey**, in the file name must specify **SS58 Address** from the generated key, in the file content must specify **seed** phrase in quotes. \\n\\nExample creating one key.\\n - Generate key:\\n    ```\\n    $ ./subkey -n robonomics generate\\n    Secret phrase `display cargo domain april joy still bundle notice bridge pencil fat approve` is account:\\n      Network ID/version: substrate\\n      Secret seed:        0x0275ab9bce53e4359184f02112943162c708f483009e0b7b3ba63549c5c2e514\\n      Public key (hex):   0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      Account ID:         0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      SS58 Address:       4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n - Create key file:\\n    ```\\n    $ touch ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx && echo '\\\"display cargo domain april joy still bundle notice bridge pencil fat approve\\\"' | tee ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n  \\nCommand template for creating a validator key file:  \\n`touch ./local/validators/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/validators/**SS58_Address**`\\n\\nCommand template for creating a sudo key file:   \\n`touch ./local/sudo/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/sudo/**SS58_Address**`\\n\\nThree keys are stored in the **local/validators** folder and one in the **local/sudo** folder. As a result, the following content should appear in the **local** directory:\\n```\\n./local/\\n├── sudo\\n│   └── 4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\n└── validators\\n    ├── 4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ├── 4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\n    └── 4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\n```\\n\\nNow fill the palletBalances section in the spec.json file with these keys.\\nAs a result, it should look like this:\\n```\\n\\\"palletBalances\\\": {\\n  \\\"balances\\\": [\\n    [\\n      \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Generated validator 1 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Generated validator 2 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Generated validator 3 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\",    <-- Generated sudo key\\n      1000000000000000000\\n    ],\\n  ]\\n},\\n```\\nThe values that were previously presented in the palletBalances section must be deleted.\\n\\n### palletSession\\nNext step is the **palletSession** section in file **spec.json**. First let's describe its format. \\nThis section contains the \\\"keys\\\" field, that contains a list of three lists (equals of nodes count). Each of these lists looks like follows:\\n```\\n[\\n    \\\"%validator_SS58_address%\\\",\\n    \\\"%validator_SS58_address%\\\",\\n    {\\n        \\\"babe\\\": \\\"%sr25519_babe_SS58_address%\\\",\\n        \\\"im_online\\\": \\\"%sr25519_im_online_SS58_address%\\\"\\n        \\\"authority_discovery\\\": \\\"%sr25519_authority_discovery_SS58_address%\\\",\\n        \\\"grandpa\\\": \\\"%ed25519_grandpa_SS58_address%\\\",\\n    }\\n]\\n```\\n**%validator_SS58_address%** is the validator key that was generated for each node in the **palletBalances** section of this manual. Just copy it twice for each node.\\n\\nTo fill in the remaining 4 lines for each node, you need to create 4 key files for each node and store them in the **keystore** folders.\\nAs key files are generated, you can fill **palletSession**.\\n\\nEach key file must contain a **seed** phrase in quotes.\\nMaking of the name of each key file require separate consideration.\\nThe name of each key file is formed as **prefix** + **account_id without leading hexadecimal zero**.\\n\\nPrefixes matching:  \\n>      grandpa: '6772616e'  \\n>      babe: '62616265'\\n>      im_online: '696d6f6e'  \\n>      authority_discovery: '61756469'  \\n\\nAn example of creating keys for one node:\\n- Creating a **babe** (prefix *62616265*) key file.   \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  >  Secret phrase **cover once garment syrup income chair elder business diary frozen rack damage** is account:  \\n  >\\n  >  Network ID/version: `substrate`\\n  >\\n  >  Secret seed:        `0x90ddeee3a9a0c464572021d311c245eefc41f9a59c739faefda47efcf4755677`\\n  >\\n  >  Public key (hex):   `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  >\\n  >  Account ID:         `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  > \\n  >  SS58 Address:       `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`\\n  \\n ```\\n $ touch uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 && echo '\\\"cover once garment syrup income chair elder business diary frozen rack damage\\\"' | tee ./uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 \\n ```\\n This command creates a **babe** key file for the `165.227.171.127` node. To fill in **spec.json**, need to take from this output the value **SS58 Address**: `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`. This address need to insert instead of `%sr25519_babe_SS58_address%` in the above **palletSession** template.\\n   \\n **babe** key file creation command template:  \\n`touch ./uploads/[node_ip]/keystore/62616265+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/62616265+[Account_ID]`  \\n\\nAs you can see, the name of the babe key file is the sum of two substrings: `babe prefix ('62616265')`, and the `account_id` of the generated key, without the leading zero (`fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`). \\n  Note that the keys `babe, im_online, authority_discovery` are generated with the indication `--sr25519`.  \\n  **grandpa** key have to generate with the indication `--ed25519`.\\n \\n\\n- Creating an **im_online** (prefix *696d6f6e*) key file.  \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  > Secret phrase **envelope truly balance turkey undo casual waste skill average ordinary gun split** is account:\\n  >\\n  >   Network ID/version: `substrate`\\n  > \\n  >   Secret seed:        `0x8a19df08feeff9f1fa3581902ca22a305252aea32e284d32f10e990d00bb8926`\\n  > \\n  >   Public key (hex):   `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   Account ID:         `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   SS58 Address:       `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt`\\n   \\n  ```\\n  $ touch uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09 && echo '\\\"envelope truly balance turkey undo casual waste skill average ordinary gun split\\\"' | tee uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n  ```\\n  **im_online** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID]`\\n  \\n  **spec.json**: `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt` need to insert instead of `%sr25519_im_online_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating an **authority_discovery** (prefix *61756469*) key file.\\n   ```\\n   $ ./subkey --sr25519 -n robonomics generate\\n   ```\\n   > Secret phrase **boy harsh because omit equip atom apart spring undo explain walnut crystal** is account:\\n   >\\n   > Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0x27838c9ea0524353da3717862ef0ecef123f40e81b73bb5ef377d12b47d1c543`\\n   > \\n   >   Public key (hex):   `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   > \\n   >   Account ID:         `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   >  \\n   >   SS58 Address:       `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t`\\n   \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07 && echo '\\\"boy harsh because omit equip atom apart spring undo explain walnut crystal\\\"' | tee uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n   ```\\n  **authority_discovery** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/61756469+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/61756469+[Account_ID]` \\n  \\n   **spec.json**: `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t` need to insert instead of `%sr25519_authority_discovery_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating a **grandpa** (prefix *6772616e*) key file.\\n   ```\\n   $ ./subkey --ed25519 -n robonomics generate\\n   ```\\n   > Secret phrase **squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle** is account:\\n   > \\n   >   Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0xef0a9f51a4da7b789c0a25d39b44428d4da7262cc3fe013d4383b45216e8b83e`\\n   >  \\n   >   Public key (hex):   `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   >  \\n   >   Account ID:         `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   > \\n   >   SS58 Address:       `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa`\\n    \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009 && echo '\\\"squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle\\\"' | tee uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n   ```\\n   **grandpa** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/6772616e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/6772616e+[Account_ID]`\\n   \\n   **spec.json**: `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa` need to insert instead of `%sr25519_grandpa_SS58_address%` in the above **palletSession** template.\\n   \\n   \\n**Now 4 key files have been created for one node. Need to repeat this actions for the remaining two nodes.**\\n\\nYou should get the following **uploads** directory structure after creating all the keys:\\n```\\n./uploads/\\n├── 165.227.171.127\\n│   ├── keystore\\n│   │   ├── 617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n│   │   ├── 62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43\\n│   │   ├── 6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n│   │   └── 696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n│   └── network\\n│       └── secret_ed25519\\n├── 159.89.25.75\\n│   ├── keystore\\n│   │   ├── 617564692ac9bd30c0168fa623cfd66abb4327992d900a652bcbb238b740bdde497a565f\\n│   │   ├── 626162657cd666bb540c41cb33896a34d7413ffb86fcef1eddddfcd4edb325166df6335d\\n│   │   ├── 6772616e084402349bc08ef90c2837e8e3f12ebe8bd4ab86809e9ee5f4f8ca26e73a0518\\n│   │   └── 696d6f6e6ed2d507c0283ae869ba6514975bd8765eb8e06abd22afc09e8f36ef3950a116\\n│   └── network\\n│       └── secret_ed25519\\n└── 159.89.30.50\\n|   ├── keystore\\n|   │   ├── 61756469f20a4e16a0ee79431d6f9a70c38892c7532ad1347c2226d43ef6ffe8966e9b30\\n|   │   ├── 62616265e695aa459dbfd42bea7ed3b87970f164f34b6fee4d5a831ffbecd89eb9769b26\\n|   │   ├── 6772616eadef59f896ea6b94bcd4519be8cc4b70263fc318cec1a3be14850bbc22117c34\\n|   │   └── 696d6f6e2cb4dc8f8a67f477da15045ca40ef3861a2a6b2034ae0c64a179b4431341ea2c\\n|   └── network\\n|       └── secret_ed25519\\n└── spec.json\\n```\\n\\nThe palletSession section should look like this:\\n```\\n\\\"palletSession\\\": {\\n    \\\"keys\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t\\\",\\n                \\\"babe\\\": \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",\\n                \\\"grandpa\\\": \\\"4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa\\\",\\n                \\\"im_online\\\": \\\"4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt\\\"\\n            }\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4F6daoG2gBXRLvbT4mVRajExZdZBHH7APmX3wDuLYJyzxHSS\\\",\\n                \\\"babe\\\": \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",\\n                \\\"grandpa\\\": \\\"4G3Ai6BGUjqtCoM2aTvWyR19gQ8WZiNnh1KFM47RyiYTwkE6\\\",\\n                \\\"im_online\\\": \\\"4FHA7gzKfSLvd8jP85JUCWV6RyeRLm331KHcjnynGx7TWm7D\\\"\\n            }\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address                        \\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4CqzJFkdSZg52PfV6Fd4gJ3vPLmRu1HGuPvNivjJ8dDWaz1a\\\",\\n                \\\"babe\\\": \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",\\n                \\\"grandpa\\\": \\\"4Cqi4rG3CzWRZairhZX4isT8qG2jyz9fGDXJMrP6uBYkrft5\\\",\\n                \\\"im_online\\\": \\\"4C7V6R59cZVbabExqgWvHVE1vj1E1cV42SZr8d8zZD3gmsqk\\\"\\n            }\\n        ]\\n    ]\\n},\\n```\\n\\n### palletStaking\\n**palletStaking** must be filled in as follows:\\n```\\n\\\"palletStaking\\\": {\\n    \\\"historyDepth\\\": 84,\\n    \\\"validatorCount\\\": 10,\\n    \\\"minimumValidatorCount\\\": 2,\\n    \\\"invulnerables\\\": [\\n        \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",     <-- Validator 1 SS58 Address\\n        \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",     <-- Validator 2 SS58 Address\\n        \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\"      <-- Validator 3 SS58 Address\\n    ],\\n    \\\"forceEra\\\": \\\"NotForcing\\\",\\n    \\\"slashRewardFraction\\\": 100000000,\\n    \\\"canceledPayout\\\": 0,\\n    \\\"stakers\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",  <-- Validator 1 SS58 Address\\n            \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",  <-- Validator 1 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",  <-- Validator 2 SS58 Address\\n            \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",  <-- Validator 2 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",   <-- Validator 3 SS58 Address\\n            \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",   <-- Validator 3 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ]\\n    ]\\n},\\n```\\nThe example specified in which fields what values should be substituted.\\n\\n### palletSudo\\nIn the rest of the **spec.json** file, you need to change only the contents of **palletSudo**, substituting the previously generated **sudo** address there:\\n```\\n            \\\"palletBabe\\\": {\\n                \\\"authorities\\\": []\\n            },\\n            \\\"palletGrandpa\\\": {\\n                \\\"authorities\\\": []  \\n            },\\n            \\\"palletImOnline\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletAuthorityDiscovery\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletTreasury\\\": {},\\n            \\\"palletElectionsPhragmen\\\": {\\n                \\\"members\\\": []\\n            },\\n            \\\"palletCollectiveInstance1\\\": {\\n                \\\"phantom\\\": null,\\n                \\\"members\\\": []\\n            },\\n            \\\"palletSudo\\\": {\\n                \\\"key\\\": \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\"   <-- sudo address\\n            }\\n        }\\n    }\\n}\\n```\\n\\n## systemd unit file\\nNow create systemd unit file:\\n```\\n$ touch ./uploads/robonomics.service\\n```\\n\\nAnd fill it like this:\\n```\\n[Unit]\\nDescription=robonomics\\nAfter=network.target\\n\\n[Service]\\nUser=root\\nGroup=root\\nType=users\\nWorkingDirectory=/root\\nRestart=on-failure\\nExecStart=/usr/bin/robonomics  --chain /etc/substrate/spec.json --name ${HOSTNAME} --validator\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\nAs you can see from the \\\"ExecStart\\\" line, the **robonomics** binary is stored in the **/usr/bin/** directory, and the **spec.json** file is stored in the **/etc/substrate/** directory.\\n\\n## Uploading files\\nThe following one-line command uploads all files to the required directories on the servers. It is important that there are no other folders in the **uploads** directory, except for the folders with the ip-addresses of the nodes:\\n```\\n$ \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n    ssh root@\\\"$IP\\\" \\\"mkdir -p /root/.local/share/robonomics/chains/dev\\\" && \\\\\\n    scp -r ./uploads/$IP/* root@$IP:/root/.local/share/robonomics/chains/dev/ && \\\\\\n    scp ./uploads/robonomics.service root@$IP:/etc/systemd/system/ && \\\\\\n    scp ./robonomics root@$IP:/usr/bin/ && \\\\\\n    ssh root@$IP \\\"mkdir -p /etc/substrate\\\" && \\\\\\n    scp ./uploads/spec.json root@$IP:/etc/substrate/ \\\\\\n; done\\n```\\n\\n## Network launch\\nNow connect to all nodes, enable and start the **robonomics.service** unit:\\n```\\n$  \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n   ssh root@$IP \\\"systemctl enable robonomics.service && systemctl start robonomics.service\\\" \\\\\\n; done\\n```\\nAfter starting the service on all three nodes, you can view the node logs using **journalctl**. \\nTo do this, you can connect to any existing server via ssh and run the following command:\\n```\\n$ journalctl -u robonomics.service -f\\n```\\n![Robonomics Chart](../images/robonomics-test-network-manual/result-journalctl.jpg \\\"Robonomics Network journalctl stdout\\\")\\n\"}},{\"node\":{\"id\":\"c0a27d2c25eadaae092e6ca0bb821e80\",\"title\":\"Robonomics + Prometheus + Grafana\",\"path\":\"/docs/ja/robonomics-prometheus-grafana/\",\"content\":\"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](../images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](../images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](../images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](../images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](../images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](../images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](../images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](../images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](../images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"}},{\"node\":{\"id\":\"610d93aaeaac4f15f0357394449e889e\",\"title\":\"Robonomics Liability\",\"path\":\"/docs/ja/robonomics-liability/\",\"content\":\"\\nThe package is responsible for receiving `New Liability` events (`listener` node) and playing topics from `objective` field (`executor` node).\\nThe launch file also include `ipfs_channel` node and `signer` node.\\n\\n## ROS Parameters\\n\\n### ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~web3_ws_provider\\n\\nWeb3 WebSocket provider address. The type is `string`, defaults to `ws://127.0.0.1:8546`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~enable_executor\\n\\nEnable or disable executor node. If it's `false`, no topics from objective would be published. The type is `boolean`, defaults to `true`\\n\\n### ~master_check_interval\\n\\nPeriod (in seconds) to check master for new topic publications. It's necessary for the Recorder, which records all the topics a CPS publishes. The type is `double`, defaults to `0.1`\\n\\n### ~recording_topics\\n\\nList of topics name separated by comma. It allows you to specify which topics would be recorded. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Subscribed topics\\n\\n### /liability/infochan/eth/signing/demand (robonomics_msgs/Demand)\\n\\n[robonomics_msgs/Demand](/docs/market-messages#demand) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/offer (robonomics_msgs/Offer)\\n\\n[robonomics_msgs/Offer](/docs/market-messages#offer) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/result (robonomics_msgs/Result)\\n\\n[robonomics_msgs/Result](/docs/market-messages#result) message to sign and send further to IPFS channel\\n\\n\\n## Published topics\\n\\n### /liability/infochan/incoming/demand (robonomics_msgs/Demand)\\n\\nContains a [robonomics_msgs/Demand](/docs/market-messages#demand) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/offer (robonomics_msgs/Offer)\\n\\nContains a [robonomics_msgs/Offer](/docs/market-messages#offer) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/result (robonomics_msgs/Result)\\n\\nContains a [robonomics_msgs/Result](/docs/market-messages#result) message which was read from IPFS channel\\n\\n### /liability/incoming (robonomics_liability/Liability)\\n\\nContains all the information about the last created [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)\\n\\n### /liability/ready (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)is ready for execution\\n\\n### /liability/complete (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg) has done its job\\n\\n### /liability/finalized (std_msgs/String)\\n\\nSignals when a liability has been finalized\\n\\n## Services\\n\\n### /liability/start (robonomics_liability/StartLiability)\\n\\nThe service tells executor to play topics from the objective. It's required to pass a liability address ([robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)), which you can get from `/liability/ready` topic\\n\\n### /liability/finish (robonomics_liability/FinishLiability)\\n\\nCPS should call the service after performing the task. The input is [robonomics_liability/FinishLiability](/docs/robonomics-liability-messages#robonomics_liabilityfinishiabilitysrv)\\n\\n### /liability/restart (robonomics_liability/StartLiability)\\n\\nThe service allows to restart a liability after the system shutdown. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/resume (robonomics_liability/StartLiability)\\n\\nThe service allows to resume a liability from the last timestamp available in the persistence store. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/read (robonomics_liability/ReadLiability)\\n\\nThe service returns all the data about a liability by its address. The input is [robonomics_liability/ReadLiability](/docs/robonomics-liability-messages#robonomics_liabilityreadliabilitysrv)\\n\"}},{\"node\":{\"id\":\"296d752b7425930e966f7470233fca85\",\"title\":\"Robonomics Liability Messages\",\"path\":\"/docs/ja/robonomics-liability-messages/\",\"content\":\"\\n## robonomics_liability/Liability.msg\\n\\n| Field        \\t| Type                                                                         \\t| Description                                    \\t|\\n|--------------\\t|------------------------------------------------------------------------------\\t|------------------------------------------------\\t|\\n| address      \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The Liability’s address                        \\t|\\n| model        \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model Identifier                \\t|\\n| objective    \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model parameters in rosbag file \\t|\\n| result       \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| Liability result hash                          \\t|\\n| promisee     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisee address                           \\t|\\n| promisor     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisor address (usually CPS)             \\t|\\n| lighthouse   \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The address of lighthouse your CPS works on    \\t|\\n| token        \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Operational token address                      \\t|\\n| cost         \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| CPS behavioral model implementation cost       \\t|\\n| validator    \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Observing network address                      \\t|\\n| validatorFee \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| Observing network commission                   \\t|\\n\\n## robonomics_liability/StartLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                                           |\\n|---------  |-----------------  |-----------------------------------------------------  |\\n| address   | std_msgs/String   | The address of Liability you are willing to execute   |\\n\\n**Response**\\n\\n| Field     | Type              | Description                               |\\n|---------  |-----------------  |------------------------------------------ |\\n| success   | std_msgs/Bool     | Weather or not the Liability was started  |\\n| msg       | std_msgs/String   | Status of launch                          |\\n\\n## robonomics_liability/FinishLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                           |\\n|---------  |-----------------  |------------------------------------   |\\n| address   | std_msgs/String   | The address of Liability to finish    |\\n| success   | std_msgs/Bool     | The status of execution               |\\n\\n**Response**\\n\\nThe response is empty\\n\\n## robonomics_liability/ReadLiability.srv\\n\\n**Request**\\n\\n| Field     | Type                                                                          | Description                   |\\n|---------  |------------------------------------------------------------------------------ |----------------------------   |\\n| address   | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)  | The address of a liability    |\\n\\n**Response**\\n\\n| Field         | Type                                                                  | Description           |\\n|-----------    |---------------------------------------------------------------------  |---------------------  |\\n| read          | std_msgs/Bool                                                         | Status of execution   |\\n| liability     | [robonomics_liability/Liability](#robonomics_liabilityliabilitymsg)   | Liability             |\\n\"}},{\"node\":{\"id\":\"35929027353b3f1db519b7558822d36e\",\"title\":\"Robonomics-js\",\"path\":\"/docs/ja/robonomics-js/\",\"content\":\"\\n[Robonomics-js](https://github.com/airalab/robonomics-js) is a simple Javascript library for working with Robonomics Network.\\n\\n## Installation\\n\\n```\\nnpm install robonomics-js --save\\n```\\n\\nor\\n\\n```\\nyarn add robonomics-js\\n```\\n\\n### Dependencies \\n\\n* [Web3](https://github.com/ethereum/web3.js/) version 1.2.4\\n* [Ipfs](https://github.com/ipfs/js-ipfs) version 0.34.0\\n\\n\\n## Usage \\n\\nCreates a Robonomics instance\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\n```\\n\\n### options\\n\\nThe object of properties:\\n\\n```\\noptions.web3\\n```\\n\\nAn instance of [web3.js](https://github.com/ethereum/web3.js/):\\n\\n```JavaScript\\n// metamask\\nconst options = {\\n  web3: new Web3(window.ethereum),\\n  ...\\n};\\n\\n// infura\\nconst options = {\\n  web3: new Web3(\\n    new Web3.providers.WebsocketProvider(\\n      \\\"wss://mainnet.infura.io/ws/v3/0b2f2a5026264b57b6d698b480332e89\\\"\\n    )\\n  ),\\n  ...\\n};\\n```\\n\\n```\\noptions.messageProvider\\n```\\n\\nThis is an instance of MessageProviderIpfs which uses a [js-ipfs](https://github.com/ipfs/js-ipfs) node with pubsub support\\n\\n```JavaScript\\nconst ipfs = new Ipfs({\\n  repo: 'robonomics-example',\\n  relay: {\\n    enabled: true,\\n    hop: {\\n      enabled: true\\n    }\\n  },\\n  EXPERIMENTAL: {\\n    pubsub: true\\n  },\\n  config: {\\n    Addresses: {\\n      Swarm: [\\n        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star',\\n        '/dns4/1.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/2.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/3.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/'\\n      ]\\n    },\\n    Bootstrap: [\\n      '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',\\n      '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',\\n      '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',\\n      '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',\\n      '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',\\n      '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',\\n      '/dns4/1.pubsub.aira.life/tcp/443/wss/ipfs/QmdfQmbmXt6sqjZyowxPUsmvBsgSGQjm4VXrV7WGy62dv8',\\n      '/dns4/2.pubsub.aira.life/tcp/443/wss/ipfs/QmPTFt7GJ2MfDuVYwJJTULr6EnsQtGVp8ahYn9NSyoxmd9',\\n      '/dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw'\\n    ]\\n  }\\n})\\n\\nconst options = {\\n  messageProvider: new MessageProviderIpfs(ipfs),\\n  ...\\n};\\n```\\n\\n```\\noptions.account\\n```\\n\\nThis is an account object which will be used to sign messages. It's necessary to specify either account address (that one must be unlocked) or a private key (the address will be recovered from the given private key).\\n\\nOption `isSignPrefix` tells whether or not a prefix must be appended. Default is `true`.\\n\\n```JavaScript\\nconst options = {\\n  account: {\\n    address: '0x0000000000000000000000000000000000000000',\\n    privateKey: '0x0000000000000000000000000000000000000000000000000000',\\n    isSignPrefix: true\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.ens\\n```\\n\\nThis is a `ens` contract object. This one is not required. If it's necessary you may specify `address` of the contract if the network is not set to mainnet. `suffix` may be `sid` for sidechain or `eth` for mainnet. `eth` is default. `version` is the version of Robonomics Network. Default is the latest deployed version.\\n\\n```JavaScript\\nconst options = {\\n  ens: {\\n    address: '0x314159265dD8dbb310642f98f50C066173C1259b',\\n    suffix: 'eth',\\n    version: 5\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.lighthouse\\n```\\n\\nENS name of a lighthouse, not required. Default is `airalab.lighthouse.5.robonomics.eth`. It's possible to specify only the first part of the name, like `airalab`.\\n\\n```JavaScript\\nconst options = {\\n  lighthouse: 'airalab.lighthouse.5.robonomics.eth',\\n  ...\\n};\\n```\\n\\nIt's necessary to wait until full initialization\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\nrobonomics.ready().then(() => {\\n  console.log('Robonomics instance ready')\\n})\\n```\\n\\n## API\\n\\n### Messages\\n\\n#### Demand \\n\\nThe message specification\\n\\n```JavaScript\\nconst demand = {\\n  // REQUIRED\\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost\\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED \\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  validatorFee: 0,                                              // validator fee \\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendDemand`\\n\\nSigning and broadcasting the demand message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendDemand(demand).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onDemand`\\n\\nListens to demand messages with a defined model. If model is `null` returns any demand message.\\n\\n```JavaScript\\nrobonomics.onDemand(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Offer \\n\\nThe message specification\\n\\n```JavaScript\\nconst offer = {\\n  // REQUIRED \\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost \\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED\\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  lighthouseFee: 0,                                             // lighthouse fee\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendOffer`\\n\\nSigns and broadcasts an offer message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendOffer(offer).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onOffer`\\n\\nListens to offer messages with a defined model. If model is `null` returns any offer message\\n\\n```JavaScript\\nrobonomics.onOffer(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Result \\n\\nThe message specification\\n\\n```JavaScript\\nconst result = {\\n  // REQUIRED \\n  liability: \\\"0x0000000000000000000000000000000000000000\\\",  // liability contract address\\n  success: true,                                            // status of the task\\n  result: \\\"QmWXk8D1Fh5XFJvBodcWbwgyw9htjc6FJg8qi1YYEoPnrg\\\"  // ipfs hash of the rosbag log file\\n};\\n```\\n\\n`robonomics.sendResult`\\n\\nSigns and broadcasts a result message\\n\\n```JavaScript\\nrobonomics.sendResult(result).then(() => {\\n  console.log(\\\"ok\\\");\\n});\\n```\\n\\n`robonomics.onResult`\\n\\nListens to result messages. These results may be not valid. Valid results are stored in a liability contract\\n\\n```JavaScript\\nrobonomics.onResult(result => {\\n  console.log(result);\\n});\\n```\\n\\n### Smart Contracts \\n\\n#### Liability \\n\\n`liability.getInfo`\\n\\nReturn a property object of the contract\\n\\n```JavaScript\\nliability.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    model,\\n    objective,\\n    result,\\n    token,\\n    cost,\\n    lighthouseFee,\\n    validatorFee,\\n    demandHash,\\n    offerHash,\\n    promisor,\\n    promisee,\\n    lighthouse,\\n    validator,\\n    isSuccess,\\n    isFinalized\\n  }\\n  */\\n});\\n```\\n\\n`liability.onResult`\\n\\nWaits until a liability is finished. Returns a result\\n\\n```JavaScript\\nliability.onResult().then(result => {\\n  console.log(result);\\n});\\n```\\n\\n#### Lighthouse \\n\\n`robonomics.lighthouse.getInfo`\\n\\nReturns a property object of the contract\\n\\n```JavaScript\\nrobonomics.lighthouse.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    minimalStake,\\n    timeoutInBlocks,\\n    keepAliveBlock,\\n    marker,\\n    quota\\n  }\\n  */\\n});\\n```\\n\\n`robonomics.lighthouse.getProviders`\\n\\nReturns a list of providers on the lighthouse\\n\\n```JavaScript\\nrobonomics.lighthouse.getProviders().then(list => {\\n  console.log(list);\\n});\\n```\\n\\n##### Creation of a new lighthouse\\n\\n```JavaScript\\nconst minimalFreeze = 1000      // Wn\\nconst timeout = 25              // blocks\\nconst name = 'mylighthouse'     // lighthouse name\\nrobonomics.factory.methods.createLighthouse(minimalFreeze, timeout, name).send({ from: robonomics.account.address })\\n    .then((tx) => console.log(tx))\\n\\nrobonomics.factory.onLighthouse((lighthouse) => {\\n    console.log(lighthouse.name)\\n})\\n```\\n\\n##### Become a provider \\n\\nPreliminarily you must call `approve` for the tokens `XRT`\\n\\n```JavaScript\\nconst name = \\\"mylighthouse\\\";    // lighthouse name\\nconst stake = 1000;             // Wn\\nrobonomics.lighthouse.methods\\n  .refill(stake)\\n  .send({ from: robonomics.account.address })\\n  .then(tx => console.log(tx));\\n```\\n\\n#### Token \\n\\n`robonomics.xrt.getInfo`\\n\\nReturns property object of the token\\n\\n```JavaScript\\nrobonomics.xrt.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    name,\\n    totalSupply,\\n    decimals,\\n    symbol\\n  }\\n  */\\n});\\n```\\n\\n##### Check balance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .balanceOf(robonomics.account.address)\\n  .call()\\n  .then(balance => console.log(balance));\\n```\\n\\n##### Check allowance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .allowance(robonomics.account.address, robonomics.factory.address)\\n  .call()\\n  .then(allowance => console.log(allowance));\\n```\\n\\n##### Approve \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .approve(robonomics.lighthouse.address, 100)\\n  .send({\\n    from: robonomics.account.address\\n  })\\n  .then(tx => console.log(tx));\\n```\\n\\n## Links \\n\\n- [Website](https://robonomics.network/)\\n- [Minimal template of dApp](https://github.com/airalab/vue-dapp-robonomics-template)\\n- [dApp example](https://codesandbox.io/s/robonomics-vue-template-ewuiw)\\n\"}},{\"node\":{\"id\":\"e7acbac6ee9e5031c53eb4e90b2db5a1\",\"title\":\"How Robonomics Network Works\",\"path\":\"/docs/ja/robonomics-how-it-works/\",\"content\":\"\\nIn this section we will discuss the Robonomics Network scenario.\\n\\nThere are few main parts in the Robonomics network:\\n\\n- IPFS for the messages exchanging\\n- the Ethereum blockchain for storing new liability contracts\\n- a provider that is responsible for matching messages\\n- an agent\\n\\nLet's have a look at the following diagram that describes the scenario without any additional details:\\n\\n![The main scenario of Robonomics Network](../images/robonomics_network_scenario.jpg \\\"The main scenario of Robonomics Network\\\")\\n\\nThere are three types of [messages](/docs/market-messages) in IPFS: Demand, Offer, Result.\\n\\n**Below there is the specification for a Demand message:**\\n\\n| Field         | Type                      | Description                                       | Example                                           |\\n|-------------- |-------------------------  |------------------------------------------------   |------------------------------------------------   |\\n| model         | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model Identifier                   | QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC    |\\n| objective     | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    | QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r    |\\n| token         | ethereum_common/Address   | Operational token address                         | 0xbD949595eE52346c225a19724084cE517B2cB735        |\\n| cost          | ethereum_common/UInt256   | CPS behavioral model implementation cost          | 1                                                 |\\n| lighthouse    | ethereum_common/Address   | Lighthouse address                                | 0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1       |\\n| validator     | ethereum_common/Address   | Observing network address                         | 0x0000000000000000000000000000000000000000        |\\n| validatorFee  | ethereum_common/UInt256   | Observing network commission                      | 0                                                 |\\n| deadline      | ethereum_common/UInt256   | Deadline block number                             | 6393332                                           |\\n| sender        | ethereum_common/Address   | Message sender address                            | 0x0000000000000000000000000000000000000000        |\\n| signature     | std_msgs/UInt8[]          | Sender’s digital signature                        | 0x23bc…c617                                       |\\n\\n<!--\\n=============== ============================================================== ================================================ ================================================\\n     Field                                   Type                                                Description                                        Example\\n=============== ============================================================== ================================================ ================================================\\n  model          :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model Identifier                  QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC\\n  objective      :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model parameters in rosbag file   QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r\\n  token          :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Operational token address                        0xbD949595eE52346c225a19724084cE517B2cB735\\n  cost           :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   CPS behavioral model implementation cost         1\\n  lighthouse     :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Lighthouse address                               0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1\\n  validator      :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Observing network address                        0x0000000000000000000000000000000000000000\\n  validatorFee   :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Observing network commission                     0\\n  deadline       :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Deadline block number                            6393332\\n  sender         :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Message sender address                           0x0000000000000000000000000000000000000000\\n  signature      std_msgs/UInt8[]                                               Sender's digital signature                       0x23bc...c617\\n=============== ============================================================== ================================================ ================================================\\n-->\\n\\nAn Offer message has the same fields but instead of `validatorFee` there is a `lighthouseFee` field. This field determines the amount of fee for a lighthouse.\\n\\nNow let's have a look at the following diagram and walk step by step from the moment of publishing messages to a liability finalization.\\n\\n![Robonomics Network detailed scenario](../images/robonomics_network_detailed_scenario.jpg \\\"Robonomics Network detailed scenario\\\")\\n\\nA liability contract is created only if the following fields match: `model`, `objective`, `token`, `cost`. A provider of Robonomics Network watches every message and finds those ones that have a match.\\nAfter the match is found the provider calls `createLiability(demand, offer)` method from the contract factory where `demand` and `offer` are serialized.\\n\\nBelow is the package diagram for the Robonomics communication stack:\\n\\n![Robonomics communication stack](../images/robonomics_network_communication_stack.jpg \\\"Robonomics communication stack\\\")\\n\\nThe factory deserializes arguments and recovers *promisee* and *promisor* addresses from signatures.\\n\\nNext step is token transfer. The factory transfers **cost** tokens from the *promisee* address and **validatorFee** and **lighthouseFee** from the *promisor* address to the new liability address.\\n\\n> - **You should approve sufficient amount of tokens for the factory.**\\n> - **It's not required to approve tokens from the *promisor* address if fees are null.**\\n\\nNow the factory emits a NewLiability event with the liability address. An agent gets the address, reads fields, perform a task and at the same time writes a log file in rosbag format.\\n\\nWhen the work is done the agent sends a Result message with the following fields: hash of the rosbag file, a success flag, a signature. If the **validator** field is not null it means that only validator is able to finalize the liability.\\n\\nAfter the successful liability finalization the agent gets **cost** tokens. Otherwise, the *promisee* gets tokens back.\"}},{\"node\":{\"id\":\"2c054004663fb1883fe3404a76683811\",\"title\":\"Robonomics DApp Overview\",\"path\":\"/docs/ja/robonomics-dapp-overview/\",\"content\":\"\\nYou can operate with Robonomics Network using the interface of [Robonomics Network Dapp (decentralized application)](https://dapp.robonomics.network/#/). It is available in browsers with [Metamask extension](https://metamask.io). On the first page you will see the statistics of the network:\\n\\n![Robonomics DApp's first page](../images/robonomics_dapp_first_page.jpg \\\"Robonomics DApp's first page\\\")\\n\\nLet's have a look at the bottom table \\\"Robonomics Telemetry\\\".\\n\\nEvery time an instance of AIRA is launched it broadcasts a piece of information about itself. Usually it takes some time for the Dapp to receive data from an instance of AIRA.\\n\\nHave a brief look at the page [\\\"AIRA installation\\\"](/docs/aira-installation) to understand where `IPNS` and `Address Eth` came from.\\n\\n## IPNS\\n\\nYou can treat it as a unique identifier of your instance in IPFS network. Under that name AIRA publishes metadata about itself.\\n\\n## Address Eth\\n\\nBy default AIRA generates new Ethereum address for you (it's [possible](/docs/aira-faq#how-to-change-ethereum-address-of-aira) to generate new one).\\n\\nIt's mainly used to sign all the outcoming messages.\\n\\n## Lighthouse\\n\\nIn Robonomics Network an agent must choose a lighthouse to work on. By default it's `airalab.lighthouse.5.robonomics.eth`.\\n\\nYou can choose existing one or create your own on [Lighthouses](https://dapp.robonomics.network/#/lighthouse) page.\\n\\n## Peers\\n\\nThe amount of IPFS pubsub [peers](/docs/aira-faq#how-to-check-the-quantity-of-ipfs-peers).\\n\\n## Date\\n\\nThe date and time of last update\\n\\n## Network\\n\\nRobonomics Network officially works in Ethereum Mainnet.\\nThere is also [Sidechain](https://github.com/airalab/airalab-sidechain) which is mostly for testing purpose.\\n\\n\\n\"}},{\"node\":{\"id\":\"e4f7e773b1a4ce70a9efa64c1cf881e0\",\"title\":\"Contracts deployment\",\"path\":\"/docs/ja/robonomics-contracts-deployment/\",\"content\":\"\\nRobonomics network works on top of the existing Ethereum network. The protocol is implemented by smart contracts. A source code is on [Github](https://github.com/airalab/robonomics_contracts). Airalab team deploys new version of contracts and supports a current one. \\n\\nIn this lesson we are going to learn more about these contracts. To do this we will deploy our test copy. Also we are going to use these contracts in the future lessons. \\n\\nYou need a client running Ethereum node. You can use either one of existing network (e.g. Mainnet, Ropsten, Kovan) or your local one. For testing purpose we suggest to use this [docker container](https://github.com/f-o-a-m/cliquebait) \\n\\n    $ docker run --rm -d -p 9545:8545 -p 9546:8546 foamspace/cliquebait:latest\\n\\nNext step is obtain a copy of robonomics contracts source code:\\n\\n    $ git clone --recursive https://github.com/airalab/robonomics_contracts\\n\\nA file truffle.js contains available networks for migration. We will work with development network. When you are in `robonomics_contracts` directory install dependencies and run a migration:\\n\\n    npm install // to install dependencies\\n    truffle migrate --network development\\n\\nIt's time to learn how to create a new lighthouse. For more information about Robonomics network and Lighthouse in particular read [white paper](http://static.robonomics.network/docs/book-the-economy-of-robots-1-2017/robonomics.network-book-the-economy-of-robots-1-2017-en.pdf). Briefly lighthouse o distributes the running time of providers. Every lighthouse serves its own broadcast channel. Ask and Bid messages come into this channel. XRT tokens are used as a payment. \\n\\nWhen XRT contracts was deployed some tokens were issued on our account. Let's check the balance:\\n\\n    $ truffle --network development console\\n    > xrt = XRT.at(XRT.address)\\n    > xrt.balanceOf(web3.eth.accounts[0])\\n\\nAnd that's how we create a lighthouse:\\n\\n    > factory = LiabilityFactory.at(LiabilityFactory.address)\\n    > tx = factory.createLighthouse(1000, 10, \\\"test\\\")\\n    > tx.then(x => {laddress = x.logs[0].args.lighthouse})\\n    > l = LighthouseLib.at(laddress)\\n\\nInstead of deploying a lighthouse contract every time we need a new one, we ask a factory to do this job. A `l` variable contains lighthouse instance. The lighthouse should be able to spend our tokens. Let's make an approve and check everything went well:\\n\\n    > xrt.approve(l.address,1000)\\n    > xrt.allowance(web3.eth.accounts[0],l.address)\\n\\nAnd a very important step is become a worker:\\n\\n    > l.refill(1000)\\n\\nEach worker has to put a stake. In this case it's 1000 Wn.\\n\\nBelow is a table of our addresses:\\n\\n| Contract          | Address                                       | ENS name                          |\\n|------------------ |--------------------------------------------   |---------------------------------- |\\n| ENSRegistry       | 0x80c77a7de64a15450bb8cf45ece4fbb7bae6fb49    |                                   |\\n| XRT               | 0x673583a369eb3a830a5571208cf6eb7ce83987f8    | xrt.3.robonomics.eth              |\\n| LiabilityFactory  | 0x1b3190e00c1903266862af1f31714d4b81ef59b2    | factory.3.robonomics.eth          |\\n| Lighthouse        | 0xd2b78c032b6c8851a8b6cbf950caa02a77618d8e    | test.lighthouse.3.robonomics.eth  |\\n\"}},{\"node\":{\"id\":\"2d738d3b4f1aa546b8498035228879a7\",\"title\":\"Robonomics Coffee\",\"path\":\"/docs/ja/robonomics-coffee/\",\"content\":\"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](../images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](../images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](../images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](../images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](../images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](../images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](../images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](../images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](../images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](../images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](../images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](../images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](../images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"}},{\"node\":{\"id\":\"51d632384678015c9a079e2499038e70\",\"title\":\"Become a Provider\",\"path\":\"/docs/ja/robonomics-become-a-provider/\",\"content\":\"\\nThis page describes how to create a lighthouse and become a provider in the Robonomics network.\\n\\n## Prepare an address\\n\\nFirst of all, an Ethereum address is required. You must have access to a private key of the address. In case you don't have one, below are steps to create an address via [Parity](https://www.parity.io/ethereum/).\\n\\n```\\n$ sudo snap install parity\\n$ parity.ethkey generate random\\nsecret:  15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539\\npublic: 38b800bfd90d486c78c646da79bb94b9d038aca8aad221062ce1b148df7764bfef02f6b3cf931786b6997540b798ea226ae60bd201c222d8f702e408a1a5cbff\\naddress: c531fa8f141493df3da264a864bdcbec19695b4c\\n```\\n\\nThe `secret` field is a private key, you'll need it to run the provider client. Save it to a file:\\n\\n```\\n$ echo '0x15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539' > private.key\\n```\\n\\nThe next step is to deposit some ethers and XRT tokens to the address which is held in the `address` field.\\n\\n## Create a lighthouse\\n\\nGo to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse) and fill in a name in the right side:\\n\\n![The Right Side](../images/become_a_provider_1.jpg \\\"The Right Side\\\")\\n\\nClick on the `Create lighthouse and connect to the network` button and sign a transaction. After a while you should see:\\n\\n![Success of Creating a Lighthouse](../images/become_a_provider_2.jpg \\\"Success of Creating a Lighthouse\\\")\\n\\nNow it's time to put a stake. Select the new lighthouse and click `Connect to the network`:\\n\\n![Selecting the Lighthouse](../images/become_a_provider_3.jpg \\\"Selecting the Lighthouse\\\")\\n\\nOn this page in the `Provider` section click the `Approve` button, sign a transaction. When it's mined click the `Refill` button and do the same.\\n\\n## Install the client\\n\\nNow you need to install [robonomics-tools](https://github.com/airalab/robonomics-tools) at least 0.4.2 version. You can build from the source or do the following steps:\\n\\n**Make sure you have Nix and Stack installed:**\\n    \\n```\\n$ curl -sSL https://get.haskellstack.org/ | sh\\n$ curl https://nixos.org/nix/install | sh\\n```\\n\\n* Setup Airalab binary cache at [https://aira.cachix.org](https://aira.cachix.org/)\\n* Import Airalab channel:\\n\\n```\\n$ nix-channel --add http://aira.life/channels/aira-unstable/ aira\\n$ nix-channel --update\\n```\\n* Install from the binary cache:\\n\\n```\\n$ nix-env -iA aira.robonomics-tools\\n```\\n* Run the client:\\n\\n```\\n$ xrtd --lighthouse mobilerobotics.lighthouse.5.robonomics.eth --private $(cat private.key)\\n```\\n\\n**Get familiar with the `xrtd` options via `xrtd --help`.**\\n\\n## Test the provider\\n\\nTo test your provider go again to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse/) and connect to the just created lighthouse.\\n\\nAt the bottom you should see the `TEST LIGHTHOUSE` section.\\n\\nClick on the `Demand` button and then on the `Offer` one. You should see something similar to:\\n\\n![Demand and Offer messages](../images/provider_mobilerobotics_demand_offer.jpg \\\"Demand and Offer messages\\\")\\n\\nDon't forget to sign every message with the MetaMask extension.\\n\\nFinally you should see a new liability contract created:\\n\\n![Liability is created](../images/provider_mobilerobotics_liability.jpg \\\"Liability is created\\\")\\n\"}},{\"node\":{\"id\":\"13d6b0afc508706f9aea25da687c6f0f\",\"title\":\"Robonomics IO Overview\",\"path\":\"/docs/ja/rio-overview/\",\"content\":\"\\nThe [crate](https://crates.robonomics.network/robonomics_io/index.html) provides a convenient way to interact with blockchain and includes a set of tools. The latest release can be found [here](https://github.com/airalab/robonomics/releases)\\n\\n```\\n% ./robonomics io\\nrobonomics-io 0.21.0\\nRobonomics Framework I/O operations\\n\\nUSAGE:\\n    robonomics io [FLAGS] [OPTIONS] <SUBCOMMAND>\\n\\nFLAGS:\\n        --dev        Specify the development chain\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nOPTIONS:\\n    -d, --base-path <PATH>        Specify custom base path\\n        --chain <CHAIN_SPEC>      Specify the chain specification (one of dev, local, or staging)\\n    -l, --log <LOG_PATTERN>...    Sets a custom logging filter. Syntax is <target>=<level>, e.g. -lsync=debug\\n\\nSUBCOMMANDS:\\n    help     Prints this message or the help of the given subcommand(s)\\n    read     Read information from device\\n    write    Write information into device\\n```\\n\\n## The Pipeline Philosophy \\n\\nThe tool is designed in order to be included in a pipeline chain of processes. From Unix user experience everyone is familiar with commands like:\\n\\n```\\nps aux | grep robonomics\\n```\\n\\nIt means standard output produced by the `ps` program becomes standard input for the `grep` program. \\n\\nThe `robonomics io` consists of several subcommands with reading, writing abilities or both. It treats everything as a virtual or physical device ([everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file))\\n\\n## Read Overview\\n\\nIn general `read` means it reads data from a device or a network and prints it in `stdout`.\\n\\nHow to use it for:\\n\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io read\\nrobonomics-io-read 0.4.0\\nRead information from device\\n\\nUSAGE:\\n    robonomics io read <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    help      Prints this message or the help of the given subcommand(s)\\n    ipfs      Download data from IPFS storage\\n    launch    Robot launch request events\\n    pubsub    Subscribe for broadcasing data\\n    sds011    Nova SDS011 particle sensor\\n```\\n\\n## Write Overview\\n\\nUsually it writes data to blockchain or publishes to pubsub channel. \\n\\nHow to use it for:\\n\\n* [datalog](/docs/rio-datalog)\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io write\\nrobonomics-io-write 0.4.0\\nWrite information into device\\n\\nUSAGE:\\n    robonomics io write <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    datalog    Data blockchainization subsystem command\\n    help       Prints this message or the help of the given subcommand(s)\\n    ipfs       Upload data into IPFS storage\\n    launch     CPS launch subsystem command\\n    pubsub     Broadcast data into PubSub topic\\n```\\n\\n## Local Testnet\\n\\nFor testing purpose it's possible to run the development environment:\\n\\n```\\n% ./robonomics --dev --rpc-cors all\\n```\\n\\n`--rpc-cors all` allows the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) to be connected to local node. After launching the node, go to the dapp, click on Robonomics icon in the upper left corner, choose Development and put node's local address\\n\\n![Robonomics Dapp Connect to Local Node](../images/robonomics-dapp-connect-local.jpg \\\"Robonomics Dapp Connect to Local Node\\\")\\n\\nFinally click Switch and you should be connected to the local node. Check out Accounts tab. There you can create new accounts and transfer tokens.\\n\\n\"}},{\"node\":{\"id\":\"6a710f8046cf246621eeb62d6e0d4056\",\"title\":\"Robonomics IO Launch\",\"path\":\"/docs/ja/rio-launch/\",\"content\":\"\\nA simple way to turn on and off an IoT device or a robot. Basically sending \\\"ON\\\" will result in `true` state for a device, anything else will result in `false`.\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Accounts on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Usage\\n\\nTo see the result of transaction first of all run `read` part:\\n\\n```\\n% ./robonomics io read launch\\n```\\n\\nNow let's turn a robot on:\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nThen you should see in the first terminal window:\\n\\n```\\n% ./robonomics io read launch\\n5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH >> 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL : true\\n```\\n\\nLet's describe all the accounts and options above.\\n\\n* `-r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL` means robot's address\\n* `-s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` private key of the account to launch from (must have tokens for a transaction)\\n* `5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH` address that launches a robot\\n* `true` turn it on\\n\\nIf we pass anything else but \\\"ON\\\" the state becomes `false`\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\\nand\\n\\n```\\n% ./robonomics io read launch --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"80dfb9552daca0abf7da618de716cc9f\",\"title\":\"Robonomics IO IPFS\",\"path\":\"/docs/ja/rio-ipfs/\",\"content\":\"\\nIt serves downloading and uploading files from/to IPFS network\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Running [IPFS](https://ipfs.io/#install) daemon \\n\\n## Write\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\n## Read\\n\\n```\\n% echo QmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy | ./robonomics io read ipfs\\nHello Robonomics\\n```\\n\\n## Remote IPFS node\\n\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs --remote https://ipfs.infura.io:5001/\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\nThe same applies for `read`\\n\\n\"}},{\"node\":{\"id\":\"e9f07ff7ed181e69c4daac95677a99d5\",\"title\":\"Robonomics IO Datalog\",\"path\":\"/docs/ja/rio-datalog/\",\"content\":\"\\nDatalog module allows you to store any string on blockchain\\n\\nhttps://www.youtube.com/watch?v=rs67AMyd-gE\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Account on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Write\\n\\nAssuming local node is running:\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nwhere `0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` is a private key for the account with tokens.\\nIn this example the public key is 5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH. Let's go to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/)\\nand see what happened.\\n\\nIn the Dapp go to Developer -> Chain state. In the \\\"selected state query\\\" list choose datalog and below choose your account. Click plus button on the right and you should see the following:\\n\\n![Robonomics Chain State Datalog](../images/robonomics-dapp-chain-state-datalog.jpg \\\"Robonomics Chain State Datalog\\\")\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"9361805a58ef34738150c8dab88b1339\",\"title\":\"Raspberry Setup\",\"path\":\"/docs/ja/raspberry-setup/\",\"content\":\"\\nFor both methods, the first thing you need to do is setup a Raspberry Pi.\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card and run the Imager program. From the menu, select 64-bit Ubuntu Server as the operating system and ensure to select your SD card from the storage dropdown, and then press `write`.\\n\\n![pi](../images/home-assistant/pi.png)\\n\\nOpen the SD card's storage from your computer and navigate inside the root folder of the card. The name of the folder should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Copy the below text and paste it into the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end (also you can use `arp -a`):\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\n\\nIn this example we can see that the Raspberry Pi's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\".\\n\\n## Home Assistant\\n\\nNow we need to install Home Assistant to the Raspberry Pi. Detailed instructions can be found [here](https://www.home-assistant.io/installation/linux#install-home-assistant-core). You need to install `Home Assistant Core`. It's actual version is 2021.11.5 and instruction assumes that we already have installed Python 3.9 or newer.\\n\\nUpdate your system and install necessary packages:\\n```bash\\nsudo apt-get update\\nsudo apt-get upgrade -y\\nsudo apt-get install -y python3 python3-dev python3-venv python3-pip libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 tzdata libcurl4-openssl-dev\\n```\\n\\nCreate user `homeassistant` and the directory for homeassistant core:\\n```bash\\nsudo useradd -rm homeassistant\\nsudo mkdir /srv/homeassistant\\nsudo chown homeassistant:homeassistant /srv/homeassistant\\n```\\n\\nNext up is to create and change to a virtual environment for Home Assistant Core. This will be done as the homeassistant account.\\n```bash\\nsudo -u homeassistant -H -s\\ncd /srv/homeassistant\\npython3.9 -m venv .\\nsource bin/activate\\n```\\n![terminal1](../images/home-assistant/terminal1.png)\\n\\nThen install required Python packages:\\n```bash\\npython3 -m pip install wheel\\npip3 install homeassistant==2021.11.5\\n```\\n\\nStart Home Assistant Core for the first time. This will complete the installation for you, automatically creating the `.homeassistant `configuration directory in the `/home/homeassistant` directory, and installing any basic dependencies:\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant$ hass\\n```\\n\\nYou can now reach your installation via the web interface on `http://%RASPBERRY_IP_ADDRESS%:8123`. \\nIn this example: `http://192.168.43.56:8123`\\n\\n> You don't need to connect you raspberry to the screen, you can open Web UI from any computer connected to your local network\\n\\nCreate user and finish setup (first setup is described [here](https://www.home-assistant.io/getting-started/onboarding/) in more details), then stop Home Assistant with `Ctrl+C`.\\n\\nAfter this installation process has been completed, from the `python_scripts` folder import some necessary scripts:\\n\\n```bash\\nmkdir python_scripts\\ncd python_scripts/\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/send_datalog.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/control.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/utils.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/create_config.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/encrypt.py\\n```\\n\\nTo use Robonomics you need account (instructions of how to create it are [here](/docs/create-account-in-dapp/)). Add mnemonic or raw seed from it in `config.config` file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\n\\nIn this format:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\n\\n## Substrate Interface\\n\\nTo pub data to Robonomics you need to install `substrate-interface` python package (you need to install RUST before) to your raspberry. \\n\\nInstall RUST:\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nsource $HOME/.cargo/env\\nrustup default nightly\\n```\\n\\nAnd install necessary python packages to the virtual environment:\\n```bash\\npip3 install pynacl==1.4.0 packaging pycurl\\npip3 install substrate-interface==1.1.2 --use-feature=2020-resolver\\npip3 install python-miio==0.5.8 --use-feature=2020-resolver\\n```\\nBe sure that you-re on virtual environment:\\n\\n![terminal1](../images/home-assistant/terminal2.png)\\n\\n## Systemd services\\n\\nNow change user (you can run under any user, which allows you to use sudo):\\n\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant/python_scripts$ exit\\n```\\n\\nCreate new service for home assistant start: \\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/home-assistant@homeassistant.service \\n```\\n\\nPaste the following:\\n\\n```\\n[Unit]\\nDescription=Home Assistant\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/hass -c \\\"/home/%i/.homeassistant\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nDo the same for robonomics control service:\\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/robonomics-control@homeassistant.service \\n```\\n\\nWith:\\n```\\n[Unit]\\nDescription=Robonomics Control\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/python3.9 \\\"/srv/%i/python_scripts/control.py\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nAnd enable both services:\\n```bash\\nubuntu@ubuntu:~$ sudo systemctl enable home-assistant@homeassistant.service\\nubuntu@ubuntu:~$ sudo systemctl enable robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\"}},{\"node\":{\"id\":\"8dccbe7afa6d28628209c87fd70ef4fe\",\"title\":\"Setup with Prepared Image\",\"path\":\"/docs/ja/raspberry-image/\",\"content\":\"## Image\\nWe prepared an image to make it easier to use the Home Assistant with Xiaomi Miio and Robonomics with the Raspberry Pi.\\n\\nYou can get it here: [download image](https://ipfs.io/ipfs/bafybeihzzqoyycflxzxlxy2aplkzxo537ggqatdlbr24b4dnlyrtpkp2eu)\\n\\nSHA256 checksum: `7ec5ea99d7e339b54cbeaaae58c8295411769d27732ec2b5464dbb495ba24120`\\n\\nWhat preinstalled in the image:\\n- Ubuntu Server 21.10 (3/4/400): 64-bit server OS for arm64 archtectures\\n- Python 3.9.7\\n- Home Assistant Core 2021.11.5\\n- rustc 1.59.0-nightly (efec54529 2021-12-04)\\n- substrate-interface 1.1.2\\n- python-miio 0.5.8\\n\\n## How To Use The Prepared Image\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Insert SD card into your PC and run the Imager program. In `Operating System` select `Use custom` and choose the previously downloaded `.img.gz` file. Then select your SD card in the `Storage` dropdown and click `WRITE`.\\n\\n![imager](../images/home-assistant/use_custom_image.png)\\n![imager](../images/home-assistant/imager_prep.png)\\n\\nAfter writing is comleted, open the SD card's files on your computer and navigate inside the root folder of the card. The name should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Write this to the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end:\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\nThere raspberry's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\". Then follow the instructions to change the password.\\n\\nThen you need to write the seed from your Robonomics account to config file. Open it:\\n```bash\\nsudo -u homeassistant -H -s\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add mnemonic:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\nThen restart Robonomics Control service:\\n```bash\\nsystemctl restart robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n\"}},{\"node\":{\"id\":\"b75101e944b78d01ca074c89c8c659ee\",\"title\":\"R&D Based on Robonomics Network\",\"path\":\"/docs/ja/r-and-d-based-on-robonomics-network/\",\"content\":\"\\nFor over 4 years, the Robonomics project participants completed 13 R&D projects in the process of writing the current version of the Robonomics platform, including:\\n\\n### Launching a drone under the control of a decentralized computer.\\n2016 - Successful field test of 3DR X8 drone compatibility with Drone Employee software.\\nBelow you can observe a workflow in which a person sends a Drone transaction through the Ethereum Blockchain.\\n\\nhttps://www.youtube.com/watch?v=V_3rcP2Duv0&t=1s\\n\\n### Management of a fleet of drones in a decentralized network.\\n[Distributed Sky](https://airmarket.io/wp-content/uploads/2018/09/Distributed-Sky-Whitepaper-v3.0.pdf) is the backbone of the Unmanned aircraft system traffic management (UTM). It uses a global network of computers to process and store identities, traffic and other sensitive information, and uses cryptography to make the UTM process secure and scalable.\\nBelow is the video of Drone Passport agent in action.\\n\\nhttps://www.youtube.com/watch?v=yxGTOkGkBJ8\\n\\n### Tokenization of data from IoT devices.\\n\\nThe 4th industrial revolution is flying the flag of CPSs’ total integration into mass production and rendering services. Machines do not engage in empty talk, they are honest in their work and can be an independent party supplying information, based on algorithmic analysis of which the network itself can emit new units of any value.\\nValues based on the labor of machines will be much more interesting for the new generation than other values, the emission of which is built on any other principle. More information available [here](https://blog.aira.life/tokenization-and-the-4th-industrial-revolution-3208022be747)\\n\\n### Digital markets for robots.\\n\\n### Industrial zone management with capital.\\n[The article](https://ieeexplore.ieee.org/abstract/document/8525391) presents the architecture of communication protocol for modern industrial processes and business based on cyber-physical systems - Industry 4.0. The main attention is paid to one of the key trends of this concept - to economical autonomous agents i.e. to robots or smart things, which are able to make decisions independently about their economic actions. Agents begin to fully participate in business processes, so it is important to automate the processes and ensure formal and secure communication between multiple heterogeneous agents, taking into account the economic component of the industry. The article shows how to organize economic interaction between agents using a peer-to-peer network based on decentralized Blockchain technology and smart contracts. More information about Industry 4.0 may be found in a video below.\\n\\nhttps://www.youtube.com/watch?v=yuxOF_z70us\\n\\n### Drones, sensors, and blockchain for monitoring the quality of water on the Volga.\\nAs part of [this river project](https://github.com/airalab/drone_on_volga), the drone offers its services through a web application allowing any user to request the service. Typically, the mission generates parameters such as drone position, travel speed, measured water quality parameters, and other minor requirements.\\nThe Robonomics network is used to communicate with the robot. With its help, the robot can offer its services, and citizens or government officials can order them by making a cryptocurrency payment through the website. The Robonomics network is built on the Ethereum blockchain platform and the IPFS protocol, which record the hash of sensor measurements in the public blockchain and thus protect historical data from possible falsification.\\nFascinating video about experiments with water drone is below.\\n\\nhttps://www.youtube.com/watch?v=Mtqm5y6Bolo\\n\\n### Civilian observatory networks.\\nIn August 2018 Airalab with support of Smart Distribution (Libelium distributor in Russia) [set up a measuring network in a living district in Tolyatti, Russia](https://www.libelium.com/libeliumworld/success-stories/preventing-asthsma-sensor-network-air-quality-pm10-dust-in-play-area/).\\nThe aim was to create the basis for the implementation of an air quality monitoring network in areas of special vulnerability (schools, playgrounds, nursing homes, hospitals, etc.) that can provide local authorities with information to take measures to protect their citizens.\\nAn example of using a sensor is shown in a video below. Also, source code may be found [here](https://github.com/airalab/sensors-connectivity).\\n\\nhttps://www.youtube.com/watch?v=shqey3tmNUk\\n\\n### Robot artist Gaka-chu.\\nModern technologies make human life more comfortable and more fun, freeing up time for reflection and experimentation.\\nIt was a series of reflections on the static nature of the industry that led the development team to the idea of ​​conducting an experiment showing the autonomous transformation of production for a specific type of product.\\nSuch an experiment became a [robot artist](https://github.com/airalab/robot_painter/) - a small, clumsy KUKA manipulator living in a large world of serious industrial robots. And his name is Gaka-chu. Why? Because of the love of drawing: \\\"gaka\\\" in Japanese is \\\"artist\\\". And \\\"chu\\\" was added for an inexplicable love for Pokemons.\\n\\nhttps://youtu.be/xSD_lsrAA0I\\n\\n### Issuance of green certificates based on the data from renewable energy sources.\\nThe conceptual goal of [DAO IPCI](https://ipci.io/ru/) is to provide a common space, common environment, tools and ecosystem that is universal, reliable, easy to use, allowing a variety of stakeholders, including businesses and people, to record quantitative impacts and quantitative commitments, invest in negative impact mitigation projects, offset the carbon footprint, acquire and trade mitigation results, join existing programs or launch new ones. Source code is provided [here](https://github.com/DAO-IPCI/DAO-IPCI).\\n\\nhttps://www.youtube.com/watch?v=q9plB0TjUnw&list=PLLepqB9oh7WvUVzbeaiwQojrip2tLPA6P\\n\\n### Roadspace negotiation for autonomous cars.\\nOur goal was to develop a [decentralized system](https://github.com/khssnv/mobi_grand_challenge) for road space negotiation where autonomous vehicles can pay for routes and right of way. We believe a market-based approach can be used to alleviate a traffic congestion problem.\\n\\nhttps://youtu.be/JFQTknMZOYg\\n\\n### Blockchain in the tasks of the chemical industry.\\nOriginally the following task was set: developing a [quality control system](https://github.com/Vourhey/chemistry-quality-control) for the production of a certain chemical product. Why is monitoring the quality so important here? The main active substance of this chemical product is chlorine dioxide. It is hazardous to health in high concentrations. And if the concentration is below normal, then this chemical product is useless.\\nAnd what does Blockchain have to do with it? Blockchain helps building trust to the manufacturing company. The consumer knows that no one can change the information in the Blockchain. That means that the manufacturing company can not forge the results of the audit.\\n\\n### Control of equipment maintenance process by supply chain participants based on IoT data.\\n\\n### Robot as a service in service robotics.\\nRobonomics is the ready-to-work and open-source platform which you can use to connect your robot as a service for end-users, they call it [‘Robot-as-a-Service’](https://blog.aira.life/how-can-you-hire-a-robot-176ba29da565). Robonomics support Web3 technologies that implement the exchange of technical and economic information between humans and machines. Robonomics is a purely technical and open source project.\\n\\nhttps://www.youtube.com/watch?v=IEgvXcj3nSo\"}},{\"node\":{\"id\":\"f3cf38e1254e040be7421ebb43f8c765\",\"title\":\"Playground Overview\",\"path\":\"/docs/ja/playground-overview/\",\"content\":\"\\nRobonomics allows to use robots as autonomous agents that receive commands from a human or another robot and do some useful work, storing a report of their actions in Blockchain. The interaction between the robot and the Robonomics platform is quite simple with a [Robonomics IO](/docs/rio-overview).\\n## What Robots You Can Control\\nThe playground section contains examples of connecting different robots to Robonomics which everyone can try to repeat step by step. In this section you can try to control:\\n* [an Unmanned Aerial Vehicle](/docs/iris-drone/)\\n* [a Mars Rover](/docs/connect-mars-curiosity-rover-under-robonomics-parachain-control/)\\n* [a Manipulator](/docs/kuka/)\\n* [an industrial Baxter Robot](/docs/baxter2/)\\n\\nSince all robots are available as simulation models, you don't need any special hardware. So you can try to connect the robot to Robonomics Network right now.\\n## How Do You Control the Robot\\nAll of our Demos are launched in a local network, however you can connect a robot to the live networks in the same way.\\n\\nAll Demos in this section follow a similar scenario. You [create an account](/docs/create-account-in-dapp/) for the robot and send him some units for paying transactions. Then the user sends an `ON/OFF` transaction to the robot's address, the robot receives it and starts working. After the job is done the telemetry is saved in IPFS and the file hash is sent to datalog. So at any time you can see how the robot performed its work.\\n## Connect Your Own Robot\\nIn addition you can create your own control package for any ROS-compatible device with [this](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) instruction.\\n\\n\"}},{\"node\":{\"id\":\"d87fad7fc0438db5796bb909f6c368b5\",\"title\":\"Market messages\",\"path\":\"/docs/ja/market-messages/\",\"content\":\"\\nMarket messages is used for exchange **Demand** and **Offer** information. It also used for delivery **Result** messages with liability execution reports.\\n\\n> This is spec for Robonomics `Generation 5`.\\n\\n- Currently for message delivery is used [IPFS PubSub](https://ipfs.io/blog/25-pubsub/) broadcaster.\\n- IPFS PubSub **topic** is set according to *Lighthouse [ENS](https://ens.domains/) name*.\\n\\n## Messages content\\n\\nRobonomics market message use [JSON](https://www.json.org/) data format.\\n\\n\\n### Demand\\n\\n| Field | ROS Type | Description |\\n|-------------- |-------------------------  |------------------------------------------------ |\\n| model | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model identifier |\\n| objective | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model parameters in rosbag file |\\n| token | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Operational token address |\\n| cost | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | CPS behavioral model execution cost |\\n| lighthouse | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Lighthouse contract address |\\n| validator | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Observing network address |\\n| validatorFee  | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Observing network fee |\\n| deadline | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Deadline block number |\\n| nonce | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Robonomics message counter |\\n| sender | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Message sender address |\\n| signature | std_msgs/UInt8[] | Sender’s Ethereum signature |\\n\\n### Offer\\n\\n| Field             | ROS Type                  | Description                                       |\\n|---------------    |-------------------------  |------------------------------------------------   |\\n| model             | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model identifier                   |\\n| objective         | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    |\\n| token             | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Operational token address                         |\\n| cost              | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | CPS behavioral model execution cost               |\\n| validator         | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Observing network address                         |\\n| lighthouse        | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Lighthouse contract address                       |\\n| lighthouseFee     | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Liability creation fee                            |\\n| deadline          | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Deadline block number                             |\\n| nonce             | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Robonomics message counter                        |\\n| sender            | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Message sender address                            |\\n| signature         | std_msgs/UInt8[]          | Sender’s Ethereum signature                       |\\n\\n### Result\\n\\n| Field         | ROS Type                  | Description                       |\\n|-----------    |-------------------------  |---------------------------------- |\\n| liability     | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Liability contract address        |\\n| result        | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | Liability result multihash        |\\n| success       | std_msgs/Bool             | Is liability executed successful  |\\n| signature     | std_msgs/UInt8[]          | Sender’s Ethereum signature       |\\n\\n## Messages signing\\n\\nBefore signing the messages is packed using [abi.encodePacked](https://solidity.readthedocs.io/en/latest/abi-spec.html#non-standard-packed-mode\\n) solidity finction and hashed by Keccak_256.\\n\\n```\\n   demandHash = keccak256(abi.encodePacked(\\n        _model\\n      , _objective\\n      , _token\\n      , _cost\\n      , _lighthouse\\n      , _validator\\n      , _validator_fee\\n      , _deadline\\n      , IFactory(factory).nonceOf(_sender)\\n      , _sender\\n      ));\\n```\\n\\n**`nonce` parameter is counted by factory smart contract and incremented for each created liability smart contract.**\\n\\nMessage hash are signed using Ethereum ``secp256k1`` [signature](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sign).\\n\"}},{\"node\":{\"id\":\"82663754528cff8b1c970d83669613b4\",\"title\":\"Control Kuka manipulator with robonomics\",\"path\":\"/docs/ja/kuka/\",\"content\":\"\\nVideo with an example of work can be found here:\\n\\nhttps://youtu.be/z55HepXbHr8\\n\\n***\\n\\n## Requirements\\n* ROS melodic, Gazebo (installation instraction [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n* Some extra packages\\n```bash\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n* IPFS 0.4.22 (download from [here](https://www.npackd.org/p/ipfs/0.4.22) and install)\\n```bash\\ntar -xvzf go-ipfs_v0.4.22_linux-386.tar.gz\\ncd go-ipfs/\\nsudo bash install.sh\\nipfs init\\n```\\n* pip3\\n```bash\\nsudo apt-get install python3-pip\\n```\\n* ipfshttpclient\\n```bash\\npip3 install ipfshttpclient\\n```\\n* substrate-interface\\n```bash\\npip3 install substrate-interface\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n* IPFS browser extension (not necessary)\\n***\\n## Installation\\nInstall Kuka manipulator and control packages\\n```bash\\ncd catkin_wc/src/\\ngit clone https://github.com/orsalmon/kuka_manipulator_gazebo\\ngit clone https://github.com/LoSk-p/kuka_controller\\ncd ..\\ncatkin_make\\n```\\n***\\n## Running gazebo model\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch manipulator_gazebo manipulator_empty_world.launch\\n```\\nIn a new window\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun manipulator_gazebo move_arm_server\\n```\\n![model](../images/kuka-demo/1.png)\\n***\\n## Running robonomics\\nGo to the folder with robonomics file ad create a local robonomics network:\\n```bash\\n./robonomics --dev --tmp\\n```\\n\\n![robonomics](../images/kuka-demo/robonomics.png)\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node\\n\\n![local](../images/kuka-demo/local.png)\\n\\nThen go to Accounts and create `KUKA` account. Save account's mnemonic key, you will need it later. \\n\\n![acc](../images/kuka-demo/create_acc.png)\\n\\nSend some units to the new account from one of default accounts.\\n\\n![accs](../images/kuka-demo/send_money.png)\\n***\\n## Running ipfs\\nRun ipfs daemon:\\n```bash\\nipfs daemon\\n```\\n***\\n## Running control package\\nIn config directory in kuka_control package you need to create config file with this lines, where `<your_mnemonic>` is saved mnemonic seed:\\n```bash\\n{\\n    \\\"kuka_mnemonic\\\": \\\"<your_mnemonic>\\\",\\n    \\\"node\\\": \\\"ws://127.0.0.1:9944\\\"\\n}\\n```\\n\\nNow you can run control script:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun kuka_controller move_arm_client.py\\n```\\n![control](../images/kuka-demo/run.png)\\n\\n## Sending transaction\\nIn [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) go to `Developer/Extrinsics`, change `extrinsic` to `launch`. Chose your `KUKA` account in `robot` and change `param` to `Yes`. The press `Submit Transaction`\\n\\n![transaction](../images/kuka-demo/launch.png)\\n\\nIn the window with kuka_control package you will see:\\n\\n![done](../images/kuka-demo/res.png)\\n\\nThen go `Developer/Chain State` on the Robonomics portal, select `datalog` and `datalogItem((AccountId,u64)): RingBufferItem` in query and add `KUKA` datalog with button '+':\\n\\n![datalog](../images/kuka-demo/datalog.png)\\n\\nNow you can find robot's telemetry in IPFS via this link with your hash `https://gateway.ipfs.io/ipfs/<hash>`.\\n\\n## Troubleshooting\\n\\nIf `catkin_make` doesn't work with the message that it can't find MoveArm.h, try to remove last four lines in CMakeLists.txt in kuka_manipulator_gazebo package:\\n```\\ninclude_directories(include ${catkin_INCLUDE_DIRS})\\n\\nadd_executable(move_arm_server src/move_arm_server.cpp)\\ntarget_link_libraries(move_arm_server ${catkin_LIBRARIES})\\nadd_dependencies(move_arm_server beginner_tutorials_gencpp)\\n```\\nDo `catkin_make` without these lines, then returm them and do `catkin_make` again.\\n\"}},{\"node\":{\"id\":\"7e176f3ca88116710bed8c64d0487200\",\"title\":\"Drone control with robonomics\",\"path\":\"/docs/ja/iris-drone/\",\"content\":\"\\n**Drone starts moving after transcation and store file with the coordinates in IPFS. The control script is based on the [GAAS demo script](https://github.com/generalized-intelligence/GAAS)**  \\n\\nhttps://youtu.be/4CwtGAX1OwM\\n\\n## Requirements\\n* dependencies for control:\\n``` sh\\nsudo apt install -y \\\\\\n\\tpython3-pip \\\\\\n\\tninja-build \\\\\\n\\texiftool \\\\\\n\\tpython-argparse \\\\\\n\\tpython-empy \\\\\\n\\tpython-toml \\\\\\n\\tpython-numpy \\\\\\n\\tpython-yaml \\\\\\n\\tpython-dev \\\\\\n\\tpython-pip \\\\\\n\\tninja-build \\\\\\n\\tprotobuf-compiler \\\\\\n\\tlibeigen3-dev \\\\\\n\\tgenromfs\\n```\\n```sh \\npip3 install \\\\\\n\\tpandas \\\\\\n\\tjinja2 \\\\\\n\\tpyserial \\\\\\n\\tcerberus \\\\\\n\\tpyulog \\\\\\n\\tnumpy \\\\\\n\\ttoml \\\\\\n\\tpyquaternion\\n```\\n* ROS Melodic + Gazebo [installation tutorial](http://wiki.ros.org/melodic/Installation)\\n* extra packages: \\n``` bash \\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\nsudo apt-get install python-jinja2\\nsudo apt-get install python-catkin-pkg\\nsudo apt-get install python3-catkin-pkg-modules\\n```\\n* IPFS verson 0.4.22\\n```bash\\nwget https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-amd64.tar.gz\\ntar -xvzf go-ipfs_v0.4.22_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh\\nipfs init\\n```\\n* ipfshttpclient\\n```sh\\npip3 install ipfshttpclient\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n## Environment Setup\\n```bash \\nsudo apt-get install ros-melodic-mavros ros-melodic-mavros-extras\\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\\nsudo ./install_geographiclib_datasets.sh\\ncd ~/catkin_ws/src\\ngit clone https://github.com/PX4/Firmware.git\\ncd Firmware\\ngit checkout v1.9.0\\nbash ./Tools/setup/ubuntu.sh\\n```\\n```bash\\ncd ~/catkin_ws/src\\ngit clone https://github.com/generalized-intelligence/GAAS.git\\ncp -r ~/catkin_ws/src/GAAS/simulator/models/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/models/\\ncp -r ~/catkin_ws/src/GAAS/simulator/worlds/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/worlds/\\ncp -r ~/catkin_ws/src/GAAS/simulator/posix-config/* ~/catkin_ws/src/Firmware/posix-configs/SITL/init/ekf2/\\n```\\n\\nModifying your `.bashrc` file, adding the following lines to the bottom:  \\n\\n`source ~/catkin_ws/devel/setup.bash `  \\n`source ~/catkin_ws/src/Firmware/Tools/setup_gazebo.bash ~/catkin_ws/src/Firmware/ ~/catkin_ws/src/Firmware/build posix_sitl_default `   \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware/Tools/sitl_gazebo`  \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models:~/catkin_ws/src/GAAS/simulator/models`  \\n\\n  \\n## Control Package Installation\\nIn a new Terminal:\\n```bash\\ncd catkin_ws/src\\ngit clone https://github.com/tubleronchik/robonomics_drone_sim.git\\ncd ..\\ncatkin build\\n```\\n## Robonomics Network\\nTo create a local robonomics network go to the folder with the robonomic binary file and run:  \\n`./robonomics --dev --rpc-cors all`  \\n\\nAdd robonomic's path to `config.py`\\n\\n![IPFS](../images/iris-drone-demo/IPFS.jpg)\\n\\nGo to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node.\\n![localNode](../images/iris-drone-demo/localNode.jpg)\\n\\nGo to **Accounts** and create **DRONE** and **EMPLOYER** accounts. Save the account names and keys and path to **robonomics** to `~/catkin_ws/src/drone_sim/src/config.py`. Transfer some money into the accounts.\\n\\n![accounts](../images/iris-drone-demo/addingAcc.jpg)\\n\\n## Running Simulation\\nRun IPFS daemon\\n```bash\\ncd go-ipfs\\nipfs daemon\\n```\\nIn another terminal launch the simulation:\\n```bash\\nroslaunch px4 mavros_posix_sitl.launch\\ncd ~/catkin_ws/src/robonomics_drone_sim/src\\npython3 takeoff.py\\n```\\nWaiting till \\\"Waiting for payment\\\" \\n\\n![launch](../images/iris-drone-demo/launch.jpg)\\n\\nTo send a transaction run in another window:\\n`echo \\\"ON\\\" | ./robonomics io write launch -r <drone_addres> -s <employer_key>` - where **<drone_address>** and **<employer_key>** should be replaced with the strings from `config.py` accordingly.\\n\\nAfter data was pushed to IPFS, go to the **Chain State** in [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/). Select **datalog** in query and add DRONE datalog using `+` button.\\n\\n![datalog](../images/iris-drone-demo/datalog.jpg)\\n\\nYou can find drone's telemetry running `https://gateway.ipfs.io/ipfs/<hash>` inserting the hash from above.\\n\\n![output](../images/iris-drone-demo/output.jpg)\\n\\nIt's important to remove `db` derictory before next launches using  \\n` rm -rf ~/.local/share/robonomics/chains/dev/db`\\n\"}},{\"node\":{\"id\":\"3cfb18982d5b2cd6a007c39fa091a717\",\"title\":\"IPFS Common\",\"path\":\"/docs/ja/ipfs-common/\",\"content\":\"\\nThe package handle IPFS connections, provides useful services for working with IPFS Network. \\nIt's included in `robonomics_liability` launch file\\n\\n## ROS Parameters\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_file_providers\\n\\nA list of public nodes to pin result files. The type is `list of strings`, defaults to `[ipfs_public_providers]`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_swarm_connect_to\\n\\nA list of IPFS nodes to connect to. The type is `list of strings`, defaults to `[ipfs_swarm_connect_addresses]`\\n\\n## Subscribed topics\"}},{\"node\":{\"id\":\"3549e53e4798589986c48bf6b53839e8\",\"title\":\"IPFS Common Messages\",\"path\":\"/docs/ja/ipfs-common-messages/\",\"content\":\"\\n## ipfs_common/Filepath.msg\\n\\n| Field         | Type                  | Description           |\\n|------------   |-------------------    |--------------------   |\\n| filepath      | std_msgs/String       | A path to a file      |\\n\\n## ipfs_common/Multihash.msg\\n\\n| Field         | Type              | Description                               |\\n|-----------    |-----------------  |------------------------------------------ |\\n| multihash     | std_msgs/String   | A wrapper for model and objective fields  |\\n\\n## ipfs_common/IpfsDownloadFile.srv\\n\\n**Request**\\n\\n| Field         | Type                                                  | Description               |\\n|-------------- |---------------------------------------------------    |------------------------   |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of a file       |\\n| file          | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)       | Where to save the file    |\\n\\n**Response**\\n\\n| Field         | Type              | Description           |\\n|-----------    |-----------------  |---------------------  |\\n| success       | std_msgs/Bool     | Status of execution   |\\n| error_msg     | std_msgs/String   | Error message         |\\n\\n## ipfs_common/IpfsUploadFile.srv\\n\\n**Request**\\n\\n| Field     | Type                                              | Description                               |\\n|-------    |-------------------------------------------------  |---------------------------------------    |\\n| file      | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)   | Path to a file to be uploaded to IPFS     |\\n\\n**Response**\\n\\n| Field         | Type                                                  | Description                   |\\n|-------------- |---------------------------------------------------    |----------------------------   |\\n| success       | std_msgs/Bool                                         | Status of execution           |\\n| error_msg     | std_msgs/String                                       | Error message                 |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of uploaded file    |\\n\"}},{\"node\":{\"id\":\"f5d482cdcbc241a51996676255e125c2\",\"title\":\"IoT Sensors Connectivity\",\"path\":\"/docs/ja/iot-sensors-connectivity/\",\"content\":\"\\nRobonomics Network allows you to communicate with any sensor you wish and get data from the sensor all around the world. This data can be transferred to different destinations.\\n\\nOn this page you'll find step-by-step instructions to connect an ESP board to the connectivity server provided by AiraLab.\\n\\n## Requirements\\n\\n* ESP8266/ESP32 like board with WiFi\\n\\n## 1. Get the software\\n\\n### On Windows\\n\\nInstall [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\\n\\nInstall Ubuntu via Windows Store:\\n\\n![Windows Store](../images/windows_store.jpg \\\"Windows Store\\\")\\n\\nand clone the [package](https://github.com/airalab/sensors-connectivity)\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\n```\\n\\nThe next step is to install python and dependencies:\\n\\n```\\nsudo apt update && sudo apt install python3-pip\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n### On Ubuntu\\n\\n```\\nsudo apt update && sudo apt install python3-pip git\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n> You can ignore such warnings:\\n>\\n> ```\\n> The script ... is installed in '...' which is not on PATH.\\n> Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\n> ```\\n\\n### On NixOS\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\nnix build -f release.nix\\nsource result/setup.bash\\n```\\n\"}},{\"node\":{\"id\":\"09ec48d30b4ec3cb3475f2a4424b2c1f\",\"title\":\"IoT Firmware Upload\",\"path\":\"/docs/ja/iot-firmware-upload/\",\"content\":\"\\nThere are few firmwares for ESP like boards:\\n\\n* [Ping](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/ping)\\n* [TCP](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/tcp)\\n* [Mobile GPS](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/mobile_gps)\\n\\nThere is a script to upload a firmware for each one, called `flash_firmware.py`. It's located in the root of the repository\\n\\n> **Requirements**\\n> In order to install all dependencies run in the root of the repository folder:\\n>\\n> ```\\n> pip install -r requirements.txt\\n> ```\\n>\\n> Python3 is required!\\n\\nUsually in order to upload a firmware to your board follow these steps:\\n\\n1. Assemble the board and connect it to PC\\n2. Edit a `config.yaml` in a corresponding folder (e.g. `boards/esp/tcp/config.yaml`)\\n3. Run `python flash_firmware.py -s PATH_TO_FOLDER -c PATH_TO_CONFIG` where `PATH_TO_FOLDER` is a path to the desired firmware (e.g. `boards/esp/ping`) and `PATH_TO_CONFIG` is a path to the configuration file (e.g. `boards/esp/ping/config.yaml`)\\n\\n\"}},{\"node\":{\"id\":\"f411ed9773f3a8c5bcddcaebdf6f3926\",\"title\":\"How to launch the Robonomics collator\",\"path\":\"/docs/ja/how-to-launch-the-robonomics-collator/\",\"content\":\"\\nNote: In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is maintained by developers, but anyone can support the project. Every additional full node of the blockchain helps it to be more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it could be [built from source](/docs/how-to-build-collator-node/).\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nBut we recommend that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need use *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can simply launch a collator directly in the command line to check for errors.\\nAfter that we strongly recommend to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](../images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](../images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with : `journalctl -u robonomics.service -f` \\n\\nNow the robonomics collator is launched it will sync with the Kusama Relay Chain, this can take up quite some time depending on your network speed and system specifications, so we recommend to download a Kusama snapshot and use it. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the robonomics service. You can find more info about snapshots and usage instructions on the followin page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](../images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](../images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\"}},{\"node\":{\"id\":\"9ab7b17934d634e9ce44ea460affd984\",\"title\":\"Interact with AIRA\",\"path\":\"/docs/ja/interact-with-aira/\",\"content\":\"\\nAt this point you should be familiar with a [DApp](/docs/get-weather-on-fuji-mountain/) and how to launch [AIRA image](/docs/aira-installation-on-vb/).\\nNow you are ready to do more complicated stuff like installing a package and interacting with it via DApp.\\n\\n> **Important:**\\n> Make sure you have covered previous lessons before you continue.\\n\\n\\n> **Tip:**\\n> During the lesson you will type a few commands in terminal. AIRA image doesn't support clipboard, so to make life easier have a look at [Connect via SSH](/docs/aira-connecting-via-ssh/) and log in via SSH to the VM.\\n\\nWalkthrough video:\\n\\nhttps://www.youtube.com/embed/QM06l07_wuA\\n\\n## Package installation\\n\\nAfter you launched AIRA and logged in using your terminal do the following:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nRun one by one commands above. After the last one you should see a link to DApp generated specifically for your instance.\\n\\n![Terminal with AIRA](../images/aira_hello_terminal.jpg \\\"Terminal with AIRA\\\")\\n\\nClick on the link, the DApp should be shown.\\n\\n## DApp \\n\\nConnect [MetaMask](http://metamask.io/) if prompted and click on the button\\n\\n![Request connection in Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Request connection in Robonomics Dapp\\\")\\n\\nSign the message as usual and wait for the result\\n\\n![Wait for Result of request](../images/aira_hello_dapp_2.jpg \\\"Wait for Result of request\\\")\\n\\nMeanwhile have a look at the terminal. You should see the greeting\\n\\n![AIRA greeting in terminal](../images/aira_hello_terminal_2.jpg \\\"AIRA greeting in terminal\\\")\\n\\nIn the end the greeting will appear in the DApp\\n\\n![Robonomics DApp Greeting for AIRA](../images/aira_hello_dapp_3.jpg \\\"Robonomics DApp Greeting for AIRA\\\")\\n\\n## Troubleshooting\\n\\n### You click \\\"Request current values\\\" but see no greeting\\n\\nProbably you have just launched AIRA and IPFS hasn't finished initialization. Wait a minute or so and try again.\\n\\n### I see response hash but the data doesn't appear\\n\\nAgain most probably the issue comes from IPFS connection. Click and the hash and you'll see the result. It's not necessary to download the file.\\n\\n## Home Task (optional)\\n\\nIf you are familiar with [Python](https://www.python.org/) change the shown text to something different and complete the lesson with your version of `hello_aira`\\n\\n- Make a fork of the [repository](https://github.com/vourhey/hello_aira)\\n- The output text is located [here](https://github.com/Vourhey/hello_aira/blob/master/scripts/hello_aira#L45)\\n\"}},{\"node\":{\"id\":\"57f800cc196cf3bd59ba2a16151bf695\",\"title\":\"How to build collator node from source\",\"path\":\"/docs/ja/how-to-build-collator-node/\",\"content\":\"\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](../images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v1.4.0:\\n\\n```\\n  rustup install nightly-2021-11-02\\n```\\n![Install nightly](../images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2021-11-02\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2021-11-02\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v1.4.0 robonomics-node\\n```\\n![Start build Robonomics](../images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](../images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"}},{\"node\":{\"id\":\"44382e738424fe0b0b631dfff1da92d5\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/ja/home-assistant-begin/\",\"content\":\"There are instructions on how to connect your smart home devices to the Robonomics network. You need Robonomics [accounts](/docs/create-account-in-dapp/) for each device, they will publish encrypted data in datalog. Also you need user account that will send commands to devices end encrypt/decrypt data.\\n\\nIn this video you can see the example of connecting temperature sensor:\\n\\nhttps://youtu.be/iB2Z8HtERgs\\n\\n# Requirements\\n\\n* Raspberry Pi 4 or 3\\n* SD card and SD adapter\\n* Temperature sensor - [Keen Home RS-THP-MP-1.0](https://www.zigbee2mqtt.io/devices/RS-THP-MP-1.0.html) (or another [supported device](https://www.zigbee2mqtt.io/information/supported_devices.html))\\n\\n### Method 1 (with SLS Gateway)\\n* [Robonomics SLS Gateway](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01)\\n\\n### Method 2 (with zigbee2MQTT)\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\n### Method 3 (with Xiaomi Gateway)\\n* Xiaomi Gateway (one of [supported](https://www.home-assistant.io/integrations/xiaomi_miio#xiaomi-gateway))\\n* [Mi Home app](https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&hl=ru&gl=US) or HomeKit app\\n\\nAlso you can connect some devices directly through Mi Home app (for example, Vacuum Cleaner).\\n\\n# Setup\\n\\n1. First you need to [setup Raspberry Pi](/docs/raspberry-setup/) (also you can [use prepared image](/docs/raspberry-image/)).\\n2. Then you need to connect devices to Home Assistant:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n3. And [connect them to Robonomics Network](/docs/add-smart-device-to-robonomics/).\\n\"}},{\"node\":{\"id\":\"404ef1fb2f377cba6e130f5166857ac9\",\"title\":\"Glossary\",\"path\":\"/docs/ja/glossary/\",\"content\":\"\\n## Agent\\n\\nIn terms of Robonomics Network agent is a program module that uses IPFS or blockchain or both interfaces of the network and does some actual work.\\nUsually it's represented as a ROS package and it may connect (but not necessarily) a real cyber-physical system to the Robonomics Network.\\n\\n## Cyber-physical system\\n\\nIt is a combination of a physical mechanism that is usually called a robot and a program algorithm that controls the behavior of the mechanism.\\n\\n## Dapp\\n\\nIt is a short form for Decentralized application. Usually it is a single page web based application that helps to interact with an agent.\\n\\n## IPFS\\n\\nAccording to the official [documentation](https://docs.ipfs.io/introduction/) \\\"IPFS is a distributed system for storing and accessing files, websites, applications, and data\\\".\\nFor more detail how it works go to the official website.\\n\\n## Lighthouse\\n\\nA lighthouse is an autonomous workflow that allows us to distribute the running time of providers that serve a single broadcast channel.\\n\\nFor more information read [Robonomics Whitepaper](https://static.robonomics.network/docs/whitepaper/Robonomics-whitepaper-en.pdf) section 5.2.\\n\\n## Sidechain\\n\\nEthereum based blockchain network with Proof-of-Authority consensus owned by Airalab.\\n\\n\"}},{\"node\":{\"id\":\"f1d7cb71b6c1ee74303497aaf643b7a1\",\"title\":\"Getting Started\",\"path\":\"/docs/ja/\",\"content\":\"\\n## What is Robonomics\\n\\nRobonomics platform provides tools for working with the robot economy network. Robonomics allow designers of smart cities and industry 4.0 zones to build trust among the [autonomous robots services](/docs/glossary#cyber-physical-system), provide [direct user access via dapp](/docs/glossary#dapp) for ordering products from autonomous factories and services of urban sensor networks. This in turn will allow us to put in place a decentralized system that globally monitors the activities of cyber physical systems.\\n\\nFind more in [Robonomics whitepaper](https://github.com/airalab/robonomics_specs/blob/master/pdf/whitepaper_en.pdf)\\n\\nThe following chart describes what place Robonomics takes in the scenario:\\n\\n![Robonomics Chart](../images/robonomics_network_basic_scheme.jpg \\\"Robonomics Network scenario\\\")\\n\\n## What the documentation contains\\n\\n### Robonomics Network quick start\\nStart with quick example of what Robonomics is able to do within 5 minutes: [DEMO \\\"Get Weather on Fuji Mountain\\\"](/docs/get-weather-on-fuji-mountain).\\n\\n### I'm interested in using Robonomics services\\n\\nTake a look at the [Robonomics Dapp](https://dapp.robonomics.network/#/). Get familiar with the statistic, average miner reward etc.\\nTry out existing [services](https://dapp.robonomics.network/#/services)\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"}},{\"node\":{\"id\":\"4e4cd65ee6e34ac528b427f7a4d26748\",\"title\":\"DEMO \\\"Get Weather on Fuji Mountain\\\"\",\"path\":\"/docs/ja/get-weather-on-fuji-mountain/\",\"content\":\"\\n**Let's start from a quick example of what Robonomics is able to do within 5 minutes. Requirements: [Metamask extension](https://metamask.io/)**\\n\\nTo get the weather from sensor on Fuji Mountain, please, open the page of [Fuji Weather sensor](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/) in Robonomics dApp and follow instructions below.\\n\\nHere's a walkthrough video:\\n\\nhttps://www.youtube.com/embed/t098NlMELk4\\n\\n## 1. Open the Dapp\\n\\nIn case you don't have MetaMask extension you'll see the picture below. Go to the link provided above and install one.\\n\\n![\\\"Robonomics dApp if no MetaMask installed\\\"](../images/sensor-demo/sensor-demo-1.png \\\"Robonomics dApp if no MetaMask installed\\\")\\n\\n## 2. Allow connection to the extension\\n![\\\"Connection to Robonomics dApp via Metamask\\\"](../images/sensor-demo/sensor-demo-2.png \\\"Connection to Robonomics dApp via Metamask\\\")\\n\\n## 3. Press \\\"Request current values\\\"\\n![\\\"Request sensor's data in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-3.png \\\"Request sensor's data in Robonomics network via dApp\\\")\\n\\n## 4. Sign a message. No token or ether are needed\\n![\\\"Sign a message in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-4.png \\\"Sign a message in Robonomics network via dApp\\\")\\n\\n## 5. Wait until the agent collects the data and sends it back\\n![\\\"Wait for response of the agent in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-5.png \\\"Wait for response of the agent in Robonomics network via dApp\\\")\\n\\n## 6. Wait until the Dapp downloads the result file from IPFS\\n![\\\"Wait for IPFS file with results in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-6.png \\\"Wait for IPFS file with results in Robonomics network via dApp\\\")\\n\\n## 7. Look at the weather data on Fuji Mountain\\n![\\\"The results of sensor network in Robonomics via dApp\\\"](../images/sensor-demo/sensor-demo-7.png \\\"The results of sensor network in Robonomics via dApp\\\")\\n\\nJust now you have broadcasted a demand message and got a result from an autonomous agent! The result file is stored in IPFS, the result message is signed with the agent's private key.\\n\"}},{\"node\":{\"id\":\"313f04e158e031c293f370cb3d19eec1\",\"title\":\"How to Buy a Subscription\",\"path\":\"/docs/ja/get-subscription/\",\"content\":\"\\nhttps://youtu.be/EsUiG_4ZGcw\\n\\nWe will use [Robonomics dev node](/docs/run-dev-node) to try the subscription, but in the production network everything works the same. \\n\\nIn `Developer/Chain state` you can see auctions for subscriptions (to get a subscription you need to win a fast auction). Choose `rws` and `auctionQueue` and press `+` button, you will see IDs of available auctions:\\n\\n![queue](../images/dev-node/queue.png)\\n\\nYou can see an information about any subscription with `rws` `auction` and ID of auction (the auction's ID in the picture is 0):\\n\\n![auction](../images/dev-node/auction.png)\\n\\nIn the information about the auction you can see `winner` field, at the moment it is `null` so nobody has this subscription and we can get it. For that go to `Developer/Extrinsic`, choose your account and `rws -> bid`. Also set auction ID (0) and the amount of units to bid (more than 1000000000 Wn):\\n\\n![bid](../images/dev-node/bid.png)\\n\\nSubmit the transaction and check the information about the auction with ID 0 (in `Chain state` choose `rws -> auction` and ID 0):\\n\\n![win](../images/dev-node/auc_win.png)\\n\\nNow in `winner` field you will see your account address, it means that this account has the subscription 0. An auction starts with the first bid and lasts a few blocks, so if somebody bids more tokens than you in the next few blocks one will be the winner and one will take the subscription.\\n\\nNow you can add devices. Devices are accounts that are able to use this subscription and send extrinsics with no fee. To test it lets create a new account with no tokens and add it to devices. \\n\\nTo add devices choose `rws -> setDevices` in `Developer/Extrinsic`. Then press `Add Item` button and choose recently created account with no tokens:\\n\\n![set_devices](../images/dev-node/set_devices.png)\\n\\nSubmit the transaction. Now you can check the list of devices in `Chain state` with `rws -> devices`. There you will see the address of your account without tokens. Choose the account that has bought the subscription and press `+`:\\n\\n![devices](../images/dev-node/devices.png)\\n\\nNow you can try to [send launch](/docs/subscription-launch) extrinsic using the subscription.\"}},{\"node\":{\"id\":\"2126bcb8c846b9c692ce7479f7bd445e\",\"title\":\"Gaka-Chu setup and software Installation\",\"path\":\"/docs/ja/gaka-chu/\",\"content\":\"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](../images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](../images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"}},{\"node\":{\"id\":\"a87f4a8d1e39f9d0b66d7eb057ab56b0\",\"title\":\"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\"path\":\"/docs/ja/freertos-mqtt/\",\"content\":\"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](../images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](../images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](../images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](../images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](../images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"}},{\"node\":{\"id\":\"dd90352e834440095da2589eeb5af9eb\",\"title\":\"Ethereum Common\",\"path\":\"/docs/ja/ethereum-common/\",\"content\":\"\\nThe packages contains two launch files: `erc20.launch` and `signer.launch`. The last one is included in [Robonomics Liability](/docs/robonomics-liability).\\n\\nBelow is the description for `erc20` node which contains utils for convenient work with Ethereum accounts and XRT token.\\n\\n## ROS Parameters\\n\\n###  ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~erc20_token\\n\\nERC20 token to work with. Type is `string`, defaults to `xrt.5.robonomics.eth`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Published topics\\n\\n### /eth/event/transfer (ethereum_common/TransferEvent)\\n\\nThe event [ethereum_common/TransferEvent](/docs/ethereum-common-messages#ethereum_commontransfereventmsg) is emitted after the transfer of tokens was made\\n\\n### /eth/event/approval (ethereum_common/ApprovalEvent)\\n\\nThe event [ethereum_common/ApprovalEvent](/docs/ethereum-common-messages#ethereum_commonapprovaleventmsg) is emitted after the approval of tokens was made\\n\\n## Services\\n\\n### /eth/accounts (ethereum_common/Accounts)\\n\\nList of available Ethereum accounts. See [ethereum_common/Accounts](/docs/ethereum-common-messages#ethereum_commonaccountssrv)\\n\\n### /eth/account_eth_balance (ethereum_common/AccountBalance)\\n\\nReturns the balance of the given address in Wei. See [ethereum_common/AccountBalance](/docs/ethereum-common-messages#ethereum_commonaccountbalancesrv)\\n\\n### /eth/eth_balance (ethereum_common/Balance)\\n\\nReturns the balance of the default address. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/current_block (ethereum_common/BlockNumber)\\n\\nReturns current block number. See :ref:`Ethereum-common-BlockNumber.srv`\\n\\n### /eth/transfer (ethereum_common/Transfer)\\n\\nTransfers tokens from the default account to a given one. See :ref:`Ethereum-common-Transfer.srv`\\n\\n### /eth/transfer_from (ethereum_common/TransferFrom)\\n\\nTransfers tokens from a given account to another one. See :ref:`Ethereum-common-TransferFrom.srv`\\n\\n### /eth/approve (ethereum_common/Approve)\\n\\nApproves tokens from the default account to a given one. See :ref:`Ethereum-common-Approve.srv`\\n\\n### /eth/account_xrt_balance (ethereum_common/AccountBalance)\\n\\nReturns the XRT balance of a given account. See :ref:`Ethereum-common-AccountBalance.srv`\\n\\n### /eth/xrt_balance (ethereum_common/Balance)\\n\\nReturn the XRT balance of the default account. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/account_xrt_allowance (ethereum_common/AccountToAddressAllowance)\\n\\nReturns how much one account is allowed to spend from another account. See :ref:`Ethereum-common-AccountToAddressAllowance.srv`\\n\\n### /eth/xrt_allowance (ethereum_common/Allowance)\\n\\nReturns how much the Factory is allowed to spend from the default account. See :ref:`Ethereum-common-Allowance.srv`\"}},{\"node\":{\"id\":\"26ae19a4adc3634a3ffcc2cec1562ad8\",\"title\":\"Ethereum Common Messages\",\"path\":\"/docs/ja/ethereum-common-messages/\",\"content\":\"\\n## ethereum_common/Address.msg\\n\\n| Field   \\t| Type            \\t| Description                    \\t|\\n|---------\\t|-----------------\\t|--------------------------------\\t|\\n| address \\t| std_msgs/String \\t| Address in Ethereum blockchain \\t|\\n\\n## ethereum_common/UInt256.msg\\n\\n| Field   \\t| Type            \\t| Description                \\t|\\n|---------\\t|-----------------\\t|----------------------------\\t|\\n| uint256 \\t| std_msgs/String \\t| A wrapper for big integers \\t|\\n\\n## ethereum_common/TransferEvent.msg\\n\\n| Field      \\t| Type                                                  \\t| Description      \\t|\\n|------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_from  \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Sender address   \\t|\\n| args_to    \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Receiver address \\t|\\n| args_value \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/ApprovalEvent.msg\\n\\n| Field        \\t| Type                                                  \\t| Description      \\t|\\n|--------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_owner   \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Owner address    \\t|\\n| args_spender \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Spender address  \\t|\\n| args_value   \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/AccountBalance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field   \\t| Type                                                  \\t| Description    \\t|\\n|---------\\t|-------------------------------------------------------\\t|----------------\\t|\\n| balance \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wei \\t|\\n\\n## ethereum_common/AccountToAddressAllowance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n| to      \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field  \\t| Type                                                  \\t| Description   \\t|\\n|--------\\t|-------------------------------------------------------\\t|---------------\\t|\\n| amount \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wn \\t|\\n\\n## ethereum_common/Accounts.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------- |-------------------------------------------------------    |----------------------------   |\\n| accounts  | [ethereum_common/Address[]](#ethereum_commonaddressmsg)     | List of available accounts    |\\n\\n## ethereum_common/Allowance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                                       |\\n|--------   |-------------------------------------------------------    |-----------------------------------------------    |\\n| amount    | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | Amount of XRT the Factory is allowed to spend     |\\n\\n## ethereum_common/Approve.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------  |-------------------------------------------------------    |-----------------------------  |\\n| spender   | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Who is allowed to spend       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | How much tokens are allowed   |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/Balance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                       |\\n|---------  |-------------------------------------------------------    |--------------------------------   |\\n| balance   | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The balance of default account    |\\n\\n## ethereum_common/BlockNumber.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type              | Description           |\\n|--------   |-----------------  |---------------------- |\\n| number    | std_msgs/Uint64   | Current block number  |\\n\\n## ethereum_common/Transfer.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Ethereum address      |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/TransferFrom.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| owner     | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Owner's address       |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Another account       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\"}},{\"node\":{\"id\":\"98b1c2569cca28586e1c221a5e189f0b\",\"title\":\"How to edit WIKI\",\"path\":\"/docs/ja/edit-wiki/\",\"content\":\"\\n**Robonomics WIKI is open source. Any corrections are welcome: fixing errors, typos, some unclear or outdated information, translation into any language. You'll need a [GitHub](https://github.com/) account.**\\n\\n## Edit existing doc\\n\\n1. Choose page\\n2. Click button \\\"Edit page\\\" marked with the Github logo on the page you want to edit\\n3. Clicking on the button will take you to the .md file.\\n4. Please, follow common rules for editing [Markdown files](https://en.wikipedia.org/wiki/Markdown), bearing in mind a few features of the WIKI stack:\\n\\n### Frontmatter\\nDocs in Robonomics WIKI contain frontmatter block. It must be at the top of the Markdown file, and must take the form of valid YAML set between triple-dashed lines. Between the triple-dashed lines, you can set or edit folowing options:\\n\\n```YAML\\n---\\ntitle: How to contribute # Title for the page, you do not need to duplicate it in text\\ncontributors: [positivecrash] # Main contributors (who actively curates this page). GitHub nickname required, without any additional symbols\\ntranslated: true # \\\"true\\\" if it has been translated in current language (see locale folder name of doc)\\n---\\n```\\n\\n### Images\\n1. Upload image in folder `/docs/images/url-of-your-doc`\\n* If image needs to be localized, insert all of them in one folder\\n* Use locale appendix in name of images if it's localized, e.g. `image_en.jpg`\\n* Make sure your image is web optimised and at the same time it looks good\\n2. Insert images standart way for Markdown files.\\n\\n### YouTube videos\\nYou can embed any YouTube video in doc by inserting share link as separate paragraph without any additional quotes or tags, e.g.: `https://youtu.be/kQaSwNYHJQ8`\\n\\n### Asciinema\\nRobonomics WIKI has support for Asciinema. To insert Asciinema, please, follow these instructions:\\n* Import component after frontmatter block `import Asciinema from '~/components/Asciinema.vue'`\\n* Insert as separate paragraph `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, where is vid is ID of specific asciicast\\n\\n> You can get the widget script for a specific asciicast by clicking on “Embed” link on asciicast page.\\n> It looks like this:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Asciinema docs](https://asciinema.org/docs/embedding)\\n\\nIn the example above vid is 14.\\n\\n## Add new doc\\n\\nIf you need to add new page in docs of Robonomics WIKI, please, follow these steps:\\n\\n1. Find the folder with the locale that matches the language of the article you are adding, e.g. `/docs/en/`\\n2. Create .md file, using in name latin characters and follow common rules for [url structure](https://developers.google.com/search/docs/advanced/guidelines/url-structure)\\n3. Edit file as described above\\n4. Duplicate file to other locale folders, even if you do not plan to translate them. Do not forget mark in frontmatter not translated pages as `translated: false`\\n5. Add doc in menu:\\n* Open file `/data/sidebar_docs.yaml`\\n* Decide where to place your doc\\n* If you want to create new section, provide title with locale appendix, using only locales your section is translated\\n* Add doc with link. The link must be only one, and must not contain locale characters. Correct is `/docs/url-of-your-doc`, not correct is `/docs/en/url-of-your-doc`\\n* Use valid YAML for `/data/sidebar_docs.yaml` and rely on the existing file structure\\n\\n## Submit Pull Request\\n\\n[Make pull request](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) for any content you changed including typos, translations, outdated information or broken links.\\n\\nDecisions about individual PRs made by Robonomics core team. Special grants in [XRT](https://robonomics.network/community#token) are also possible for extended contribution 🤖💙💛💚💎🍭🎉🔌\"}},{\"node\":{\"id\":\"6d6c0dd50b7ff09493a43cf62e6865d0\",\"title\":\"Digital Twins\",\"path\":\"/docs/ja/digital-twins/\",\"content\":\"\\n## Requirements\\n- `robonomics` [executable][ln1]\\n- Be familiar with [parachain.robonomics][ln2]\\n\\n## Digital Twins Schema\\n\\nDigital twins have the following structure:\\n\\n| DT id \\t| Topic Name \\t| Source    \\t|\\n|-------\\t|------------\\t|-----------\\t|\\n| 0     \\t| 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1     \\t| 0x00...001 \\t| 4GVi...Bn \\t|\\n|       \\t| 0x00...002 \\t| 4Hm...vLS \\t|\\n|       \\t| 0x00...... \\t| 4HQ...RQY \\t|\\n|       \\t| 0xFF...FFF \\t| 4Hw...CyK \\t|\\n| 2     \\t| 0x00...000 \\t| 4HJ...k3o \\t|\\n\\n Where:\\n* **DT id** - is unsigned integer unique number.\\n* **Topic name** - is 0x prefixed `H256 hex` or `ascii data` with 32 bytes length. For example: `0x1234....FF` and  `hello.parachain.robonomics.world`.\\n* **Source** - is Account address.\\n\\n## Create Digital Twin\\nGo to ***Developer -> Extrinsics*** and choose `digitalTwin.create()` extrinsic.\\n![digital Twin create][im1]\\n\\n Submit transaction and go to ***Network -> Explorer*** and in the **recent events** you will see information about digital twin.\\n ![digital Twin create info][im2]\\n\\n## Add DT Topic\\n\\nYou can create multiple topics for one digital twin. for creating topic you need go to ***Developer -> Extrinsics*** and choose `digitalTwin.setSource(id,topic,source)` extrinsic. Fill in the fields and submit transaction.\\n![DT topic fields][im3]\\n\\nAgain go to **Network -> Explorer*** and in the **recent events** you will see information about created topic.\\n![info about topic][im4]\\n\\nYou can create several topics for one twin.\\n![topics][im5]\\n\\n## Chain State\\n\\nYou can find all information about existing *digital twins in* ***Developer -> Chain state*** such as:\\n- Total number of Digital twins - total()\\n- Information about owner of digital twin - owner(u32)\\n- Information about topics in digital twin - digitalTwin(u32)\\n![chain info][im6]\\n\\n\\n[ln1]: <https://github.com/airalab/robonomics/releases>\\n[ln2]: </docs/create-account-in-dapp>\\n[im1]: <../images/digital-twin/twin-create.jpg>\\n[im2]: <../images/digital-twin/create-log.jpg>\\n[im3]: <../images/digital-twin/fields.jpg>\\n[im4]: <../images/digital-twin/topic.jpg>\\n[im5]: <../images/digital-twin/topics.jpg>\\n[im6]: <../images/digital-twin/chain-state.jpg>\\n\"}},{\"node\":{\"id\":\"9c2332216d547fb7a5c86cf3fe221ae4\",\"title\":\"Cross-chain Message\",\"path\":\"/docs/ja/cross-chain-messages/\",\"content\":\"\\nXCM (Cross-chain Message) allows sending messages between parachains. You can send launchXcm transaction to run/stop your robot or datalogXcm transaction to save data to blockchain.\\n\\nhttps://www.youtube.com/watch?v=a6XrqoaYhK8&feature=emb_logo\\n\\n## Create Account\\n\\nLets try to send message from Earth to Mars.\\nGo to [parachain.robonomics.network](https://parachain.robonomics.network/#/explorer) and choose `Airalab Rococo` testnet:\\n\\n![testnets](../images/cross-chain/testnet.jpg)\\n\\nIn `Network/Parachains` you will see two parachains with their id:\\n\\n![ids](../images/cross-chain/Parachains_id.jpg)\\n\\nThen go to Earth parachain and [create](https://wiki.robonomics.network/docs/create-account-in-dapp/) two accounts (for example `ROBOT` and `EMPLOYER`). In a new tab go to Mars parachain.\\n\\n## LaunchXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `EMPLOYER` account and launchXcm. Then write Mars parachain id (2000) and choose the `ROBOT` account:\\n\\n![launch](../images/cross-chain/launch.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nTo see your transaction in Mars parachain go to `Network/Explorer` and look at Recent Events.\\n\\n![recent_launch](../images/cross-chain/recent_launch.jpg)\\n\\n## DatalogXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `ROBOT` account and datalogXcm. Write Mars parachain id (2000) and the message:\\n\\n![datalog](../images/cross-chain/datalog.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nYou can see your transaction in Recent Events in Mars parachain:\\n\\n![recent_datalog](../images/cross-chain/recent_datalog.jpg)\\n\\n\\n\"}},{\"node\":{\"id\":\"ecad3f4a1150c61fe472a4e455505c04\",\"title\":\"Create digital identity run by Ethereum\",\"path\":\"/docs/ja/create-digital-identity-run-by-ethereum/\",\"content\":\"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](../images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](../images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](../images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](../images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](../images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](../images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"}},{\"node\":{\"id\":\"c1bcdea4ffa2219ae5c02a1962672477\",\"title\":\"Create Account for Robonomics Parachain\",\"path\":\"/docs/ja/create-account-in-dapp/\",\"content\":\"\\n**In order to interact and operate with Robonomics Parachain, developers and users need to create an account on the Polkadot / Substrate Portal. The account performs basic functions for the network: your public network address(the public key), the access control to the address and funds (the private key), sending transactions to the network, showing your tokens and their amount, etc. Below are two main ways to create an account for Robonomics Parachain.**\\n\\n## 1. Using Polkadot{.js} Browser Extension\\n\\nThe Polkadot Extension provides a mechanism to generate the account and interact with all Polkadot / Kusama projects including Robonomics Parachain. This is not the safest way to manage your account, but it is the most convenient in terms of security / usability balance.\\n\\n## 1.1. Install Browser Extension\\n\\nThe browser extension is available for [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) and [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=en) (plus Chromium-based browsers).\\n\\n![Browser Extension](../images/creating-an-account/1.1-polkadot-extension.png \\\"Browser Extension\\\")\\n\\n## 1.2. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. If this is the first time you entered the portal, it will request access to the browser extension, so allow access. \\n\\nOnce you've opened the app, take a look at the top left corner. The name of the network, its icon and the number of the last block are displayed there. Clicking on this area will open a list of all Polkadot / Kusama networks, including test networks and local nodes. You can switch between networks by selecting the required one and pressing the `Switch` button. **Make sure you are connected to Robonomics Parachain now**. \\n\\n![Robonomics Parachain app](../images/creating-an-account/1.2-robonomics-app.png \\\"Robonomics Parachain app\\\")\\n\\n## 1.3. Update Extension Metadata\\n\\nIt is very likely that the app will ask you to update the metadata for the extension to display the correct information about the chain you are connected to. Go to **Settings -> Metadata**, press `Update metadata` button and then, in the pop-up window, allow the extension to do it. \\n\\n![Updating metadata](../images/creating-an-account/1.3-metadata-update.png \\\"Updating metadata\\\")\\n\\n## 1.4. Create Account in Extension\\n\\nOpen the Polkadot{.js} browser extension. Click the big plus button or select `Create new account` from the small plus icon in the top right. You should see the following menu, with generated mnemonic seed in the form of twelve words and the address. \\n\\n![Account creation, step one](../images/creating-an-account/1.4-create-account-step-1.png \\\"Account creation, step one\\\")\\n\\nThe seed is your key to the account. Knowing the seed allows you (or anyone else who knows the seed) to get control on this account and even re-create it, if you forget the password. **It's very important to store it somewhere securely**, preferably on paper or other non-digital device, not in digital storage or on a computer. \\n\\nSave the seed and press `Next step`. You should see the following menu.\\n\\n![Account creation, step two](../images/creating-an-account/1.5-create-account-step-2.png \\\"Account creation, step two\\\")\\n\\n- *Network* allows you to choose which of the networks this account will be exclusively used for. You can use the same address on multiple networks, however, for privacy reasons, it is recommended that you create a new address for each network you use. \\nSelect the Robonomics network from the drop-down list. If you could not find the Robonomics network, then most likely you did not update the metadata, go back and do it.\\n\\n    - You will notice that the format of the address and the account icon will change — this is normal. Different network formats are merely other representations of the same public key. \\n\\n- *Name* is just account's name for your use only. It is not stored on the blockchain and will not be visible to other users. \\n\\n- *Password* is used to encrypt your account's information. You will need to re-enter it when signing transactions on the portal. Create one and remember it.\\n\\nAs a result, after creating an account, you will see it in the list of accounts in Polkadot{.js} extension. By clicking on three dots, you can rename the account, export it, remove it from the extension and change the network used for the account. \\n\\nAlso, the account will appear in the **Accounts -> Accounts** menu on the portal, where it will be noted that it was injected using the extension.\\n\\n![Successful account creation](../images/creating-an-account/1.6-account-injected.png \\\"Successful account creation\\\")\\n\\n\\n## 2. Directly on Robonomics Parachain App\\n\\nYou can use the user interface on the Polkadot / Substrate Portal to create an account, although this is not recommended as it is the less secure method for the account creation. It should be used when other methods are not applicable or for development and tests. \\n\\n## 2.1. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check at the top left corner that you are connected to Robonomics Parachain**.  \\n\\nGo to **Accounts -> Accounts** and press `Add account` button. \\n\\n![Robonomics Parachain App](../images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Robonomics Parachain App\\\")\\n\\n## 2.2. Create Account\\n\\nYou should see the following popup menu with account seed. \\n\\n![Generating account seed](../images/creating-an-account/2.2-robonomics-app-seed.png \\\"Generating account seed\\\")\\n\\nIt has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). Save the seed phrase securely and press `Next`.\\n\\nIn the next menu, you need to set the account name and password, similar to the extension instructions described above.\\n\\n![Generating account name and password](../images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Generating account name and password\\\")\\n\\nClicking on the `Next` button will take you to the last window. Click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n![Successful account creation](../images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Successful account creation\\\")\\n\\n## 3. Account Сreated Successfully \\n\\nNow you can fully operate with your fresh-created account. Send and receive tokens, messages, write datalog and more. Feel free to explore all the features of app. To copy your account's address simply click on its icon, address will be copied to clipboard. \\n\\nIf you would like to know more about Polkadot / Kusama accounts and additional ways to create them, more information can be found [here](https://wiki.polkadot.network/docs/learn-accounts) and [here](https://wiki.polkadot.network/docs/learn-account-generation).\\n\"}},{\"node\":{\"id\":\"a98a4b4c83ef0924a5d40a258ad6ac94\",\"title\":\"How to contribute\",\"path\":\"/docs/ja/contributing/\",\"content\":\"\\nRobonomics network is an open-source project built by core maintainers from Airalab and contributors. We want to make it easy for anyone to contribute. You may contribute to core, suggest changes, improve documentation or write a blog post. Please, read some rules and suggestions for contributing.\\n\\n## Main Airalab repositories \\n\\n- [aira](https://github.com/airalab/aira) - AIRA client for Robonomics network. \\n- [robonomics_comm](https://github.com/airalab/robonomics_comm) - Robonomics communication stack\\n- [robonomics_contracts](https://github.com/airalab/robonomics_contracts) - smart contracts of Robonomics network\\n\\n## Bugs and proposals for improvements\\n\\nIf you find a bug in AIRA client, Robonomics repositories, this documentation or would like to propose an improvement, please, open a new issue in the same repository, that you want to contribute.\\n\\n### Rules for reporting\\n\\nWhen opening a new issue, do not forget about a few basic rules for reporting:\\n\\n1. Choose exact repository, that you want to submit an issue.\\n\\n2. If you are reporting bug, make sure the bug was not already reported.\\n\\n3. Be sure to include title and clear description, as much relevant information as possible.\\n\\n4. Please prefix your issue with one of the following: `[BUG]`, `[PROPOSAL]`, `[QUESTION]`.\\n\\n\\n## Pull requests\\n\\nAny Airalab repository or this documentation may be subject to pull requests or changes by contributors where you believe you have something valuable to add or change. Please, do not forget about basic rules for contributors.\\n\\n### Rules for contributing\\n\\n1. Pull requests are preferred to issues, if you have some fixes, especially for small changes such as typos.\\n\\n2. Make sure the PR description clearly describes the problem and the solution. Include the relevant issue number if applicable.\\n\\n3. Please, do not fix whitespace, format code, or make a purely cosmetic patch.\\n\\n4. Please, attempt to adhere to the prevailing Markdown style, language, and layout.\\n\\n\\n\"}},{\"node\":{\"id\":\"8a57b87693074db89b60627639a0f70f\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/ja/connectivity-terminal-readme/\",\"content\":\"\\n# Sensors-Connectivity Terminal Readme\\n\\n## Connection\\n\\nTo connect to the server:\\n\\n```bash\\nssh <user>@<address>\\n```\\nWhere user and address are replaced with user, which connectivity service runs under, and address of the VM respectively.\\n\\n## Installation\\n\\nInstallation guide can be found on this [page](https://wiki.robonomics.network/docs/en/sensors-connectivity-on-aira/).\\n\\n\\n## Status checking \\n\\nAssuming you launch the code as a systemd service. Therefore, to check service status:\\n\\n```bash\\nsystemctl status connectivity.service\\n```\\nThere you will find all necessary information about the service, including path to the log files.\\n\\n## Logs\\n\\nGeneral path for log files is: ` ~/.ros/log/latest/connectivity-worker-1.log` where `connectivity-worker-1.log` is the last recordered file.\\n\\nFor watching logs in real time:\\n```bash\\ntail -f  <path>\\n```\\nWhere path should be replced with the log path. To look through the whole file simply open the log file in your favourite editor.\\n\\nIt can be useful to copy log files to your local machine:\\n\\n```bash\\nscp -rv <user>@<address>: <path-to-log-files> <path-in-your-local-machine>\\n```\"}},{\"node\":{\"id\":\"bc0a302d7db419a1e8ef759221b97e4b\",\"title\":\"Connect the simplest CPS\",\"path\":\"/docs/ja/connect-simple-cps/\",\"content\":\"\\nIn this section we will build the simplest real cyber-physical system!\\n\\nWe will buy a \\\"wink\\\" from Arduino, e.g. make Arduino blink with its onboard led. The lesson is tested on Arduino Uno, but any other board with a led will do the job.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_blink).\\n\\n## Arduino\\n\\nThe firmware for the board is located in [arduino_blink/misc/arduino/arduino.ino](https://github.com/airalab/robonomics_tutorials/blob/master/arduino_blink/misc/arduino/arduino.ino). Use [Arduino IDE](https://www.arduino.cc/en/Main/Software) to load the code to your Arduino board.\\n\\nIn the code we subscribe for the ``/blink_led`` topic and set a callback. The type of the topic is ``Empty``, so the board waits until someone publishes to the topic and performs the LED blinking.\\n\\n```\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle  nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void messageCb( const std_msgs::Empty& toggle_msg){\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> sub(\\\"blink_led\\\", &messageCb );\\n\\n  void setup()\\n  {\\n    pinMode(LED_BUILTIN, OUTPUT);\\n    nh.initNode();\\n    nh.subscribe(sub);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n\\n## AIRA client\\n\\n> You can download the latest release from [here](https://github.com/airalab/aira/releases).\\n\\nSet up the COM port forwarding. You should forward your `/dev/ttyUSB0` or `/dev/ttyACM0` port (depending on the system) to `COM1`. In the client `/dev/ttyS0` will represent the board. After this launch the virtual machine.\\n\\n## ROS\\n\\nWhen new liability is created it goes to `/liability/ready` topic. We have to remember the address and call `/liability/start` service to get the data from objective.\\n\\n```\\n  def newliability(l):\\n    self.liability = l.address\\n    rospy.loginfo(\\\"Got new liability {}\\\".format(self.liability))\\n\\n    prefix = \\\"/liability/eth_\\\" + self.liability\\n    rospy.Subscriber(prefix + '/blink', Empty, self.blink)\\n\\n    rospy.wait_for_service(\\\"/liability/start\\\")\\n    rospy.ServiceProxy('/liability/start', StartLiability)(StartLiabilityRequest(address=self.liability))\\n  rospy.Subscriber(\\\"/liability/ready\\\", Liability, newliability)\\n```\\n\\nA message in the `/blink` topic come from the objective field. Have a look at [Basic usage](/docs/aira-basic-usage) page.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh). All tutorials are pre-installed. To launch the ros package run the following command:\\n\\n```\\n$ rosrun arduino_blink blink.py\\n```\\n\\nAlso we need to add a rosbag file to IPFS::\\n\\n```\\n$ ipfs add rosbag/blink.bag\\n```\\n\\n> Before the next step you should approve XRT tokens on the Factory.\\n\\nOn your host system build and launch an Dapp for the lesson:\\n\\n```\\n$ git clone https://github.com/airalab/robonomics_tutorials/\\n$ cd robonomics_tutorials/arduino_blink_dapp\\n$ npm i && npm run dev\\n```\\n\\nOpen [http://localhost:8000/](http://localhost:8000/) and press \\\"Demand\\\" then \\\"Offer\\\" buttons. Wait until a new liability is created and you should see the board blinking. Congratulations on the first agent!\\n\"}},{\"node\":{\"id\":\"36508ccdf68d4864b6d43be36878f329\",\"title\":\"Connect Sensor To Robonomics Network\",\"path\":\"/docs/ja/connect-sensor-to-robonomics/\",\"content\":\"\\n## Hardware\\n\\nUniversal board for air quality sensor, based on ESP8266 allows to use the following modules: NODEMCU v3, NODEMCU v2, WEMOS D1 MINI. The device is designed for 6 - 24 volt power supply, using DC-DC converter DC MINI560.\\n\\n![plata](../images/sensors-connectivity/plata.png)\\n\\nThis board allows you to connect PM sensors:\\n\\n- [SDS011](https://cdn-reichelt.de/documents/datenblatt/X200/SDS011-DATASHEET.pdf)\\n- PMS1003-6003\\n- [PMS7003/G7](http://www.plantower.com/en/content/?110.html)\\n- [SPS 30 PM Sensor](https://sensirion.com/products/catalog/SPS30/)\\n\\nI2C connectivity:\\n\\n- [BMP180](https://cdn-shop.adafruit.com/datasheets/BST-BMP180-DS000-09.pdf) - temperature and humidity\\n- [BME/P280](https://www.mouser.com/datasheet/2/783/BST-BME280-DS002-1509607.pdf) - temperature, humidity, atmospheric pressure\\n- [HTU21D](https://eu.mouser.com/ProductDetail/Measurement-Specialties/HTU21D?qs=tx5doIiTu8oixw1WN5Uy8A%3D%3D) - temperature and humidity\\n- SHT3x(I2C) - temperature and humidity\\n- [CCS811 VOC SENSOR](https://www.sciosense.com/wp-content/uploads/documents/Application-Note-Baseline-Save-and-Restore-on-CCS811.pdf) - volatile Organic Compounds, CO2 equivalent\\n- LCD1602/ 2004 / OLED SSD1306 / SH1106 - supported displays\\n\\nPossibility of connection via 1 Wire interface:\\n\\n- DTH22(AM2302) - temperature and humidity\\n- DS18B20 - temperature.\\n\\nThere is also a smaller MINI model with a trimmed down list of connectable devices. The source circuits for both models can be found at [full model](https://oshwlab.com/ludovich88/aira_sensor_rev0-1) and [MINI model](https://oshwlab.com/ludovich88/aira_sensor_d1_mini).\\n\\n> To obtain a ready-made board, contact the developers at vm@multi-agent.io.\\n\\nAfter receiving/assembling the sensor, all that remains is to flash and configure it.\\n\\n## Firmware\\n\\nOur firmware is based on the firmware from [Sensor.Community](https://github.com/opendata-stuttgart/sensors-software), with some sensors added and the data sending scheme changed. The source code can be found [at the link](https://github.com/LoSk-p/sensors-software/tree/master/airrohr-firmware). \\n\\nTo flash the sensor you can use `airrohr-flasher`. Download the executable for your operating system from [latest release](https://github.com/airalab/sensors-connectivity/releases).\\n\\n### For Linux\\n\\nFirst you need to add a user to the `dialout` group (for Ubuntu) to gain access to the USB port:\\n\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\n\\nAfter that, reboot the computer. Next, change the permissions of the file and run it:\\n\\n```bash\\nchmod +x airrohr-flasher-linux\\n./airrohr-flasher-linux\\n```\\n\\n### For Windows:\\nUnzip the flasher and double-click to run it. You will also need to install drivers for USB2serial (Windows 10 should start automatically):\\n\\n* Drivers for NodeMCU v3 (CH340): [Windows](http://www.wch.cn/downloads/file/5.html) ([2018/09/04 v3.4 mirror](https://d.inf.re/luftdaten/CH341SER.ZIP))\\n\\n### For MacOS.\\nDownload the flasher and run it. You will also need to install the drivers for USB2serial: \\n* Drivers for NodeMCU v3 (CH340): [macOS](http://www.wch.cn/downloads/file/178.html) ([2018/09/04 v1.4 mirror](https://d.inf.re/luftdaten/CH341SER_MAC.ZIP))\\n\\n---\\n\\nSelect the firmware (in English or Russian) and click `Upload`. Uploading the firmware will take some time.\\n\\n![flasher](../images/sensors-connectivity/7_flasher.jpg)\\n\\n## Setup\\n\\nAfter downloading the firmware, reboot the ESP (just disconnect and reconnect the USB).\\n\\nAfter a while after the reboot, ESP will create a Wi-Fi network called RobonomicsSensor-xxxxxxxxx. Connect to it from your phone or computer, then an authorization window will open (if it doesn't open in any browser go to 192.168.4.1). Select your Wi-Fi network from the list (or write it yourself if it's not on the list) and fill in the password field. Also write the coordinates of the place where the sensor will be installed in the field below:\\n\\n![guest](../images/sensors-connectivity/guest.jpg)\\n\\nClick `Save and restart`.\\n\\nThe board will connect to the specified Wi-Fi network and in a couple of minutes you will be able to see the data on [map](https://sensors.robonomics.network/#/):\\n\\n![map](../images/sensors-connectivity/14_map.jpg)\\n\\n## Advanced Setup\\n\\nFor a more detailed setup (you may need it to connect additional sensors or send data to your own server) you need to find the address of the sensor in your Wi-Fi network. To do this, you can use `airrohr-flasher` (your computer must be on the same network as the sensor is connected to). Start it and go to the `Discovery` tab, then press `Refresh`, wait a moment and your sensor address will appear.\\n\\n![addr](../images/sensors-connectivity/11_flaser2.jpg)\\n\\nDouble-click on this address (or type it into your browser), you will get to the sensor menu:\\n\\n![home](../images/sensors-connectivity/home.png)\\n\\nUnder the `Configuration` tab you can configure the sensors used:\\n\\n![sensors](../images/sensors-connectivity/sensors.png)\\n\\nAnd also set up sending to your own server. To do this, in the tab `APIs` uncheck `Robonomics` and check `Send to own API` and specify the server address and port (65 for sensors connectivity):\\n\\n![apis](../images/sensors-connectivity/apis_en.png)\\n\\nClick `Save and restart` to save the settings.\\n\\n\\n\"}},{\"node\":{\"id\":\"9a477fa449601547bb20455eea5a53c8\",\"title\":\"Connect Mars Curiosity rover under Robonomics parachain control\",\"path\":\"/docs/ja/connect-mars-curiosity-rover-under-robonomics-parachain-control/\",\"content\":\"\\n**Let's see how Robonomics Parachain control allows to make Mars Curiosity rover move. Requirements:**\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n- IPFS up to [0.6.0](https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz)\\n- [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases). This tutorial tested fine on v1.1)\\n\\nHere is the video showing successful launch:\\n\\nhttps://www.youtube.com/watch?v=6BSOyRbmac8\\n\\n### 1. Set up a simulation\\nDownload Curiosity rover package:\\n```shell\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src\\ngit clone https://bitbucket.org/theconstructcore/curiosity_mars_rover/src/master/\\ncd ..\\ncatkin build\\n```\\nWe need to adjust starting conditions to make our rover spawn smoothly:\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/worlds` and change line 14 of the file` mars_curiosity.world` to \\n`<pose>0 0 8 0 0 0</pose>`\\n\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/launch` and change line 4 of the file `mars_curiosity_world.launch` to \\n`<arg name=\\\"paused\\\" default=\\\"false\\\"/>`\\n\\nDon't forget to add source command to `~/.bashrc`\\n`source /home/$USER/robonomics_ws/devel/setup.bash`\\n\\n\\n- Reboot console and launch the simulation:\\n\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\n![Mars rover](../images/curiosity-demo/rover.jpg?raw=true \\\"Mars rover\\\")\\n\\nNote: if the image is dark, e.g. shadowed, change `Camera` to `Orthorgraphic` in Gazebo toolbar.\\nThe simulation can be closed for a while.\\n\\n------------\\n\\n### 2. Download Robonomics controller package\\nTo download a controller package for Rover type in terminal:\\n```shell\\ncd ~/robonomics_ws/src\\ngit clone https://github.com/PaTara43/robonomics_sample_controller\\ncd robonomics_sample_controller\\npip3 install -r requirements.txt\\npip3 install rospkg\\ncd ..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3 # The controller supports python3\\n```\\n\\n------------\\n\\n### 3. Manage accounts in DAPP\\nSince we are testing, let us create a local robonomics network with robonomics binary file:\\n```shell\\n./robonomics --dev --tmp\\n```\\n\\n![Running node](../images/curiosity-demo/robonomics.jpg?raw=true \\\"Running node\\\")\\n\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node \\n\\n![Local node](../images/curiosity-demo/local_node.jpg?raw=true \\\"Local node\\\")\\n\\n\\nGo to Accounts and create **CURIOSITY** and **EMPLOYER** accounts.\\n\\n**Important**! Copy each account's address (to copy address click on account's icon) and Curiosity's account **mnemonic seed** (obtained while creating the account)\\nTransfer some money (units) to these accounts. You can read more about accounts in Robonomics [here](https://wiki.robonomics.network/docs/en/create-account-in-dapp/)\\n\\n![Account creation](../images/curiosity-demo/account_creation.jpg?raw=true \\\"Account creation\\\")\\n\\n\\nAdd these addresses, seed and node address (defaults to `ws://127.0.0.1:9944` for developer node) in `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. No quotes.\\n\\n------------\\n\\n\\n### 4. Start Robonomics\\n\\nBefore going further, make sure that you have installed [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion).\\n\\nIn a separate terminal launch IPFS:\\n```shell\\nifps init #you only need to do this once per IPFS installation\\nipfs daemon\\n```\\n\\nIn another separate terminal launch Curiosity simulation if it's not live:\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\nWait till it stays still\\n\\nIn another terminal launch the controller:\\n```shell\\nrosrun robonomics_sample_controller sample_controller.py\\n```\\n![Controller](../images/curiosity-demo/controller.jpg?raw=true \\\"Controller\\\")\\n\\n\\nNow you can send a transaction triggering the Rover to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/).\\nGo to `Developer->Extrinsics` and select Curiosity's employer account, `launch` extrinsic, Curiosity's account as a target account and `yes` as a parameter.\\nSubmit the extrinsic.\\n\\n![Extrinsic](../images/curiosity-demo/extrinsic.jpg?raw=true \\\"Extrinsic\\\")\\n\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter. The rover will move around and collect data for about a minute.\\nLater, when the job is done:\\n\\n![Job done](../images/curiosity-demo/job_done.jpg?raw=true \\\"Job done\\\")\\n\\n\\nOn the Robonomics portal go to `Developer -> Chain state` and obtain a `CURIOSITY` datalog using “+” button with selected `datalog -> RingBufferItem` as query: \\n\\n![Datalog](../images/curiosity-demo/datalog.jpg?raw=true \\\"Datalog\\\")\\n\\nNow the IPFS hash of the telemetry is saved in the blockchain. To see the data simply copy the hash and find it on a gateway:\\n\\n![Data in IPFS](../images/curiosity-demo/data_in_ipfs.jpg?raw=true \\\"Data in IPFS\\\")\\n\\n\\nThis telemetry is kept in a decentralized storage, and it's hash is stored in a blockchain!\\n\"}},{\"node\":{\"id\":\"f0380c631f1524d147f23b941892978e\",\"title\":\"Connect any ROS-compatible robot under Robonomics parachain control. Part 2, IPFS\",\"path\":\"/docs/ja/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/\",\"content\":\"\\n**In this article we will continue using Robonomics tools to make a drone be controlled by a parachain. This time we will add sending data to IPFS and hash storing in chain options. Below is the instruction and code snippets. Requirements:**\\n- [**Part 1 of this tutorial**](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1)\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- IPFS 0.4.22 (download from [here](https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-386.tar.gz) and install)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n- Python dependencies:\\n```\\npip install cv_bridge ipfshttpclient\\n```\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=dliLb6GHgpo&feature=youtu.be\\n\\n\\n## 1. Add dependencies\\nIf we launch a simulation and look at the topic list (see previous tutorial), we will see, that there is one topic containing front camera data and using `sensor_msgs/Image` message type:\\n\\n![front_camera](../images/drone-demo/front_camera.jpg \\\"front_camera\\\")\\n\\nLet's try to take a picture every 1 second and after the flight publish these photos to IPFS. If you have completed the first tutorial, you don't need to download anything else. It's the `drone_sample_controller_pictures.py` script.\\n## 2. Manage accounts in DAPP\\nAs done in a previous tutorial, create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 3. Launch\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nIn another one launch ipfs daemon:\\n```\\nifps init # you only need to do this once\\nipfs daemon\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller_pictures.py\\n```\\nNow you can send a transaction triggering the drone to start flying and taking pictures. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying and taking pictures:\\n\\n![flying_picturing](../images/drone-demo/flying_picturing.jpg \\\"flying_picturing\\\")\\n\\nLater, when the job is done, on the Robonomics portal go to `Developer` -> `Chain state` and add a `DRONE` datalog using `“+”` button with selected `datalog` as state query. The IPFS hash of the telemetry has been saved in the blockchain. To see the data simply copy the hash and add it to the local [gateway](https://gateway.ipfs.io/ipfs/QmeYYwD4y4DgVVdAzhT7wW5vrvmbKPQj8wcV2pAzjbj886/docs/getting-started/) address `localhost:8080/ipfs/`:\\n\\n![Voila](../images/drone-demo/datalog.jpg \\\"Voila\\\")\\n\"}},{\"node\":{\"id\":\"bd30c0d8390ac26debb3955bdcf4e985\",\"title\":\"Connect ROS-compatibale Drone To Robonomics Parachain. Part 1. Launch by Transaction\",\"path\":\"/docs/ja/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/\",\"content\":\"\\n**In this article we will show that with the help of Robonomics tools you can control any ROS-compatible device. We will find a random drone simulation package on the web and adjust it to run with Robonomics.**\\n**Requirements:**\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=fDpwhBasQ5o&feature=youtu.be\\n\\n## 1. Find a simulation\\nLet's surf the web. Google for `ROS drone simulator`. The first link will mostly likely show you the `tum_simulator` page on [http://wiki.ros.org/tum_simulator](http://wiki.ros.org/tum_simulator)\\n\\n![tum_simulator](../images/drone-demo/tum_simulator.jpg \\\"tum_simulator\\\")\\n\\nIt's pretty outdated, so we better find a fork for our system. Google for `tum_simulator Ubuntu 18 Gazebo 9 fork`. The first result is a GitHub [repo](https://github.com/tahsinkose/sjtu-drone) with an appropriate package. Dowload it\\n```\\nmkdir -p drone_simulator_ws/src\\ncd drone_simulator_ws/src\\ngit clone https://github.com/tahsinkose/sjtu-drone\\ncd ..\\ncatkin build\\n```\\nDon’t forget to add source command to `~/.bashrc`:\\n```\\necho \\\"source /home/$USER/drone_simulator_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource \\\"~/.bashrc\\\"\\n```\\nNow we can run the simulation to see what do we need to do to take the drone under parachain control.\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\n\\n## 2. Inspect ROS topics\\nWhen the simulation is runnung, in a new tab run the following command to see the list of topics used by the drone:\\n```\\nrostopic list\\n```\\nLet's take a look at `/cmd_vel`, `/drone/takeoff` and `/drone/land`:\\n```\\nrostopic info /cmd_vel\\nrostopic info /drone/takeoff\\nrostopic info /drone/land\\n```\\n\\n![topics_info](../images/drone-demo/topics_info.jpg \\\"topics_info\\\")\\n\\nAs may be seen, there should be messages of `Twist` and `Empty` types, they are parts of `std_msgs` and `geometry_msgs`, we'll use this in the controller. Shut the simulation for a while.\\n## 3. Download controller package\\nGlobally, the main difference from the casual ROS robot controller is a block of code, which checks all the transactions in the network using [Robonomics IO](https://wiki.robonomics.network/docs/rio-overview/). The package itself is available on GitHub. Download it and build the workspace:\\n```\\ncd ~/drone_simulator_ws/src\\ngit clone https://github.com/PaTara43/drone_simulator_controller\\ncd drone_simulator_controller/src\\nchmod +x *.py\\ncd ~/drone_simulator_ws/src\\ncatkin build\\n```\\n## 4. Manage accounts in DAPP\\nSince we are testing, let's create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 5. Launching the drone under parachain control\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller.py\\n```\\n\\n![launched_drone](../images/drone-demo/launched_drone.jpg \\\"launched_drone\\\")\\n\\nNow you can send a transaction triggering the drone to start flying. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying:\\n\\n![flying](../images/drone-demo/flying.jpg \\\"flying\\\")\\n\\nThat's how any ROS-compatible robot can be controlled by Robonomics parachain control. Proceed to [part 2](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2) to learn more\\n\"}},{\"node\":{\"id\":\"c87920f846f5ae1464a4a54371444a59\",\"title\":\"Configuration Options Description\",\"path\":\"/docs/ja/configuration-options-description/\",\"content\":\"\\nBasically, you can think of the package as a black box with one input (sensor data) and many outputs.\\nFor now only SDS011 sensor is supported, but if you are familiar with Python it'd be easy to add other sensors as well.\\n\\nHave a look at [configuration](https://github.com/airalab/sensors-connectivity/blob/master/config/default.json) file:\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"port\\\": \\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\": 300,\\n      \\\"geo\\\": \\\"\\\",\\n      \\\"public_key\\\": \\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\nAt the moment it's possible to publish data to [Luftdaten](https://luftdaten.info/), [Robonomics Network](https://robonomics.network/) and [Datalog](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer).\\nThe last one is experimental!\\n\\n> DO NOT edit `config/default.json` file. Instead make a copy\\n\\nPlay around with the configuration!\\n\\nExplanation of options:\\n\\n| Field                         | Description                                                                                                                                                                                                                                           |\\n|------------------------------    |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |\\n| `general/publish_interval`         | integer number from 1 and above. Tells how often send measurements. Keep in mind that if measurements from sensors come less often than this number connectivity sends last data      |\\n| `general/db_path`                  |   path to the database (.db) file    |\\n| `comstation/enable`                | true/false. Enabling/disabling the station      |\\n| `comstation/port`                  | valid path to com port, for example `/dev/ttyUSB0`. It is where a sensor is connected to      |\\n| `comstation/work_period`           | integer from 0 to 1800. For SDS011 sensor 0 means continuous work. Recommended period is 300 seconds     |\\n| `comstation/geo`                   | `lat,lon` a string with two floats separated by a comma. It represents latitude and longitude of a sensor     |\\n| `comstation/public_key`            | Ed25519 verifying key in hex format. If not provided connectivity generates a new one      |\\n| `httpstation/enable`                | true/false. Enabling/disabling the station   |\\n| `httpstation/port`                  | what port listen to      |\\n| `mqttstation/enable`                | true/false. Enabling/disabling the station   |\\n|`mqttstation/host`                   | the hostname or IP address of the remote broker |\\n|`mqttstation/port`                   | the network port of the server host to connect to |\\n| `luftdaten/enable`                 | true/false. Whether or not publish data to [Luftdaten](https://devices.sensor.community/). Don't forget to register the sensor's mac address on the site         |\\n| `robonomics/enable`                | true/false. Whether or not publish data to IPFS topic according to Robonomics communication protocol      |\\n| `robonomics/ipfs_proveder`         | an endpoint for IPFS daemon. By default it's `/ip4/127.0.0.1/tcp/5001/http` that means local daemon. The endpoint must by in multiaddr format. For example for [Infura.io](https://infura.io/) it would be `/dns/ipfs.infura.io/tcp/5001/https`       |\\n| `robonomics/ipfs_topic`            | IPFS topic's name. If you want to use [DApp](https://sensors.robonomics.network) provided by Robonomics team leave it untouched                 |\\n| `datalog/enable`                   | true/false. Enable/Disable saving log to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)    |\\n| `datalog/suri`                     | a private key from robonomics parachain account  |\\n| `datalog/dump_interval`            | specify a period of time for collecting log in seconds                                      |\\n| `datalog/temporal_username`        | set username to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `detalog/temporal_password`        | set password to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `datalog/pinata_api`                | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) api key                      |\\n| `datalog/pinata_secret`            | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) secret api key                |\\n| `dev/sentry`                       | for development purpose. If you have a [Sentry.io](https://sentry.io/) account you can put sentry's credentials in here   |\\n| `frontier/enable`                  | true/false. Whether or not publish telemetry to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)   |\\n| `frontier/suri`                    | a private key from robonomics parachain account                                                       |\\n| `trackagro/enable`                 | true/false. Enabling/disabling the station from [TrackAgro](https://tmeteo.docs.apiary.io/#)          |\\n| `trackagro/token`                  | authorization token for [TrackAgro](https://tmeteo.docs.apiary.io/#)                                  |\\n\\n## Scenario #1: Connect SDS011 to serial port\\n\\nThe easiest and the most straightforward way to connect your sensor to the network is using the serial port\\n\\nConnect you SDS011 sensor to a USB port, let's assume it got `/dev/ttyUSB0` address\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #2: Connect SDS011 via HTTP\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n> Do not forget to open the port in system firewall\\n>\\n> On NixOS you can do:\\n> ```\\n> networking.firewall.allowedTCPPorts = [ 31313 ];\\n> ```\\n\\n## Scenario #3: Connect SDS011 via MQTT\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #4: Connect Multiple Sensors and Publish to Datalog\\n\\n### Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": true\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n\\n\"}},{\"node\":{\"id\":\"e3944f34d4d0a1c8789124183746d959\",\"title\":\"Community\",\"path\":\"/docs/ja/community/\",\"content\":\"\\n**Here you can learn how to get involved in the Robonomics Network Community.**\\n\\nThere are many ways to contribute to Robonomics Network: you can contribute directly based on your skills and professional background, you can attend an event, join the conversation online or watch for our latest news and release.\\n\\n## For Developers\\n\\n- [Robonomics' code base and new releases on GitHub](https://github.com/airalab)\\n- [Ask your technical question on Riot](https://riot.im/app/#/room/#robonomics:matrix.org)\\n\\n## For Researchers & Academics\\n\\n- [Read Robonomics White Paper and our scientific articles](https://robonomics.network/community/#science)\\n\\nIf you have a background in mathematics, cryptography, or economics you might be interested for collaboration with us, write us to [research@aira.life](mailto:research@aira.life)\\n\\n## For All, even non-technical\\n\\n- [Get familiar with Robonomics services and statistics in dApp - open in browser with Metamask](https://dapp.robonomics.network)\\n- [Read our blog](https://blog.aira.life)\\n- [Stay tuned by following us on Twitter](https://twitter.com/AIRA_Robonomics)\\n\\nIf you are not a developer or a researcher, you can start with other suggestions for getting involeved in Robonomics Network Community. If you want to organize a meetup in your city, write content about Robonomics, translate Robonomics content into your native language, write to [community@aira.life](mailto:community@aira.life)\\n\"}},{\"node\":{\"id\":\"6b073ac9b460f949dadd6516c463961f\",\"title\":\"Changing Exodus Bridge Receiving Address\",\"path\":\"/docs/ja/changing-exodus-receiving-address/\",\"content\":\"\\r\\nThis article will provide guidance on how you can change your Robonomics parachain receiving address in the event that you have input the wrong receiving address in the [Exodus bridge dapp](https://dapp.robonomics.network/#/exodus)\\r\\n\\r\\nPlease be aware that the process of changing the receiving address is not something that will be able to be carried out indefinitely, in fact the intervention of the development team is only possible during the early stages of the Robonomics parachain development, and eventually it will not be possible for the development team to conduct this kind of operation. **Please always ensure that you input the correct parachain address (i.e. one you have the seed phrase for) into the Exodus bridging application**.\\r\\n\\r\\n*Please be informed that the currently, if you input the wrong Robonomics parachain account address into the Exodus bridge dapp, then the process will be carried out as follows:*\\r\\n\\r\\n1. Complete the process as described in this article (i.e. signing the message & raising a GitHub issue).\\r\\n2. Bridged $XRT will be sent to the account originally input into the Exodus bridge dapp (i.e. the incorrect account).\\r\\n3. If no transactions are made on the incorrect account for 1 month, then the Robonomics team will transfer the $XRT tokens to the new address stipulated in the message (which you will sign as per the instructions below).\\r\\n\\r\\nOf course, the utmost priority for the Robonomics team is to ensure only valid changes of address are executed, as such you need to sign a message **from the Ethereum account which you originally deposited the $XRT tokens into the Exodus dapp**. We recommend that you utilize a site such as [MyCrypto](https://app.mycrypto.com/sign-message) to create this message (the following images will show how to conduct this process on MyCrypto).\\r\\n\\r\\nSelect the icon which corresponds to your web3 wallet, in our case we will choose MetaMask.\\r\\n\\r\\n![MyCrypto.com-Landing-Page](https://i.imgur.com/fyJyBG0.png)\\r\\n\\r\\nNow, click on the \\\"Connect to MetaMask\\\" button as shown above, and select the correct account (the account which you previously **sent $XRT tokens from**).\\r\\n\\r\\n![Page-after-selecing-metamask](https://i.imgur.com/1rd6izf.png)\\r\\n\\r\\nNow, we get the option to input a message, you shall follow the below template when inputting the message into this section, otherwise the process will not work. **These addresses relate to the Robonomics parachain addresses**.\\r\\n\\r\\n>Wrong target address: **WRONG_ADDRESS**. Right target address: **RIGHT_ADDRESS**\\r\\n\\r\\nSo, your message will look something like the message below (please make sure you input your own address, and not the one shown below). The message should all be on 1 line, don't use any line breaks (i.e. pressing enter). Afterwards, press the \\\"Sign Message\\\" button located under the message text.\\r\\n\\r\\n![example-of-how-the-message-should-look](https://i.imgur.com/jb1YqLs.png)\\r\\n\\r\\nNow you should get a notification on your web 3 wallet, click \\\"Sign\\\".\\r\\n\\r\\n![Example-metamask-notification](https://i.imgur.com/GTHEYTs.png)\\r\\n\\r\\nOnce signed, wait a few moments and then the MyCrypto page should change, and a signature shall appear.\\r\\n\\r\\n![signature-generated-from-signed-message](https://i.imgur.com/JemAEPm.png)\\r\\n\\r\\nNext, you need to head on over to the [Robonomics GitHub page](https://github.com/airalab/robonomics/issues/new), and open a new issue. The issue should have the title \\\"Robonomics exodus: a request to change the target address\\\", and the body / comment of the issue shall be the signature generated by MyCrypto. Afterwards, click \\\"Submit new issue\\\", and the Robonomics team will handle your issue and leave a reply to your issue regarding the status of your request.\\r\\n\\r\\n![example-of-GitHub-issue](https://i.imgur.com/6ZHSFRw.png)\"}},{\"node\":{\"id\":\"574afe46e71167a0ea6e984b005c4d30\",\"title\":\"Offsetting Service\",\"path\":\"/docs/ja/carbon-footprint-service/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"}},{\"node\":{\"id\":\"b930ddf9a834a0199d6dc86f12cd3021\",\"title\":\"Connect sensor\",\"path\":\"/docs/ja/carbon-footprint-sensor/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"}},{\"node\":{\"id\":\"d1aec3a1462e0a0afb0af73d09f74112\",\"title\":\"Say \\\"Hello Baxter!\\\" with robonomics\",\"path\":\"/docs/ja/baxter2/\",\"content\":\"Example of how it works:\\n\\nhttps://youtu.be/2Dvuv0ZE2Bw\\n\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```sh\\nsudo apt-get install ros-melodic-qt-build ros-melodic-driver-common ros-melodic-gazebo-ros-control ros-melodic-gazebo-ros-pkgs ros-melodic-ros-control ros-melodic-control-toolbox ros-melodic-realtime-tools ros-melodic-ros-controllers ros-melodic-xacro python-wstool ros-melodic-tf-conversions ros-melodic-kdl-parser python-wstool python-catkin-tools qt4-default\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```sh\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node (binary file) (download latest [release][db4] here)\\n - Create __Baxter__ and __Employer__ accounts  on **Robonomics Portal**  \\n (you can find tutorial [\\\"Create an Account on Robonomics Portal\\\"][db8] here).\\n - IPFS browser extension (not necessary)\\n\\n## 0. install CV Bridge extension for python3\\n\\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n## 1. Download simulation and controller packages\\nWe will need to create 2 workspaces - one for main Baxter's packages and other for main control programme.\\nFirst workspace. It's main control programme. It will run under python3.\\n\\n```sh\\ncd ~\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src/\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\npip3 install -r requirements.txt\\n```\\nSecond workspace. There will be all Baxter's packages. Simulation is very old, so it could run only under python2.\\n```shell\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src/\\nwstool init .\\nwstool merge https://raw.githubusercontent.com/RethinkRobotics/baxter_simulator/master/baxter_simulator.rosinstall\\nwstool update\\n```\\nThese packages were created for ROS indigo. We have to change some files to run them on ROS melodic.\\nWe will use **patch** files.\\n```sh\\npatch ./baxter_simulator/baxter_sim_io/include/baxter_sim_io/qnode.hpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/qnode_patch\\npatch ./baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/arm_patch\\npatch ./baxter_interface/src/baxter_interface/robot_enable.py ~/robonomics_ws/src/Baxter_simulation_controller/patch/interface_patch\\n```\\nAnd let's build  all our packages:  \\nFirst build Baxter's packages\\n```sh\\ncd ../\\ncatkin build\\n```\\nThen return to first workspace and build it too:\\n```sh\\ncd ~/Baxter_simulation_controller/\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\necho \\\"source /home/$USER/robonomics_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```  \\n\\n\\n## 2. Start simulation\\n### Let's start our simulation:\\nAt first go to `robot_ws` and copy and edit baxter.sh\\n```sh\\ncd ~/robot_ws/\\ncp src/baxter/baxter.sh .\\n```\\nFind your local ip address with command:\\n```\\nip a\\n```\\n![ip_a][im14]\\n\\nEdit the following values in `baxter.sh` :\\n```\\nnano baxter.sh\\n```\\n\\n- your_ip - put your local ip address. See `ip a`\\n- ros_version - for example \\\"melodic\\\"\\n\\n![baxtersh][im15]\\n\\nRun the baxter shell script with sim specified:\\n```sh\\n./baxter.sh sim\\nroslaunch baxter_gazebo baxter_world.launch\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp\\n```\\n![robonomics][im3]\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts.\\n\\nYou can find The manual \\\"Create an Account on Robonomics Portal\\\" [here][db8]\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\n\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n![create account2][im16]\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robonomics_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same portal [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nWhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL:  \\n#### gateway.ipfs.io/ipfs/< put your hash here>\\n\\n\\n\\nThat's all!\\n\\n![result1][im12]\\n![result2][im13]\\n\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/ip_a.png>\\n[im15]: <../images/baxter_demo/baxter_sh.jpg>\\n[im16]: <../images/baxter_demo/create_account2.jpg>\\n[db8]: <https://wiki.robonomics.network/docs/create-account-in-dapp/>\"}},{\"node\":{\"id\":\"92b1d2270c986871832ad10e7277f00b\",\"title\":\"Control Baxter robot with robonomics\",\"path\":\"/docs/ja/baxter/\",\"content\":\"\\nExample of how it works:\\n\\nhttps://www.youtube.com/watch?v=JivTDhDJLHo\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-melodic-cv-bridge\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```shell\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node download latest [release][db4] here (last tested release v1.1)\\n - IPFS browser extension (not necessary)\\n## 0. install CV Bridge extension for python3\\n \\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\n\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n\\n## 1. Download simulation and controller packages\\nDownload packages:\\n```sh\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\ngit checkout old_version\\npip3 install -r requirements.txt\\ncd ../..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n## 2. Start simulation\\nLet's start gazebo world and put our baxter in it:\\n```sh\\nroslaunch gazebo_ros empty_world.launch\\n```\\n![empty world][im1]\\n\\nOpen one more window in terminal:\\n```sh\\nrosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp --rpc-cors all\\n```\\n![robonomics][im3]\\n\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts (__Robot__ is not necessary)\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n\\n![create account2][im14]\\n\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robot_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nwhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL: gateway.ipfs.io/ipfs/< put your hash here >\\n\\n![ipfs][im11]\\n\\nClick  __View on Gateway__ and that's all!\\n\\n![result1][im12]\\n\\n![result2][im13]\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/create_account2.jpg>\"}},{\"node\":{\"id\":\"b50f46ed9c5ea9e7556a3e589da2c0cf\",\"title\":\"AIRA Overview\",\"path\":\"/docs/ja/aira-overview/\",\"content\":\"\\n## Introduction\\n\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It implements the standard of economic interaction between human-robot and robot-robot. AIRA makes it possible to connect a variety of different robots under decentralized computer's control (currently supported Ethereum and Polkadot/Substrate).\\n\\nBasically it is the client for Robonomics Network developed by [Airalab](https://aira.life).\\n\\nAIRA is NixOS based operating system and officially supports the following architectures: x86, Raspberry Pi 3 B+ and Raspberry Pi 4.\\n\\nThe most simple way to get familiar with AIRA is to try installing AIRA as a [virtual machine](/docs/aira-installation-on-vb/).\\n\\nAIRA comes with a few preinstalled and configured services to help you focus on [agent](/docs/glossary#agent) development.\\n\\nMeanwhile it's highly customizable, but it's recommended to understand [NixOS](http://nixos.org/) and [Nix](https://nixos.org/nix/) language.\\n\\n## What's included? \\n\\nThe following services are included in the default distribution:\\n\\n* [Robonomics communication stack](https://github.com/airalab/robonomics_comm)\\n* [IPFS](https://ipfs.io/)\\n* OpenSSH\\n* [cjdns](https://github.com/cjdelisle/cjdns)\\n* [Yggdrasil-go](https://yggdrasil-network.github.io/)\\n\\nBesides at the first launch AIRA [generates](/docs/aira-installation-on-vb#launch-the-machine) for you new Ethereum address and IPNS identifier.\\n\\nIt's possible to use AIRA as a virtual machine or install as a main operating system. Also you can install only the services you need.\\n\"}},{\"node\":{\"id\":\"7e5be80d03ded19ce4ce981224eb234d\",\"title\":\"AIRA Installation\",\"path\":\"/docs/ja/aira-installation/\",\"content\":\"\\n- [**How to launch AIRA on VirtualBox**](/docs/aira-installation-on-vb/)\\n\\n- **The installation on Raspberry Pi** is as simple as writing an image of AIRA on SD card using `dd` or [Etcher](https://www.balena.io/etcher/), for example.\\n\\n\\n\"}},{\"node\":{\"id\":\"cf7476fb84c6c3be3b6662d4270adec8\",\"title\":\"AIRA Installation on VirtualBox\",\"path\":\"/docs/ja/aira-installation-on-vb/\",\"content\":\"\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It is the client for Robonomics Network developed by [Airalab](https://aira.life). It is an operating system based on [NixOS](https://nixos.org/). With AIRA you can  turn any cyber-physical system in an economic agent, where robots operate as a services for the reasonable payments. [More theory about AIRA here](/docs/aira-overview).\\n\\nIt's possible to install AIRA on a x86_64 PC. Also there are images for Raspberry Pi 3 and 4 supported by the team.\\n\\nThe best way to try AIRA is to start from installing it as a virtual machine on [VirtualBox](https://www.virtualbox.org/).\\n\\n## Requirements\\n\\n* VirtualBox\\n* [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2Gb of RAM for the machine\\n* 40Gb of free disk space\\n\\n## Obtain the image\\n\\nAIRA has [stable](https://aira.life/channels/aira-stable/) and [unstable](https://aira.life/channels/aira-unstable/) channels.\\n\\nTo get stable image download the file with `.ova` extension.\\n\\tThe link for stable image is [here](https://releases.aira.life/channels/aira/stable/862-aira-stable/nixos-20.03pre-git-x86_64-linux.ova)\\n\\nDon't forget to compare checksum of the downloaded image with the last column `SHA-256 hash` on the [download page](https://aira.life/channels/aira-stable/). It must be equal to the output of the following command (it is an example, please check the name of downloaded by you .ova file first):\\n\\n```\\nsha256sum nixos-20.03pre-git-x86_64-linux.ova\\n```\\n\\nYou may wish to check out the walkthrough video:\\n\\nhttps://www.youtube.com/embed/cDcaypYPBhI\\n\\n## Troubleshooting\\n\\nIf you have fresh installed VirtualBox, you need to install the [extension](https://www.virtualbox.org/wiki/Downloads) pack or disable USB 2.0 controller.\\n\\nAlso VirtualBox may show a warning about `Display settings`. Consider switching `Graphics Controller` in settings of the VM to `VMSVGA`.\\n\\n## Import to VirtualBox\\n\\nOpen VirtualBox and press `Ctrl+I` or go to `File > Import Applicance...`\\n\\n![AIRA import VB image](../images/aira-installation/aira_import_vb_image.jpg \\\"AIRA import VB image\\\")\\n\\nAt this moment the next step is not necessary but it will help you to connect to the VM via SSH easily.\\n\\nFirst add `Host-Only` adapter in VirtualBox menu `File > Host Network Manager...` or by pressing `Ctrl+H`\\n\\n![Host Only](../images/aira-installation/host_only_adapter.jpg \\\"Host Only\\\")\\n\\nThen go to the image's settings, Network and add the second network adapter\\n\\n![Second adapter](../images/aira-installation/add_second_adapter.jpg \\\"Second adapter\\\")\\n\\nFor more details look at the standalone [lesson](/docs/aira-connecting-via-ssh/).\\n\\nOptionally you can increase the amount of video memory and switch `Graphics Controller` to `VMSVGA`.\\n\\n## Launch the machine\\n\\nFinally press Start and you'll see AIRA welcoming you with generated Ethereum address and IPFS identifier\\n\\n![AIRA image ready, Welcome screen](../images/aira-installation/aira_image_ready.jpg \\\"AIRA image ready, Welcome screen\\\")\\n\\nAt the very first initialization AIRA generates new Ethereum address and IPNS identifier for you.\\n\\n\"}},{\"node\":{\"id\":\"0705abac9038b5676dc00c5ff2e74ecc\",\"title\":\"Frequently Asked Questions about AIRA\",\"path\":\"/docs/ja/aira-faq/\",\"content\":\"\\n## How to see logs from main services?\\n\\nIPFS in real time:\\n\\n    journalctl -u ipfs -f\\n\\nand Liability::\\n\\n    journalctl -u liability -f\\n\\n## How to check the quantity of IPFS peers?\\n\\n    ipfs pubsub peers \\n\\n## IPFS can't connect to the daemon, what should I do?\\n\\nTry to specify `--api` option\\n\\n    ipfs swarm peers --api=/ip4/127.0.0.1/tcp/5001/\\n\\n## How to change ethereum address of AIRA?\\n\\nDelete `keyfile` and `keyfile-psk` in `/var/lib/liability` and restart the service\\n\\n```\\nsystemctl restart liability\\n```\\n\\n## IPFS daemon doesn't start\\n\\nThe error mostly occurs on single-board computers like Raspberry Pi or LattePanda after unexpected electricity lost.\\n\\nUsually the file `/var/lib/ipfs/api` is corrupted and one may see error:\\n\\n```\\nError: Failed to parse '/var/lib/ipfs/api' file.\\n  error: failed to parse multiaddr \\\"\\\": empty multiaddr\\nIf you're sure go-ipfs isn't running, you can just delete it.\\nOtherwise check:\\n  ps aux | grep ipfs\\n```\\n\\nYou can delete `/var/lib/ipfs/api` file and restart the service\\n\\n\"}},{\"node\":{\"id\":\"fdb82cf8b8e66b4c7e0741d07680b03c\",\"title\":\"Connecting AIRA via SSH\",\"path\":\"/docs/ja/aira-connecting-via-ssh/\",\"content\":\"\\nIt is more convenient to work with virtual machine via ssh connection. In this section we will configure VM.\\n\\n> **It's required to have your ssh public key on Github. In case you don't have one, please follow the [link](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\nBelow is the walkthrough video:\\n\\nhttps://www.youtube.com/embed/R6waDG5iwm0\\n\\n## Add Host Adapter\\n\\nGo to `File` -> `Host Network Manager...` or press `Ctrl+H`\\n\\n![VirtualBox Network Manager](../images/virtualbox_network_manager.png \\\"VirtualBox Network Manager\\\")\\n\\nClick `Create` button.\\n\\n## Add the Second Adapter to the VM\\n\\nSelect imported VM and click `Settings`. Go to `Network` tab and enable the second adapter\\n\\n![Add Second Adapter](../images/add_second_adapter_to_vm.png \\\"Add Second Adapter\\\")\\n\\n## Populate Authorized Keys\\n\\nLaunch the VM and run the following command replacing `<username>` with your Github user name:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nFind out the VM's IP address by running:\\n\\n```\\nip a\\n```\\n\\nYou should look for an address which starts with `192.168.xx.xx`\\n\\n## Log in via SSH\\n\\nNow open your terminal and log in via SSH as usual using the address from the previous step:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n\"}},{\"node\":{\"id\":\"86b3f1c497cdee4f0ddc3cdcc3661e3c\",\"title\":\"Basic usage of AIRA\",\"path\":\"/docs/ja/aira-basic-usage/\",\"content\":\"\\nTo get familiar with AIRA, let's see what is under the hood.\\n\\nOnce you launch the client several ros nodes will already be on the run. Here's a list of robonomics communication stack nodes:\\n\\n```bash\\n$ rosnode list\\n/eth/erc20_token\\n/eth/eth_node\\n/graph/aira_graph\\n/liability/executor\\n/liability/infochan/eth/signer\\n/liability/infochan/ipfs_channel\\n/liability/persistence\\n/liability/listener\\n/rosout\\n```\\n\\n- `/eth/erc20_token`, `/eth/eth_node` - proved services for Ethereum blockchain and ERC20 tokens\\n- `/graph/aira_graph` - service node for exploring other AIRA instances\\n- `/liability/executor` - gets rosbag file from IPFS and plays it\\n- `/liability/infochan/ipfs_channel` - is responsible for offer, demand and result messages. It catches messages from the channel and sends signed messages back\\n- `/liability/infochan/eth/signer` - offers services for signing offer, demand and result messages\\n- `/liability/listener` - watches for a new liability contracts. When the event is received the node calls executor node\\n- `/liability/persistence` - helps to store incoming liabilities and restart them after shutdown\\n\\nAnd here's a list of robonomics stack topics.\\n\\n```bash\\n$ rostopic list\\n/eth/event/approval\\n/eth/event/transfer\\n/graph/greetings\\n/liability/complete\\n/liability/finalized\\n/liability/incoming\\n/liability/infochan/eth/sending/demand\\n/liability/infochan/eth/sending/offer\\n/liability/infochan/eth/sending/result\\n/liability/infochan/eth/signing/demand\\n/liability/infochan/eth/signing/offer\\n/liability/infochan/eth/signing/result\\n/liability/infochan/incoming/demand\\n/liability/infochan/incoming/offer\\n/liability/infochan/incoming/result\\n/liability/persistence/add\\n/liability/persistence/del\\n/liability/persistence/update_timestamp\\n/liability/ready\\n/liability/result\\n/rosout\\n/rosout_agg\\n```\\n\\nThe most important topics for us are:\\n\\n- `/liability/incoming` - when a new liability is created, this topic publishes Ethereum address of the contract\\n- `/liability/result` - this topic is for publishing results. But don't publish a result directly to this topic! Use a service instead\\n- `/liability/infochan/incoming/*` - a CPS gets information about offer, demand or result from corresponding topics\\n- `/liability/infochan/eth/signing/*` - a CPS sends offer, demand or result messages to corresponding topics\\n\\nFor the details check out the [API page](/docs/robonomics-liability/).\\n\\nLet's start with greetings - say hello to AIRA!\\n\\nYou should just launch a pre-installed package `hello_aira`:\\n\\n```\\n$ rosrun hello_aira hello_aira\\n```\\n\\nWe've launched our agent. It will wait for a demand message. Now it's time to send the message. Go to [dapp](https://airalab.github.io/robonomics_tutorials/) and press Order.\\nNow go back to the console and see the result!\"}},{\"node\":{\"id\":\"34ec3362199344bcc5b9a72a3ef4d885\",\"title\":\"Agent development examples\",\"path\":\"/docs/ja/agent-development-examples/\",\"content\":\"\\nUseful pieces of code and a few scenarios. All source code is [here](https://github.com/vourhey/robonomics_tutorials).\\n\\n1. [Broadcast Demand](https://github.com/Vourhey/robonomics_tutorials/tree/master/01_broadcast_demand/)\\n2. [Broadcast Offer](https://github.com/Vourhey/robonomics_tutorials/tree/master/02_broadcast_offer/)\\n3. [Trader](https://github.com/Vourhey/robonomics_tutorials/tree/master/03_trader/)\\n4. [Trader with ACL](https://github.com/Vourhey/robonomics_tutorials/tree/master/04_trader_with_acl/)\\n5. [Open Sensor Data](https://github.com/Vourhey/robonomics_tutorials/tree/master/05_open_sensor_data/)\\n\\n\"}},{\"node\":{\"id\":\"bfb44d68b0e67e6d1966d8931e35a0be\",\"title\":\"Add Device to Robonomics\",\"path\":\"/docs/ja/add-smart-device-to-robonomics/\",\"content\":\"For each device you need separate [Robonomics accounts](/docs/create-account-in-dapp/). After you've added your devices, you need to add them in a `config.config` file with their seeds. Firstly in `Configuration/Entities` tab in your Home Assistant find entity ids of your devices:\\n\\n![entity_id](../images/home-assistant/entity_id.png)\\n\\nOpen the configuration file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add there information of your devices in the following format:\\n\\n```\\n[device_name]\\nIDS = ['entity_id1', 'entity_id2']\\nSEED = word word word\\n```\\nWhere `device_name` is the name of your device (you can choose any name), `IDS` are entity ids of the data from the device (it may be one or more ids) and `SEED` is a mnemonic or raw seed from robonomics account to this device.\\n\\nAfter you fill the configuration file you need to get access token from Home Assistant. For that open your `profile` in the lower left corner:\\n\\n![profile](../images/home-assistant/profile.png)\\n\\nIn the end of the page find `Long-Lived Access Tokens` and press `create token`. Save it somewhere, you will not be able to see it again.\\n\\n![token](../images/home-assistant/token.png)\\n\\nNow run `create_config.py` script with your token:\\n\\n```bash\\ncd /srv/homeassistant\\nsource bin/activate\\npython3 python_scripts/create_config.py --token <access_token>\\n```\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\\n\\nYou can add the data from sensors to your homepage like in `Home Assistant setup` in the description to [Method 1](/docs/zigbee2-mqtt/).\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. Data looks like this:\\n\\n![datalog_data](../images/home-assistant/datalog_data.png)\\n\\nYou can decrypt it with script `decrypt.py`, run it with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"891f83d862b990f7082cba94eaa2760e\",\"title\":\"Connect Sensors with Zigbee2MQTT\",\"path\":\"/docs/es/zigbee2-mqtt/\",\"content\":\"\\n## Mosquitto MQTT broker\\n\\nFor this method, you neet to install MQTT broker to the Raspberry Pi:\\n\\n```bash\\nsudo apt update\\nsudo apt install mosquitto mosquitto-clients\\n```\\nThe Mosquitto program will run automatically after installation.\\n\\n## Zigbee2MQTT setup\\n\\nIf you have the JetHome USB JetStick Z2 it will already have the necessary firmware so you don't need to flash it. However, if you have another adapter the first thing you need to flash it with zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nThen we need to install the ziqbee2mqtt software on the  Raspberry PI. Connect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\nInstall zigbee2MQTT:\\n```bash\\n# Setup Node.js repository\\nsudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\\n\\n# NOTE 1: If you see the message below please follow: https://gist.github.com/Koenkk/11fe6d4845f5275a2a8791d04ea223cb.\\n# ## You appear to be running on ARMv6 hardware. Unfortunately this is not currently supported by the NodeSource Linux distributions. Please use the 'linux-armv6l' binary tarballs available directly from nodejs.org for Node.js 4 and later.\\n# IMPORTANT: In this case instead of the apt-get install mentioned below; do: sudo apt-get install -y git make g++ gcc\\n\\n# NOTE 2: On x86, Node.js 10 may not work. It's recommended to install an unofficial Node.js 14 build which can be found here: https://unofficial-builds.nodejs.org/download/release/ (e.g. v14.16.0)\\n\\n# Install Node.js;\\nsudo apt-get install -y nodejs git make g++ gcc\\n\\n# Verify that the correct nodejs and npm (automatically installed with nodejs)\\n# version has been installed\\nnode --version  # Should output v10.X, v12.X, v14.X or v15.X\\nnpm --version  # Should output 6.X or 7.X\\n\\n# Clone Zigbee2MQTT repository\\nsudo git clone https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\nsudo chown -R ubuntu:ubuntu /opt/zigbee2mqtt\\n\\n# Install dependencies (as user \\\"ubuntu\\\")\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\nThen you need to configure it. Open configuration file:\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\nAnd paste this:\\n```\\npermit_join: true\\nmqtt:\\n  # MQTT base topic for Zigbee2MQTT MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n```\\nNow you can run zigbee2mqtt:\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n## Pairing device\\n\\nThen you need to pair your sensor. For that just long press the power button until it starts to blink (zigbee2MQTT must be launched). After sensor connects you will see the message like:\\n```\\nZigbee2MQTT:info  2019-11-09T12:19:56: Successfully interviewed '0x00158d0001dc126a', device has successfully been paired\\n```\\n> Remember this number `0x00158d0001dc126a` it will be the topic name for your sensor's data.\\nThen open configuration file again and set `permit_join: false`.\\n\\nThen lets make a service. Create the file:\\n```bash\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\nAdd the following to this file:\\n```\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\n# Or use StandardOutput=null if you don't want Zigbee2MQTT messages filling syslog, for more options see systemd.exec(5)\\nStandardError=inherit\\nRestart=always\\nUser=pi\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nVerify that the configuration works:\\n\\n```bash\\nsudo systemctl start zigbee2mqtt\\n```\\n\\n```bash\\nsystemctl status zigbee2mqtt.service\\n```\\n\\nOutput should look like:\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\nNow that everything works, we want systemctl to start Zigbee2MQTT automatically on boot, this can be done by executing:\\n\\n```bash\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n## Home Assistant Setup\\n\\nOpen Home Assistant configuration file:\\n\\n```bash\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add the following to setup MQTT broker and sensor (replace `topic_name` with the topic name from previous step):\\n\\n```\\n# MQTT broker setup\\nmqtt:\\n  broker: localhost\\n  port: 1883\\n\\n# Sensor setup\\nsensor:\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Humidity\\\"\\n    unit_of_measurement: '%'\\n    value_template: \\\"{{ value_json.humidity }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Temperature\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.temperature }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Pressure\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.pressure }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Battery\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.battery }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Link Quality\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.linkquality }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Voltage\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.voltage }}\\\"\\n\\n# Trigger on receiving data\\nautomation:\\n  - alias: \\\"send_datalog_climate\\\"\\n    trigger:\\n      platform: mqtt\\n      topic: \\\"zigbee2mqtt/0x00158d0006bcd022\\\"\\n    action:\\n      service: shell_command.send_datalog_climate\\n\\n# Shell command that will run on the trigger\\nshell_command:\\n  send_datalog_climate: 'python3 python_scripts/send_datalog.py temperature={{ states(\\\"sensor.mqtt_climate_temperature\\\")  }} humidity={{ states(\\\"sensor.mqtt_climate_humidity\\\") }} pressure={{ states(\\\"sensor.mqtt_pressure\\\") }} battery={{ states(\\\"sensor.mqtt_climate_battery\\\") }} linkquality={{ states(\\\"sensor.mqtt_climate_link_quality\\\") }} voltage={{ states(\\\"sensor.mqtt_climate_voltage\\\") }}'\\n```\\n\\nThen start Home Assistant with new configuration:\\n\\n```bash\\ncd /srv/homeassistant\\nhass\\n```\\n\\nTo see the sensor data in Home Assistant you need to add it. For that open the browser on your computer and go to:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nPress on three dots on the right side and choose `Edit Dashboard`\\n\\n![edit_dashboard](../images/home-assistant/dashboard.png)\\n\\nThen press `Add Card`\\n\\n![card](../images/home-assistant/card.png)\\n\\nGo to `By Entity` and tick all sensors that you need\\n\\n![sensors](../images/home-assistant/sensors.png)\\n\\nPress continue and you will be able to see sensor data at the homepage (you may see `unknown` before sensor send new data)\\n\\nIn a similar way you can add card for Robonomics Service. With this you can start or stop the servise or send current measurements with `run action` button.\\n\\n![action](../images/home-assistant/datalog.png)\\n\\nYou homepage will look like this\\n\\n![home](../images/home-assistant/home.png)\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. You can decrypt the data with script [decrypt.py](https://github.com/airalab/robonomics-smarthome/blob/main/python_scripts/decrypt.py), download it:\\n\\n```bash\\ncd /srv/homeassistant/python_scripts\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\n```\\nAnd run with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"91b05e239163656ebc9533bea21ff5aa\",\"title\":\"Connect Sensors with Xiaomi Gateway\",\"path\":\"/docs/es/xiaomi-gateway/\",\"content\":\"\\nYou need your Xiaomi gateway along with all the sensors to be connected to the Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your hub (it must be in connecting mode which is achieved via a long press of the power button) and follow instructions in the app. After you add the gateway, you need to add sensors: press on your gateway, then go to `Child device` and press `+`. Find required device and follow the instructions on the screen. For more details refer to the user manual of your Xiaomi Gateway hub.\\n\\n## Add Gateway to Home Assistant\\nBe sure that you're logged in you raspberry as `homeassistant` user, if not do the following:\\n```bash\\nsudo -u homeassistant -H -s\\n```\\n\\nIn your Home Assistant:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations` and press `Add Intagration`. There you need to Find `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Hub (Aqara Hub in this example):\\n\\n![hub](../images/home-assistant/hub.png)\\n\\nPress `Submit` and you will be able to see your gateway in Integrations page.\\n\\n## Add Gateway to Home Assistant using Homekit Controller integration\\n\\nYou can also connect your hub to Aqara Home app on ios and then add it to Home Assistant through Homekit Controller integration. \\n\\nAdd your hub to the app using `add device` or `+` button. Right after your hub added to Aqara Home app you will be proposed to bind it with your Homekit account. \\n\\n![homekit](../images/home-assistant/homekit.png)\\n\\nWhen you see a menu like the picture, open your Home Assistant page:\\n\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations`. Here you can find your device discovered and click `Configure` button to add it by Homekit Controller integration. You have to enter pairing code of your device, which you can find on the sticker on your device.\\n\\n![configure1](../images/home-assistant/configure1.png)\\n\\n![configure2](../images/home-assistant/configure2.png)\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"07c305e94622361cb1089f05f1c216a3\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/es/xcm-robobank/\",\"content\":\"\\n\\nMain goal of this project is simplification of parachain runtime development, when cross-chain messages are used. \\nAllows to develop runtime code with integration tests with high repeatablility and simple usage.\\nAutomates building, construction of pre-set network configuration (f.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and running tests, sending messages, using call to runtime, constructed and composed in Python.\\n\\nXCM Testsuite is used for testing production cycle for Robobank - the set of Substrate pallets, allowing robots to register in external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside Robonomics network with all needed infrastructure, but, in the same time, offer their services in any external parachain.\\n\\nVideo example is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe demo scenary main steps are:\\n- launch relay chain and two parachains in pack of 6 processes\\n- setup XCM messages channels between parachains\\n- register a robot in both parachains\\n- create order for this robot in client parachain (reserving payment for completion of order)\\n- send XCM message to Robonomica\\n- creating \\\"mirrored\\\" order record in Robonomica parachain\\n- accept order by robot in Robonomica\\n- send XCM message about order acceptance back to client parachain\\n- accept order in client parachain (reserving penalty fee for no-completion of order until deadline)\\n- complete order by robot in Robonomica\\n- send XCM message about order completion to client parachain\\n- settle all payments (client payment is transfered to robot, as well as penalty fee)\\n- close order\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nContains code of runtime pallets being tested.\\nAs in original node code of parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] First build can take a lot of time, up to several hours on weak machines\\n\\n[NOTE] Script works with FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains\\n\\n[NOTE] By default script re-creates same environment every launch, by removing all previous states. this behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for relay chain and for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (f.e. 4 validators of some stable Rococo revision)\\n    - collators for parachain-100 (f.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (f.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing to study any chain using frontend apps (explorer, DApp)\\n - keep printing all output of all chains to console\\n\\n[WARNING] After launch, wait until a network is up, make sure that blocks finalization started, and parachains are registered. These processes require approximately 5 min (50 blocks x 6 sec ).\\n\\n## Checking if all works \\n\\nUse standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, consensus started off, we can proceed to run test cases (in a new terminal)\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to relay.\\nWhen relay receives message it will transfer 15 tokens from `para 100` account to the Charlie's.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates `Balance.transfer` message in `parachain-100` and passes it to `sibling 200` one.\\nBefore that, it endows `subl 100` account with 1000 tokens and  establish a channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace balances and authorities with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit code. The above command will rebuild project and update collator node before start.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent version of software. For this change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\"}},{\"node\":{\"id\":\"d97aa8c0c70c0214551d89682c1e0f14\",\"title\":\"Lección 4, Robonomics Parachain en la Práctica\",\"path\":\"/docs/es/wschool2021-robonomics-parachain-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\nLa Parachain de Robonomics no es una parachain de propósito general en el ecosistema de Polkadot. El objetivo de Robonomics es la construcción de la economía de las máquinas, el parachain en este ámbito de objetivos ayuda a integrar el ecosistema Polkadot con los conceptos de IoT, Smart Cities e Industria 4.0.\\n\\n## Requerimientos\\n\\n* Docker, por favor [instale](https://docs.docker.com/engine/install/).\\n* Polkadot-launch, por favor [instale](https://github.com/paritytech/polkadot-launch#install).\\n\\n## Lanzar el Relay\\n\\nLa cadena de retransmisión es un núcleo de Polkadot, [proporciona seguridad](https://wiki.polkadot.network/docs/en/learn-security) compartida para todos los niños parachains e implementa mecanismos de transmisión de mensajes para ellos. Lancemos una instancia local de la Rococó relay chain (polkadot testnet) con dos parachains basadas en robonomics como niños. Usaré la etiqueta de imagen preparada de [Docker: “winter-school-2”](https://hub.docker.com/layers/robonomics/robonomics/winter-school-2/images/sha256-92f4795262f3ded3e6a153999d2777c4009106a7d37fd29969ebf1c3a262dc85?context=explore) pero todo el código fuente de los ejemplos está disponible en [Robonomics GitHub](https://github.com/airalab/robonomics/tree/master/scripts/polkadot-launch).\\n\\n<Asciinema vid=\\\"419Jrg22ziFfMFPZlh2WtiLvg\\\"/>\\n\\nPodría llevar un tiempo, pero sea partícipe. Como resultado, debe tener tres instancias de cadena en los puertos:\\n\\n* `9944` - local rococo relay chain.\\n* `9988` - robonomics parachain with `id=100`\\n* `9989` - robonomics parachain with `id=200`\\n\\nSi usa un servidor remoto, necesita crear algunos túneles SSH en la VM:\\n```\\nssh -f -N -L 9944:127.0.0.1:9944 root@REMOTE_SERVER_IP\\nssh -f -N -L 9988:127.0.0.1:9988 root@REMOTE_SERVER_IP\\nssh -f -N -L 9989:127.0.0.1:9989 root@REMOTE_SERVER_IP\\n```\\nDespués de eso, puede usar `ws://127.0.0.1:9944`, `ws://127.0.0.1:9988`and `ws://127.0.0.1:9989` en https://parachain.robonomics.network/\\n\\n![relay](../images/ws_lesson4/upcoming.jpg)\\n\\nHace algún tiempo se deberían registrar las parachains.\\n\\n![relay2](../images/ws_lesson4/parachains.jpg)\\n\\nY empieza a producir bloques.\\n\\n![relay3](../images/ws_lesson4/parachains2.jpg)\\n\\nComo siguiente paso, creemos un canal HRMP para pasar mensajes entre parachains. Usaré la llamada del módulo `sudo` en la página de la relay chain.\\n\\n![hrmp](../images/ws_lesson4/hrmp.jpg)\\n\\nCuando se crea el canal, las llamadas XCM están disponibles. Usemos la paleta `datalogXcm`, una versión XCM de la paleta de `datalog`.\\n\\n![datalogXcmSend](../images/ws_lesson4/datalogXcmSend.jpg)\\n\\nComo resultado, el mensaje en el segundo parachain llamará a la paleta de `datalog` y escribirá los datos en la cadena.\\n\\n![datalogXcmRecv](../images/ws_lesson4/datalogXcmRecv.jpg)\\n\\nComo resultado, este ejemplo demuestra cómo se podría utilizar XCM para el uso de cadenas cruzadas de palets estándar de robonomics.\\n\"}},{\"node\":{\"id\":\"f5829d6bd28b4b4102d737deea5a7fdf\",\"title\":\"Lección 3, Robonomics IO en la Practica\",\"path\":\"/docs/es/wschool2021-robonomics-io-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\n## Requirements\\n\\n* the Docker is required, please [install](https://docs.docker.com/engine/install/) it first.\\n* the [Nova SDS011](https://aqicn.org/sensor/sds011) sensor is *optional*.\\n\\n### SDS011 check (optional)\\n\\nIf you have connected SDS011 sensor then please check that it presented in `/dev` and have correct access rights.\\n\\n<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>\\n\\n## Quick start\\n\\nWhen docker is installed let's launch robonomics docker image from [Official repository](https://hub.docker.com/r/robonomics/robonomics). I'll use `winter-school` tag during this lesson.\\n\\n<Asciinema vid=\\\"wM43jozIVfcRmt52ENrJ6yPlH\\\"/>\\n\\nWhen docker image is ready let's try to read a data using `robonomics io` command (optional if you have SDS011 device).\\n\\n<Asciinema vid=\\\"iztt22tKGaV8wq3cMXY1oUEYv\\\"/>\\n\\nIf you have no SDS011 sensor then feel free to use virtual SDS011 sensor available in the same docker container via `vsds011.sh`. And everywhere in folloding command please use it as transparent replacement for physical sensor.\\n\\n<Asciinema vid=\\\"GCkSiJBA1DgpLAAHiMhIOSpgG\\\"/>\\n\\nThe Robonomics IO subsystem have two kind of commands:\\n\\n* `read` - get data from device that support read access;\\n* `write` - write data into device that support write access.\\n\\nSome devices support them both, in that case devices presented in both command arguments.\\n\\n> For example, virtual device `ipfs` supports `read` data from IPFS by hash as same as `write` data into IPFS.\\n\\nFull list of supported devices is possible to get running `robonomics io read` or `robonomics io write` without arguments.\\n\\n## IPFS access\\n\\nOn next step runned IPFS daemon is required. For this purpose let's run init IPFS and run daemon on dedicated\\nterminal tab.\\n\\n<Asciinema vid=\\\"ir6ziXSBUDrRltTmNxg7sdXVY\\\"/>\\n\\nWhen daemon launched is possible to connect docker image in separate tab and use `robonomics io` for writing and reading a data.\\n\\n<Asciinema vid=\\\"ZtwcmpB9Lhum2Sc221QmNwHG4\\\"/>\\n\\nThe output forwarding is also works here, that means it's possible to forward SDS011 sensor data into IPFS using `|` (pipe) symbol in console. Let's try to do it.\\n\\n<Asciinema vid=\\\"XS0QESWG7f8ELsQe1bGQllb9O\\\"/>\\n\\nWhere JSON data from SDS011 forwarded as input for IPFS writer and result is published on stdout.\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs\\n```\\n\\nThis approach permits engineer extrimely quickly make a simple program just combine a primitive readers and writers from `robonomics io` tools.\\n\\n```bash\\nrobonomics io read sds011 | gz | robonomics io write pubsub my-sensor-data\\n```\\n\\n## Robonomics Datalog\\n\\n> The target of Robonomics [Datalog](https://crates.robonomics.network/robonomics_protocol/datalog/index.html) is data blockchainization. This pallet provides function to store custom data on blockchain to make it immutable, impossible to change in future.\\n\\nFor the final part of this lesson runned robonomics node is required. Development mode is preffered because of quick block time and already distributed balances on preset accounts. Let's launch it on separate terminal tab in the same container.\\n\\n<Asciinema vid=\\\"QnN9l0sdaZZOyK9ah0DntvCXt\\\"/>\\n\\nThen private seed also required as argument for `datalog` device. This seed is used to sign transaction and presents account as a sender. Let's generate it using embedded `robonomics key` command.\\n\\n<Asciinema vid=\\\"4Cdfl9F0GgjNWv1c1ZcTBBktF\\\"/>\\n\\nSave generated address and seed on safe place for use it later.\\n\\nCurrently address balance is zero and the network don't permits to send transactions from this address. To fix it let's transfer a bit of tokens from `Alice` account. I'll use Robonomics Portal on https://parachain.robonomics.network connected to local node with address `ws://127.0.0.1:9944`.\\n\\n![portal transfer](../images/ws_lesson3/tran.jpg)\\n\\nAnd then `datalog` device could be used for saving any data on blockchain. The key `-s` is used to set secret seed of account. Account should have non-zero balance to send transactions.\\n\\n<Asciinema vid=\\\"FzERH9TmFB8oRuas8ZU202Pv8\\\"/>\\n\\nIf every thing is correct the you should see `Datalog` event on `Explorer` page of Robonomics portal.\\n\\n![portal datalog](../images/ws_lesson3/datalog.jpg)\\n\\nThe final step is a bit complex but it's good to try use all knowledge of this lesson. Let's make a simple program\\nthat collects data from SDS011 sensor (or file), pack it into IPFS and then send `datalog` transaction to save hash on blockchain.\\n\\n```\\nSDS011 -> IPFS -> Blockchain\\n```\\n\\nIt's easy to implement using Robonomics IO, let's do that.\\n\\n<Asciinema vid=\\\"MTpiawGo8DKEn081OozbYb5mU\\\"/>\\n\\nFor virtual sensor use:\\n```\\nvsds011.sh | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n\\nIf everything well the `Datalog` event with IPFS hash should be presented.\\n\\n![portal datalog complex](../images/ws_lesson3/datalog_complex.jpg)\\n\\n> Contributor [@Akru](https://github.com/akru)\"}},{\"node\":{\"id\":\"9800d77dd1aeccee1d01b7734403051a\",\"title\":\"Lección 2, Robonomics AIRA Descripción General\",\"path\":\"/docs/es/wschool2021-robonomics-github-overview/\",\"content\":\"\\n## Paso 1: Instalación de AIRA en VirtualBox\\n\\nhttps://youtu.be/ISKilRfY3Ow\\n\\n[Instrucción de texto](/docs/aira-installation-on-vb/)\\n\\n## Paso 2: Conexión de Aira a través de SSH\\n\\nhttps://youtu.be/W0rOcRA2sEc\\n\\n[Instrucción de texto](/docs/aira-connecting-via-ssh/)\\n\\n## Paso 3: Interactuar con AIRA\\n\\nhttps://youtu.be/fhRTF2mddfU\\n\\n[Instrucción de texto](/docs/interact-with-aira/)\"}},{\"node\":{\"id\":\"135f37f39d7e38b3873a5e4a29d08652\",\"title\":\"Robonomics Winter School 2021 Introducción y Ceremonia de Apertura\",\"path\":\"/docs/es/wschool2021-intro/\",\"content\":\"\\nRobonomics Winter School 2021 se llevo a cabo del 10 al 24 de febrero de manera online y gratis. Para mas información del evento entren al siguiente link con toda la información de Robonomics Winter School 2021: [Robonomics Winter School 2021](https://medium.com/robonomics-espa%C3%B1ol/robonomics-winter-school-2021-1ce2d37fb158)\\n\\nSe publican las lecciones en línea de diferentes maneras: texto en Wiki, video en nuestro [canal de YouTube](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ), anuncio en la cuenta de [Twitter](https://twitter.com/AIRA_Robonomics). Por favor, tenga en cuenta que las lecciones en video y las lecciones de texto no son lo mismo.  \\n\\nÚnase a nosotros, siga sus pasos a través de las lecciones, discuta y haga preguntas en [Discord](https://discord.gg/5UWNGNaAUf).\\n\\n## Miren la Ceremonia de Apertura\\n\\nhttp://www.youtube.com/watch?v=kQaSwNYHJQ8\\n\\n## Enlaces de contacto\\n\\nUnete a la Comunidad en Español de Robonomics: [https://t.me/RobonomicsESP](https://t.me/RobonomicsESP)  \\n\\nTelegram: [t.me/robonomics](http://t.me/robonomics)  \\nTwitter: [twitter.com/aira_robonomics](http://twitter.com/aira_robonomics)  \\nFacebook: [facebook.com/aira.robobomics](http://facebook.com/aira.robobomics)  \\nInstagram: [instagram.com/aira_robonomics](http://instagram.com/aira_robonomics)  \\nForum: [discourse.robonomics.network](http://discourse.robonomics.network/)  \\nReddit: [reddit.com/r/robonomics](http://reddit.com/r/robonomics)  \\nYoutube: [youtube.com/c/airalab](http://youtube.com/c/airalab)  \\nGithub: [github.com/airalab](http://github.com/airalab)  \\nMedium: [blog.aira.life](http://blog.aira.life/)\"}},{\"node\":{\"id\":\"1bd1698fe196417fbb72ea478d18368a\",\"title\":\"Lección 5, Conectividad\",\"path\":\"/docs/es/wschool2021-connectivity-service/\",\"content\":\"\\n## IoT como un pie multiple\\n\\n* Software del dispositivo\\n    * FreeRTOS\\n    * ESP/Arduino\\n    * Computadoras de placa única (RPi, LattePanda, etc.)\\n* Conectividad\\n    * IoT Hub\\n    * IoT Manager\\n* Servicios analíticos\\n    * AWS\\n    * Google Cloud IoT Core\\n    * ThingsBoard\\n\\nComo regla general, la mayoría no está interesada en sensores y servidores, sino en análisis de datos. Para obtenerlo, debe decidir qué dispositivo usar, cómo trabajar con él y dónde conectarse.\\n\\n## Software del Dispositivo\\n\\nConsidere el ejemplo de una estación meteorológica doméstica. Es necesario recopilar datos sobre contaminación atmosférica (SDS011), temperatura y humedad (BME). El microcontrolador ESP8266 puede manejar esta tarea.\\n\\nRequisitos:\\n\\n* Leer correctamente los datos de los sensores\\n* Tener un identificador único\\n* Transferir datos a un servidor conocido\\n* Proporcionar firma digital de datos (opcional)\\n\\nPuede encontrar el firmware actual [aquí](https://github.com/LoSk-p/sensors-software/tree/366b19bf447a5fc19220ef89eab0f2440f8db1c2).\\n\\n## Que es Conectividad?\\n\\nEn el mundo de IoT, la conectividad se refiere a la conexión de varios dispositivos de IoT a Internet para enviar datos y/o controlar el dispositivo.\\n\\nLas soluciones arquitectónicas conocidas se pueden dividir aproximadamente en 3 grupos:\\n\\n* Totalmente descentralizado. Por ejemplo, los dispositivos están conectados por una red de malla. No apto para redes de área extensa debido a los altos requisitos de hardware.\\n* Centralizado. Por ejemplo, AWS. Proporciona un único punto de entrada y facilidad de conexión, pero existe un alto riesgo de falla en caso de problemas con el servidor.\\n* Híbrido. Por ejemplo, [Robonomics Connectivity](https://github.com/airalab/sensors-connectivity). Proporciona una dirección para dispositivos en una red “local” y publica datos en un canal de mensajes IPFS distribuido.\\n\\n## Comparison of AWS and Robonomics Connectivity\\n\\n| Management services \\t| AWS                               \\t|               Robonomics              \\t|\\n|---------------------\\t|-----------------------------------\\t|---------------------------------------\\t|\\n| Transaction type    \\t| Technical                         \\t| Technical and economic                \\t|\\n| Security            \\t| IT-company cloud control          \\t| Polkadot and Ethereum                 \\t|\\n| Protocol            \\t| HTTPS, MQTT                       \\t| IPFS, Robonomics                      \\t|\\n| Ecosystem           \\t| Private                           \\t| Shared                                \\t|\\n| Access to DeFi      \\t| No                                \\t| Yes                                   \\t|\\n| Costs               \\t| Pushing data - $1-2 a sensor      \\t| Pushing data - $0                     \\t|\\n|                     \\t| Shadow         - from $10 a month \\t| Digital Twin    - $0,01 a transaction \\t|\\n\\n## Instalación de Conectividad en AIRA\\n\\nhttps://www.youtube.com/watch?v=JbBNMHAzJKM\\n\\n### Requerimientos\\n\\n* [VirtualBox 6.1 o superior](https://www.virtualbox.org/wiki/Downloads) and above\\n* [Aira OS ova image](https://static.aira.life/ova/airaos-21.03_robonomics-winter-school.ova)\\n\\nImporte la Aira Image en VirtualBox como se describe [aquí](/docs/aira-installation-on-vb/)\\n\\nConfigurar una conexión a través de [SSH](/docs/aira-connecting-via-ssh/)\\n\\nCuando todo esté configurado e inicie sesión con éxito a través de SSH, clonemos el paquete principal y compilemos.\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\ngit checkout v0.9\\nnix build -f release.nix\\n```\\n\\nAhora creemos una copia del archivo de configuración predeterminado para su uso posterior. Para conocer todas las opciones, consulte [este artículo]((/docs/configuration-options-description/). Luego lanza el paquete con `roslaunch`.\\n\\n```\\ncp config/default.json config/my.json\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n## Conectar el Sensor a la Conectividad\\n\\nhttps://www.youtube.com/watch?v=yxqxBk-6bpI\\n\\n### Requerimientos\\n\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) sensor \\n* [Yarn Packet Manager](https://yarnpkg.com/getting-started/install)\\n\\nAhora conectemos un sensor real, enviemos el puerto USB a la máquina virtual, configuremos un mapa y miremos nuestras propias medidas.\\n\\nPrimero, detenga el AIRA OS si se estaba ejecutando y agregue un dispositivo USB correspondiente.\\n\\n![VB USB Forwarding](../images/vb_forward_usb.jpg)\\n\\nInicie la VM, conéctese a través de SSH y configure la opción de `comstation/port` de acuerdo con su dispositivo USB en la VM. También habilite la `comstation` y configure su latitud y longitud. Al final, `config/my.json` debería verse así:\\n\\n```\\n{\\n   \\\"general\\\":{\\n      \\\"publish_interval\\\":30\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":0,\\n      \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"connectivity.robonomics.network\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\":{\\n      \\\"enable\\\":false\\n   },\\n   \\\"robonomics\\\":{\\n      \\\"enable\\\":true,\\n      \\\"ipfs_provider\\\":\\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\":\\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\":{\\n      \\\"enable\\\":false,\\n      \\\"path\\\":\\\"\\\",\\n      \\\"suri\\\":\\\"\\\",\\n      \\\"remote\\\":\\\"wss://substrate.ipci.io\\\",\\n      \\\"dump_interval\\\":3600,\\n      \\\"temporal_username\\\":\\\"\\\",\\n      \\\"temporal_password\\\":\\\"\\\"\\n   },\\n   \\\"dev\\\":{\\n      \\\"sentry\\\":\\\"\\\"\\n   }\\n}\\n```\\n\\n> Si no tiene un sensor real, puede usar el script de `sensors-connectivity/utils/virtual-sensor.py` para emular uno.\\n> \\n> Habilite `HTTPStation` y deshabilite `COMStation` cambiando el archivo de configuración como:\\n> ```\\n> {\\n>    \\\"general\\\":{\\n>       \\\"publish_interval\\\":30\\n>    },\\n>    \\\"comstation\\\":{\\n>       \\\"enable\\\":false,\\n>       \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n>       \\\"work_period\\\":0,\\n>       \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n>       \\\"public_key\\\":\\\"\\\"\\n>    },\\n>    \\\"httpstation\\\":{\\n>       \\\"enable\\\":true,\\n>       \\\"port\\\":8001\\n>    },\\n>    ...\\n> }\\n> ```\\n>\\n> y el lanzamiento de `utils/virtual-sensor.py` en una terminal dedicada en la VM.  \\n\\nGuarde el archivo e inicie la conectividad desde la carpeta de `sensors-connectivity`:\\n\\n```\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\nDebería ver las primeras medidas en la salida de la consola\\n\\nBusque su ID de IPFS en la VM. Aparece justo después de iniciar la imagen o mediante el comando `ipfs id`. Lo necesitaremos más tarde.\\n\\nAhora configuremos nuestra propia instancia del mapa. En su computadora portátil (no en la VM), clone [este](https://github.com/airalab/sensors.robonomics.network) repositorio y compile la aplicación:\\n\\n```\\ngit clone https://github.com/airalab/sensors.robonomics.network\\ncd sensors.robonomics.network\\nyarn install\\n```\\n\\nEdite el archivo `src/agents.json` y ponga su ID de IPFS. Por ejemplo:\\n\\n```\\n[\\n  \\\"12D3KooWSCFAD3Lpew1HijniE6oFTuo4jsMwHzF87wNnXkpCRYWn\\\"\\n]\\n```\\n\\nLanzar el mapa:\\n\\n```\\nyarn serve\\n```\\n\\nVaya a [http://localhost:8080/](http://localhost:8080/) o la dirección que le dio el hilo y busque el sensor.\\n\\n## Práctica\\n\\n### Trayectoria 1. Flashear un sensor ESP + SD011\\n\\nRequerimientos:\\n\\n* ESP8266\\n* Al menos uno de los sensores SDS011, BME280, HTU21D\\n\\nUse la [instrucción](https://wiki.robonomics.network/docs/connect-sensor-to-robonomics/) para conectar un sensor a la Robonomics Connectivity.\\n\\nFíjese que su sensor aparezca en nuestro [mapa](https://sensors.robonomics.network/#/).\\n\\n### Trayectoria 2. Lanzamiento de Conectividad\\n\\nRequerimientos:\\n\\n* ROS\\n* Python\\n* Nix (Opcional)\\n\\nConstrucción y lanzamiento [sensores-conectividad](https://github.com/airalab/sensors-connectivity#get-a-package-and-build)\\n\\n> Como construir, instalar [aqui](https://wiki.robonomics.network/docs/iot-sensors-connectivity/) y configurar [aqui](https://wiki.robonomics.network/docs/configuration-options-description/)\\n\\nEsquema General del paquete:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSe propone la opción de implementar una nueva estación, por ejemplo, un generador de números aleatorios, o un nuevo alimentador, por ejemplo, mostrando una cadena en la pantalla.\\n\\nInterfase `IStation` [aqui](https://github.com/airalab/sensors-connectivity/blob/master/src/stations/istation.py#L73).\\n\\nInterfase `IFeeder` [aqui](https://github.com/airalab/sensors-connectivity/blob/master/src/feeders/ifeeder.py#L5)\\n\\n\\n\"}},{\"node\":{\"id\":\"e19b2ca25ff47f01fecbeee99d41c4dc\",\"title\":\"Lección 1, Conectar la robótica a la dapp\",\"path\":\"/docs/es/wschool2021-connect-robotics-to-user-app/\",\"content\":\"\\nhttps://youtu.be/NOQxyojvaao\\n\\n- [Instrucción de texto](/docs/get-weather-on-fuji-mountain/)\\n- [Dapp](https://dapp.robonomics.network/#/)\"}},{\"node\":{\"id\":\"71bffb0a71c38c4beece48d97290cd82\",\"title\":\"Construir la interfaz de la DApp, Parte 2\",\"path\":\"/docs/es/wschool2021-build-dapp-interface/\",\"content\":\"\\n![Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot](../images/build-dapp-interface/sum.gif \\\"Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot\\\")\\n\\n## Introducción\\n\\nEste tutorial continúa la lección anterior, donde ya ha creado una aplicación simple y se centró en conectar una cuenta a un nodo, enviar transacciones y otras funciones vitales de la dapp. Ahora **crearemos una interfaz fácil de usar** para esa aplicación.\\n\\n## Prerrequisitos\\n\\nEste tutorial está diseñado para personas que están familiarizadas un poco con **HTML, CSS, JavaScript** y quieren aprender a aplicar estas habilidades para aplicaciones descentralizadas.\\n\\nPara crear la interfaz de su dapp, puede elegir cualquier marco de JavaScript que le resulte cómodo o incluso intentar crear una interfaz sin ningún marco. En Robonomics 2021 usamos [Vue.js](https://vuejs.org) ya que es bastante escalable y fácil de usar.\\n\\n## Configuración para el Tutorial\\n\\nSi comienza con este paso y prefiere **aprender con la práctica**, siga esta lista de tareas para iniciar el dapp resultante de la lección anterior:\\n\\n1. Descargue un nodo Robonomics local v0.22 de la [releases page](https://github.com/airalab/robonomics/releases/tag/v0.22.0) que se adapte a su sistema operativo. Si no encuentra su sistema en la última versión, busque la versión más reciente en las versiones anteriores.\\n\\n2. Inicie el nodo Robononomics en el modo Desarrollador escribiendo `./robonomics --dev --tmp` en su terminal.\\n\\n3. Descargue la extensión Polkadot para Chrome o Firefox [here](https://polkadot.js.org/extension/)\\n\\n4. Clona [this repository](https://github.com/vol4tim/example-robonomics-dapp/).\\n\\n5. Instale [Yarn](https://yarnpkg.com).\\n\\n6. Instale [@vue/cli](https://cli.vuejs.org/guide/installation.html)\\n\\n7. Comience a desarrollar dapp con el comando en su terminal:\\n\\n```shell\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n\\n**Debería tener esta pantalla en su navegador:**\\n\\n![Dapp Start](../images/build-dapp-interface/dapp-start.png \\\"Dapp Start\\\")\\n\\n\\n<details>\\n\\n  <summary>Algunos consejos adicionales para el lanzamiento</summary>\\n\\n  - Asegúrate de que tu **nodo se esté ejecutando**:\\n    ![Example of running a Robonomics node](../images/build-dapp-interface/robonomics-node-launch.png \\\"Example of running Robonomics node\\\")\\n\\n  - En **macOS**, es posible que deba cambiar los **permisos de acceso** `chmod +x robonomics`\\n\\n  - Asegúrese de haber permitido **acceso para Polkadot Extension**:\\n    ![Polkadot Extension giving access](../images/build-dapp-interface/polkadot-permission.png \\\"Polkadot Extension giving access\\\")\\n\\n  - Si tiene errores en el registro del nodo en ejecución y dapp no se carga correctamente, intente eliminar la base de datos de la cadena de desarrollo: `sudo rm -rf <YOUR LOCAL PATH>/robonomics/chains/dev/db/` y reinicia el nodo. Si no ayuda, reinicie su máquina.\\n\\n</details>\\n\\n## Inspección del Código\\n\\nInspeccionemos la estructura de la dapp para aclarar qué y dónde podemos arreglar para cambiar la interfaz de usuario.\\n\\n```\\n.\\n├── public/\\n│   ├── favicon.ico           # Icon for your dapp\\n│   └── index.html            # The template file (injects icons links, JavaScript and CSS files for the app)\\n├── src/\\n│   ├── assets/               # Folder for images and global styles\\n│   ├── components/           # Folder with components\\n│   │   ├── Datalog.vue       # Tab 'Datalog' in dapp\\n│   │   ├── Demo.vue          # Tab 'Demo' in dapp\\n│   │   ├── Launch.vue        # Tab 'Launch' in dapp\\n│   ├── utils/                # Folder with important for app js functions (we will touch api.js in this tutorial)\\n│   ├── App.vue               # The root of our app, contains HTML, CSS, JS for the whole page. In fact it is Vue Component also\\n│   ├── main.js               # The app’s entry file, we will import here global styles\\n├── ...                       # There are config files and dependencies files, that we will not change mannually\\n├── README.md                 # You can write here any instructions for your dapp\\n\\n```\\n\\n> **El código de este tutorial está en este [repository](https://github.com/positivecrash/wscool21-ui-dapp)**\\n\\n## CSS-in-JS VS. Hojas de Estilos Globales\\n\\nEn este tutorial, muestro cómo cambiar la interfaz de una pequeña dapp desde cero sin una biblioteca estable de componentes de UI. Por lo tanto, importaré y crearé no solo diferentes componentes de Vue, sino que también escribiré mis propios estilos.\\n\\nSi su aplicación es grande o su proyecto tiene un montón de dapps, en el futuro será mejor que busque construir una biblioteca de componentes específicamente para su proyecto para hacer que la interfaz de usuario sea más organizada y eficiente (por ejemplo, [aquí hay una herramienta para organizar componentes](https://storybook.js.org)). O si está de acuerdo con los temas de la interfaz estándar, puede usar cualquier biblioteca de interfaz de usuario de terceros ([por ejemplo](https://vuetifyjs.com/)).\\n\\n## Primera Importacion o por donde empezar\\n\\nNo tengo ningún diseño específico para este dapp, pero tengo [Brandbook](https://static.robonomics.network/assets/Robonomics-Visual-Identity.pdf) y [tipografia](https://robonomics.network), las fuentes, los estilos de botones, etc. bien establecidos. Así que, para empezar, importaré los siguientes archivos css a nivel mundial:\\n\\n```\\n...\\n├── src/\\n│   ├── assets/\\n│   │   ├── styles/\\n│   │   │   ├── reset.css         # The goal is to reduce browser inconsistencies\\n│   │   │   ├── variables.css     # Contains specific values to be reused such as colors, font-names, space values etc.\\n│   │   │   ├── typography.css    # Global typography for the whole dapp\\n│   │   │   ├── animation.css     # Keyframe animations used throughout the dapp\\n...\\n\\n```\\n\\nEn su lugar, puede escribir el contenido de cualquiera de estos archivos en App.vue, si se ajusta mejor a su percepción. Pero recomiendo importar algunos archivos CSS globalmente para este ejemplo para mantener App.vue un poco más claro.\\n\\nImporte estos archivos CSS a su aplicación editando el archivo **main.js**:\\n![Importar CSS global en la Vue app](../images/build-dapp-interface/import-css-vue-1.png \\\"Import global CSS in Vue app\\\")\\n\\n```JS\\nimport './assets/styles/reset.css'\\nimport './assets/styles/variables.css'\\nimport './assets/styles/typography.css'\\nimport './assets/styles/animation.css'\\n```\\n\\n**Compruebe si se han cambiado las fuentes en la dapp:**\\n\\n![Paso 1 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-1.png \\\"Dapp Interface changing step 1\\\")\\n\\n\\n## Cambiar el diseño y pretificar el titulo\\n\\nCambiemos el diseño de la aplicación. Como mencioné anteriormente, puede escribir sus estilos directamente en App.vue, pero para este ejemplo prefiero separar este proceso.\\n\\n- Comente o elimine estilos de la etiqueta `<style\\\\` en **App.vue**\\n\\n- Cree el archivo css **app.css** en la carpeta de estilos para esta aplicación e impórtelo en **main.js**\\n\\n```JS\\nimport './assets/styles/app.css'\\n```\\n\\n<details>\\n\\n<summary>Escriba en app.css los primeros estilos básicos para la aplicación:</summary>\\n\\n```css\\n#app {\\n  display: grid;\\n  grid-template-rows: auto 1fr;\\n  align-items: stretch;\\n\\n  text-align: center;\\n}\\n\\nbody {\\n  background-color: var(--color-gray-light);\\n}\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Cambiar el título de la aplicación [App.vue]</summary>\\n\\n```html\\n<div class=\\\"top\\\">\\n    <h1>dApp Robonomics Demo</h1>\\n    <i>Winter School 2021</i>\\n    <img class=\\\"label\\\" alt=\\\"\\\" src=\\\"./assets/images/robonomics-winter-school-2021-logo.png\\\"/>\\n</div>\\n```\\n\\n</details>\\n\\n\\n\\n<details>\\n\\n<summary>Escribe estilos para el título [app.css]</summary>\\n\\n```css\\n.top {\\n  position: relative;\\n  padding-top: var(--space);\\n  padding-bottom: calc(var(--space)*2);\\n\\n  border-bottom: 2px solid var(--color-dark);\\n  background-color: var(--color-light);\\n}\\n\\n.top h1 {\\n  font-size: 1.8rem;\\n}\\n\\n.top i {\\n  display: block;\\n}\\n\\n.top .loader-label {\\n  display: block;\\n  margin: calc(var(--space)/3) auto;\\n  max-width: 150px;\\n\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.5s FadeIn 0.3s ease forwards, 0.5s ScaleDown 0.1s ease forwards;\\n}\\n\\n.top .label {\\n  position: absolute;\\n  width: 100px;\\n  bottom: -50px;\\n  left: calc(50% - 50px);\\n  display: block;\\n\\n  transform: translateY(1rem);\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.7s FadeIn 0.5s ease forwards, 1s ScaleUp 0.5s ease forwards;\\n}\\n```\\n\\n</details>\\n\\n- Coloque un archivo con el logo de la escuela de invierno de Robonomics Winter School 2021 en la carpeta **./src/assets/images**\\n\\n**Obtendrá la siguiente pantalla:**\\n![Paso 2 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-2.png \\\"Dapp Interface changing step 2\\\")\\n\\n## Definir estilos segun los datos de la Dapp\\n\\nAhora envolveré el contenido de la aplicación en el elemento `<div>`. También necesitaré diferentes estilos para diferentes estados de la dapp (cargada o no cargada).\\n\\n- Abra **App.vue** y escriba un elemento de envoltura:\\n```html\\n<div class=\\\"content\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n- Busque la variable `load`, ya se ha definido en `<script>`.\\n- Pase un objeto a `v-bind:class` para alternar dinámicamente las clases (yo uso la versión abreviada `:class`):\\n```html\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\nAsí es como puede alternar fácilmente los estilos en su aplicación de acuerdo con los datos que obtiene. Verá el uso de esta clase a continuación.\\n\\n## Definir vistas segun los datos de la Dapp\\n\\nCambiemos el cargador de la aplicación.\\n- Para este propósito, importaré mi componente de otro proyecto de Robonomics\\n\\n<details>\\n\\n<summary>./src/components/AnimatedRobonomicsLogo.vue</summary>\\n\\n```HTML\\n<template>\\n  <div class=\\\"logo-animated\\\" :style=\\\"{transform: 'scale('+scale+')'}\\\">\\n      <svg version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" width=\\\"196.9px\\\" height=\\\"170.3px\\\" viewBox=\\\"0 0 196.9 170.3\\\" style=\\\"enable-background:new 0 0 196.9 170.3;\\\" xml:space=\\\"preserve\\\">\\n\\t\\t<g transform=\\\"translate(2530 155)\\\">\\n            <path class=\\\"line\\\" d=\\\"M-2523.4,7.9l184.2,0.5l-91.7-158.1L-2523.4,7.9z\\\"/>\\n\\n            <circle class=\\\"dot\\\" cx=\\\"-2339.7\\\" cy=\\\"8.7\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2523.4\\\" cy=\\\"8.2\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2430.8\\\" cy=\\\"-148.4\\\" r=\\\"6.6\\\"/>\\n            \\n            <path class=\\\"triangle-1\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-45.8-79L-2477.3-18.3z\\\"/>\\n            <path class=\\\"triangle-2\\\" d=\\\"M-2431.2-18.1l46,0.1l-45.8-79L-2431.2-18.1z\\\"/>\\n            <path class=\\\"triangle-3\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-46-20.3L-2477.3-18.3z\\\"/>\\n          </g>\\n\\t</svg>\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style scoped>\\n    /*\\n    Global styles required:\\n    FadeIn - keyframe animation from animation: .css\\n    all --color- variables from variables.css\\n    */\\n\\n    .logo-animated {\\n        transform-origin: 0 0;\\n    }\\n\\n    .logo-animated .dot {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 1s FadeIn 0.3s ease forwards;\\n    }\\n\\n    .logo-animated .line {\\n        fill: transparent;\\n        stroke: var(--color-blue);\\n        stroke-miterlimit:10;\\n        stroke-dasharray: 700;\\n        stroke-dashoffset: 700;\\n        animation: 1s DrawSvgPath 0.5s ease-in-out forwards; \\n    }\\n\\n    .logo-animated .triangle-1 {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-1 0.1s linear infinite;\\n    }\\n\\n    .triangle-2 {\\n        fill: var(--color-violet-light);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-2 0.1s linear infinite;\\n    }\\n\\n    .triangle-3 {\\n        fill: var(--color-violet-mid);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-3 0.1s linear infinite;\\n    }\\n\\n\\n    @keyframes DrawSvgPath\\n        {\\n        to {\\n            stroke-dashoffset: 0;\\n        }\\n        }\\n\\n    @keyframes logo-triangle-1\\n    {\\n        0% { fill: var(--color-blue); }\\n        25% { fill: var(--color-blue); }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-violet-light); }\\n        100% { fill: var(--color-blue); }\\n    }\\n\\n    @keyframes logo-triangle-2\\n    {\\n        0% { fill: var(--color-violet-light); }\\n        25% { fill: #E0BDED; }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-blue); }\\n        100% { fill: var(--color-violet-light); }\\n    }\\n\\n    @keyframes logo-triangle-3\\n    {\\n        0% { fill: var(--color-violet-mid); }\\n        25% { fill: var(--color-violet-light); }\\n        50% { fill: var(--color-violet-light); }\\n        75% { fill: var(--color-violet-dark); }\\n        100% { fill: var(--color-violet-mid); }\\n    }\\n</style>\\n```\\n\\n</details>\\n\\n- Registre este componente en **App.vue**\\n```JS\\nexport default {\\n  components: {\\n    Loader: () => import(\\\"./components/AnimatedRobonomicsLogo\\\")\\n  }\\n}\\n```\\n- Insértelo con la condicional directiva Vue `v-if`, usando la `load` variable ya conocida:\\n```HTML\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <Loader v-if=\\\"load\\\" />\\n  <template v-else>\\n    <!-- here will be main content of loaded dapp -->\\n  </template>\\n</div>\\n```\\n- Mira el resultado en el navegador. Tiene algunos problemas que arreglaremos ahora:\\n\\n1. Loader aparece con el título (debería estar en el centro). Insertemos estas líneas en **app.css**:\\n```css\\nbody, html, #app {\\n  height: 100%;\\n  position: relative;\\n}\\n```\\n2. Si su conexión va demasiado rápido, verá el cargador parpadeando por un momento. Puede confundir mucho. Establezcamos un tiempo de espera para la respuesta de la aplicación. Para hacer eso, abra **api.js** y busque en la función `initAccount` este código:\\n```JS\\nconst timeout = new Promise(resolve => {\\n  setTimeout(resolve, 300);\\n});\\n```\\nConfiguré `1700` en lugar de `300` y verifico el resultado:\\n\\n![Dapp Interface changing step 3](../images/build-dapp-interface/dapp-3.gif \\\"Dapp Interface changing step 3\\\")\\n\\n\\n## Uso componentes reutilizables\\n\\nYa ha visto cómo registrar y utilizar un componente en la sección anterior sobre Loader, pero ahora quiero centrarme en él con más atención.\\n\\nCambiemos la sección Account. Aquí usaré componentes escritos por mí mismo (box, button, icon) y el de terceros ([from Vue Polkadot Library](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon )).\\n\\n### Añadir la Caja  \\n\\n<details>\\n\\n<summary>Crear componente Box en archivo ./src/components/Box.vue </summary>\\n\\n```HTML\\n<template>\\n    <section class=\\\"box\\\" :class=\\\"classList\\\">\\n        <slot />\\n    </section>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    classList: {\\n      type: String\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .box {\\n        background-color: var(--color-light);\\n        border: 1px solid var(--color-dark);\\n        padding: calc(var(--space)*0.5) var(--space);\\n        box-shadow: 2px 2px 0 var(--color-dark);\\n        margin-bottom: calc(var(--space)*1.5);\\n    }\\n</style>\\n```\\n</details>\\n\\nAhora podemos usarlo muchas veces a lo largo de la dapp. Veamos esto en el ejemplo de la sección Cuenta:\\n\\n-  Componente de registro (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Box: () => import(\\\"./components/Box\\\")\\n  }\\n}\\n```\\n\\n- Úselo para la sección Account con una clase adicional pasada con prop `classList`:\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }} |\\n  <button @click=\\\"faucet\\\">\\n    faucet\\n  </button>\\n</Box>\\n```\\n\\n**Comprueba el resultado:**\\n![Dapp Interface changing step 4](../images/build-dapp-interface/dapp-4.png \\\"Dapp Interface changing step 4\\\")\\n\\n### Añadir el Boton\\n\\nEs posible que ni siquiera note el botón en el cuadro que hemos agregado. Arreglemoslo y agreguemos un componente para los botones, ya que no es el único botón de la aplicación.\\n\\n<details>\\n\\n<summary>Crear componente de botón en el archivo ./src/components/Button.vue </summary>\\n\\n```HTML\\n<template>\\n  <button type=\\\"button\\\" :class=\\\"classList\\\" @click=\\\"onClick\\\" :disabled=\\\"disabled\\\" class=\\\"inline-block\\\">\\n    {{ label }}\\n  </button>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  components: {\\n    Icon: () => import(\\\"./Icon\\\")\\n  },\\n\\n  props: {\\n    label: {\\n      type: String,\\n    },\\n    type: {\\n      type: String,\\n      default: 'primary',\\n      validator: function (value) {\\n        return ['primary', 'secondary'].indexOf(value) !== -1;\\n      }\\n    },\\n    disabled: {\\n      type: Boolean,\\n      default: false,\\n    },\\n    size: {\\n      type: String,\\n      default: 'medium',\\n      validator: function (value) {\\n        return ['small', 'medium', 'large'].indexOf(value) !== -1;\\n      }\\n    }\\n  },\\n\\n  computed: {\\n    classList() {\\n      return {\\n        'button': true,\\n        [`${this.type}`]: true,\\n        [`button__${this.size}`]: true,\\n      };\\n    },\\n  },\\n\\n  methods: {\\n    onClick() {\\n      this.$emit('onClick');\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .button {\\n        appearance: none;\\n        -webkit-appearance: none;\\n        outline: 0;\\n        border: 0;\\n\\n        transition: 0.1s all linear;\\n\\n        padding: .15rem 0.6rem;\\n        border-width: 1px;\\n        border-style: solid;\\n        border-radius: .25rem;\\n  \\n        cursor: pointer;\\n\\n        font-family: var(--font-family);\\n        font-size: calc(var(--font-size)*0.9);\\n        line-height: 1;\\n        font-weight: 500;\\n\\n        text-transform: uppercase;\\n        letter-spacing: 1px;\\n    }   \\n\\n    .button:not([disabled]):hover {\\n    filter: saturate(1.5);\\n    }\\n\\n    .button[disabled] {\\n        cursor: default;\\n        opacity: 0.6;\\n    }\\n\\n    button.primary {\\n        border-color: var(--color-green);\\n        background-color: var(--color-green);\\n        color: var(--color-light);\\n    }\\n\\n    button.secondary {\\n        border-color: var(--color-blue);\\n        color: var(--color-blue);\\n    }\\n\\n    button.secondary:not([disabled]):hover {\\n        background-color: var(--color-blue);\\n        color: var(--color-light);\\n    }\\n\\n    .button__small {\\n        font-size: .85rem;\\n        padding: .1rem 0.45rem;\\n    }\\n\\n    .button__large {\\n        font-size: 1.2rem;\\n        padding: .5rem 1.7rem;\\n    }\\n\\n</style>\\n```\\n</details>\\n\\n\\n- Registre el componente (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Button: () => import(\\\"./components/Button\\\")\\n  }\\n}\\n```\\n\\n- Úselo para el botón ‘Faucet’ con accesorios definidos en el componente 'Button' \\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }}\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n</Box>\\n```\\n\\n**Obtenemos esta vista:**\\n![Dapp Interface changing step 5](../images/build-dapp-interface/dapp-5.png \\\"Dapp Interface changing step 5\\\")\\n\\nPara el componente Botón, hemos emitido el clic de prop con `@onClick`, por lo que prestaré atención si la función de faucet está funcionando correctamente ahora (el saldo debería cambiar al hacer clic):\\n\\n![Dapp Interface changing step 6](../images/build-dapp-interface/dapp-6.gif \\\"Dapp Interface changing step 6\\\")\\n\\n### AAñadir el Icono\\n\\nAgreguemos un ícono a este botón para atraer más atención a este elemento de la interfaz, ya que el usuario no puede interactuar con la dapp correctamente sin unidades y haciendo clic en este botón.\\n\\nPara este propósito, puede usar cualquier biblioteca Vue lista para íconos, crearé mi propio componente con el ícono.\\n\\n- Encontré un ícono apropiado en [el gran archivo de íconos en línea](https://www.flaticon.com).\\n- Descargué el archivo .svg y lo editó en el editor de gráficos vectoriales para obtener el tamaño adecuado.\\n- Se insertó svg como texto en el componente Icon.vue.\\n\\n<details>\\n\\n<summary>Esto es lo que obtuve como componente Icon.vue</summary>\\n\\n```JS\\n<template>\\n  <div class=\\\"icon inline-block\\\" :class=\\\"classList\\\">\\n    <svg v-if=\\\"icon == 'faucet'\\\" class=\\\"icon-fill\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" :width=\\\"SvgWidth(20)\\\"  viewBox=\\\"0 0 20 24.9\\\" style=\\\"enable-background:new 0 0 20 24.9;\\\" xml:space=\\\"preserve\\\">\\n      <path d=\\\"M2.7,24.9c0.2,0,2.4,0,2.4-2.4c0-2-2.2-5.2-2.2-5.2s-2.5,3.3-2.5,5.3C0.4,24.6,2.4,24.9,2.7,24.9z M20,10.8V7.2V3.1h-2.6v2.6h-3.1V1.5h2.6c0.4,0,0.8-0.3,0.8-0.8S17.3,0,16.9,0h-6.7C9.8,0,9.5,0.3,9.5,0.8s0.3,0.8,0.8,0.8h2.6v4.1H7.9c-4.7,0-6.2,3.2-6.3,4.8c0,0,0,0.1,0,0.1v2.8H0v2.1h6.2v-2.1H4.6v-2.7c0-0.3,0.4-1.9,3.3-1.9h9.6v2.1L20,10.8L20,10.8z\\\"/>\\n    </svg>\\n\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n  props: {\\n    icon: {\\n      type: String\\n    },\\n    classList: {\\n      type: String\\n    },\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n  methods: {\\n    SvgWidth(SvgWidth) {\\n      return `${SvgWidth * this.scale}px`;\\n    }\\n  }\\n};\\n</script>\\n\\n<style>\\n.icon {\\n    line-height: 1;\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\nPara usarlo con el botón, edite el componente Botón.\\n\\nImporte el icono en **Button.vue**:\\n\\n```JS\\ncomponents: {\\n    Icon: () => import(\\\"./Icon\\\")\\n}\\n```\\n\\nObjeto de registro:\\n\\n```JS\\nprops: {\\n  icon: {\\n    type: String,\\n    default: 'none'\\n  }\\n}\\n```\\n\\nAgregue el ícono al botón (podemos especificar diferentes plantillas con la condición `v-if`):\\n\\n```HTML\\n<template v-if=\\\"icon != 'none'\\\">\\n  <Icon :icon=\\\"icon\\\" />\\n  <span v-if=\\\"label != ''\\\" class=\\\"inline-block\\\">{{ label }}</span>\\n</template>\\n<template v-if=\\\"icon == 'none' & label != ''\\\">\\n  {{ label }}\\n</template>\\n```\\n\\nAgregar estilos:\\n\\n```CSS\\n.button .icon-fill path {\\n  fill: var(--color-light);\\n}\\n\\n.button > *:not(:last-child) {\\n  margin-right: calc(var(--space)/2);\\n}\\n\\n```\\n\\nAgregue el icono de apoyo en el botón en **App.vue**:\\n\\n```HTML\\n<Button label=\\\"Faucet\\\" size=\\\"large\\\" icon=\\\"faucet\\\" @onClick=\\\"faucet\\\" />\\n```\\n\\n**Check:**\\n\\n![Dapp Interface changing step 7](../images/build-dapp-interface/dapp-7.png \\\"Dapp Interface changing step 7\\\")\\n\\n### Agregar Polkadot Avatar\\n\\n- Instalar [@vue-polkadot/vue-identicon](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon)\\n\\n- Importar a App.vue:\\n```JS\\ncomponents: {\\n    Identicon: () => import(\\\"@vue-polkadot/vue-identicon\\\")\\n}\\n```\\n\\n- Inserte el avatar en lugar de la palabra ‘Account’, pase los accesorios de acuerdo con la documentación, use los datos de la \\\"account' como un valor de apoyo:\\n```HTML\\n<Identicon\\n  :value=\\\"account\\\"\\n  :theme=\\\"'polkadot'\\\"\\n  :size=\\\"40\\\"\\n  :class=\\\"'inline-block'\\\"\\n/>\\n```\\n\\n**Cheque:**\\n\\n![Paso 8 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-8.png \\\"Dapp Interface changing step 8\\\")\\n\\n## Manipulación de datos para una mejor vista\\n\\nCortemos la dirección de la cuenta:\\n\\n- Envuelva la `account` variable en la propiedad calculada:\\n\\n```JS\\ncomputed: {\\n  AccountAddress() {\\n    return this.account.slice(0, 6) + \\\"...\\\" + this.account.slice(-4);\\n  }\\n}\\n```\\n\\n- Reemplace la `account` variable con `AccountAddress` en la plantilla.\\n\\n**Cheque:**\\n\\n![Paso 9 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-9.png \\\"Dapp Interface changing step 9\\\")\\n\\n## CMagia CSS\\n\\nEmbellezcamos un poco más la sección de la cuenta:\\n\\n<details>\\n\\n<summary>Plantilla</summary>\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n              \\n  <div class=\\\"account__address\\\">\\n    <Identicon\\n      :value=\\\"account\\\"\\n      :theme=\\\"'polkadot'\\\"\\n      :size=\\\"40\\\"\\n      :class=\\\"'inline-block'\\\"\\n    />\\n\\n    <code class=\\\"inline-block\\\">{{ AccountAddress }}</code>\\n  </div>\\n  \\n  <div class=\\\"account__balance\\\">{{ balance }}</div>\\n\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n  \\n</Box>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Estilos (en app.css)</summary>\\n\\n```CSS\\n.account {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  align-items: center;\\n  justify-items: stretch;\\n  column-gap: var(--space);\\n}\\n\\n.account__balance {\\n    font-size: 150%;\\n    font-weight: 500;\\n    font-family: var(--font-family-code);\\n    white-space: nowrap;\\n}\\n\\n.account__address > *:not(:last-child) {\\n    margin-right: calc(var(--space)/2);\\n}\\n```\\n\\n</details>\\n\\n![Paso 10 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-10.gif \\\"Dapp Interface changing step 10\\\")\\n\\nEditemos estilos para las pestañas:\\n\\n<details>\\n\\n<summary>Estilos (en app.css)</summary>\\n\\n```CSS\\n.tabs {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  margin-top: calc(var(--space)*2.5);\\n}\\n\\n.tabs button {\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  border-width: 0 0 1px;\\n  font-family: var(--font-family);\\n  font-size: calc(var(--font-size)*1.5);\\n  font-weight: 300;\\n  cursor: pointer;\\n  transition: 0.2s all linear;\\n}\\n\\n.tabs button:not(.active) {\\n  opacity: 0.5;\\n  border-color: var(--color-gray)\\n}\\n\\n.tabs-content {\\n  padding-top: var(--space);\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>Cambios mínimos en la plantilla:</summary>\\n\\n```HTML\\n<div class=\\\"tabs-content\\\">\\n  <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" /> \\n</div>\\n```\\n\\n</details>\\n\\n![Paso 11 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-11.gif \\\"Dapp Interface changing step 11\\\")\\n\\n> Permítanme recordarles que el código terminado para este tutorial se encuentra en [este](https://github.com/positivecrash/wscool21-ui-dapp) repositorio. Y pasemos a los siguientes pasos :)\\n\\n## Registro de Datos (Datalog)\\n\\nComience por arreglar elementos de la interfaz de usuario que ya se conocen en los botones dapp: (lo mismo que hemos hecho para el ‘Faucet’, pero con diferentes accesorios).\\n\\nLuego, envolveré estos elementos en `<fieldset>` para separarlos por significado. Y escribiré mis propios estilos para el conjunto de campos y los elementos de entrada.\\n<details>\\n\\n<summary>Plantilla en Datalog.vue:</summary>\\n\\n```HTML\\n<div class=\\\"tools\\\">\\n  <fieldset>\\n    <Button label=\\\"Read data\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"read\\\" />\\n  </fieldset>\\n\\n  <fieldset>\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" class=\\\"large\\\" />\\n    <Button label=\\\"Write\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"write\\\" />\\n  </fieldset>\\n</div>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Estilos para elementos de entrada en app.css: se supone que es global:</summary>\\n\\n```CSS\\ninput, select{\\n  padding: .3rem 0.6rem;\\n  border: 1px solid var(--color-gray);\\n  background-color: var(--color-light);\\n  border-radius: var(--radius);\\n  font-size: var(--font-size);\\n  font-family: var(--font-family-code);\\n  border-radius: .25rem;\\n  transition: 0.2s ease all;\\n}\\n\\ninput:focus {\\n  border-color: var(--color-dark);\\n}\\n\\ninput.large, select.large {\\n  font-size: 1.2rem;\\n  padding: .35rem 1rem;\\n}\\n\\n\\n.tools *, .tools fieldset:not(:last-child):after {\\n  display: inline-block;\\n  vertical-align: middle;\\n  vertical-align: -moz-middle-with-baseline;\\n  vertical-align: -webkit-baseline-middle;\\n}\\n\\n.tools fieldset {\\n  border: 0;\\n}\\n\\n.tools fieldset:not(:last-child):after {\\n  content: \\\"•\\\";\\n}\\n\\n.tools fieldset > *,  .tools > * {\\n  margin-right: calc(var(--space)/2)\\n}\\n```\\n\\n</details>\\n\\n**Comprobemos que todo funciona bien después de las actualizaciones:**\\n\\n![Paso 12 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-12.gif \\\"Dapp Interface changing step 12\\\")\\n\\nTenemos una sección de registro de datos en todo el dapp, así que crearé un componente para él.\\n\\n<details>\\n\\n<summary>Tengo el siguiente código para un nuevo componente DatalogSection.vue</summary>\\n\\n```HTML\\n<template>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <h4 class=\\\"log-title\\\">Datalog</h4>\\n\\n        <div class=\\\"log-content\\\">\\n\\n          <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n\\n          <details v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"box\\\" :open=\\\"k === 0\\\">\\n              <summary>{{ item[0] }}</summary>\\n              <pre>{{ item[1] }}</pre>\\n          </details>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    log: {\\n      type: Array\\n    }\\n  },\\n\\n}\\n\\n</script>\\n\\n<style>\\n\\n.log {\\n  text-align: left;\\n  margin: var(--space) auto;\\n  width: 100%;\\n}\\n\\n.log-content {\\n  border: 1px solid var(--color-gray);\\n  max-height: 500px;\\n  overflow-y: auto;\\n  padding: var(--space);\\n  background-color: var(--color-gray-middark);\\n  outline: 1px solid #fff;\\n  box-shadow: 0 0 60px 20px #fff inset;\\n}\\n\\n.log-title {\\n  color: var(--color-gray-dark);\\n  font-weight: 300;\\n  font-family: var(--font-family-code);\\n\\n  border-bottom: 1px solid var(--color-gray);\\n}\\n\\n.log .box {\\n  margin-bottom: var(--space);\\n}\\n\\ndetails {\\n  transition: 0.2s all ease;\\n}\\n\\ndetails summary {\\n  cursor: pointer;\\n}\\n\\ndetails.box {\\n  padding-top: 0;\\n  padding-bottom: 0;\\n}\\n\\ndetails.box[open] {\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box:focus {\\n  box-shadow: 0 0 5px var(--color-gray)\\n}\\n\\ndetails.box summary {\\n  padding-top: calc(var(--space)*0.5);\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box[open] summary {\\n  border-bottom: 1px solid var(--color-dark);\\n  margin-bottom: calc(var(--space)*0.5);\\n  font-weight: 500;\\n}\\n\\n.log details.box summary {\\n  font-family: var(--font-family-code);\\n}\\n\\n</style>\\n```\\n\\n</details>\\n\\nA lo que debe prestar atención aquí: pasamos prop `log` como una matriz. Supongo que esta matriz multidimensional contendrá un registro de entradas y cada entrada tiene un título (escribí la fecha para todos los registros en el dapp) y contenido. Necesitamos reformatear las matrices en los componentes **Datalog.vue** y **Launch.vue**.\\n\\nAhora edite **Datalog.vue**. Método de búsqueda, donde obtenemos el registro:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n}\\n```\\n\\nAhora tenemos que formatear los datos en **Datalog.vue** y pasar la matriz de registro lista para **DatalogSection.vue**. Así que mapeemos la matriz de registros:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray().map((item) => {\\n    return [new Date(Number(item[0])).toLocaleString(), u8aToString(item[1])]\\n  });\\n}\\n```\\n\\nYa no necesitamos este código:\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return u8aToString(v);\\n  }\\n}\\n```\\n\\n**Revisemos la sección de registro de datos en la pestaña Datalog:**\\n\\n![Paso 13 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-13.gif \\\"Dapp Interface changing step 13\\\")\\n\\n## Lanzamiento\\n\\nPara este paso, la mayoría de las mejoras ya se han hecho, solo necesitamos aplicarlas a la plantilla: Importar componentes Button y Datalog, eliminar el título excesivo:\\n\\n![Paso 14 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-14.gif \\\"Dapp Interface changing step 14\\\")\\n\\nReemplacemos el elemento de control de `select` con `checkbox`..\\n\\nEn lugar de esto:\\n```HTML\\n<select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n  <option value=\\\"ON\\\">ON</option>\\n  <option value=\\\"OFF\\\">OFF</option>\\n</select>\\n```\\n\\nEscribe esto:\\n```HTML\\n<div class=\\\"toggler inline-block\\\">\\n  <input v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\" type=\\\"checkbox\\\" id=\\\"robot-switch\\\" />\\n  <label for=\\\"robot-switch\\\"><span></span></label>\\n</div>\\n```\\n\\n<details>\\n\\n<summary>Estilos en app.css:</summary>\\n\\n```CSS\\n.toggler input { display: none; }\\n.toggler label {\\n  position: relative;\\n  display: block;\\n  width: 60px;\\n  height: 40px;\\n  border-radius: 4px;\\n  font-weight: 500;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  cursor: pointer;\\n  background-color: var(--color-gray);\\n  color: var(--color-light);\\n  text-align: center;\\n}\\n\\n.toggler label:before {\\n  content: 'Off';\\n  width: 100%;\\n  text-align: center;\\n  line-height: 40px;\\n}\\n\\n.toggler label:after {\\n  content: '';\\n  display: block;\\n  width: 6px;\\n  height: 100%;\\n  border-radius: 10px;\\n  background-color: var(--color-gray-dark);\\n\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  z-index: 10;\\n\\n  transition: 0.3s ease-out all;\\n}\\n\\n.toggler input:checked + label {\\n  background-color: var(--color-green);\\n}\\n\\n.toggler input:checked + label:before {\\n  content: 'On';\\n}\\n\\n.toggler input:checked + label:after {\\n  transform: translateX(54px);\\n  background-color: #007038;\\n}\\n```\\n\\n</details>\\n\\n![Paso 15 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-15.gif \\\"Dapp Interface changing step 15\\\")\\n\\nQuiero aclarar algo con la interfaz: con estos elementos arrancamos algún dispositivo. Visualicémoslo. Elegí un dron, así que alternaré las clases según `item.parameter`.\\n\\nCree una nueva propiedad en `data`:\\n```JS\\ndata() {\\n  status: false\\n}\\n```\\n\\nAsignar el valor del `parameter` al `status` después de hacer clic en el botón y enviar tx al bloque:\\n```JS\\nmethods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n            this.status = this.parameter; // new line here\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n```\\n\\nEscribe estilos para el dron en Launch.vue. No olvide el `scoped` de la etiqueta `<style>`, para aplicar estilos solo para este componente.\\n\\n<details>\\n\\n<summary>CSS para drones:</summary>\\n\\n```CSS\\n<style scoped>\\n.tools {\\n  position: relative;\\n  padding-left: 120px;\\n  text-align: left;\\n  display: inline-block;\\n}\\n\\n.launch-drone {\\n  position: absolute;\\n  width: 100px;\\n  left: 0;\\n  filter: grayscale(1);\\n  transition: 1s all ease-in;\\n}\\n\\n.launch-drone.on {\\n  filter: grayscale(0);\\n  animation: DroneLaunch 10s linear infinite;\\n}\\n\\n@keyframes DroneLaunch {\\n  0%, 20%, 40%, 60%, 80%, 100% {\\n    transform: translateY(0);\\n  }\\n  10%, 30%, 50%, 70%, 90% {\\n    transform: translateY(-20%);\\n  }\\n}\\n</style>\\n```\\n\\n</details>\\n\\n![Paso 16 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-16.gif \\\"Dapp Interface changing step 16\\\")\\n\\nAhora agreguemos el componente **DatalogSection.vue**.\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\nVuelva a formatear la matriz de registros desde:\\n\\n```JS\\nthis.log.push({\\n  sender,\\n  robot,\\n  parameter\\n});\\n```\\n\\na (para estructuras como `[[\\\"entry 1 date\\\", \\\"entry 1 content\\\"], [\\\"entry 2 date\\\", \\\"entry 2 content\\\"]]`):\\n\\n```JS\\nthis.log.push([new Date().toLocaleString(), {\\n  sender,\\n  robot,\\n  parameter\\n}]);\\n```\\n\\nReemplace el código de la plantilla:\\n\\n```HTML\\n<div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    sender: <b>{{ item.sender }}</b>\\n    <br />\\n    robot: <b>{{ item.robot }}</b>\\n    <br />\\n    parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n  </div>\\n</div>\\n```\\n\\ncon esto:\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n**Cheque:**\\n![Paso 17 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-17.gif \\\"Dapp Interface changing step 17\\\")\\n\\nA veces tienes algunos errores, es casi inevitable. Algo puede salir mal con la conexión o puede suceder cualquier otra cosa. Entonces tenemos alternativas con mensajes de error en todo el dapp, no los he cambiado desde el principio, en el código se ven así:\\n\\n```HTML\\n<div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n```\\n\\nEn la interfaz, los errores se ven de esta manera ahora:\\n\\n![Paso 18 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-18.png \\\"Dapp Interface changing step 18\\\")\\n\\nAgregue estilos para el `.error` en **app.css**:\\n\\n```CSS\\n.error {\\n  font-weight: 400;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  color: var(--color-red);\\n}\\n```\\n\\nY arreglaré un espacio entre la sección `.tools` y otro contenido desde la parte inferior también en **app.css**:\\n\\n```CSS\\n.tools {\\n  margin-bottom: var(--space);\\n}\\n```\\n\\nObtendremos:\\n\\n![Paso 19 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-19.png \\\"Dapp Interface changing step 19\\\")\\n\\nAhora en esta página tenemos los botones “primary”. Técnicamente está bien, pero esto no está bien según la experiencia del usuario anterior. Es mejor no utilizar más de un botón predominante en la pantalla. Así que arreglemoslo y agreguemos para el `Button` en **Launch.vue** con la propiedad `type = \\\"secundaria\\\"`:\\n\\n![Paso 20 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-20.png \\\"Dapp Interface changing step 20\\\")\\n\\nGenial, ahora solucionaré algunos problemas con mi nodo e iré al paso de demostración.\\n\\n## Demo\\n\\nPara empezar, me gustaría intercambiar pestañas, para prestar más atención a la más relevante, pero este no es el primer paso que hacemos para practicar. Invertir pestañas en **App.vue**.\\n\\nNo olvide reemplazar los datos predeterminados:\\n\\n```JS\\ndata() {\\n    return {\\n      ...\\n      tab: \\\"demo\\\"\\n    };\\n},\\n```\\n\\n![Paso 21 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-21.png \\\"Dapp Interface changing step 21\\\")\\n\\nComo de costumbre, comencemos por cambiar lo que ya tenemos.\\n\\n- EliminaR el título `<h2>Demo</h2>` como en los pasos anteriores\\n- Encontrar elementos de la interfaz de usuario que ya hemos aprendido: registro de datos, botones, dirección de cuenta. Pero no tan rápido. Ahora cambiaremos solo el registro de datos.\\n\\nAgregar el componente a **Demo.vue**:\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\nTenemos datos sin procesar en el registro, por lo que debemos reformatear la matriz con el registro para pasar los datos de vista lista del componente como en los pasos anteriores. Busque la devolución de línea `return [item[0], item[1]];` in `async created()` y reemplácelo con:\\n\\n```JS\\nreturn [new Date(Number(item[0])).toLocaleString(), JSON.parse(u8aToString(item[1]))];\\n```\\n\\nElimine el código no utilizado del registro:\\n\\n```HTML\\n<div v-if=\\\"log\\\" class=\\\"log\\\">\\n  <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    <b>{{ item[0] | dateFormat }}</b>\\n    <pre>{{ item[1] | dataFormat }}</pre>\\n  </div>\\n</div>\\n```\\n\\ny:\\n\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return JSON.parse(u8aToString(v));\\n  }\\n},\\n```\\n\\n**Cheque:**\\n![Paso 22 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-22.png \\\"Dapp Interface changing step 22\\\")\\n\\nPara la personalización de este ejemplo de demostración con el lanzamiento de un robot, puede proponer cualquier idea. Personalmente, comencé con esta ciudad:\\n\\n![Paso 23 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-23.gif \\\"Dapp Interface changing step 23\\\")\\n\\nNo mostraré el código completo para que esto no te confunda en absoluto, pero esquemáticamente habrá algo como esto:\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back\\\"></div>\\n  <div class=\\\"demo-city\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n</div>\\n```\\n\\nQue dentro del elemento `.demo.play` escriba estilos para mover la ciudad hacia atrás y el automóvil hacia adelante.\\n\\nMientras trabajaba en esto, se me ocurrió la idea de realizar la ciudad CyberPunk. Como no tengo ninguna tarea en particular, el automóvil se convirtió en un taxi, el conductor se convirtió en un pasajero, y ahora en la interfaz tenemos un holograma de robot de IA que da la bienvenida al pasajero (todos estos son solo CSS y tweaks&&tricks).\\n\\n**TEl código de la demostración de Cyberpunk City:**\\n\\n<details>\\n\\n<summary>Plantilla</summary>\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back-1\\\"></div>\\n  <div class=\\\"demo-back-2\\\"></div>\\n  <div class=\\\"demo-city-1\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n\\n  <div class=\\\"demo-data\\\">\\n    <div class=\\\"demo-data-driver inline-block\\\">\\n      <img alt=\\\"Driver's avatar\\\" src=\\\"../assets/images/cabman.png\\\" v-if=\\\"robot.state\\\"/>\\n    </div>\\n    <div class=\\\"demo-data-lines inline-block\\\">\\n      <div class=\\\"demo-data-line\\\">\\n          <div>Robot</div>\\n          <div>[ {{ addressShort(robot.address) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-line\\\" v-if=\\\"robot.state\\\">\\n          <div>Passenger</div>\\n          <div>[ {{ addressShort(robot.driver) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-welcome\\\" v-if=\\\"robot.state\\\">\\n          <span>Hello, passenger. </span>\\n          <span>I've linked to the vehicle. </span>\\n          <span>Your ride begins, congrats! </span>\\n      </div>\\n    </div>\\n\\n  </div>\\n\\n  <Button :label=\\\"robot.state ? 'stop' : 'run'\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" @onClick=\\\"run\\\" />\\n</div>\\n```\\n\\n</details>\\n\\nHay más de una dirección hash que debería acortarse, así que agregué el método:\\n\\n```JS\\nmethods: {\\n  addressShort(address) {\\n    return address.slice(0, 6) + \\\"...\\\" + address.slice(-4);\\n  }\\n}\\n```\\n\\nNo olvide registrar el componente Button\\n\\n```JS\\ncomponents: {\\n  Button: () => import(\\\"./Button\\\")\\n}\\n```\\n\\n<details>\\n\\n<summary>Estilos</summary>\\n\\n```CSS\\n<style scoped>\\n.demo {\\n    --h: 120px;\\n    --color-yellow: #F2F209;\\n\\n    background-color: #AFCCD3;\\n\\n    background: linear-gradient(#010123, #4baac7);\\n\\n    position: relative;\\n    height: 500px;\\n    overflow: hidden;\\n\\n    border-width: 2px 2px 2px 15px;\\n    border-style: solid;\\n    border-color: var(--color-yellow);\\n    \\n}\\n\\n.demo:before {\\n    content: '[ Delamain cabs rental DEMO ]';\\n    background-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    padding: .5rem 1rem;\\n\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 300;\\n\\n    border-width: 0 6px 2px 0;\\n    border-style: solid;\\n    border-color: #7B186E;\\n}\\n\\ndiv[class^=demo-back-], div[class^=demo-city-] {\\n    position: absolute;\\n    left: 0;\\n    width: 100%;\\n    z-index: 2;\\n}\\n\\ndiv[class^=demo-back-]{\\n    border-top: 1px solid #364444;\\n}\\n\\ndiv[class^=demo-city-] {\\n    background-repeat: repeat-x;\\n    background-size: cover;\\n    background-position: 100% 0;\\n\\n    height: 300px;\\n    bottom: var(--h);\\n\\n    animation: 50s MoveCity infinite linear 1.5s;\\n}\\n\\ndiv.demo-back-1 {\\n    background-color: #060236;\\n    background: linear-gradient(#7B186E, #060236);\\n    height: var(--h);\\n    bottom: 0;\\n}\\n\\ndiv.demo-back-2 {\\n    background-color: #c515ae;\\n    border-width: 2px 0;\\n    border-style: solid;\\n    border-color: #69045c;\\n\\n    height: 20px;\\n    bottom: var(--h);\\n    z-index: 10;\\n}\\n\\ndiv.demo-city-1 {\\n    background-image: url(../assets/images/city-1.png);\\n}\\n\\n.demo-car {\\n    background-image: url(../assets/images/car.png);\\n    background-size: contain;\\n    background-repeat: no-repeat;\\n    background-position: 100% 0;\\n\\n    width: calc(508px * 0.5);\\n    height: calc(257px * 0.5);\\n    position: absolute;\\n    bottom: calc(var(--h) + 4px);\\n    z-index: 10;\\n\\n    transform: translateX(-100px);\\n    animation: MoveCar 50s infinite 1.5s linear;\\n}\\n\\n.demo.play div[class^=demo-city-], .demo.play .demo-car { animation-play-state: running; }\\n.demo.stop div[class^=demo-city-], .demo.stop .demo-car { animation-play-state: paused; }\\n\\n.demo.play .demo-car {\\n    background-image: url(../assets/images/car-ride.png);\\n}\\n\\n\\n.demo button {\\n    background-color: var(--color-yellow);\\n    border-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    bottom: 30px;\\n    right: 30px;\\n    z-index: 1000;\\n}\\n\\n.demo-data {\\n    position: absolute;\\n    bottom: 30px;\\n    left: 30px;\\n    z-index: 1000;\\n\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    padding: .5rem;\\n    font-family: var(--font-family-code);\\n\\n    transition: 0.2s all ease;\\n}\\n\\n.demo-data-lines {\\n    max-width: 400px;\\n}\\n\\n.demo-data-line {\\n    display: grid;\\n    grid-template-columns: 100px auto;\\n    gap: .5rem;\\n    text-align: left;\\n}\\n\\n.demo-data-line div:first-child {\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 700;\\n}\\n\\n.demo-data-driver {\\n    margin-right: 1rem;\\n}\\n\\n.demo-data-driver img {\\n    display: block;\\n    max-width: 100px;\\n\\n    visibility: hidden;\\n    opacity: 0;\\n    animation: FadeInBlink .3s cubic-bezier(0.075, 0.82, 0.165, 1) 0.6s forwards;\\n}\\n\\n.demo-data-welcome {\\n    text-align: left;\\n    padding-top: .5rem;\\n}\\n\\n.demo-data-welcome span {\\n    visibility: hidden;\\n    opacity: 0;\\n\\n    animation-name: FadeIn;\\n    animation-timing-function: cubic-bezier(0.075, 0.82, 0.165, 1);\\n    animation-duration: 0.6s;\\n    animation-fill-mode: forwards;\\n}\\n\\n.demo-data-welcome span:nth-child(1) { animation-delay: 1.5s; }\\n.demo-data-welcome span:nth-child(2) { animation-delay: 2.5s; }\\n.demo-data-welcome span:nth-child(3) { animation-delay: 3.2s; }\\n\\n\\n@keyframes MoveCity\\n{\\n  100% {\\n    background-position: -1000px 0;\\n  }\\n}\\n\\n@keyframes MoveCar\\n{\\n    0% {\\n        transform: translateX(-100px);\\n    }\\n    100% {\\n        transform: translateX(960px);\\n    }\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n**Resultado:**\\n\\n![Paso 25 de cambio de interfaz Dapp](../images/build-dapp-interface/dapp-25.gif \\\"Dapp Interface changing step 25\\\")\\n\\n## Conclusion\\n\\nFelicidades! Ahora ha rediseñado la dapp y da pistas sobre cómo comenzar a construir la interfaz de su aplicación.\\n\\n### Enlaces de pago\\n\\n- [Código completo de este tutorial](https://github.com/positivecrash/wscool21-ui-dapp)\\n- [Discutir en discordia](https://discord.gg/5UWNGNaAUf)\\n- [Ver el calendario y resumen de Robonomics Winter School 2021](https://robonomics.network/blog/winter-robonomics-school/)\\n- [Github de colaborador](https://github.com/positivecrash)\\n\\n### Practica\\n\\nSi tiene algo de tiempo extra o quiere practicar sus habilidades, hay algunas ideas de mejoras que podría hacer en esta demostración:\\n\\n- Adapte la interfaz de usuario para pantallas estrechas, haga que dapp sea compatible con dispositivos móviles.\\n- Agregue el modo ‘day/night’, editando el archivo **_variables.scss** y el archivo de plantilla de la dapp.\\n- Agregar botones ‘Copy to clipboard’ para direcciones.\\n- Haga popus delicados para informar a los usuarios sobre los cambios (por ejemplo, puede mostrar un mensaje emergente de que se reciben las unidades después de hacer clic en el botón ‘Faucet’, o puede mover en la ventana emergente un error que teníamos en la sección ‘Iniciar’).\\n\\nPor favor, llénate gratis para hacer preguntas y compartir tus resultados en [Discord](https://discord.gg/5UWNGNaAUf), márcame en tu mensaje `@positivecrash`.\\n\\n\\n\\n\\n\\n\\n\"}},{\"node\":{\"id\":\"f2d5dd6f257e85ed16430c1379f5d547\",\"title\":\"Lección 6.1, Crear dApps IoT para usuarios finales\",\"path\":\"/docs/es/wschool2021-build-dapp-for-end-users/\",\"content\":\"\\n## Preparándose\\n\\n### Lanzamiento del nodo de Robonomics\\n\\nPara el desarrollo y la prueba de dApp, usaremos un nodo local de Robonomics. Para hacer esto, necesita descargar el archivo binario compilado v0.24 [https://github.com/airalab/robonomics/releases](https://github.com/airalab/robonomics/releases). Usaré Ubuntu, así uno descarga la versión apropiada.\\n\\nDesempaquetar el archivo:\\n```sh\\nwget https://github.com/airalab/robonomics/releases/download/v0.24.0/robonomics-ubuntu-0.24.0-x86_64.tar.xz\\ntar -xvf robonomics-ubuntu-0.24.0-x86_64.tar.xz\\nchmod +x robonomics\\n```\\n\\nAhora podemos iniciar el nodo en modo de desarrollo. Para hacer esto, use -dev flag.\\n```sh\\n./robonomics --dev --tmp\\n```\\n\\n> Solución de problemas\\n```sh\\n./robonomics purge-chain --dev\\n```\\n\\n### Extension del Navegador\\n\\nPara almacenar claves en un navegador, existe `polkadot{.js} extension`. En dApp lo usaremos para firmar transacciones.\\n\\nLa extensión está disponible actualmente para `Google Chrome` y `Firefox` [https://polkadot.js.org/extension/](https://polkadot.js.org/extension/)\\n\\nDespués de instalar la extensión, cree una nueva cuenta.\\n![screen1](../images/build-iot-dapps/screen1.png)\\n\\n> El primer paso esta completado.\\n\\n## Desarrollo Dapp\\n\\n### Paso 1\\n\\n> Escribiremos la dApp usando el marco vue.js, aunque puede usar lo que uno quiera o pueda.\\n\\nComencemos a desarrollar la dApp creando una aplicación de inicio con vue.js Y aquí puedes hacerlo de dos maneras.\\n\\nCamino 1:\\n\\nUsando la utilidad de consola `Vue cli`.\\nPara hacer esto, debe [instalarlo] (https://cli.vuejs.org/guide/installation.html)\\nAlso we will need `yarn`. Install it from [here](https://yarnpkg.com)\\n\\nDespués de la instalación, puede ejecutar el comando en la terminal\\n\\n```sh\\nvue create mydapp\\n```\\n\\nResponda algunas preguntas del asistente de configuración. Usaremos la versión Vue 2, por lo que mantenemos la versión predeterminada `Default ([Vue 2] babel, eslint)`.\\n\\nCamino 2:\\n\\nClone el repositorio de git preparado con el ejemplo y cambie al paso 1\\n\\n```sh\\ngit clone https://github.com/airalab/example-robonomics-dapp.git mydapp\\ncd mydapp\\ngit checkout step-1\\n```\\n\\nComo resultado, obtendremos un directorio con la aplicación de inicio instalada, que ya se puede iniciar y abrir en el navegador.\\n\\n```sh\\nyarn\\nyarn serve\\n```\\n\\n### Paso 2. Comienzo con polkadot.js\\n\\n#### Instalacion de Dependencias\\n\\nPara conectar la dApp a Robonomics, existe la biblioteca `@polkadot/api`. Y para la interacción de dApp con una extensión con claves, tenemos la librería `@polkadot/extension-dapp`. Necesitamos instalarlos en nuestra aplicación.\\nSe pueden encontrar más detalles sobre el uso de esta biblioteca en la documentación https://polkadot.js.org/docs/.\\n\\nCamino 1:\\n\\n```sh\\nyarn add @polkadot/api @polkadot/extension-dapp\\n```\\n\\nTambién debe agregar el archivo `vue.config.js` para admitir la extensión `mjs`.\\n\\n`vue.config.js`\\n```js\\nmodule.exports = {\\n  publicPath: \\\"\\\",\\n  configureWebpack: {\\n    resolve: {\\n      extensions: [\\\"*\\\", \\\".mjs\\\", \\\".js\\\", \\\".vue\\\", \\\".json\\\", \\\".gql\\\", \\\".graphql\\\"]\\n    },\\n    module: {\\n      rules: [\\n        {\\n          test: /\\\\.mjs$/,\\n          include: /node_modules/,\\n          type: \\\"javascript/auto\\\"\\n        }\\n      ]\\n    }\\n  }\\n};\\n```\\n\\n#### Conectarse a Robonomics\\n\\nPrimero, creemos un archivo de configuración con los parámetros para conectarse al nodo de Robonomics. En el repositorio de demostración, hay un ejemplo de este archivo `config.template.json`.\\n\\n`src/config.json`\\n```json\\n{\\n  \\\"endpoint\\\": \\\"ws://localhost:9944\\\",\\n  \\\"types\\\": {\\n    \\\"Record\\\": \\\"Vec<u8>\\\",\\n    \\\"Parameter\\\": \\\"Bool\\\",\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\"\\n  }\\n}\\n```\\n\\nEn este archivo, indicamos el nodo al que nos vamos a conectar y los tipos personalizados.\\n\\nAhora necesitamos escribir un script para conectarnos a nuestro nodo en ejecución.\\n\\n`src/utils/api.js`\\n```js\\nimport { ApiPromise, WsProvider } from \\\"@polkadot/api\\\";\\nimport config from \\\"../config.json\\\";\\n\\nlet api;\\nexport async function initApi() {\\n  const provider = new WsProvider(config.endpoint);\\n  api = await ApiPromise.create({\\n    provider,\\n    types: config.types\\n  });\\n  return api;\\n}\\n\\nexport function getApi() {\\n  return api;\\n}\\n```\\n\\nPara que podamos firmar transacciones con la clave de la extensión, agreguemos dos funciones para conectarse a la extensión y la función para inicializar la cuenta.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport {\\n  web3Accounts,\\n  web3Enable,\\n  web3FromAddress\\n} from \\\"@polkadot/extension-dapp\\\";\\n\\nasync function getExtension() {\\n  const extensions = await web3Enable(\\\"demo\\\");\\n  if (extensions.length === 0) throw new Error(\\\"no extension\\\");\\n  return extensions[0];\\n}\\n\\nexport async function initAccount(index = 0) {\\n  const timeout = new Promise(resolve => {\\n    setTimeout(resolve, 300);\\n  });\\n  await timeout;\\n  await getExtension();\\n  const accounts = await web3Accounts();\\n  if (accounts.length > 0) {\\n    const injector = await web3FromAddress(accounts[index].address);\\n    api.setSigner(injector.signer);\\n    return accounts[index].address;\\n  }\\n  throw new Error(\\\"no accounts\\\");\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nNuestra cuenta tendrá un saldo de cero, mientras que necesitamos un poco de fondos. Entonces necesitamos crear otra función de faucet. Como lanzamos Robonomics con la `--dev` flag, tenemos una cuenta de `Alice` con un saldo grande, por lo que solicitemos fondos desde allí.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport { Keyring } from \\\"@polkadot/keyring\\\";\\n\\nexport function getBalance(account, cb) {\\n  api.query.system.account(account, ({ data: { free: currentFree } }) => {\\n    cb(currentFree);\\n  });\\n}\\n\\nexport const keyring = new Keyring({ type: \\\"sr25519\\\" });\\n\\nexport async function faucet(address) {\\n  keyring.setSS58Format(api.registry.chainSS58);\\n  const account = keyring.addFromUri(\\\"//Alice\\\");\\n  const tx = api.tx.balances.transfer(address, 1000000000000000);\\n  await tx.signAndSend(account);\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nLa versión completa del script https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/api.js\\n\\nEjecutar la aplicación\\n\\n```sh\\nyarn serve\\n```\\n\\nCamino 2:\\n\\nSi inicia la aplicación con la clonación del repositorio, entonces para completar estos pasos, será suficiente con cambiar al paso 2 e instalar el resto de las dependencias.\\n\\n```sh\\ngit checkout step-2\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n### Paso 3. Componente de Conexion de Vue\\n\\n#### Conectando\\n\\nYa hemos escrito un guión para conectarse. Ahora podemos usarlo en nuestra interfaz. Basta con llamar a la función `initApi` escrita en el componente raíz `App.vue`. Y mientras el usuario espera una conexión, le mostraremos un pequeño cargador, por ahora en forma de puntos suspensivos.\\n\\nCamino 1:\\n\\nPlantilla de componente y estilos base.\\n\\n`src/App.vue`\\n```js\\n<template>\\n  <div id=\\\"app\\\">\\n    <h1>Robonomics dApp</h1>\\n    <div v-if=\\\"load\\\">...</div>\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api\\\">\\n        connected\\n      </template>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style>\\n#app {\\n  font-family: Avenir, Helvetica, Arial, sans-serif;\\n  -webkit-font-smoothing: antialiased;\\n  -moz-osx-font-smoothing: grayscale;\\n  text-align: center;\\n  color: #2c3e50;\\n  margin-top: 60px;\\n}\\nbutton {\\n  font-size: 14px;\\n  padding: 5px 12px;\\n}\\nbutton:hover {\\n  cursor: pointer;\\n}\\ninput {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nselect {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nbutton:focus,\\ninput:focus {\\n  outline: none;\\n}\\n.error {\\n  color: rgb(151, 31, 31);\\n  font-weight: bold;\\n  text-align: center;\\n  margin: 10px 0;\\n}\\n</style>\\n```\\n\\nExiste el código del componente donde se llamará a la función `initApi`\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi } from \\\"./utils/api\\\";\\n\\nexport default {\\n  name: \\\"App\\\",\\n  data() {\\n    return {\\n      load: false,\\n      api: null,\\n      error: null\\n    };\\n  },\\n  created() {\\n    this.init();\\n  },\\n  methods: {\\n    async init() {\\n      try {\\n        this.load = true;\\n        this.api = await initApi();\\n        this.load = false;\\n      } catch (error) {\\n        this.error = error.message;\\n        this.load = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\n#### Cuenta con Saldo\\n\\nAhora podemos usar nuestra cuenta, recargar su saldo y mostrarlo en la interfaz.\\n\\nAgreguemos el marcado apropiado a la plantilla.\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n  ...OTHER_CODE...\\n\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api && account\\\">\\n        <p>\\n          Account: <b>{{ account }}</b> {{ balance }} |\\n          <button @click=\\\"faucet\\\">\\n            faucet\\n          </button>\\n        </p>\\n      </template>\\n    </template>\\n\\n  ...OTHER_CODE...\\n\\n</template>\\n```\\n\\nAgreguemos nuevos campos para la dirección y el saldo de la cuenta.\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\ndata() {\\n  return {\\n\\n    ...OTHER_CODE...\\n\\n    account: null,\\n    balance: 0,\\n\\n    ...OTHER_CODE...\\n\\n  };\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nNecesitamos agregar la inicialización de la cuenta a la función init y obtener su saldo\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi, initAccount, getBalance, faucet } from \\\"./utils/api\\\";\\nimport { formatBalance } from \\\"@polkadot/util\\\";\\n\\n...OTHER_CODE...\\n\\nasync init() {\\n\\n  ...OTHER_CODE...\\n\\n  this.api = await initApi();\\n  this.account = await initAccount();\\n  getBalance(this.account, balance => {\\n    this.balance = formatBalance(balance);\\n  });\\n\\n  ...OTHER_CODE...\\n\\n}\\n\\n...OTHER_CODE...\\n</script>\\n```\\n\\nQueda por agregar la función de reponer el saldo, al hacer clic en el botón\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\n  methods: {\\n    faucet() {\\n      faucet(this.account);\\n    },\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/step-3/src/App.vue\\n\\nEjecutar la aplicación\\n\\n```sh\\nyarn serve\\n```\\n\\nCamino 2:\\n\\nSi inicia la aplicación con la clonación del repositorio, para completar estos pasos, solo tendrá que pasar al paso 3.\\n\\n```sh\\ngit checkout step-3\\nyarn serve\\n```\\n\\nComo resultado, obtendremos la siguiente imagen en el navegador\\n\\n![screen2](../images/build-iot-dapps/screen2.png)\\n\\n### Paso 4. Datalog\\n\\nPara guardar y leer cualquier dato en la cadena, usamos el módulo de `datalog`.\\n\\nPara ver un ejemplo de cómo usar este módulo, creemos un componente `Datalog.vue`.\\n\\nCamino 1:\\n\\nEn el marcado, tendremos un botón de lectura de datos `read` con un bloque, donde mostraremos una lista en forma de fecha y el propio dato. Y habrá un formulario con una entrada de texto, en el que puede ingresar cualquier dato en forma de cadena y un botón `write`.\\n\\n`src/components/Datalog.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Datalog</h2>\\n    <button @click=\\\"read\\\">read</button> |\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" />\\n    <button @click=\\\"write\\\" :disabled=\\\"isWrite\\\">write</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n      <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        date: <b>{{ item[0] | dateFormat }}</b>\\n        <br />\\n        data: <b>{{ item[1] | dataFormat }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nCódigo de componente. Aquí el punto principal al enviar una transacción es llamar a la función, a la que transferimos datos y que firmamos con nuestra cuenta, a través de api `this.api.tx.datalog.record(stringToHex(this.data)).signAsync(this.account);`\\n\\n`src/components/Datalog.vue`\\n```js\\n<script>\\nimport { stringToHex, u8aToString } from \\\"@polkadot/util\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      data: \\\"data string\\\",\\n      log: null,\\n      isWrite: false,\\n      error: \\\"\\\"\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return u8aToString(v);\\n    }\\n  },\\n  methods: {\\n    async read() {\\n      this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n    },\\n    async write() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.datalog\\n          .record(stringToHex(this.data))\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.read();\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Datalog.vue\\n\\nPara cambiar entre componentes, agregue a `App.vue` la salida de nuestro componente.\\n\\n`src/App.vue`\\n```js\\n...OTHER_CODE...\\n\\n<template v-else-if=\\\"api && account\\\">\\n  <p>\\n    Account: <b>{{ account }}</b> {{ balance }} |\\n    <button @click=\\\"faucet\\\">faucet</button>\\n  </p>\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\n\\n...OTHER_CODE...\\n\\nexport default {\\n  name: \\\"App\\\",\\n  components: {\\n    Datalog\\n  },\\n  data() {\\n    return {\\n      tab: \\\"datalog\\\"\\n\\n...OTHER_CODE...\\n</script>\\n\\n<style>\\n...OTHER_CODE...\\n\\n.tabs button {\\n  font-size: 14px;\\n  padding: 10px 20px;\\n  font-weight: bold;\\n  background: #ececec;\\n  border: 1px solid #aaa;\\n}\\n.tabs button:hover {\\n  background: #bfbfbf;\\n}\\n.tabs button:last-child {\\n  border-left: none;\\n}\\n.tabs button.active {\\n  background: #ced5e2;\\n}\\n</style>\\n```\\n\\nEjecutar la aplicación\\n\\n```sh\\nyarn serve\\n```\\n\\nCamino 2:\\n\\nSi inicia la aplicación con la clonación del repositorio, para completar estos pasos, solo tendrá que pasar al paso 4.\\n\\n```sh\\ngit checkout step-4\\nyarn serve\\n```\\n\\nComo resultado, obtendremos la siguiente imagen en el navegador:\\n\\n![screen3](../images/build-iot-dapps/screen3.png)\\n\\n### Step 5. Lanzamiento\\n\\nEsta función se utiliza para iniciar y detener el robot. Para demostrar cómo usar este módulo, escribamos el componente `Launch.vue`.\\n\\nCamino 1:\\n\\nEn la plantilla del componente, tendremos un formulario donde se puede especificar la dirección del robot, el clicker ON / OFF y el botón para enviar.\\n\\n`src/components/Launch.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Launch</h2>\\n    <input v-model=\\\"robot\\\" :disabled=\\\"isWrite\\\" placeholder=\\\"Robot address\\\" />\\n    <select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n      <option value=\\\"ON\\\">ON</option>\\n      <option value=\\\"OFF\\\">OFF</option>\\n    </select>\\n    <button @click=\\\"launch\\\" :disabled=\\\"isWrite\\\">launch</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        sender: <b>{{ item.sender }}</b>\\n        <br />\\n        robot: <b>{{ item.robot }}</b>\\n        <br />\\n        parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nEl código se parece al componente `Datalog.vue`. La diferencia está solo en la lectura. El robot recibirá el comando a través de eventos.\\n\\n`src/components/Launch.vue`\\n```js\\n<script>\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      robot: this.account,\\n      parameter: \\\"ON\\\",\\n      log: [],\\n      isWrite: false,\\n      error: \\\"\\\",\\n      unsubscribe: null\\n    };\\n  },\\n  async created() {\\n    this.unsubscribe = await this.api.query.system.events(events => {\\n      events.forEach(record => {\\n        const { event } = record;\\n        if (event.section === \\\"launch\\\" && event.method === \\\"NewLaunch\\\") {\\n          const sender = event.data[0].toString();\\n          const robot = event.data[1].toString();\\n          const parameter = event.data[2].toHuman();\\n          this.log.push({\\n            sender,\\n            robot,\\n            parameter\\n          });\\n        }\\n      });\\n    });\\n  },\\n  destroyed() {\\n    if (this.unsubscribe) {\\n      this.unsubscribe();\\n    }\\n  },\\n  methods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Launch.vue\\n\\nPara la visualización, agregue un nuevo componente a `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nCamino 2:\\n\\nSi inicia la aplicación con la clonación del repositorio, para completar estos pasos, solo tendrá que pasar al paso 5.\\n\\n```sh\\ngit checkout step-5\\nyarn serve\\n```\\n\\nComo resultado, obtendremos la siguiente imagen en el navegador\\n\\n![screen4](../images/build-iot-dapps/screen4.png)\\n\\n### Paso 6. Demo\\n\\nEn esta demostración, tendremos un automóvil que se puede iniciar y detener a través de la dApp. El automóvil recoge un tronco durante el viaje y, después de detenerse, lo guarda en la cadena. Aquí usaremos ambos módulos, que probamos por separado, en conjunto.\\n\\nPara emular el comportamiento de un robot (automóvil), escribiremos una clase Robot. Usaremos la clave `Alice` como una cuenta para este robot. La clase `Robot` observará que los eventos `NewLaunch` se enciendan y apaguen. Después de encenderse, comienza a recopilar datos en el registro, en términos de datos, será solo una marca de tiempo. Y después del apagado, guarda este registro en el módulo `datalog`.\\n\\nCamino 1:\\n\\nCree el archivo `src/utils/robot.js`. El código completo del archivo https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/robot.js\\n\\nPara la visualización, crearemos un componente `Demo.vue`, donde tendremos un botón de inicio, una animación de automóvil y una salida de registro.\\n\\n`src/components/Demo.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Demo</h2>\\n    <template v-if=\\\"robot\\\">\\n      <h3>Robot: {{ robot.address }}</h3>\\n      <p v-if=\\\"robot.state\\\">Driver: {{ robot.driver }}</p>\\n      <button @click=\\\"run\\\" :disabled=\\\"isWrite\\\">\\n        <template v-if=\\\"!robot.state\\\">run</template>\\n        <template v-else>stop</template>\\n      </button>\\n      <div class=\\\"road\\\">\\n        <div\\n          class=\\\"robot\\\"\\n          :class=\\\"[robot.state ? 'robot-play' : 'robot-stop']\\\"\\n        ></div>\\n      </div>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n        <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n          <b>{{ item[0] | dateFormat }}</b>\\n          <pre>{{ item[1] | dataFormat }}</pre>\\n        </div>\\n      </div>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n  height: 500px;\\n  overflow-y: auto;\\n}\\n.log .row {\\n  margin: 10px;\\n  border-bottom: 1px solid #eee;\\n}\\n.road {\\n  width: 1000px;\\n  margin: 20px auto;\\n  background-color: #eee;\\n  padding: 20px 0;\\n  border: 5px solid #a5a5a5;\\n  border-left: 0;\\n  border-right: 0;\\n  position: relative;\\n}\\n.road::before {\\n  content: \\\" \\\";\\n  width: 1000px;\\n  border-top: 5px dashed #a5a5a5;\\n  position: absolute;\\n  top: 50%;\\n  left: 0;\\n}\\n@keyframes move {\\n  from {\\n    transform: translateX(0);\\n  }\\n  to {\\n    transform: translateX(100%);\\n  }\\n}\\n.robot {\\n  height: 100px;\\n  width: 100px;\\n  color: #fff;\\n  font-weight: bold;\\n  font-style: 14px;\\n  animation: move 30s linear infinite;\\n  border-radius: 0 10px 10px 0;\\n  background: url(\\\"../images/build-iot-dapps/car.png\\\") no-repeat 0 0;\\n  background-size: cover;\\n}\\n.robot-play {\\n  animation-play-state: running;\\n}\\n.robot-stop {\\n  animation-play-state: paused;\\n}\\n</style>\\n```\\n\\nCódigo de componente. Aquí necesitamos crear una instancia de la clase Robot y una función de inicio y detención.\\n\\n`src/components/Demo.vue`\\n```js\\n...OTHER_CODE...\\n\\n<script>\\nimport { u8aToString } from \\\"@polkadot/util\\\";\\nimport Robot from \\\"../utils/robot\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      isWrite: false,\\n      error: \\\"\\\",\\n      robot: null,\\n      log: []\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return JSON.parse(u8aToString(v));\\n    }\\n  },\\n  async created() {\\n    this.robot = new Robot(\\\"//Alice\\\", this.api);\\n    await this.robot.subscribeLog(r => {\\n      this.log = r.reverse().map(item => {\\n        return [item[0], item[1]];\\n      });\\n    });\\n  },\\n  destroyed() {\\n    this.robot.destroy();\\n  },\\n  methods: {\\n    async run() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot.account.address, !this.robot.state)\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Demo.vue\\n\\nAgreguemos otra imagen de nuestro automóvil a `src/images/build-iot-dapps/car.png`and `src/assets/car.png`. Ejemplo https://github.com/airalab/example-robonomics-dapp/blob/master/src/assets/car.png\\n\\nPara la visualización, agregue un nuevo componente a `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n      <button @click=\\\"tab = 'demo'\\\" :class=\\\"{ active: tab === 'demo' }\\\">\\n        demo\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\nimport Demo from \\\"./components/Demo\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch,\\n  Demo\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nEjecutar la aplicación\\n\\n```sh\\nyarn serve\\n```\\n\\nCamino 2:\\n\\nSi inicia la aplicación con la clonación del repositorio, para completar estos pasos, solo tendrá que pasar al paso 6.\\n\\n```sh\\ngit checkout step-6\\nyarn serve\\n```\\n\\nComo resultado, obtendremos la siguiente imagen en el navegador\\n\\n![screen5](../images/build-iot-dapps/screen5.png)\\n\\nCon esto concluye nuestra lección.\\n\\nGracias!\\n\"}},{\"node\":{\"id\":\"7f2f306ea9fed4dc72ccdc42d44842b2\",\"title\":\"Connect Vacuum Cleaner\",\"path\":\"/docs/es/vacuum-connect/\",\"content\":\"\\n## Connect to Home Assistant\\n\\nYou need your vacuum to be connected to Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your vacuum (it must be in connecting mode via a long press of the power button) and follow instructions in the app. For more details look at the user manual of your vacuum.\\n\\nOpen Home Assistant web page with this address:\\n```\\nhttp://<raspberry_address>:8123\\n```\\n\\nGo to `Integrations` tab, press `Add integration` and choose `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Vacuum (Robot vacuum in this example):\\n\\n![vacuum](../images/home-assistant/vacuum_int.png)\\n\\nAfter that you can connect your device to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"93ed43cffb868a560f0d3b1c80f3dc76\",\"title\":\"Troubleshooting\",\"path\":\"/docs/es/troubleshooting/\",\"content\":\"\\n## Can't create HRMP channel\\n\\nIt's not possible to create HRMP channel.\\n#### Solution\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n\\\"Address\\\": \\\"MultiAddress\\\",\\n\\\"LookupSource\\\": \\\"MultiAddress\\\",\\n\\\"AccountInfo\\\": \\\"AccountInfoWithRefCount\\\"\\n}\\n```\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n## Couldn't send XCM call with datalogXcm\\n If you try to send message between parachains and get error like this:\\n\\n![error_4lesson][im1]\\n\\n#### Solution\\n\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\n![XCM][im2]\\n\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n\\n\\n [im1]: <../images/troubleshooting/lesson4_error.jpg>\\n [im2]: <../images/troubleshooting/XCM.jpg>\\n\"}},{\"node\":{\"id\":\"93ef003a14a8d47c9a576a8a98c5e18e\",\"title\":\"Cómo participar en la traducción Wiki\",\"path\":\"/docs/es/translate-wiki/\",\"content\":\"\\nTodos pueden contribuir a Robonomics. Si quieres contribuir a la traducción de la documentación, estás en el camino correcto: este artículo te dirá cómo hacerlo.\\n\\n## Editando un articulo\\n\\nSi ya se agregó al sitio la compatibilidad con su idioma, siga estos pasos:\\n\\n1. Haga clic en el botón \\\"Editar esta página\\\" en el artículo que le gustaría traducir. Cada artículo está duplicado en un idioma admitido, incluso si aún no se ha traducido del inglés.\\n2. Edite respetando el marcado existente. Puedes leer el artículo [Cómo editar WIKI](/docs/edit-wiki)\\n3. Envíe [Solicitud de Extracción](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) con los cambios que ha realizado.\\n\\n## Agregar un nuevo idioma\\n\\nSi aún no se ha agregado el idioma al que le gustaría traducir el artículo, solicítelo al equipo raíz de Robonomics al [crear problema](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) en GitHub.\\n\\nCuando agreguemos soporte para el idioma solicitado al sitio, cerraremos el Issue, comentando si es necesario. Se le notificará en consecuencia. Esto significa que puede traducir páginas (ya estarán duplicadas en inglés en una carpeta como `/docs/locale`)\\n\\n## Notas\\n* Si ve una forma de mejorar una traducción existente de un artículo, también puede usar el PR o Issue en GitHub para solicitar cambios\\n* Si realiza una contribución significativa a la traducción, puede participar en el programa de recompensas.\\n\"}},{\"node\":{\"id\":\"9176ef46945cd00bc47845817119f6c6\",\"title\":\"How the technical committee is fast-tracking the democracy proposals\",\"path\":\"/docs/es/technical-committee-fast-track/\",\"content\":\"\\nNote: The screenshots contained in this article were taken using v1.9.0 of Robonomics node implementation, launched in **dev** mode.\\n\\nThe Robonomics Technical Committee can use the **fast-track** function to speed up the proposals enacting in the Democracy module.\\n\\nIf you want to learn more about how Polkadot ecosystem Governance works, then we strongly recommend reading [this article](https://polkadot.network/blog/polkadot-governance/) on the Polkadot blog.\\n\\nThere are six members who make up the Technical Committee for the Robonomics parachain. For our example, let's create the same setup in our dev mode environment:\\n![Techcomm membership](../images/technical-committee-fast-track/techcomm_membership.png)\\n\\nBriefly, the process of fast-tracking a proposal involves a few steps:\\n1. Creating the proposal preimage\\n2. Creating the proposal using the created preimage hash\\n3. Technical committee votes on the created proposal\\n4. Initiating proposal fast-tracking \\n5. Technical committee votes regarding fast-tracking the proposal\\n6. Voting on enacted proposal in the Democracy pallet\\n\\nFor example, let's set the free balance for the account *4EnEc9ZD1jpA1H3HpVzr1v6SGGYGrue2k9Ny5KzFHhti5xQv* to 10 XRT\\n\\n## 1. Creating the proposal preimage\\nOpen the **Governance -> Democracy** page and click the **Submit preimage** button, and then input the required parameters:\\n![Creating preimage](../images/technical-committee-fast-track/creating_preimage.png)\\n\\nAfter all fields are filled, then we need to save generated preimage hash (*0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b* in this example). As we will need it in the next step.\\n\\nAfter saving the preimage hash we can click the **Submit preimage** button in this window and sign the transaction:\\n![Sign submitting preimage](../images/technical-committee-fast-track/sign_submitting_preimage.png)\\n\\n\\n## 2. Creating proposal using created preimage hash\\nOpen the **Governance -> Tech. comm.** page and go to the **Proposals** tab:\\n![Techcomm proposals interface](../images/technical-committee-fast-track/techcomm_proposals_interface.png)\\n\\nThen click **\\\"Submit proposal\\\"** button and create *democracy.externalProposeMajority(0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b)* using your technical committee account and the preimage hash from earlier:\\n![Create techcomm proposal 1](../images/technical-committee-fast-track/create_techcomm_proposal_1.png)\\n\\nAfter signing transaction, the proposal will appear on this page:\\n![Created techcomm proposal 1](../images/technical-committee-fast-track/created_techcomm_proposal_1.png)\\n\\n## 3. Technical committee voting for created proposal\\nOn this step the majority of the technical committee members need to vote **Aye** in this poll. For example:\\n![First vote result](../images/technical-committee-fast-track/first_vote_result.png)\\n\\nThen we can decide to close this vote/poll using the **Close** button. After this action the proposal will appear on the **Democracy** page on the **external** table. You may wonder how can you see the **Fast track** button. This button appears and is active ONLY if we used the **democracy.externalProposeMajority** function:\\n![Created democracy proposal](../images/technical-committee-fast-track/created_democracy_proposal.png)\\n\\n\\n## 4. Initiating proposal fast-tracking\\nGo to the **Governance -> Democracy** page and click on the **Fast track** button. In this newly opened window set the required parameters and click **Fast track**.\\n![Fast track interface](../images/technical-committee-fast-track/fast_track_interface.png)\\n\\nAfter this, the fast-track proposal should now appear on the Technical Committee proposals page:\\n![Techcomm fast-track proposal](../images/technical-committee-fast-track/techcomm_fasttrack_proposal.png)\\n\\n\\n## 5. Technical committee voting for fast-track the proposal\\nNow the technical committee need to vote unanimously for fast-tracking the earlier created proposal. It means that all six members need to vote **Aye**:\\n![Fast-track vote result](../images/technical-committee-fast-track/fasttrack_vote_result.png)\\n\\nAfter this anyone can **Close** this voting, and the proposal will be enacted and moved from **external** table to active **referenda**:\\n![Democracy enacted proposal](../images/technical-committee-fast-track/democracy_enacted_proposal.png)\\n\\n\\n## 6. Voting on enacted proposal in Democracy\\nNow at least one account needs to vote **Aye** on the referenda:\\n![Voting for enacted proposal](../images/technical-committee-fast-track/voting_for_enacted_proposal.png)\\n\\nAs a result we'll get the active referenda with one positive vote on it:\\n![Positive voted referenda](../images/technical-committee-fast-track/positive_voted_referenda.png)\\n\\nAfter the voting period ends, this democracy proposal will be executed. In current example this will be happen in block #3351. Let's wait for this block and check it:\\n![Result](../images/technical-committee-fast-track/result.png)\\n\"}},{\"node\":{\"id\":\"2281fdb745d7e29a8823156c6dfaff33\",\"title\":\"How to Send Launch with Subscription\",\"path\":\"/docs/es/subscription-launch/\",\"content\":\"\\nIf your address is in devices of any subscription you can send extrinsics with no fee. Lets try to send `launch`.\\n\\nGo to `Developer/Extrinsics`, choose your account (`MAIN` in the picture) and `rws -> call`. Then in `subscriptionID` field write the subscription's owner address (`SUBSCRIPTION OWNER` in the picture) and in the next field choose `launch -> launch`. In the `robot` field write the address you want to send `launch` transaction to(`LIGHTBULB (EXTENTION)` in the picture) and choose the parameter `Yes` or `No`. Then submit transaction:\\n\\n![launch](../images/dev-node/launch.png)\\n\\n\\nNow go to `Network/Explorer` and in the `Recent Events` you will see two events `rws.NewCall` and `launch.NewLaunch`:\\n\\n![events](../images/dev-node/events.png)\"}},{\"node\":{\"id\":\"4d5335eb2de5563365cf754a3597a9be\",\"title\":\"Try It Out\",\"path\":\"/docs/es/spot-try-it-out/\",\"content\":\"\\nWith this tutorial you will be able to see in simulation what real Spot did.\\n\\n## Requirements\\n\\n* ROS melodic desktop (installation instructions [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n\\n## Install package\\n\\nCreate workspace and clone packages:\\n```bash\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/src\\ngit clone https://github.com/clearpathrobotics/spot_ros.git\\ngit clone https://github.com/ros/geometry2 --branch 0.6.5\\n```\\nOpen the `view_model.launch` file:\\n```bash\\nnano ~/catkin_ws/src/spot_ros/spot_viz/launch/view_model.launch\\n```\\n\\nAnd set `use_sim_time` parameter to `true`, file must look like this:\\n```xml\\n<launch>\\n  <param name=\\\"/use_sim_time\\\" value=\\\"true\\\"/>\\n  <include file=\\\"$(find spot_description)/launch/description.launch\\\"/>\\n\\n  <node name=\\\"joint_state_publisher_gui\\\" pkg=\\\"joint_state_publisher_gui\\\" type=\\\"joint_state_publisher_gui\\\" />\\n\\n  <node name=\\\"rviz\\\" pkg=\\\"rviz\\\" type=\\\"rviz\\\" args=\\\"-d $(find spot_viz)/rviz/model.rviz\\\" />\\n</launch>\\n```\\n\\nThen install dependencies:\\n```bash\\ncd ~/catkin_ws/\\nrosdep install --from-paths src --ignore-src -y\\ncatkin_make\\n```\\n\\n## Run\\n\\nGet example rosbag file:\\n```bash\\nwget -O spot_rosbag.bag https://gateway.ipfs.io/ipfs/QmTDrfMy7Zs7uDLN3KPBC1UYqXNMXBKEwX7ggVmJKAm7Ef\\n```\\n\\nRun rviz with the Spot model:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_model.launch\\n``` \\nThen in a new terminal:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_robot.launch\\n``` \\n![spot_viz](../images/spot/spot.jpg)\\n\\n\\nPlay rosbag file and you will see the robot move:\\n```bash\\nrosbag play spot_rosbag.bag\\n```\\n![spot_viz](../images/spot/spot2.jpg)\"}},{\"node\":{\"id\":\"15b1c0dd49df2c0a7741ed0d62bc83f0\",\"title\":\"Troubleshooting\",\"path\":\"/docs/es/spot-troubleshooting/\",\"content\":\"\\n### Admin socket already exists \\n\\nIf you can't run yggdrasil with this error:\\n```bash\\nAdmin socket /var/run/yggdrasil.sock already exists and is in use by another process\\n```\\nTry to remove file yggdrasil.sock and run it again:\\n```bash\\nsudo rm /var/run/yggdrasil.sock\\n```\\n\\n### Can't get lease\\n\\nIf you can't get lease with this error:\\n```python\\nGeneric exception during check-in:\\nNo lease for resource \\\"body\\\"\\n    (resuming check-in)\\n```\\nOr this error:\\n```python\\nGeneric exception during check-in:\\nbosdyn.api.RetainLeaseResponse (LeaseUseError): \\n    (resuming check-in)\\n```\\n\\nYou need to acquire lease (if you have already done it, try again):\\n```python\\nlease = lease_client.acquire()\\n```\\n\"}},{\"node\":{\"id\":\"7fd40182d1658aac682a27e2fad044aa\",\"title\":\"Lesson 5. Robot service. Camera calibration and \\\"Spot check\\\" procedure\",\"path\":\"/docs/es/spot-lesson5/\",\"content\":\"\\nIn this lesson you will learn what should you do if you just got the robot: the first run and network setup. Also you will learn how to run the calibration process that should be run monthly.\\n\\n## The challenge\\n\\nCreate and execute Python script implements behaviors described.\\n\\n1. Run \\\"spot check\\\" and save the result of the calibration in a `/home/student/result` directory as a text file.\\n2. Run camera calibration procedure.\\n\\n## Theory\\n\\n### First Run\\n\\nLook at [Startup Procedure](https://support.bostondynamics.com/s/article/Startup-Procedure) page in Documentation.\\n\\n### Networking\\n\\nSpot offers a variety of networking options to support a diverse set of applications and environments. Options include:\\n\\n* Spot as a connected peer. Physicall connection to Spot.\\n\\n* Spot as a WiFi access point. \\n\\n* Spot as a WiFi client. Spot can join an existing WiFi network, and applications can also join the same WiFi network to talk to Spot.\\n\\nFor more information look at [Networking page](https://dev.bostondynamics.com/docs/concepts/networking).\\n\\nSpot Core is connected to the Spot via payload port. Spot Core can be connected to the Internet with Wi-Fi dongle. The setup instructions you can find at [Spot Core Cockpit](https://dev.bostondynamics.com/docs/payload/spot_core_cockpit.html?highlight=spot%20check) page.\\n\\n### Calibration\\n\\nSpot Check is a full calibration of the robot. Also you can run the camera calibration \\n\\n* [run_spot_check](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L164) runs full spot check routine. The robot should be sitting on flat ground when this routine is started. This routine calibrates robot joints and checks camera health.\\n\\n* [run_camera_calibration](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L204). Run full camera calibration routine for robot. This function blocks until calibration has completed. This function should be called once the robot is powered on and standing with his back to the calibration stand at a distance of 1 meter. Calibation process takes about 20 minutes.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"24b372f9b4825be5eac5cc2f58050e5a\",\"title\":\"Lesson 4. GraphNav service. Mapping and navigating on the map\",\"path\":\"/docs/es/spot-lesson4/\",\"content\":\"\\nIn the fourth lesson you will learn how to record and play autonomous missions with GraphNav service.\\n\\n## The challenge\\n\\nThis lesson you can solve the challenge without writing your own Python script.\\n\\n1. Record a map avioding obstacles. You can use WASD remote control tool. Save your mission in `/home/student/result`.\\n2. Move Spot through recorded waypoints. You can use GraphNav service command line tool.\\n\\n## Theory\\n\\nThe Spot SDK includes APIs, client libraries, and examples that support the development of autonomous navigation behaviors for the Spot robot. Collectively, this service is referred to as GraphNav. Maps are recorded and saved and later can be replayed with any robot in your fleet. During the map recording process, you can assign actions and API callbacks to waypoints along the map route.\\n\\nRead [GraphNav Tech Summary](https://dev.bostondynamics.com/docs/concepts/autonomy/graphnav_tech_summary) to learn how it works. [Initialisation](https://dev.bostondynamics.com/docs/concepts/autonomy/initialization) is also important part, it will be usefull in this lesson.\\n\\n> You can view recorded maps with [View Map](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_view_map) example. For that you need to copy the map to your computer:\\n> ```bash\\n> scp -r student@strelka.ygg.merklebot.com:<path_to_the_map_on_spot> <path_to_the_map_to_download>\\n> ```\\n> Also you need [install spot packages](https://github.com/boston-dynamics/spot-sdk/blob/master/docs/python/quickstart.md#install-spot-python-packages).\\n\\nStudy [recording and playing missions](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_command_line) examples in order to use it to record the map and playback the mission recorded.\\nUse [wasd](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/wasd) example to move robot while recording the map.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\\nYou can run remote control tool from examples directory.\\n\\n```console\\ncd ~/spot-sdk/python/examples/wasd\\npython3 wasd.py --username <SPOT_AUTH_USERNAME> --password <SPOT_AUTH_PASSWORD> <SPOT_ADDRESS>\\n```\\n\\nGraphNav command line tool is located at `~/spot-sdk/python/examples/graph_nav_command_line`.\\n\"}},{\"node\":{\"id\":\"b1597f1d9f685f914115c1001a1a9e55\",\"title\":\"Lesson 3. Find and follow an object, navigate between them\",\"path\":\"/docs/es/spot-lesson3/\",\"content\":\"\\nIn the third lesson you will learn how to find World Objects and go to them.\\n\\n## The challenge\\n\\nYou start with Spot in the place with some fiducials (a mark on the object) around. Create and execute Python script detects at least two fiducials and moves Spot to each of them within 1 m.\\n\\n## Theory\\n\\nSpot has the World Object Service that provides a way to track and store objects detected in the world around Spot. A world object is considered a higher-level item in the scene that has some amount of semantic information associated with it. More information you can find in [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services#world-object) tab in Spot SDK documentation.\\n\\nUsing world object service you can find fiducials near the Spot. \\n\\n> Spot can find objects around faster if he stands.\\n\\nIn the task you will need find fiducials' coordinates and go to them. You already know how to move to the local coordinates from the [Lesson 2](/docs/en/spot-lesson2.md). The example of how to find a fiducial and it's coordinates is in [fiducial_follow example](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/examples/fiducial_follow/fiducial_follow.py).\\n\\nIn your script, firstly, you need to find fiducial object with World Object Service:\\n\\n```python\\nfiducial_objects = world_object_client.list_world_objects(\\n            object_type=[world_object_pb2.WORLD_OBJECT_APRILTAG]).world_objects\\n```\\n\\nThen get fiducial coordinates in a visual frame:\\n\\n```python\\nfiducial = fiducial_objects[0]\\nvision_tform_fiducial = get_a_tform_b(fiducial.transforms_snapshot, VISION_FRAME_NAME,fiducial.apriltag_properties.frame_name_fiducial.to_proto()\\n```\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"325e11a2b9015544e5265600550c2e54\",\"title\":\"Lesson 2. Remote controlled and programmed motion\",\"path\":\"/docs/es/spot-lesson2/\",\"content\":\"\\nIn the second lesson you will learn how to use Spot Command services and walk with Spot.\\n\\n## The challenge\\n\\nYou have a list of points with their local coordinates in the `/home/student/lessons` directory. Spot should go through these points. The origin of the local coordinates is in the place where Spot was turned on. On each point Spot should make one of the motions from the following list, then go to the next point. \\n\\nThe list of moves:\\n* To turn around himself\\n* To lie down in pose to change battery\\n* To nod\\n* To change the stance of robot's legs\\n* To go sideways to the next point\\n\\nCreate and execute a Python script that implements behavior described.\\n\\n> You can find Spot local coordinates with:\\n> ```python\\n> get_vision_tform_body(robot_state_client.get_robot_state().kinematic_state.transforms_snapshot)\\n> ```\\n\\n## Theory\\n\\nYou can control Spot with `Robot Command Service`. Firstly you need to build a command to supply it to the command service.\\nSpot SDK has a `RobotCommandBuilder` class for it.\\nFull list of methods and its descriprions you can find [here](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/bosdyn-client/src/bosdyn/client/robot_command.py#L593). \\n\\nIn this lesson you may need to use:\\n\\n* Stand Command\\n\\n```python\\ndef stand_command(params=None, body_height=0.0, \\n                footprint_R_body=geometry.EulerZXY())\\n```\\n\\n* Go to point\\n\\n```python\\ndef synchro_se2_trajectory_point_command(goal_x, goal_y, goal_heading,      \\n                                    frame_name, params=None,\\n                                    body_height=0.0,\\n                                    locomotion_hint=spot_command_pb2.HINT_AUTO,\\n                                    build_on_command=None)\\n```\\n\\nCheck usage example [here](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/frame_trajectory_command/frame_trajectory_command.py).\\n\\n* Velocity Command\\n\\n```python\\ndef synchro_velocity_command(v_x, v_y, v_rot, params=None, body_height=0.0,\\n                            locomotion_hint=spot_command_pb2.HINT_AUTO, \\n                            frame_name=BODY_FRAME_NAME)\\n```\\n\\n* Stance Command\\n\\n```python\\ndef stance_command(se2_frame_name, pos_fl_rt_frame, pos_fr_rt_frame, \\n                        pos_hl_rt_frame,\\n                        pos_hr_rt_frame, accuracy=0.05, \\n                        params=None, body_height=0.0,\\n                        footprint_R_body=geometry.EulerZXY(), \\n                        build_on_command=None)\\n```\\n\\nThe example of use is [here](https://github.com/boston-dynamics/spot-sdk/blob/91ed30607264e795699995d6d7834ba0c8a94d36/python/examples/stance/stance_in_place.py)\\n\\n* Pose to change battery\\n\\n```python\\ndef battery_change_pose_command(dir_hint=1)\\n```\\n\\nExample of building and running velocity command:\\n\\n```python\\nfrom bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder\\nimport time\\n\\ncommand_client = robot.ensure_client(RobotCommandClient.default_service_name)\\ncmd = RobotCommandBuilder.velocity_command(0.5, 0, 0.5)\\ncommand_client.robot_command(cmd, end_time_secs=time.time() + 2)\\n```\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"af94deccd611049313ed8496bc01c4b8\",\"title\":\"Lesson 1. Emergency stop, initialization, body position control\",\"path\":\"/docs/es/spot-lesson1/\",\"content\":\"\\nWelcome to the first lesson!\\n\\nDuring this lesson you will learn how to authorize yourself as a user, get motor power control and send basic commands to Spot.\\n\\nWatch our introductory video if you haven't seen it already:\\n\\nhttps://youtu.be/qdk7BjWJprc\\n\\n## The challenge\\n\\nCreate a Python script controls robot body position. Run your script on Spot to let it execute a sequence of motions:\\n\\n1. Stand-up,\\n2. Trace your initials with it's face (one letter, at least 3 points),\\n3. Sit-down.\\n\\n## Theory\\n\\nRead [Understanding Spot Programming](https://dev.bostondynamics.com/docs/python/understanding_spot_programming) page in Spot SDK documentation.\\nYou need to understand what is `E-Stop` and how make initialization in your Python script in order to to let the robot execute commands.\\n\\nYou can find more detailed information for this lesson in [Base Services](https://dev.bostondynamics.com/docs/concepts/base_services), [Geometry and Frames](https://dev.bostondynamics.com/docs/concepts/geometry_and_frames), [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services) and [E-Stop](https://dev.bostondynamics.com/docs/concepts/estop_service) sections of the Spot SDK documentation.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to SpotCORE by SSH from the terminal,\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Create a script can authenticate in Spot, acquire control (lease) and power on the robot.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file. Spot address is `192.168.50.3`.\\n\\n> In [Taking ownership of Spot (Leases)](https://dev.bostondynamics.com/docs/python/understanding_spot_programming#taking-ownership-of-spot-leases) section use `lease = lease_client.acquire()` before `lease_keep_alive = bosdyn.client.lease.LeaseKeepAlive(lease_client)`\\n\\n3. Try your script with stand-up and sit-down commands. Ensure robot moves as expected,\\n\\n> Make sure you run your script by Python 3 with `python3` command. Command `python` refers to an obsolete Python 2 interpreter.\\n\\n4. Add body position control to your script. Experiment with `bosdyn.geometry.EulerZXY` robot command argument builder in order to identify what yaw, roll and pitch parameters you need to set to solve the challenge. The range of Pitch, Yaw and Roll is from -0.5 to 0.5.\\n\"}},{\"node\":{\"id\":\"dd863a781242cdba90b2eae24f3d19fd\",\"title\":\"Lesson 0. Configure and test connection to Spot\",\"path\":\"/docs/es/spot-lesson0/\",\"content\":\"\\nLet's start establishing connection to the robot.\\nOur goal is to get answers from Spot to our [ping](https://en.wikipedia.org/wiki/Ping_(networking_utility)) signals.\\nWe use Yggdrasil Network to expose Spot to the internet, that means we will need to configure Yggdrasil Network support on your computer first.\\n\\n## 1. Yggdrasil Installation \\n\\nYggdrasil is an early-stage implementation of a fully end-to-end encrypted IPv6 network. Before startitng the lessons you need to install it on your computer.\\n\\n### For Linux: \\nInstallation instructions [here](https://yggdrasil-network.github.io/installation-linux-deb.html).\\n\\n### For MacOS: \\nDownload .pkg file from [here](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4.0-macos-amd64.pkg).\\n\\nLocate the downloaded file in Finder. Right-click it and click Open. Step through the installer as usual.\\n\\n### For Windows:\\nDownload .msi file for [x64 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x64.msi) or for [x32 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x86.msi) and run it with double click.\\n\\n## 2. Open configuration file\\n\\nYou need to add a list of peers (public nodes) to configuration file so that you will be able to connect to Spot. \\n\\n### For MacOS and Linux:\\nFor that, edit the `yggdrasil.conf` file with this command in a terminal:\\n\\n```bash\\nsudo nano /etc/yggdrasil.conf\\n```\\n\\n### For Windows:\\nRun `updateconfig.bat` in `C:/Program Files/Yggdrasil`. \\n\\nThen in `C:/ProgramData/Yggdrasil` open `yggdrasil.conf` with any text editor.\\n\\n> `ProgramData` is a hidden folder, so you need to show hidden data.\\n\\n## 3. Write peers\\n\\nIn the file that you opened find line `Peers:` (it is at the beginning of the file) add 5-6 peers geografically near to you (write them inside the brackets). You can find list of available peers [here](https://github.com/yggdrasil-network/public-peers) or add peers from example below. Example in yggdrasil.conf:\\n\\n```bash\\n  Peers:\\n  [\\n    tcp://213.188.199.150:10010\\n    tcp://213.188.210.9:10010\\n    tcp://[2a09:8280:1::3:312]:10010\\n    tcp://[2a09:8280:1::a:2e2]:10010\\n    tcp://46.151.26.194:60575\\n    tcp://ygg-ru.cofob.ru:18000\\n    tcp://ygg.tomasgl.ru:61933\\n    tls://185.22.60.71:8443\\n    tcp://51.15.118.10:62486\\n    tls://ygg.loskiq.dev:17314\\n    tls://longseason.1200bps.xyz:13122\\n  ]\\n  ```\\nCheck if the peers online in [Puplic Peers](https://publicpeers.neilalexander.dev/).\\n\\n## 4. Save and close configuration file\\n\\n### For Linux and MacOS:\\n\\nPress `Ctrl+x`, then press `y` to save changes and press `Enter`.\\n\\n### For Windows:\\n\\nSave and close file.\\n\\n## 5. Restart service\\n\\n### For Linux:\\n\\nThen restart Yggdrasil using this command:\\n\\n```bash\\nsystemctl restart yggdrasil\\n```\\n### For macOS:\\n\\nUnload the service and run Yggdrasil with changed config file:\\n\\n```bash\\nsudo launchctl unload /Library/LaunchDaemons/yggdrasil.plist\\nsudo yggdrasil -useconffile /etc/yggdrasil.conf\\n```\\n> You will need to do that before every lesson.\\n\\n### For Windows:\\n\\nPress win + r and type `services.msc`, find Yggdrasil service, open it and restart (press Stop and Start).\\n\\n![win-service](../images/spot/spot-windows.jpg)\\n\\n## 6. Check Connection\\n\\nCheck if Yggdrasil works well.\\n\\nFor that try to ping Spot address:\\n```bash\\nping strelka.ygg.khassanov.xyz\\n```\\n> To open terminal in Windows press `Win+R`, type `cmd` and press `Enter`.\\n\\n> On MacOS use `ping6` instead of `ping`.\\n\\nIf you can't ping Spot or you had any errors during the Yggdrasil setup look in [Troubleshooting page](/docs/spot-troubleshooting). If you can't find the solution there, please email spot@robonomics.network.\\n\\n## 7. Create ssh key\\n\\nYou will connect to Spot via ssh, so you need to create ssh keys which you will use in booking lessons.\\n\\nRun following command in the terminal:\\n```bash\\nssh-keygen -t rsa\\n```\\n> SSH Client is available by default only in Windows 10, so if you use older versions you need to install it. For example you can use [PuTTY](https://www.putty.org/).\\n\\nRemember the path to your key (by default it is `/home/<user>/.ssh/id_rsa.pub` or `C:\\\\Users\\\\<user>\\\\.ssh\\\\id_rsa.pub`).\\n\"}},{\"node\":{\"id\":\"039e07e5f321b5dd24e190311cea6eff\",\"title\":\"Setup SLS Gateway\",\"path\":\"/docs/es/sls-setup/\",\"content\":\"\\nYou can use [SLS Gateway from Robonomics](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01) instead of Xiaomi/Aqara gateways. It works only in your local network and don't send any data to external servers, so you can control all data about your home.\\n\\n1. Ensure that the switches on the back of the gateway are properly positioned. Switches 5 (RX Zigbee to ESP) and 6 (TX Zigbee to ESP) must be in the ON position, the others must be off. \\n\\n2. Connect the type C power cable. The indicator light in the center should turn green.\\n\\n3. The first time it starts up, the gateway will begin distributing Wi-Fi with the SSID 'zgw****' to set up the SLS gateway connection. Connect to this network. Keep in mind that the signal may be quite weak, so it is best to keep the SLS Gateway closer to your computer. \\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). Configure the SLS Gateway to connect to your Wi-Fi by entering the user / pass. After that the gateway's Wi-Fi will shut down. \\n\\n5. Find the local IP of the SLS gateway to access the web interface. You can use the command 'arp -a' or 'nmap'. The resulting link should look like this: 'http://192.168.xxx.xxx'.\\n\\n6. Go to Setting/Hardware and make sure that the settings look like this. Correct the settings if necessary and reboot the gateway:\\n\\n![sls-hardware](../images/home-assistant/sls-hardware.jpg)\\n\\n7. Configure automatically adding devices to Home Assistant. Go to `Zigbee/Config` then tick `Home Assistant MQTT Discovery` and `Clear States`:\\n\\n![sls-hass](../images/home-assistant/sls-hass.png)\\n\\n8. Connect your devices by going to Zigbee/Join. Press the Enable Join button to connect and put your sensors in pairing mode. \\n\\nAfter that connect it to Home Assistant with the following [guide](/docs/sls-gateway-connect)\"}},{\"node\":{\"id\":\"a09ba1932974ed77a45f5f86311e91ae\",\"title\":\"Connect SLS Gateway to Home Assistant\",\"path\":\"/docs/es/sls-gateway-connect/\",\"content\":\"\\n## MQTT Brocker\\n\\nFirst, you need to run MQTT brocker on your raspberry with Home Assistant. Connect to it under `ubuntu` login. Then install [Mosquitto Brocker](https://mosquitto.org/):\\n\\n```bash\\nsudo apt update -y && sudo apt install mosquitto mosquitto-clients -y\\n```\\nConfigure username (you can use any username you want) and password (you will be asked to enter the password after the command):\\n```bash\\nsudo mosquitto_passwd -c /etc/mosquitto/passwd <username>\\n```\\nThen edit configuration file:\\n```bash\\nsudo nano /etc/mosquitto/mosquitto.conf\\n```\\nAdd the following at the end of the file:\\n```\\nlistener 1883\\nallow_anonymous false\\npassword_file /etc/mosquitto/passwd\\n```\\n\\nThen restart the service:\\n\\n```bash\\nsudo systemctl restart mosquitto\\n```\\n\\nAnd check the brocker status:\\n```bash\\nsystemctl status mosquitto\\n```\\n\\n![mosquitto](../images/home-assistant/mosquitto.png)\\n\\n## MQTT Integration\\n\\nThen you need to add MQTT integration to Home Assistant. Open web interface then go to `Configuration/Integrations` page and press `Add Integration` button. Find MQTT:\\n\\n![mqtt](../images/home-assistant/mqtt.png)\\n\\nPress on it and set up your brocker with address (localhost), port (1883) and your username and password, then press `submit`:\\n\\n![mqtt1](../images/home-assistant/mqtt1.png)\\n\\nThen press on three dots on MQTT integration and choose `System Options`:\\n\\n![mqtt_options](../images/home-assistant/mqtt_conf.png)\\n\\nAnd check if automatically adding new devices is enabled:\\n\\n![mqtt_dev](../images/home-assistant/add_dev.png)\\n\\n## MQTT on SLS Gateway\\n\\nAlso you need to configure MQTT on SLS Gateway. On your SLS Gateway go to `Settings/Link` -> `MQTT Setup`:\\n\\n![sls-mqtt](../images/home-assistant/sls-mqtt.png)\\n\\nAnd add your brocker address (address of the raspberry with Home Assistant in local network) and port (1883). Also write the topic name (you can choose any). Don't forget to tick `Enable` and `Retain states`:\\n\\n![sls-mqtt1](../images/home-assistant/sls-mqtt1.png)\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\"}},{\"node\":{\"id\":\"2f527bf6f63710bf42f2e5bcf4cda5de\",\"title\":\"Introduction\",\"path\":\"/docs/es/sensors-network-introduction/\",\"content\":\"\\n## What is Sensors Robonomics Network?\\n\\nThe Sensors Robonomics Network is a civilian network of sensors to monitor air quality. Anyone can build their own sensor or use an off-the-shelf solution from the development team and set it up in their home. The sensors use open source software and component wiring diagrams. One of the main sensors used is the PM10 and PM2.5 fine particulate sensor.\\n\\n## What is PM10 and PM2.5?\\n\\nPM10 is a particle of a substance 10 microns or smaller, PM2.5 is a particle 2.5 microns in diameter or smaller. They are constantly floating in the air and do not settle due to their small size, for comparison, the thickness of a human hair is 100 microns. These particles can appear for a variety of reasons, including industrial processes involving the handling of bulk materials or the burning and processing of minerals. They are also emitted after forest fires and dust storms. In addition, they can come from conventional transport when burning fuel or from wear and tear on tires and pavement. Car tires are wiped out into fine crumbs and the wind blows them from the roads all over the city.\\n\\n## Why do we need to measure them?\\n\\nPM10 and PM2.5 are the most dangerous because their size allows them to penetrate the lungs, whereas larger particles tend to linger in the nose or throat. Larger PM10 particles irritate the airways, nose, throat, and eyes. Particles smaller than 2.5 microns can penetrate deep into the lungs and even enter the bloodstream. The effects of these particles on the human body can be devastating:\\n- poisoning by harmful substances entering the bloodstream\\n- allergic reactions\\n- bacterial and fungal infections\\n- cancer\\n- mucous membrane irritation\\n- exacerbation of respiratory symptoms\\n\\n## Why the Sensors Robonomics Network?\\n\\nIn Russia there are other public monitoring networks, such as [Breathe Moscow](https://breathe.moscow/), which are based on the German project [sensor.community](https://sensor.community/ru/). But they use the usual client-server architecture, which in this case is a drawback. Data from all sensors together with user requests go to one server, which cannot always handle such load. So there are situations when the map with data is not available at the most responsible moments. With Sensors Robonomics Network, sensors send data to several different servers, and any user can bring up the Sensors Connectivity server for their sensor and see it on the map. The map itself is not overloaded because it is a decentralized application (DApp) that works directly from your browser with the data that the servers send to the IPFS pub-sub channel.\\n\\n## Sources\\n\\nhttp://www.npi.gov.au/resource/particulate-matter-pm10-and-pm25\\n\\nhttps://habr.com/ru/company/tion/blog/396111/\"}},{\"node\":{\"id\":\"41adccb8bb18451d7c615630151cb762\",\"title\":\"Sensors Connectivity\",\"path\":\"/docs/es/sensors-connectivity-on-aira/\",\"content\":\"\\nThe Sensors Robonomics Network uses the sensors community module from Robonomics to receive and process data. This module allows any user to raise his own server to receive data from sensors and process it further. Now the developers have launched several such servers and any sensor can send data to them. Running several servers allows to avoid data loss in case of problems with one of them, because sensors from a non-working server will switch to a working one.\\n\\nSensors Connectivity schematic:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSensors Connectivity is a set of stations (station1, station2...), which receive various data, including data from sensors via http protocol. But also it can be sensors connected to the computer via USB or any other data source.\\n\\nData received from the stations are processed by Sensors Connectivity and passed to feeders (feeder1, feeder2...). Feeders send the processed data to the user. In our case the data is sent to the decentralized IPFS channel.\\n\\nMap [sensors.robonomics.network](https://sensors.robonomics.network/) is a decentralized application (DApp) running on your computer. It reads data from the IPFS channel and outputs them to the map. So there is no direct connection between the server collecting the data from the sensors and the map the user sees, the data transfer between them is done via IPFS pubsub, which reduces the load on the servers.\\n\\nIn addition, every once in a while, a file with data from the last time period is saved in IPFS, and the hash of that data is further written to the blockchain. Since IPFS is a content-addressable network, storing data in it guarantees that any change in the data will not go unnoticed, because the address of the desired file contains a hash of its content, which will change if any change in the data occurs. The blockchain is used to pass the hash on to the user, who can use it to retrieve the desired data from the IPFS (which is what happens when requesting to view the history on [sensors.robonomics.network](https://sensors.robonomics.network/)). Since the transaction made cannot be changed, we can be sure that it is the correct hash.\\n\\nThe source code for Sensors Connectivity is available at [link](https://github.com/airalab/sensors-connectivity). To see the data from your server on the map, you need to contact the development team at vm@multi-agent.io and send the ipfs id of your server. \\n\\n# Run your own Sensors Connectivity\\n\\n## Pre-requirements\\n\\nTo build a python package IPFS daemon should be installed. Assyming, you work with linux:\\n\\n```\\nwget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_linux-amd64.tar.gz\\ntar -xzf go-ipfs_v0.8.0_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh \\nipfs init\\n```\\nYou can get IPFS ID with the following command after running IPFS daemon (it is in the `ID` column):\\n\\n```console\\n$ ipfs id\\n{\\n\\t\\\"ID\\\": \\\"QmUZxw8jsRpSx5rWkTpJokPGKvWihTrt5rbRCFXzJ4eCAP\\\",\\n\\t\\\"PublicKey\\\": \\\"CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC/uMV3rLM/C+LOh2DGPo3chr+VM+vyYMKi...\\n    ...\\n```\\n\\n## Installation as PyPi package\\n\\n```\\npip3 install py-sr25519-bindings\\npip3 install sensors-connectivity\\n```\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config is set, you can run the service: (in another terminal)\\n\\n```\\nsensors_connectivity \\\"path/to/your/config/file\\\"\\n```\\n\\nYou will be able to see logs in your console and in `~/.logs`.\\n\\n## Build from source\\n### Requirements\\n\\nTo build a python package fron source [poetry](https://python-poetry.org/docs/#osx--linux--bashonwindows-install-instructions) should be also installed. Assyming, you work with linux:\\n\\n```\\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -\\n```\\n\\n### Get a Package And Installing dependencies\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npoetry install\\n```\\n\\n### Documentation\\n\\nTo prepare a sensor for the work with the package follow instructions on [Robonomics Wiki](/docs/connect-sensor-to-robonomics/).\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\nMake a copy of `default.json` and fill it using description from the article.\\n\\nYou also can set a logging file. The default file for logs is `logging.py`, which uses `console` and `file` handler by default. Pay attention for the `file` handler. The template is stored in `connectivity/config/logging_template.py`. You can cpecify the path (`filename`), where your logs will be stored in (do not forget to create this directory if it doesn't exist). Default path for logs is `~/.logs`. You can figure any other handlers from the [library](https://docs.python.org/3.8/library/logging.html).\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config and log files are setted, you can run the service: (in another terminal)\\n\\n```\\npoetry run sensors_connectivity \\\"path/to/your/config/file\\\"  \\n```\\n\\nIf your log file is setted with `console` handler, you will be able to see logs in your console.\\n\\n### Example of logs:\\n\\n```\\n2022-02-17 19:30:51,248 - INFO - Getting data from the stations...\\n2022-02-17 19:30:51,443 - INFO - airalab-http-v0.8.0: [[], [{MAC: c8e2650f254e, Uptime: 0:00:14.010502, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:30:51,443 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:07,517 - INFO - Frontier Datalog: Data sent to Robonomics datalog and included in block 0x04baf3d81c6d31ec6f3ca3e515b9a6920666ee17cbd66f57130eaa000bad2cd4\\n2022-02-17 19:31:07,519 - INFO - RobonomicsFeeder: {\\\"0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a\\\": {\\\"model\\\": 2, \\\"geo\\\": \\\"53.518475,49.397178000000004\\\", \\\"measurement\\\": {\\\"airtemp\\\": -8.0, \\\"windang\\\": 45.0, \\\"windspeed\\\": 0.13, \\\"windspeedmax\\\": 0.13, \\\"pm10\\\": \\\"\\\", \\\"pm25\\\": \\\"\\\", \\\"timestamp\\\": 1645113602.0}}}\\n2022-02-17 19:31:07,523 - INFO - Checking data base...\\n127.0.0.1 - - [17/Feb/2022 19:31:13] \\\"POST / HTTP/1.1\\\" 200 -\\n2022-02-17 19:31:21,248 - INFO - Getting data from the stations...\\n2022-02-17 19:31:21,429 - INFO - airalab-http-v0.8.0: [[{MAC: c8e2650f254e, Uptime: 0:00:43.818101, M: {Public: 133b761496539ab5d1140e94f644e2ef92c7ac32446dc782bfe1a768379a669a, geo: (1,200), measurements: {'pm10': 27.58, 'pm25': 15.02, 'temperature': 22.93, 'pressure': 758.0687068706872, 'humidity': 39.44, 'timestamp': 1645115473}}}], [{MAC: c8e2650f254e, Uptime: 0:00:43.996539, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:31:21,444 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:51,249 - INFO - Getting data from the stations...\\n```\\n\\n## Troubleshooting\\n\\n### Python.h: No such file or directory\\n\\nIf during running `poetry install` comand you get such error, you need to install the header files and static libraries for python dev. Use your package manager for installation. For example, for `apt` you need to run\\n```\\nsudo apt install python3-dev\\n```\\n> Note:\\npython3-dev does not cover all versions for python3. The service needs at least python3.8, for that you may need to specify the version `sudo apt install python3.8-dev`.\\n\\n[Here](https://stackoverflow.com/a/21530768) you can find examples for other package managers.\\n\\n### Python versions mismatch\\n\\nIf during running `poetry install` comand you get `SolverProblemError`, which says \\\"The current project's Python requirement (3.6.9) is not compatible with some of the required packages Python requirement:..\\\", even though you have older version of python (e.g. python3.8), you may need to specify the python version poetry is using:\\n\\n```\\npoetry env use python3.8\\n```\\n\\n\"}},{\"node\":{\"id\":\"2a844414b15f55d3852293921e77ba93\",\"title\":\"How to contribute\",\"path\":\"/docs/es/sensors-connectivity-contribution/\",\"content\":\"\\nIf you find any bugs or would like to propose an improvement, please, open a new issue in one of tre repositories, that you want to contribute.\\n\\n## Main Repositories\\n\\n- [sensors-connectivity](https://github.com/airalab/sensors-connectivity/issues) - Sensors Connectivity server\\n- [sensors-software](https://github.com/LoSk-p/sensors-software/issues) - firmware for the sensor\\n- [airrohr-firmware-flasher](https://github.com/LoSk-p/airrohr-firmware-flasher/issues) - application for microcontroller firmware\\n\"}},{\"node\":{\"id\":\"0dccc7288404a262bcaa2a12889e9c49\",\"title\":\"Securely connect cloud AI to the factory floor\",\"path\":\"/docs/es/securely-connect-cloud-ai-to-the-factory-floor/\",\"content\":\"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n![](../images/google-play-store.gif)\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n![](../images/Veracity_Protocol_Transaction.gif)\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n![](../images/Veracity_Protocol_Launch.gif)\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"}},{\"node\":{\"id\":\"534230a310f96f75684c8396bdb1dcd3\",\"title\":\"How to Run Robonomics Dev Node\",\"path\":\"/docs/es/run-dev-node/\",\"content\":\"\\nFor testing your applications on Robonomics you may want to need to run it in the dev mode.\\n\\nhttps://youtu.be/04GsVkZ7aVg\\n\\n## Run\\n\\n1. First, you need a binary file, download the archive with it from the latest [release](https://github.com/airalab/robonomics/releases).\\n\\n2. Unpack it and change permissions:\\n\\n```bash\\ntar xf robonomics-1.7.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n3. And run in the dev mode:\\n\\n```bash\\n./robonomics --dev\\n```\\nYou will see the following output:\\n\\n![robonomics](../images/dev-node/robonomics.png)\\n\\n## Get tokens\\n\\nNow you can connect to your local node through the [Polkadot Portal](https://polkadot.js.org/apps/#/explorer).\\n\\nChange the network to `Local Node` in the upper left corner and press `Switch`.\\n\\n![local_node](../images/dev-node/portal.png)\\n\\nThen go to `Accounts`:\\n\\n![accs](../images/dev-node/accs.png)\\n\\nYou can create a new account with the button `Add Account`.\\n\\n![add_acc](../images/dev-node/add_acc.png)\\n\\nDon't forget to save your seed phrase somewhere.\\n\\nAnd use one of existing accounts to send tokens to your new one. Choose for example Alice and press `Send`. Then choose your new account and write the amount of units you want to send and press `Make Transfer`:\\n\\n![send](../images/dev-node/send.png)\"}},{\"node\":{\"id\":\"cc02e211b76b653caba698803330658c\",\"title\":\"ROS-based Projects for Smart Spaces\",\"path\":\"/docs/es/ros-smart-projects/\",\"content\":\"\\nThroughout its 15 years of development, the Robot Operating System framework was integrated with dozens of [various robotic devices](https://robots.ros.org/), and there are even more packages with algorithms and tools developed by the community. Truth be told, there are now so many projects, and the chaoticness of the description style of their repositories grew so much that it is currently quite problematic to find projects dedicated to a specific subject topic. \\n\\nHere, you’ll find a modest list of ROS-based projects that are dedicated to robots and IoT-devices that are meant for use in a home or office environment. This subject matter is one of the pillars of the Robonomics platform. Our goal is to try and bring these projects on track with Robonomics, from both a technical integration point of view and the perspective of an interesting application of these devices in a robot economy. Feel free to use this list in your search for ideas and inspiration.\\n\\nYou can check out some examples of ROS-projects integrated with Robonomics in the [Playground Overview page](https://wiki.robonomics.network/docs/en/playground-overview/). New projects, including those described here, will be added to the Wiki with time.\\n\\nAs of right now (**April 2021**), Robonomics is oriented towards ROS **Melodic** and **Noetic** versions. Older versions can also work, but there may be additional integration work needed. In the future, support for ROS version 2 will be added.\\n\\nThe main resources to search for ROS repositories and packages can be accessed [here](https://index.ros.org/).\\n\\n## Simulation\\n\\nBefore shifting our attention solely to devices, it’s worth remembering that for a large quantity of ROS projects, there exists an option to test them in a simulation. The most popular tool for the 3D modeling of various robots under ROS is the [Gazebo](http://gazebosim.org/) simulator and its offshoot project, [Ignition](https://index.ros.org/r/ros_ign/). Both simulators allow to model devices in various difficult indoor and outdoor environments, alter the model and environment itself, test control algorithms and debug before moving over to the real device. Also, this is an excellent tool for training and situations when a real device is absent.\\n\\nOverall, this is one of the best options for trying to integrate Robonomics with a ROS device without any expenditures at all. A real scenario would merely require slight code modifications. For Gazebo, Robonomics has a detailed guide that consists of two parts that cover [settings](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) and [integrations](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/) (using a drone as an example). The main challenge is in finding a ready model (for example, [here](https://github.com/osrf/gazebo_models)) for Gazebo or trying to create your own model using the [SDFormat](http://sdformat.org/) developed for simulators. \\n\\n## Single-board computers and other boards\\n\\nSuch boards act as a base component for connecting other devices to ROS, primarily sensors and recording devices (audio, photo, and video recorders, cameras, temperature, pressure, and substance concentration sensors.) because the concept of a smart space implies the creation of a [digital twin](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf) of infrastructure objects. Also, boards can act as the main computing device and controller for constructing a robotic mobile device. A list of boards that support ROS is presented below:\\n\\n| Name and link                                                                                         |                                    Description                                  | ROS version | Last update |\\n|:-----------------------------------------------------------------------------------------------------:|---------------------------------------------------------------------------------|:-----------:|:-----------:|\\n|  [Raspberry Pi](http://wiki.ros.org/ROSberryPi/Installing%20ROS%20Melodic%20on%20the%20Raspberry%20Pi)| single board computer; RaspPi versions 2, 3 and 4 are available                 |   melodic   |     2020    |\\n|    [Arduino](http://wiki.ros.org/rosserial_arduino)                                                   | single board computer                                                           |    noetic   |     2021    |\\n|    [Phidgets](http://wiki.ros.org/phidgets)                                                           | sets of boards, various sensors and devices: Ph sensor, LED, RFID, motor control|    noetic   |     2020    |\\n|   [Sense HAT](https://wiki.ros.org/sensehat_ros)                                                      | shield for RaspPi with a set of sensors and LED                                 |    noetic   |     2020    |\\n|     [Navio2](https://navio2.emlid.com/)                                                               | autopliot shield for RaspPi 2,3,4                                               |    noetic   |     2020    |\\n|     [OpenCR](http://wiki.ros.org/opencr)                                                              | robot controller                                                                |    noetic   |     2021    |\\n\\n## Smart home devices and household robots\\n\\nPresented here are ROS devices whose initial use was for smart homes or offices. The list varies widely, from vacuum cleaners and robotic assistance to home control systems.\\n\\n| Name and link                                             | Description                                                 |          ROS version          | Last update |\\n|:---------------------------------------------------------:|-------------------------------------------------------------|:-----------------------------:|:-----------:|\\n|  [Care-O-bot 4](http://wiki.ros.org/care-o-bot)           | household robot-assistant; a simulation is available        |            melodic            |     2021    |\\n|     [Kobuki](http://wiki.ros.org/kobuki)                  | mobile platform with different use cases (e.g. a waiter)    |            melodic            |     2020    |\\n|    [QTrobot](http://wiki.ros.org/Robots/qtrobot)          | humanoid social robot                                       | kinetic (melodic can be used) |     2020    |\\n|      [Nao](http://wiki.ros.org/nao)                       | humanoid robot; a simulation is available                   |            Melodic            |     2020    |\\n|     [TIAGo](http://wiki.ros.org/Robots/TIAGo)             | service robot with a manipulator; a simulation is available |            kinetic            |     2020    |\\n|     [Roomba](https://github.com/AutonomyLab/create_robot) | robot vacuum cleaner                                        |            melodic            |     2020    |\\n|    [OpenHAB](http://wiki.ros.org/iot_bridge)              | home automation system                                      |            kinetic            |     2017    |\\n|     [Sesame](https://index.ros.org/p/sesame_ros/)         | smart lock                                                  |            melodic            |     2021    |\\n\\n## Mobile platforms and manipulators\\n\\nFirst and foremost, ROS is known for supporting mobile robotics, from drones to industrial manipulators, for which many packages were created that realize simultaneous localization and mapping ([SLAM](http://wiki.ros.org/rtabmap_ros)), solve the direct and inverse task of kinematics, [trajectory planning](https://moveit.ros.org/), and etc. Mobile robotics are gradually penetrating into everyday life, which is why it is certainly interesting to test existing ROS-robots in their use within a smart space. The general list of ROS-based mobile platforms is rather large, which is why here we have selected those that are potentially convenient to operate in a home or office space. \\n\\n| Name and link                                             | Description                                | ROS version | Last update |\\n|:---------------------------------------------------------:|--------------------------------------------|:-----------:|:-----------:|\\n|   [turtlebot](http://wiki.ros.org/turtlebot3)             | mobile platform tailored for ROS           |    noetic   |     2020    |\\n|    [GoPiGo3](http://wiki.ros.org/Robots/gopigo3)          | mobile robot based on RaspPi               |   melodic   |     2020    |\\n|    [LoCoBot](http://wiki.ros.org/locobot)                 | mobile manipulator                         |   kinetic   |     2020    |\\n|   [ROSbot 2.0](http://wiki.ros.org/Robots/ROSbot-2.0)     | mobile platform; a simulation is available |    noetic   |     2021    |\\n|     [VOLTA](http://wiki.ros.org/Robots/Volta)             | mobile platform; a simulation is available |   melodic   |     2021    |\\n|    [evarobot](http://wiki.ros.org/Robots/evarobot)        | mobile platform; a simulation is available |    noetic   |     2020    |\\n|    [Freight](http://wiki.ros.org/Robots/freight)          | mobile platform; a simulation is available |   melodic   |     2021    |\\n|      [PR2](http://wiki.ros.org/Robots/PR2)                | mobile platform; a simulation is available |   melodic   |     2021    |\"}},{\"node\":{\"id\":\"d30934987ca26923abb402ad05a8dd19\",\"title\":\"Manual start of the Robonomics network, consisting of 3 nodes\",\"path\":\"/docs/es/robonomics-test-network-manual/\",\"content\":\"\\n**Need to start Robonomics network of N (N> = 2) nodes**\\n\\n## Requirements\\n- Robonomics binary, download latest here: https://github.com/airalab/robonomics/releases/\\n- Subkey tool, download latest here: https://github.com/airalab/robonomics/releases/\\n- 3 servers with root shell. Their ip-addresses in the current instruction will be `165.227.171.127`, `159.89.25.75` and `159.89.30.50`\\n\\n## Introduction\\nIn this tutorial, we will first create all key files locally, and then upload them to their corresponding nodes. \\n\\n## Prepare directories\\nDownload 2 archives from the links above and open the folder with them in the terminal.\\nThen create a directory for the project, unpack the archives into it and go to the created folder:\\n```\\n$ mkdir robonomics_test_network\\n$ tar -xf ./robonomics-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ tar -xf ./subkey-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ cd ./robonomics_test_network/\\n```\\n\\nNext, create a separate **uploads** directory and the necessary subdirectories for each server. All files intended for uploading to a specific server will be stored in these subdirectories:\\n```\\n$ mkdir -p uploads/165.227.171.127/keystore && mkdir -p uploads/165.227.171.127/network\\n$ mkdir -p uploads/159.89.25.75/keystore && mkdir -p uploads/159.89.25.75/network\\n$ mkdir -p uploads/159.89.30.50/keystore && mkdir -p uploads/159.89.30.50/network\\n```\\n\\nAlso, create a **local** folder with **validators** and **sudo** folders, which will store the validators and sudo keys locally.\\n```\\n$ mkdir -p local/validators && mkdir -p local/sudo\\n```\\n\\n## Prepare spec.json\\nUsing the robonomics binary, generate a **spec.json** file, which will use as the basis:\\n```\\n$ ./robonomics build-spec --chain dev > uploads/spec.json\\n```\\n\\nNext, edit this file. At first correct the first three fields, make them look like this:\\n```\\n\\\"name\\\": \\\"Test Robonomics Network\\\",\\n\\\"id\\\": \\\"dev\\\",\\n\\\"chainType\\\": \\\"Live\\\",\\n```\\n\\n### bootNodes\\nThe **bootNodes** field is a list of strings of special format. For each of the bootnodes must write the corresponding string here.\\nTo do this, first create a key file for each bootnode using **subkey**:\\n```\\n$ ./subkey generate-node-key uploads/165.227.171.127/network/secret_ed25519  \\n12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\n$ ./subkey generate-node-key uploads/159.89.25.75/network/secret_ed25519\\n12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\n$ ./subkey generate-node-key uploads/159.89.30.50/network/secret_ed25519\\n12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\n```\\n\\nEach command creates a key file in the specified directory and outputs to stdout the string that will be needed to fill in the **bootNodes** field in the **spec.json** file. As a result, the **bootNodes** section should look like following example:\\n```\\n\\\"bootNodes\\\": [\\n\\\"/ip4/165.227.171.127/tcp/30333/p2p/12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\\",\\n\\\"/ip4/159.89.25.75/tcp/30333/p2p/12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\\",\\n\\\"/ip4/159.89.30.50/tcp/30333/p2p/12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\\"\\n],\\n```\\nThe next 3 fields (telemetryEndpoints, protocolId, properties) can be filled like this:\\n```\\n \\\"telemetryEndpoints\\\": [\\n     [\\n       \\\"/dns4/telemetry.polkadot.io/tcp/443/x-parity-wss/%2Fsubmit%2F\\\",\\n       0\\n     ]\\n ],\\n\\\"protocolId\\\": \\\"txrt\\\",\\n\\\"properties\\\": {\\n    \\\"ss58Format\\\": 32,\\n    \\\"tokenDecimals\\\": 9,\\n    \\\"tokenSymbol\\\": \\\"TXRT\\\"\\n},\\n```\\nFurther up to the **palletBalances** field leave unchanged.\\n\\n\\n### palletBalances\\nTo fill the palletBalances field create **the number of nodes + 1** (the last key is for **sudo**) keys. This can be done using **subkey**, in the file name must specify **SS58 Address** from the generated key, in the file content must specify **seed** phrase in quotes. \\n\\nExample creating one key.\\n - Generate key:\\n    ```\\n    $ ./subkey -n robonomics generate\\n    Secret phrase `display cargo domain april joy still bundle notice bridge pencil fat approve` is account:\\n      Network ID/version: substrate\\n      Secret seed:        0x0275ab9bce53e4359184f02112943162c708f483009e0b7b3ba63549c5c2e514\\n      Public key (hex):   0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      Account ID:         0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      SS58 Address:       4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n - Create key file:\\n    ```\\n    $ touch ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx && echo '\\\"display cargo domain april joy still bundle notice bridge pencil fat approve\\\"' | tee ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n  \\nCommand template for creating a validator key file:  \\n`touch ./local/validators/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/validators/**SS58_Address**`\\n\\nCommand template for creating a sudo key file:   \\n`touch ./local/sudo/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/sudo/**SS58_Address**`\\n\\nThree keys are stored in the **local/validators** folder and one in the **local/sudo** folder. As a result, the following content should appear in the **local** directory:\\n```\\n./local/\\n├── sudo\\n│   └── 4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\n└── validators\\n    ├── 4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ├── 4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\n    └── 4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\n```\\n\\nNow fill the palletBalances section in the spec.json file with these keys.\\nAs a result, it should look like this:\\n```\\n\\\"palletBalances\\\": {\\n  \\\"balances\\\": [\\n    [\\n      \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Generated validator 1 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Generated validator 2 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Generated validator 3 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\",    <-- Generated sudo key\\n      1000000000000000000\\n    ],\\n  ]\\n},\\n```\\nThe values that were previously presented in the palletBalances section must be deleted.\\n\\n### palletSession\\nNext step is the **palletSession** section in file **spec.json**. First let's describe its format. \\nThis section contains the \\\"keys\\\" field, that contains a list of three lists (equals of nodes count). Each of these lists looks like follows:\\n```\\n[\\n    \\\"%validator_SS58_address%\\\",\\n    \\\"%validator_SS58_address%\\\",\\n    {\\n        \\\"babe\\\": \\\"%sr25519_babe_SS58_address%\\\",\\n        \\\"im_online\\\": \\\"%sr25519_im_online_SS58_address%\\\"\\n        \\\"authority_discovery\\\": \\\"%sr25519_authority_discovery_SS58_address%\\\",\\n        \\\"grandpa\\\": \\\"%ed25519_grandpa_SS58_address%\\\",\\n    }\\n]\\n```\\n**%validator_SS58_address%** is the validator key that was generated for each node in the **palletBalances** section of this manual. Just copy it twice for each node.\\n\\nTo fill in the remaining 4 lines for each node, you need to create 4 key files for each node and store them in the **keystore** folders.\\nAs key files are generated, you can fill **palletSession**.\\n\\nEach key file must contain a **seed** phrase in quotes.\\nMaking of the name of each key file require separate consideration.\\nThe name of each key file is formed as **prefix** + **account_id without leading hexadecimal zero**.\\n\\nPrefixes matching:  \\n>      grandpa: '6772616e'  \\n>      babe: '62616265'\\n>      im_online: '696d6f6e'  \\n>      authority_discovery: '61756469'  \\n\\nAn example of creating keys for one node:\\n- Creating a **babe** (prefix *62616265*) key file.   \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  >  Secret phrase **cover once garment syrup income chair elder business diary frozen rack damage** is account:  \\n  >\\n  >  Network ID/version: `substrate`\\n  >\\n  >  Secret seed:        `0x90ddeee3a9a0c464572021d311c245eefc41f9a59c739faefda47efcf4755677`\\n  >\\n  >  Public key (hex):   `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  >\\n  >  Account ID:         `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  > \\n  >  SS58 Address:       `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`\\n  \\n ```\\n $ touch uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 && echo '\\\"cover once garment syrup income chair elder business diary frozen rack damage\\\"' | tee ./uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 \\n ```\\n This command creates a **babe** key file for the `165.227.171.127` node. To fill in **spec.json**, need to take from this output the value **SS58 Address**: `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`. This address need to insert instead of `%sr25519_babe_SS58_address%` in the above **palletSession** template.\\n   \\n **babe** key file creation command template:  \\n`touch ./uploads/[node_ip]/keystore/62616265+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/62616265+[Account_ID]`  \\n\\nAs you can see, the name of the babe key file is the sum of two substrings: `babe prefix ('62616265')`, and the `account_id` of the generated key, without the leading zero (`fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`). \\n  Note that the keys `babe, im_online, authority_discovery` are generated with the indication `--sr25519`.  \\n  **grandpa** key have to generate with the indication `--ed25519`.\\n \\n\\n- Creating an **im_online** (prefix *696d6f6e*) key file.  \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  > Secret phrase **envelope truly balance turkey undo casual waste skill average ordinary gun split** is account:\\n  >\\n  >   Network ID/version: `substrate`\\n  > \\n  >   Secret seed:        `0x8a19df08feeff9f1fa3581902ca22a305252aea32e284d32f10e990d00bb8926`\\n  > \\n  >   Public key (hex):   `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   Account ID:         `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   SS58 Address:       `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt`\\n   \\n  ```\\n  $ touch uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09 && echo '\\\"envelope truly balance turkey undo casual waste skill average ordinary gun split\\\"' | tee uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n  ```\\n  **im_online** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID]`\\n  \\n  **spec.json**: `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt` need to insert instead of `%sr25519_im_online_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating an **authority_discovery** (prefix *61756469*) key file.\\n   ```\\n   $ ./subkey --sr25519 -n robonomics generate\\n   ```\\n   > Secret phrase **boy harsh because omit equip atom apart spring undo explain walnut crystal** is account:\\n   >\\n   > Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0x27838c9ea0524353da3717862ef0ecef123f40e81b73bb5ef377d12b47d1c543`\\n   > \\n   >   Public key (hex):   `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   > \\n   >   Account ID:         `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   >  \\n   >   SS58 Address:       `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t`\\n   \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07 && echo '\\\"boy harsh because omit equip atom apart spring undo explain walnut crystal\\\"' | tee uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n   ```\\n  **authority_discovery** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/61756469+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/61756469+[Account_ID]` \\n  \\n   **spec.json**: `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t` need to insert instead of `%sr25519_authority_discovery_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating a **grandpa** (prefix *6772616e*) key file.\\n   ```\\n   $ ./subkey --ed25519 -n robonomics generate\\n   ```\\n   > Secret phrase **squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle** is account:\\n   > \\n   >   Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0xef0a9f51a4da7b789c0a25d39b44428d4da7262cc3fe013d4383b45216e8b83e`\\n   >  \\n   >   Public key (hex):   `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   >  \\n   >   Account ID:         `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   > \\n   >   SS58 Address:       `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa`\\n    \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009 && echo '\\\"squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle\\\"' | tee uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n   ```\\n   **grandpa** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/6772616e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/6772616e+[Account_ID]`\\n   \\n   **spec.json**: `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa` need to insert instead of `%sr25519_grandpa_SS58_address%` in the above **palletSession** template.\\n   \\n   \\n**Now 4 key files have been created for one node. Need to repeat this actions for the remaining two nodes.**\\n\\nYou should get the following **uploads** directory structure after creating all the keys:\\n```\\n./uploads/\\n├── 165.227.171.127\\n│   ├── keystore\\n│   │   ├── 617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n│   │   ├── 62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43\\n│   │   ├── 6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n│   │   └── 696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n│   └── network\\n│       └── secret_ed25519\\n├── 159.89.25.75\\n│   ├── keystore\\n│   │   ├── 617564692ac9bd30c0168fa623cfd66abb4327992d900a652bcbb238b740bdde497a565f\\n│   │   ├── 626162657cd666bb540c41cb33896a34d7413ffb86fcef1eddddfcd4edb325166df6335d\\n│   │   ├── 6772616e084402349bc08ef90c2837e8e3f12ebe8bd4ab86809e9ee5f4f8ca26e73a0518\\n│   │   └── 696d6f6e6ed2d507c0283ae869ba6514975bd8765eb8e06abd22afc09e8f36ef3950a116\\n│   └── network\\n│       └── secret_ed25519\\n└── 159.89.30.50\\n|   ├── keystore\\n|   │   ├── 61756469f20a4e16a0ee79431d6f9a70c38892c7532ad1347c2226d43ef6ffe8966e9b30\\n|   │   ├── 62616265e695aa459dbfd42bea7ed3b87970f164f34b6fee4d5a831ffbecd89eb9769b26\\n|   │   ├── 6772616eadef59f896ea6b94bcd4519be8cc4b70263fc318cec1a3be14850bbc22117c34\\n|   │   └── 696d6f6e2cb4dc8f8a67f477da15045ca40ef3861a2a6b2034ae0c64a179b4431341ea2c\\n|   └── network\\n|       └── secret_ed25519\\n└── spec.json\\n```\\n\\nThe palletSession section should look like this:\\n```\\n\\\"palletSession\\\": {\\n    \\\"keys\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t\\\",\\n                \\\"babe\\\": \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",\\n                \\\"grandpa\\\": \\\"4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa\\\",\\n                \\\"im_online\\\": \\\"4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt\\\"\\n            }\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4F6daoG2gBXRLvbT4mVRajExZdZBHH7APmX3wDuLYJyzxHSS\\\",\\n                \\\"babe\\\": \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",\\n                \\\"grandpa\\\": \\\"4G3Ai6BGUjqtCoM2aTvWyR19gQ8WZiNnh1KFM47RyiYTwkE6\\\",\\n                \\\"im_online\\\": \\\"4FHA7gzKfSLvd8jP85JUCWV6RyeRLm331KHcjnynGx7TWm7D\\\"\\n            }\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address                        \\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4CqzJFkdSZg52PfV6Fd4gJ3vPLmRu1HGuPvNivjJ8dDWaz1a\\\",\\n                \\\"babe\\\": \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",\\n                \\\"grandpa\\\": \\\"4Cqi4rG3CzWRZairhZX4isT8qG2jyz9fGDXJMrP6uBYkrft5\\\",\\n                \\\"im_online\\\": \\\"4C7V6R59cZVbabExqgWvHVE1vj1E1cV42SZr8d8zZD3gmsqk\\\"\\n            }\\n        ]\\n    ]\\n},\\n```\\n\\n### palletStaking\\n**palletStaking** must be filled in as follows:\\n```\\n\\\"palletStaking\\\": {\\n    \\\"historyDepth\\\": 84,\\n    \\\"validatorCount\\\": 10,\\n    \\\"minimumValidatorCount\\\": 2,\\n    \\\"invulnerables\\\": [\\n        \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",     <-- Validator 1 SS58 Address\\n        \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",     <-- Validator 2 SS58 Address\\n        \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\"      <-- Validator 3 SS58 Address\\n    ],\\n    \\\"forceEra\\\": \\\"NotForcing\\\",\\n    \\\"slashRewardFraction\\\": 100000000,\\n    \\\"canceledPayout\\\": 0,\\n    \\\"stakers\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",  <-- Validator 1 SS58 Address\\n            \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",  <-- Validator 1 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",  <-- Validator 2 SS58 Address\\n            \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",  <-- Validator 2 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",   <-- Validator 3 SS58 Address\\n            \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",   <-- Validator 3 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ]\\n    ]\\n},\\n```\\nThe example specified in which fields what values should be substituted.\\n\\n### palletSudo\\nIn the rest of the **spec.json** file, you need to change only the contents of **palletSudo**, substituting the previously generated **sudo** address there:\\n```\\n            \\\"palletBabe\\\": {\\n                \\\"authorities\\\": []\\n            },\\n            \\\"palletGrandpa\\\": {\\n                \\\"authorities\\\": []  \\n            },\\n            \\\"palletImOnline\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletAuthorityDiscovery\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletTreasury\\\": {},\\n            \\\"palletElectionsPhragmen\\\": {\\n                \\\"members\\\": []\\n            },\\n            \\\"palletCollectiveInstance1\\\": {\\n                \\\"phantom\\\": null,\\n                \\\"members\\\": []\\n            },\\n            \\\"palletSudo\\\": {\\n                \\\"key\\\": \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\"   <-- sudo address\\n            }\\n        }\\n    }\\n}\\n```\\n\\n## systemd unit file\\nNow create systemd unit file:\\n```\\n$ touch ./uploads/robonomics.service\\n```\\n\\nAnd fill it like this:\\n```\\n[Unit]\\nDescription=robonomics\\nAfter=network.target\\n\\n[Service]\\nUser=root\\nGroup=root\\nType=users\\nWorkingDirectory=/root\\nRestart=on-failure\\nExecStart=/usr/bin/robonomics  --chain /etc/substrate/spec.json --name ${HOSTNAME} --validator\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\nAs you can see from the \\\"ExecStart\\\" line, the **robonomics** binary is stored in the **/usr/bin/** directory, and the **spec.json** file is stored in the **/etc/substrate/** directory.\\n\\n## Uploading files\\nThe following one-line command uploads all files to the required directories on the servers. It is important that there are no other folders in the **uploads** directory, except for the folders with the ip-addresses of the nodes:\\n```\\n$ \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n    ssh root@\\\"$IP\\\" \\\"mkdir -p /root/.local/share/robonomics/chains/dev\\\" && \\\\\\n    scp -r ./uploads/$IP/* root@$IP:/root/.local/share/robonomics/chains/dev/ && \\\\\\n    scp ./uploads/robonomics.service root@$IP:/etc/systemd/system/ && \\\\\\n    scp ./robonomics root@$IP:/usr/bin/ && \\\\\\n    ssh root@$IP \\\"mkdir -p /etc/substrate\\\" && \\\\\\n    scp ./uploads/spec.json root@$IP:/etc/substrate/ \\\\\\n; done\\n```\\n\\n## Network launch\\nNow connect to all nodes, enable and start the **robonomics.service** unit:\\n```\\n$  \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n   ssh root@$IP \\\"systemctl enable robonomics.service && systemctl start robonomics.service\\\" \\\\\\n; done\\n```\\nAfter starting the service on all three nodes, you can view the node logs using **journalctl**. \\nTo do this, you can connect to any existing server via ssh and run the following command:\\n```\\n$ journalctl -u robonomics.service -f\\n```\\n![Robonomics Chart](../images/robonomics-test-network-manual/result-journalctl.jpg \\\"Robonomics Network journalctl stdout\\\")\\n\"}},{\"node\":{\"id\":\"a8dc5a4baecb2ac1567ced959bbd0feb\",\"title\":\"Robonomics + Prometheus + Grafana\",\"path\":\"/docs/es/robonomics-prometheus-grafana/\",\"content\":\"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](../images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](../images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](../images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](../images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](../images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](../images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](../images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](../images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](../images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"}},{\"node\":{\"id\":\"0a8a7dd2b2330548e64893f1339833cd\",\"title\":\"Robonomics Liability\",\"path\":\"/docs/es/robonomics-liability/\",\"content\":\"\\nThe package is responsible for receiving `New Liability` events (`listener` node) and playing topics from `objective` field (`executor` node).\\nThe launch file also include `ipfs_channel` node and `signer` node.\\n\\n## ROS Parameters\\n\\n### ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~web3_ws_provider\\n\\nWeb3 WebSocket provider address. The type is `string`, defaults to `ws://127.0.0.1:8546`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~enable_executor\\n\\nEnable or disable executor node. If it's `false`, no topics from objective would be published. The type is `boolean`, defaults to `true`\\n\\n### ~master_check_interval\\n\\nPeriod (in seconds) to check master for new topic publications. It's necessary for the Recorder, which records all the topics a CPS publishes. The type is `double`, defaults to `0.1`\\n\\n### ~recording_topics\\n\\nList of topics name separated by comma. It allows you to specify which topics would be recorded. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Subscribed topics\\n\\n### /liability/infochan/eth/signing/demand (robonomics_msgs/Demand)\\n\\n[robonomics_msgs/Demand](/docs/market-messages#demand) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/offer (robonomics_msgs/Offer)\\n\\n[robonomics_msgs/Offer](/docs/market-messages#offer) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/result (robonomics_msgs/Result)\\n\\n[robonomics_msgs/Result](/docs/market-messages#result) message to sign and send further to IPFS channel\\n\\n\\n## Published topics\\n\\n### /liability/infochan/incoming/demand (robonomics_msgs/Demand)\\n\\nContains a [robonomics_msgs/Demand](/docs/market-messages#demand) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/offer (robonomics_msgs/Offer)\\n\\nContains a [robonomics_msgs/Offer](/docs/market-messages#offer) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/result (robonomics_msgs/Result)\\n\\nContains a [robonomics_msgs/Result](/docs/market-messages#result) message which was read from IPFS channel\\n\\n### /liability/incoming (robonomics_liability/Liability)\\n\\nContains all the information about the last created [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)\\n\\n### /liability/ready (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)is ready for execution\\n\\n### /liability/complete (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg) has done its job\\n\\n### /liability/finalized (std_msgs/String)\\n\\nSignals when a liability has been finalized\\n\\n## Services\\n\\n### /liability/start (robonomics_liability/StartLiability)\\n\\nThe service tells executor to play topics from the objective. It's required to pass a liability address ([robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)), which you can get from `/liability/ready` topic\\n\\n### /liability/finish (robonomics_liability/FinishLiability)\\n\\nCPS should call the service after performing the task. The input is [robonomics_liability/FinishLiability](/docs/robonomics-liability-messages#robonomics_liabilityfinishiabilitysrv)\\n\\n### /liability/restart (robonomics_liability/StartLiability)\\n\\nThe service allows to restart a liability after the system shutdown. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/resume (robonomics_liability/StartLiability)\\n\\nThe service allows to resume a liability from the last timestamp available in the persistence store. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/read (robonomics_liability/ReadLiability)\\n\\nThe service returns all the data about a liability by its address. The input is [robonomics_liability/ReadLiability](/docs/robonomics-liability-messages#robonomics_liabilityreadliabilitysrv)\\n\"}},{\"node\":{\"id\":\"d341a6eaaddf80a84022d3fce7629933\",\"title\":\"Robonomics Liability Messages\",\"path\":\"/docs/es/robonomics-liability-messages/\",\"content\":\"\\n## robonomics_liability/Liability.msg\\n\\n| Field        \\t| Type                                                                         \\t| Description                                    \\t|\\n|--------------\\t|------------------------------------------------------------------------------\\t|------------------------------------------------\\t|\\n| address      \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The Liability’s address                        \\t|\\n| model        \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model Identifier                \\t|\\n| objective    \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model parameters in rosbag file \\t|\\n| result       \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| Liability result hash                          \\t|\\n| promisee     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisee address                           \\t|\\n| promisor     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisor address (usually CPS)             \\t|\\n| lighthouse   \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The address of lighthouse your CPS works on    \\t|\\n| token        \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Operational token address                      \\t|\\n| cost         \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| CPS behavioral model implementation cost       \\t|\\n| validator    \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Observing network address                      \\t|\\n| validatorFee \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| Observing network commission                   \\t|\\n\\n## robonomics_liability/StartLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                                           |\\n|---------  |-----------------  |-----------------------------------------------------  |\\n| address   | std_msgs/String   | The address of Liability you are willing to execute   |\\n\\n**Response**\\n\\n| Field     | Type              | Description                               |\\n|---------  |-----------------  |------------------------------------------ |\\n| success   | std_msgs/Bool     | Weather or not the Liability was started  |\\n| msg       | std_msgs/String   | Status of launch                          |\\n\\n## robonomics_liability/FinishLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                           |\\n|---------  |-----------------  |------------------------------------   |\\n| address   | std_msgs/String   | The address of Liability to finish    |\\n| success   | std_msgs/Bool     | The status of execution               |\\n\\n**Response**\\n\\nThe response is empty\\n\\n## robonomics_liability/ReadLiability.srv\\n\\n**Request**\\n\\n| Field     | Type                                                                          | Description                   |\\n|---------  |------------------------------------------------------------------------------ |----------------------------   |\\n| address   | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)  | The address of a liability    |\\n\\n**Response**\\n\\n| Field         | Type                                                                  | Description           |\\n|-----------    |---------------------------------------------------------------------  |---------------------  |\\n| read          | std_msgs/Bool                                                         | Status of execution   |\\n| liability     | [robonomics_liability/Liability](#robonomics_liabilityliabilitymsg)   | Liability             |\\n\"}},{\"node\":{\"id\":\"f1ff8c019012bfb2612ca6f8fd3c6cc9\",\"title\":\"Robonomics-js\",\"path\":\"/docs/es/robonomics-js/\",\"content\":\"\\n[Robonomics-js](https://github.com/airalab/robonomics-js) is a simple Javascript library for working with Robonomics Network.\\n\\n## Installation\\n\\n```\\nnpm install robonomics-js --save\\n```\\n\\nor\\n\\n```\\nyarn add robonomics-js\\n```\\n\\n### Dependencies \\n\\n* [Web3](https://github.com/ethereum/web3.js/) version 1.2.4\\n* [Ipfs](https://github.com/ipfs/js-ipfs) version 0.34.0\\n\\n\\n## Usage \\n\\nCreates a Robonomics instance\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\n```\\n\\n### options\\n\\nThe object of properties:\\n\\n```\\noptions.web3\\n```\\n\\nAn instance of [web3.js](https://github.com/ethereum/web3.js/):\\n\\n```JavaScript\\n// metamask\\nconst options = {\\n  web3: new Web3(window.ethereum),\\n  ...\\n};\\n\\n// infura\\nconst options = {\\n  web3: new Web3(\\n    new Web3.providers.WebsocketProvider(\\n      \\\"wss://mainnet.infura.io/ws/v3/0b2f2a5026264b57b6d698b480332e89\\\"\\n    )\\n  ),\\n  ...\\n};\\n```\\n\\n```\\noptions.messageProvider\\n```\\n\\nThis is an instance of MessageProviderIpfs which uses a [js-ipfs](https://github.com/ipfs/js-ipfs) node with pubsub support\\n\\n```JavaScript\\nconst ipfs = new Ipfs({\\n  repo: 'robonomics-example',\\n  relay: {\\n    enabled: true,\\n    hop: {\\n      enabled: true\\n    }\\n  },\\n  EXPERIMENTAL: {\\n    pubsub: true\\n  },\\n  config: {\\n    Addresses: {\\n      Swarm: [\\n        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star',\\n        '/dns4/1.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/2.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/3.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/'\\n      ]\\n    },\\n    Bootstrap: [\\n      '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',\\n      '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',\\n      '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',\\n      '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',\\n      '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',\\n      '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',\\n      '/dns4/1.pubsub.aira.life/tcp/443/wss/ipfs/QmdfQmbmXt6sqjZyowxPUsmvBsgSGQjm4VXrV7WGy62dv8',\\n      '/dns4/2.pubsub.aira.life/tcp/443/wss/ipfs/QmPTFt7GJ2MfDuVYwJJTULr6EnsQtGVp8ahYn9NSyoxmd9',\\n      '/dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw'\\n    ]\\n  }\\n})\\n\\nconst options = {\\n  messageProvider: new MessageProviderIpfs(ipfs),\\n  ...\\n};\\n```\\n\\n```\\noptions.account\\n```\\n\\nThis is an account object which will be used to sign messages. It's necessary to specify either account address (that one must be unlocked) or a private key (the address will be recovered from the given private key).\\n\\nOption `isSignPrefix` tells whether or not a prefix must be appended. Default is `true`.\\n\\n```JavaScript\\nconst options = {\\n  account: {\\n    address: '0x0000000000000000000000000000000000000000',\\n    privateKey: '0x0000000000000000000000000000000000000000000000000000',\\n    isSignPrefix: true\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.ens\\n```\\n\\nThis is a `ens` contract object. This one is not required. If it's necessary you may specify `address` of the contract if the network is not set to mainnet. `suffix` may be `sid` for sidechain or `eth` for mainnet. `eth` is default. `version` is the version of Robonomics Network. Default is the latest deployed version.\\n\\n```JavaScript\\nconst options = {\\n  ens: {\\n    address: '0x314159265dD8dbb310642f98f50C066173C1259b',\\n    suffix: 'eth',\\n    version: 5\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.lighthouse\\n```\\n\\nENS name of a lighthouse, not required. Default is `airalab.lighthouse.5.robonomics.eth`. It's possible to specify only the first part of the name, like `airalab`.\\n\\n```JavaScript\\nconst options = {\\n  lighthouse: 'airalab.lighthouse.5.robonomics.eth',\\n  ...\\n};\\n```\\n\\nIt's necessary to wait until full initialization\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\nrobonomics.ready().then(() => {\\n  console.log('Robonomics instance ready')\\n})\\n```\\n\\n## API\\n\\n### Messages\\n\\n#### Demand \\n\\nThe message specification\\n\\n```JavaScript\\nconst demand = {\\n  // REQUIRED\\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost\\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED \\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  validatorFee: 0,                                              // validator fee \\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendDemand`\\n\\nSigning and broadcasting the demand message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendDemand(demand).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onDemand`\\n\\nListens to demand messages with a defined model. If model is `null` returns any demand message.\\n\\n```JavaScript\\nrobonomics.onDemand(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Offer \\n\\nThe message specification\\n\\n```JavaScript\\nconst offer = {\\n  // REQUIRED \\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost \\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED\\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  lighthouseFee: 0,                                             // lighthouse fee\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendOffer`\\n\\nSigns and broadcasts an offer message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendOffer(offer).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onOffer`\\n\\nListens to offer messages with a defined model. If model is `null` returns any offer message\\n\\n```JavaScript\\nrobonomics.onOffer(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Result \\n\\nThe message specification\\n\\n```JavaScript\\nconst result = {\\n  // REQUIRED \\n  liability: \\\"0x0000000000000000000000000000000000000000\\\",  // liability contract address\\n  success: true,                                            // status of the task\\n  result: \\\"QmWXk8D1Fh5XFJvBodcWbwgyw9htjc6FJg8qi1YYEoPnrg\\\"  // ipfs hash of the rosbag log file\\n};\\n```\\n\\n`robonomics.sendResult`\\n\\nSigns and broadcasts a result message\\n\\n```JavaScript\\nrobonomics.sendResult(result).then(() => {\\n  console.log(\\\"ok\\\");\\n});\\n```\\n\\n`robonomics.onResult`\\n\\nListens to result messages. These results may be not valid. Valid results are stored in a liability contract\\n\\n```JavaScript\\nrobonomics.onResult(result => {\\n  console.log(result);\\n});\\n```\\n\\n### Smart Contracts \\n\\n#### Liability \\n\\n`liability.getInfo`\\n\\nReturn a property object of the contract\\n\\n```JavaScript\\nliability.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    model,\\n    objective,\\n    result,\\n    token,\\n    cost,\\n    lighthouseFee,\\n    validatorFee,\\n    demandHash,\\n    offerHash,\\n    promisor,\\n    promisee,\\n    lighthouse,\\n    validator,\\n    isSuccess,\\n    isFinalized\\n  }\\n  */\\n});\\n```\\n\\n`liability.onResult`\\n\\nWaits until a liability is finished. Returns a result\\n\\n```JavaScript\\nliability.onResult().then(result => {\\n  console.log(result);\\n});\\n```\\n\\n#### Lighthouse \\n\\n`robonomics.lighthouse.getInfo`\\n\\nReturns a property object of the contract\\n\\n```JavaScript\\nrobonomics.lighthouse.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    minimalStake,\\n    timeoutInBlocks,\\n    keepAliveBlock,\\n    marker,\\n    quota\\n  }\\n  */\\n});\\n```\\n\\n`robonomics.lighthouse.getProviders`\\n\\nReturns a list of providers on the lighthouse\\n\\n```JavaScript\\nrobonomics.lighthouse.getProviders().then(list => {\\n  console.log(list);\\n});\\n```\\n\\n##### Creation of a new lighthouse\\n\\n```JavaScript\\nconst minimalFreeze = 1000      // Wn\\nconst timeout = 25              // blocks\\nconst name = 'mylighthouse'     // lighthouse name\\nrobonomics.factory.methods.createLighthouse(minimalFreeze, timeout, name).send({ from: robonomics.account.address })\\n    .then((tx) => console.log(tx))\\n\\nrobonomics.factory.onLighthouse((lighthouse) => {\\n    console.log(lighthouse.name)\\n})\\n```\\n\\n##### Become a provider \\n\\nPreliminarily you must call `approve` for the tokens `XRT`\\n\\n```JavaScript\\nconst name = \\\"mylighthouse\\\";    // lighthouse name\\nconst stake = 1000;             // Wn\\nrobonomics.lighthouse.methods\\n  .refill(stake)\\n  .send({ from: robonomics.account.address })\\n  .then(tx => console.log(tx));\\n```\\n\\n#### Token \\n\\n`robonomics.xrt.getInfo`\\n\\nReturns property object of the token\\n\\n```JavaScript\\nrobonomics.xrt.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    name,\\n    totalSupply,\\n    decimals,\\n    symbol\\n  }\\n  */\\n});\\n```\\n\\n##### Check balance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .balanceOf(robonomics.account.address)\\n  .call()\\n  .then(balance => console.log(balance));\\n```\\n\\n##### Check allowance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .allowance(robonomics.account.address, robonomics.factory.address)\\n  .call()\\n  .then(allowance => console.log(allowance));\\n```\\n\\n##### Approve \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .approve(robonomics.lighthouse.address, 100)\\n  .send({\\n    from: robonomics.account.address\\n  })\\n  .then(tx => console.log(tx));\\n```\\n\\n## Links \\n\\n- [Website](https://robonomics.network/)\\n- [Minimal template of dApp](https://github.com/airalab/vue-dapp-robonomics-template)\\n- [dApp example](https://codesandbox.io/s/robonomics-vue-template-ewuiw)\\n\"}},{\"node\":{\"id\":\"81ef4bd537aa1a5b897398c17b87e970\",\"title\":\"How Robonomics Network Works\",\"path\":\"/docs/es/robonomics-how-it-works/\",\"content\":\"\\nIn this section we will discuss the Robonomics Network scenario.\\n\\nThere are few main parts in the Robonomics network:\\n\\n- IPFS for the messages exchanging\\n- the Ethereum blockchain for storing new liability contracts\\n- a provider that is responsible for matching messages\\n- an agent\\n\\nLet's have a look at the following diagram that describes the scenario without any additional details:\\n\\n![The main scenario of Robonomics Network](../images/robonomics_network_scenario.jpg \\\"The main scenario of Robonomics Network\\\")\\n\\nThere are three types of [messages](/docs/market-messages) in IPFS: Demand, Offer, Result.\\n\\n**Below there is the specification for a Demand message:**\\n\\n| Field         | Type                      | Description                                       | Example                                           |\\n|-------------- |-------------------------  |------------------------------------------------   |------------------------------------------------   |\\n| model         | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model Identifier                   | QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC    |\\n| objective     | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    | QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r    |\\n| token         | ethereum_common/Address   | Operational token address                         | 0xbD949595eE52346c225a19724084cE517B2cB735        |\\n| cost          | ethereum_common/UInt256   | CPS behavioral model implementation cost          | 1                                                 |\\n| lighthouse    | ethereum_common/Address   | Lighthouse address                                | 0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1       |\\n| validator     | ethereum_common/Address   | Observing network address                         | 0x0000000000000000000000000000000000000000        |\\n| validatorFee  | ethereum_common/UInt256   | Observing network commission                      | 0                                                 |\\n| deadline      | ethereum_common/UInt256   | Deadline block number                             | 6393332                                           |\\n| sender        | ethereum_common/Address   | Message sender address                            | 0x0000000000000000000000000000000000000000        |\\n| signature     | std_msgs/UInt8[]          | Sender’s digital signature                        | 0x23bc…c617                                       |\\n\\n<!--\\n=============== ============================================================== ================================================ ================================================\\n     Field                                   Type                                                Description                                        Example\\n=============== ============================================================== ================================================ ================================================\\n  model          :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model Identifier                  QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC\\n  objective      :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model parameters in rosbag file   QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r\\n  token          :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Operational token address                        0xbD949595eE52346c225a19724084cE517B2cB735\\n  cost           :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   CPS behavioral model implementation cost         1\\n  lighthouse     :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Lighthouse address                               0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1\\n  validator      :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Observing network address                        0x0000000000000000000000000000000000000000\\n  validatorFee   :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Observing network commission                     0\\n  deadline       :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Deadline block number                            6393332\\n  sender         :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Message sender address                           0x0000000000000000000000000000000000000000\\n  signature      std_msgs/UInt8[]                                               Sender's digital signature                       0x23bc...c617\\n=============== ============================================================== ================================================ ================================================\\n-->\\n\\nAn Offer message has the same fields but instead of `validatorFee` there is a `lighthouseFee` field. This field determines the amount of fee for a lighthouse.\\n\\nNow let's have a look at the following diagram and walk step by step from the moment of publishing messages to a liability finalization.\\n\\n![Robonomics Network detailed scenario](../images/robonomics_network_detailed_scenario.jpg \\\"Robonomics Network detailed scenario\\\")\\n\\nA liability contract is created only if the following fields match: `model`, `objective`, `token`, `cost`. A provider of Robonomics Network watches every message and finds those ones that have a match.\\nAfter the match is found the provider calls `createLiability(demand, offer)` method from the contract factory where `demand` and `offer` are serialized.\\n\\nBelow is the package diagram for the Robonomics communication stack:\\n\\n![Robonomics communication stack](../images/robonomics_network_communication_stack.jpg \\\"Robonomics communication stack\\\")\\n\\nThe factory deserializes arguments and recovers *promisee* and *promisor* addresses from signatures.\\n\\nNext step is token transfer. The factory transfers **cost** tokens from the *promisee* address and **validatorFee** and **lighthouseFee** from the *promisor* address to the new liability address.\\n\\n> - **You should approve sufficient amount of tokens for the factory.**\\n> - **It's not required to approve tokens from the *promisor* address if fees are null.**\\n\\nNow the factory emits a NewLiability event with the liability address. An agent gets the address, reads fields, perform a task and at the same time writes a log file in rosbag format.\\n\\nWhen the work is done the agent sends a Result message with the following fields: hash of the rosbag file, a success flag, a signature. If the **validator** field is not null it means that only validator is able to finalize the liability.\\n\\nAfter the successful liability finalization the agent gets **cost** tokens. Otherwise, the *promisee* gets tokens back.\"}},{\"node\":{\"id\":\"42125ccdcfeece681864a23ddcd8392e\",\"title\":\"Robonomics DApp Overview\",\"path\":\"/docs/es/robonomics-dapp-overview/\",\"content\":\"\\nYou can operate with Robonomics Network using the interface of [Robonomics Network Dapp (decentralized application)](https://dapp.robonomics.network/#/). It is available in browsers with [Metamask extension](https://metamask.io). On the first page you will see the statistics of the network:\\n\\n![Robonomics DApp's first page](../images/robonomics_dapp_first_page.jpg \\\"Robonomics DApp's first page\\\")\\n\\nLet's have a look at the bottom table \\\"Robonomics Telemetry\\\".\\n\\nEvery time an instance of AIRA is launched it broadcasts a piece of information about itself. Usually it takes some time for the Dapp to receive data from an instance of AIRA.\\n\\nHave a brief look at the page [\\\"AIRA installation\\\"](/docs/aira-installation) to understand where `IPNS` and `Address Eth` came from.\\n\\n## IPNS\\n\\nYou can treat it as a unique identifier of your instance in IPFS network. Under that name AIRA publishes metadata about itself.\\n\\n## Address Eth\\n\\nBy default AIRA generates new Ethereum address for you (it's [possible](/docs/aira-faq#how-to-change-ethereum-address-of-aira) to generate new one).\\n\\nIt's mainly used to sign all the outcoming messages.\\n\\n## Lighthouse\\n\\nIn Robonomics Network an agent must choose a lighthouse to work on. By default it's `airalab.lighthouse.5.robonomics.eth`.\\n\\nYou can choose existing one or create your own on [Lighthouses](https://dapp.robonomics.network/#/lighthouse) page.\\n\\n## Peers\\n\\nThe amount of IPFS pubsub [peers](/docs/aira-faq#how-to-check-the-quantity-of-ipfs-peers).\\n\\n## Date\\n\\nThe date and time of last update\\n\\n## Network\\n\\nRobonomics Network officially works in Ethereum Mainnet.\\nThere is also [Sidechain](https://github.com/airalab/airalab-sidechain) which is mostly for testing purpose.\\n\\n\\n\"}},{\"node\":{\"id\":\"c245ef75f4c1a3cc90373a13cbde180c\",\"title\":\"Contracts deployment\",\"path\":\"/docs/es/robonomics-contracts-deployment/\",\"content\":\"\\nRobonomics network works on top of the existing Ethereum network. The protocol is implemented by smart contracts. A source code is on [Github](https://github.com/airalab/robonomics_contracts). Airalab team deploys new version of contracts and supports a current one. \\n\\nIn this lesson we are going to learn more about these contracts. To do this we will deploy our test copy. Also we are going to use these contracts in the future lessons. \\n\\nYou need a client running Ethereum node. You can use either one of existing network (e.g. Mainnet, Ropsten, Kovan) or your local one. For testing purpose we suggest to use this [docker container](https://github.com/f-o-a-m/cliquebait) \\n\\n    $ docker run --rm -d -p 9545:8545 -p 9546:8546 foamspace/cliquebait:latest\\n\\nNext step is obtain a copy of robonomics contracts source code:\\n\\n    $ git clone --recursive https://github.com/airalab/robonomics_contracts\\n\\nA file truffle.js contains available networks for migration. We will work with development network. When you are in `robonomics_contracts` directory install dependencies and run a migration:\\n\\n    npm install // to install dependencies\\n    truffle migrate --network development\\n\\nIt's time to learn how to create a new lighthouse. For more information about Robonomics network and Lighthouse in particular read [white paper](http://static.robonomics.network/docs/book-the-economy-of-robots-1-2017/robonomics.network-book-the-economy-of-robots-1-2017-en.pdf). Briefly lighthouse o distributes the running time of providers. Every lighthouse serves its own broadcast channel. Ask and Bid messages come into this channel. XRT tokens are used as a payment. \\n\\nWhen XRT contracts was deployed some tokens were issued on our account. Let's check the balance:\\n\\n    $ truffle --network development console\\n    > xrt = XRT.at(XRT.address)\\n    > xrt.balanceOf(web3.eth.accounts[0])\\n\\nAnd that's how we create a lighthouse:\\n\\n    > factory = LiabilityFactory.at(LiabilityFactory.address)\\n    > tx = factory.createLighthouse(1000, 10, \\\"test\\\")\\n    > tx.then(x => {laddress = x.logs[0].args.lighthouse})\\n    > l = LighthouseLib.at(laddress)\\n\\nInstead of deploying a lighthouse contract every time we need a new one, we ask a factory to do this job. A `l` variable contains lighthouse instance. The lighthouse should be able to spend our tokens. Let's make an approve and check everything went well:\\n\\n    > xrt.approve(l.address,1000)\\n    > xrt.allowance(web3.eth.accounts[0],l.address)\\n\\nAnd a very important step is become a worker:\\n\\n    > l.refill(1000)\\n\\nEach worker has to put a stake. In this case it's 1000 Wn.\\n\\nBelow is a table of our addresses:\\n\\n| Contract          | Address                                       | ENS name                          |\\n|------------------ |--------------------------------------------   |---------------------------------- |\\n| ENSRegistry       | 0x80c77a7de64a15450bb8cf45ece4fbb7bae6fb49    |                                   |\\n| XRT               | 0x673583a369eb3a830a5571208cf6eb7ce83987f8    | xrt.3.robonomics.eth              |\\n| LiabilityFactory  | 0x1b3190e00c1903266862af1f31714d4b81ef59b2    | factory.3.robonomics.eth          |\\n| Lighthouse        | 0xd2b78c032b6c8851a8b6cbf950caa02a77618d8e    | test.lighthouse.3.robonomics.eth  |\\n\"}},{\"node\":{\"id\":\"d303732d522873fd88efcb513786cfee\",\"title\":\"Robonomics Coffee\",\"path\":\"/docs/es/robonomics-coffee/\",\"content\":\"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](../images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](../images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](../images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](../images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](../images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](../images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](../images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](../images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](../images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](../images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](../images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](../images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](../images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"}},{\"node\":{\"id\":\"ca800a47d24dee3755fff98b1ce9d173\",\"title\":\"Become a Provider\",\"path\":\"/docs/es/robonomics-become-a-provider/\",\"content\":\"\\nThis page describes how to create a lighthouse and become a provider in the Robonomics network.\\n\\n## Prepare an address\\n\\nFirst of all, an Ethereum address is required. You must have access to a private key of the address. In case you don't have one, below are steps to create an address via [Parity](https://www.parity.io/ethereum/).\\n\\n```\\n$ sudo snap install parity\\n$ parity.ethkey generate random\\nsecret:  15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539\\npublic: 38b800bfd90d486c78c646da79bb94b9d038aca8aad221062ce1b148df7764bfef02f6b3cf931786b6997540b798ea226ae60bd201c222d8f702e408a1a5cbff\\naddress: c531fa8f141493df3da264a864bdcbec19695b4c\\n```\\n\\nThe `secret` field is a private key, you'll need it to run the provider client. Save it to a file:\\n\\n```\\n$ echo '0x15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539' > private.key\\n```\\n\\nThe next step is to deposit some ethers and XRT tokens to the address which is held in the `address` field.\\n\\n## Create a lighthouse\\n\\nGo to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse) and fill in a name in the right side:\\n\\n![The Right Side](../images/become_a_provider_1.jpg \\\"The Right Side\\\")\\n\\nClick on the `Create lighthouse and connect to the network` button and sign a transaction. After a while you should see:\\n\\n![Success of Creating a Lighthouse](../images/become_a_provider_2.jpg \\\"Success of Creating a Lighthouse\\\")\\n\\nNow it's time to put a stake. Select the new lighthouse and click `Connect to the network`:\\n\\n![Selecting the Lighthouse](../images/become_a_provider_3.jpg \\\"Selecting the Lighthouse\\\")\\n\\nOn this page in the `Provider` section click the `Approve` button, sign a transaction. When it's mined click the `Refill` button and do the same.\\n\\n## Install the client\\n\\nNow you need to install [robonomics-tools](https://github.com/airalab/robonomics-tools) at least 0.4.2 version. You can build from the source or do the following steps:\\n\\n**Make sure you have Nix and Stack installed:**\\n    \\n```\\n$ curl -sSL https://get.haskellstack.org/ | sh\\n$ curl https://nixos.org/nix/install | sh\\n```\\n\\n* Setup Airalab binary cache at [https://aira.cachix.org](https://aira.cachix.org/)\\n* Import Airalab channel:\\n\\n```\\n$ nix-channel --add http://aira.life/channels/aira-unstable/ aira\\n$ nix-channel --update\\n```\\n* Install from the binary cache:\\n\\n```\\n$ nix-env -iA aira.robonomics-tools\\n```\\n* Run the client:\\n\\n```\\n$ xrtd --lighthouse mobilerobotics.lighthouse.5.robonomics.eth --private $(cat private.key)\\n```\\n\\n**Get familiar with the `xrtd` options via `xrtd --help`.**\\n\\n## Test the provider\\n\\nTo test your provider go again to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse/) and connect to the just created lighthouse.\\n\\nAt the bottom you should see the `TEST LIGHTHOUSE` section.\\n\\nClick on the `Demand` button and then on the `Offer` one. You should see something similar to:\\n\\n![Demand and Offer messages](../images/provider_mobilerobotics_demand_offer.jpg \\\"Demand and Offer messages\\\")\\n\\nDon't forget to sign every message with the MetaMask extension.\\n\\nFinally you should see a new liability contract created:\\n\\n![Liability is created](../images/provider_mobilerobotics_liability.jpg \\\"Liability is created\\\")\\n\"}},{\"node\":{\"id\":\"fcff9004e72379cce0e3fd45feebad6a\",\"title\":\"Robonomics IO Overview\",\"path\":\"/docs/es/rio-overview/\",\"content\":\"\\nThe [crate](https://crates.robonomics.network/robonomics_io/index.html) provides a convenient way to interact with blockchain and includes a set of tools. The latest release can be found [here](https://github.com/airalab/robonomics/releases)\\n\\n```\\n% ./robonomics io\\nrobonomics-io 0.21.0\\nRobonomics Framework I/O operations\\n\\nUSAGE:\\n    robonomics io [FLAGS] [OPTIONS] <SUBCOMMAND>\\n\\nFLAGS:\\n        --dev        Specify the development chain\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nOPTIONS:\\n    -d, --base-path <PATH>        Specify custom base path\\n        --chain <CHAIN_SPEC>      Specify the chain specification (one of dev, local, or staging)\\n    -l, --log <LOG_PATTERN>...    Sets a custom logging filter. Syntax is <target>=<level>, e.g. -lsync=debug\\n\\nSUBCOMMANDS:\\n    help     Prints this message or the help of the given subcommand(s)\\n    read     Read information from device\\n    write    Write information into device\\n```\\n\\n## The Pipeline Philosophy \\n\\nThe tool is designed in order to be included in a pipeline chain of processes. From Unix user experience everyone is familiar with commands like:\\n\\n```\\nps aux | grep robonomics\\n```\\n\\nIt means standard output produced by the `ps` program becomes standard input for the `grep` program. \\n\\nThe `robonomics io` consists of several subcommands with reading, writing abilities or both. It treats everything as a virtual or physical device ([everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file))\\n\\n## Read Overview\\n\\nIn general `read` means it reads data from a device or a network and prints it in `stdout`.\\n\\nHow to use it for:\\n\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io read\\nrobonomics-io-read 0.4.0\\nRead information from device\\n\\nUSAGE:\\n    robonomics io read <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    help      Prints this message or the help of the given subcommand(s)\\n    ipfs      Download data from IPFS storage\\n    launch    Robot launch request events\\n    pubsub    Subscribe for broadcasing data\\n    sds011    Nova SDS011 particle sensor\\n```\\n\\n## Write Overview\\n\\nUsually it writes data to blockchain or publishes to pubsub channel. \\n\\nHow to use it for:\\n\\n* [datalog](/docs/rio-datalog)\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io write\\nrobonomics-io-write 0.4.0\\nWrite information into device\\n\\nUSAGE:\\n    robonomics io write <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    datalog    Data blockchainization subsystem command\\n    help       Prints this message or the help of the given subcommand(s)\\n    ipfs       Upload data into IPFS storage\\n    launch     CPS launch subsystem command\\n    pubsub     Broadcast data into PubSub topic\\n```\\n\\n## Local Testnet\\n\\nFor testing purpose it's possible to run the development environment:\\n\\n```\\n% ./robonomics --dev --rpc-cors all\\n```\\n\\n`--rpc-cors all` allows the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) to be connected to local node. After launching the node, go to the dapp, click on Robonomics icon in the upper left corner, choose Development and put node's local address\\n\\n![Robonomics Dapp Connect to Local Node](../images/robonomics-dapp-connect-local.jpg \\\"Robonomics Dapp Connect to Local Node\\\")\\n\\nFinally click Switch and you should be connected to the local node. Check out Accounts tab. There you can create new accounts and transfer tokens.\\n\\n\"}},{\"node\":{\"id\":\"b4f301149650664e555414a7e5d7ad81\",\"title\":\"Robonomics IO Launch\",\"path\":\"/docs/es/rio-launch/\",\"content\":\"\\nA simple way to turn on and off an IoT device or a robot. Basically sending \\\"ON\\\" will result in `true` state for a device, anything else will result in `false`.\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Accounts on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Usage\\n\\nTo see the result of transaction first of all run `read` part:\\n\\n```\\n% ./robonomics io read launch\\n```\\n\\nNow let's turn a robot on:\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nThen you should see in the first terminal window:\\n\\n```\\n% ./robonomics io read launch\\n5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH >> 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL : true\\n```\\n\\nLet's describe all the accounts and options above.\\n\\n* `-r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL` means robot's address\\n* `-s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` private key of the account to launch from (must have tokens for a transaction)\\n* `5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH` address that launches a robot\\n* `true` turn it on\\n\\nIf we pass anything else but \\\"ON\\\" the state becomes `false`\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\\nand\\n\\n```\\n% ./robonomics io read launch --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"b2d18eb9a2e4122d6867c1acc0fec826\",\"title\":\"Robonomics IO IPFS\",\"path\":\"/docs/es/rio-ipfs/\",\"content\":\"\\nIt serves downloading and uploading files from/to IPFS network\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Running [IPFS](https://ipfs.io/#install) daemon \\n\\n## Write\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\n## Read\\n\\n```\\n% echo QmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy | ./robonomics io read ipfs\\nHello Robonomics\\n```\\n\\n## Remote IPFS node\\n\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs --remote https://ipfs.infura.io:5001/\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\nThe same applies for `read`\\n\\n\"}},{\"node\":{\"id\":\"fa9c40d99ac8caccf671b4522f448c54\",\"title\":\"Robonomics IO Datalog\",\"path\":\"/docs/es/rio-datalog/\",\"content\":\"\\nDatalog module allows you to store any string on blockchain\\n\\nhttps://www.youtube.com/watch?v=rs67AMyd-gE\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Account on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Write\\n\\nAssuming local node is running:\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nwhere `0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` is a private key for the account with tokens.\\nIn this example the public key is 5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH. Let's go to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/)\\nand see what happened.\\n\\nIn the Dapp go to Developer -> Chain state. In the \\\"selected state query\\\" list choose datalog and below choose your account. Click plus button on the right and you should see the following:\\n\\n![Robonomics Chain State Datalog](../images/robonomics-dapp-chain-state-datalog.jpg \\\"Robonomics Chain State Datalog\\\")\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"87f99f3c87d2a3cafdd14dfc712aedfa\",\"title\":\"Raspberry Setup\",\"path\":\"/docs/es/raspberry-setup/\",\"content\":\"\\nFor both methods, the first thing you need to do is setup a Raspberry Pi.\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card and run the Imager program. From the menu, select 64-bit Ubuntu Server as the operating system and ensure to select your SD card from the storage dropdown, and then press `write`.\\n\\n![pi](../images/home-assistant/pi.png)\\n\\nOpen the SD card's storage from your computer and navigate inside the root folder of the card. The name of the folder should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Copy the below text and paste it into the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end (also you can use `arp -a`):\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\n\\nIn this example we can see that the Raspberry Pi's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\".\\n\\n## Home Assistant\\n\\nNow we need to install Home Assistant to the Raspberry Pi. Detailed instructions can be found [here](https://www.home-assistant.io/installation/linux#install-home-assistant-core). You need to install `Home Assistant Core`. It's actual version is 2021.11.5 and instruction assumes that we already have installed Python 3.9 or newer.\\n\\nUpdate your system and install necessary packages:\\n```bash\\nsudo apt-get update\\nsudo apt-get upgrade -y\\nsudo apt-get install -y python3 python3-dev python3-venv python3-pip libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 tzdata libcurl4-openssl-dev\\n```\\n\\nCreate user `homeassistant` and the directory for homeassistant core:\\n```bash\\nsudo useradd -rm homeassistant\\nsudo mkdir /srv/homeassistant\\nsudo chown homeassistant:homeassistant /srv/homeassistant\\n```\\n\\nNext up is to create and change to a virtual environment for Home Assistant Core. This will be done as the homeassistant account.\\n```bash\\nsudo -u homeassistant -H -s\\ncd /srv/homeassistant\\npython3.9 -m venv .\\nsource bin/activate\\n```\\n![terminal1](../images/home-assistant/terminal1.png)\\n\\nThen install required Python packages:\\n```bash\\npython3 -m pip install wheel\\npip3 install homeassistant==2021.11.5\\n```\\n\\nStart Home Assistant Core for the first time. This will complete the installation for you, automatically creating the `.homeassistant `configuration directory in the `/home/homeassistant` directory, and installing any basic dependencies:\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant$ hass\\n```\\n\\nYou can now reach your installation via the web interface on `http://%RASPBERRY_IP_ADDRESS%:8123`. \\nIn this example: `http://192.168.43.56:8123`\\n\\n> You don't need to connect you raspberry to the screen, you can open Web UI from any computer connected to your local network\\n\\nCreate user and finish setup (first setup is described [here](https://www.home-assistant.io/getting-started/onboarding/) in more details), then stop Home Assistant with `Ctrl+C`.\\n\\nAfter this installation process has been completed, from the `python_scripts` folder import some necessary scripts:\\n\\n```bash\\nmkdir python_scripts\\ncd python_scripts/\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/send_datalog.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/control.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/utils.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/create_config.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/encrypt.py\\n```\\n\\nTo use Robonomics you need account (instructions of how to create it are [here](/docs/create-account-in-dapp/)). Add mnemonic or raw seed from it in `config.config` file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\n\\nIn this format:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\n\\n## Substrate Interface\\n\\nTo pub data to Robonomics you need to install `substrate-interface` python package (you need to install RUST before) to your raspberry. \\n\\nInstall RUST:\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nsource $HOME/.cargo/env\\nrustup default nightly\\n```\\n\\nAnd install necessary python packages to the virtual environment:\\n```bash\\npip3 install pynacl==1.4.0 packaging pycurl\\npip3 install substrate-interface==1.1.2 --use-feature=2020-resolver\\npip3 install python-miio==0.5.8 --use-feature=2020-resolver\\n```\\nBe sure that you-re on virtual environment:\\n\\n![terminal1](../images/home-assistant/terminal2.png)\\n\\n## Systemd services\\n\\nNow change user (you can run under any user, which allows you to use sudo):\\n\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant/python_scripts$ exit\\n```\\n\\nCreate new service for home assistant start: \\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/home-assistant@homeassistant.service \\n```\\n\\nPaste the following:\\n\\n```\\n[Unit]\\nDescription=Home Assistant\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/hass -c \\\"/home/%i/.homeassistant\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nDo the same for robonomics control service:\\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/robonomics-control@homeassistant.service \\n```\\n\\nWith:\\n```\\n[Unit]\\nDescription=Robonomics Control\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/python3.9 \\\"/srv/%i/python_scripts/control.py\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nAnd enable both services:\\n```bash\\nubuntu@ubuntu:~$ sudo systemctl enable home-assistant@homeassistant.service\\nubuntu@ubuntu:~$ sudo systemctl enable robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\"}},{\"node\":{\"id\":\"2241d7840a25b7abfae563a851fb4d67\",\"title\":\"Setup with Prepared Image\",\"path\":\"/docs/es/raspberry-image/\",\"content\":\"## Image\\nWe prepared an image to make it easier to use the Home Assistant with Xiaomi Miio and Robonomics with the Raspberry Pi.\\n\\nYou can get it here: [download image](https://ipfs.io/ipfs/bafybeihzzqoyycflxzxlxy2aplkzxo537ggqatdlbr24b4dnlyrtpkp2eu)\\n\\nSHA256 checksum: `7ec5ea99d7e339b54cbeaaae58c8295411769d27732ec2b5464dbb495ba24120`\\n\\nWhat preinstalled in the image:\\n- Ubuntu Server 21.10 (3/4/400): 64-bit server OS for arm64 archtectures\\n- Python 3.9.7\\n- Home Assistant Core 2021.11.5\\n- rustc 1.59.0-nightly (efec54529 2021-12-04)\\n- substrate-interface 1.1.2\\n- python-miio 0.5.8\\n\\n## How To Use The Prepared Image\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Insert SD card into your PC and run the Imager program. In `Operating System` select `Use custom` and choose the previously downloaded `.img.gz` file. Then select your SD card in the `Storage` dropdown and click `WRITE`.\\n\\n![imager](../images/home-assistant/use_custom_image.png)\\n![imager](../images/home-assistant/imager_prep.png)\\n\\nAfter writing is comleted, open the SD card's files on your computer and navigate inside the root folder of the card. The name should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Write this to the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end:\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\nThere raspberry's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\". Then follow the instructions to change the password.\\n\\nThen you need to write the seed from your Robonomics account to config file. Open it:\\n```bash\\nsudo -u homeassistant -H -s\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add mnemonic:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\nThen restart Robonomics Control service:\\n```bash\\nsystemctl restart robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n\"}},{\"node\":{\"id\":\"1a5abeb66a29f3ab582304099ae8911e\",\"title\":\"R&D Based on Robonomics Network\",\"path\":\"/docs/es/r-and-d-based-on-robonomics-network/\",\"content\":\"\\nFor over 4 years, the Robonomics project participants completed 13 R&D projects in the process of writing the current version of the Robonomics platform, including:\\n\\n### Launching a drone under the control of a decentralized computer.\\n2016 - Successful field test of 3DR X8 drone compatibility with Drone Employee software.\\nBelow you can observe a workflow in which a person sends a Drone transaction through the Ethereum Blockchain.\\n\\nhttps://www.youtube.com/watch?v=V_3rcP2Duv0&t=1s\\n\\n### Management of a fleet of drones in a decentralized network.\\n[Distributed Sky](https://airmarket.io/wp-content/uploads/2018/09/Distributed-Sky-Whitepaper-v3.0.pdf) is the backbone of the Unmanned aircraft system traffic management (UTM). It uses a global network of computers to process and store identities, traffic and other sensitive information, and uses cryptography to make the UTM process secure and scalable.\\nBelow is the video of Drone Passport agent in action.\\n\\nhttps://www.youtube.com/watch?v=yxGTOkGkBJ8\\n\\n### Tokenization of data from IoT devices.\\n\\nThe 4th industrial revolution is flying the flag of CPSs’ total integration into mass production and rendering services. Machines do not engage in empty talk, they are honest in their work and can be an independent party supplying information, based on algorithmic analysis of which the network itself can emit new units of any value.\\nValues based on the labor of machines will be much more interesting for the new generation than other values, the emission of which is built on any other principle. More information available [here](https://blog.aira.life/tokenization-and-the-4th-industrial-revolution-3208022be747)\\n\\n### Digital markets for robots.\\n\\n### Industrial zone management with capital.\\n[The article](https://ieeexplore.ieee.org/abstract/document/8525391) presents the architecture of communication protocol for modern industrial processes and business based on cyber-physical systems - Industry 4.0. The main attention is paid to one of the key trends of this concept - to economical autonomous agents i.e. to robots or smart things, which are able to make decisions independently about their economic actions. Agents begin to fully participate in business processes, so it is important to automate the processes and ensure formal and secure communication between multiple heterogeneous agents, taking into account the economic component of the industry. The article shows how to organize economic interaction between agents using a peer-to-peer network based on decentralized Blockchain technology and smart contracts. More information about Industry 4.0 may be found in a video below.\\n\\nhttps://www.youtube.com/watch?v=yuxOF_z70us\\n\\n### Drones, sensors, and blockchain for monitoring the quality of water on the Volga.\\nAs part of [this river project](https://github.com/airalab/drone_on_volga), the drone offers its services through a web application allowing any user to request the service. Typically, the mission generates parameters such as drone position, travel speed, measured water quality parameters, and other minor requirements.\\nThe Robonomics network is used to communicate with the robot. With its help, the robot can offer its services, and citizens or government officials can order them by making a cryptocurrency payment through the website. The Robonomics network is built on the Ethereum blockchain platform and the IPFS protocol, which record the hash of sensor measurements in the public blockchain and thus protect historical data from possible falsification.\\nFascinating video about experiments with water drone is below.\\n\\nhttps://www.youtube.com/watch?v=Mtqm5y6Bolo\\n\\n### Civilian observatory networks.\\nIn August 2018 Airalab with support of Smart Distribution (Libelium distributor in Russia) [set up a measuring network in a living district in Tolyatti, Russia](https://www.libelium.com/libeliumworld/success-stories/preventing-asthsma-sensor-network-air-quality-pm10-dust-in-play-area/).\\nThe aim was to create the basis for the implementation of an air quality monitoring network in areas of special vulnerability (schools, playgrounds, nursing homes, hospitals, etc.) that can provide local authorities with information to take measures to protect their citizens.\\nAn example of using a sensor is shown in a video below. Also, source code may be found [here](https://github.com/airalab/sensors-connectivity).\\n\\nhttps://www.youtube.com/watch?v=shqey3tmNUk\\n\\n### Robot artist Gaka-chu.\\nModern technologies make human life more comfortable and more fun, freeing up time for reflection and experimentation.\\nIt was a series of reflections on the static nature of the industry that led the development team to the idea of ​​conducting an experiment showing the autonomous transformation of production for a specific type of product.\\nSuch an experiment became a [robot artist](https://github.com/airalab/robot_painter/) - a small, clumsy KUKA manipulator living in a large world of serious industrial robots. And his name is Gaka-chu. Why? Because of the love of drawing: \\\"gaka\\\" in Japanese is \\\"artist\\\". And \\\"chu\\\" was added for an inexplicable love for Pokemons.\\n\\nhttps://youtu.be/xSD_lsrAA0I\\n\\n### Issuance of green certificates based on the data from renewable energy sources.\\nThe conceptual goal of [DAO IPCI](https://ipci.io/ru/) is to provide a common space, common environment, tools and ecosystem that is universal, reliable, easy to use, allowing a variety of stakeholders, including businesses and people, to record quantitative impacts and quantitative commitments, invest in negative impact mitigation projects, offset the carbon footprint, acquire and trade mitigation results, join existing programs or launch new ones. Source code is provided [here](https://github.com/DAO-IPCI/DAO-IPCI).\\n\\nhttps://www.youtube.com/watch?v=q9plB0TjUnw&list=PLLepqB9oh7WvUVzbeaiwQojrip2tLPA6P\\n\\n### Roadspace negotiation for autonomous cars.\\nOur goal was to develop a [decentralized system](https://github.com/khssnv/mobi_grand_challenge) for road space negotiation where autonomous vehicles can pay for routes and right of way. We believe a market-based approach can be used to alleviate a traffic congestion problem.\\n\\nhttps://youtu.be/JFQTknMZOYg\\n\\n### Blockchain in the tasks of the chemical industry.\\nOriginally the following task was set: developing a [quality control system](https://github.com/Vourhey/chemistry-quality-control) for the production of a certain chemical product. Why is monitoring the quality so important here? The main active substance of this chemical product is chlorine dioxide. It is hazardous to health in high concentrations. And if the concentration is below normal, then this chemical product is useless.\\nAnd what does Blockchain have to do with it? Blockchain helps building trust to the manufacturing company. The consumer knows that no one can change the information in the Blockchain. That means that the manufacturing company can not forge the results of the audit.\\n\\n### Control of equipment maintenance process by supply chain participants based on IoT data.\\n\\n### Robot as a service in service robotics.\\nRobonomics is the ready-to-work and open-source platform which you can use to connect your robot as a service for end-users, they call it [‘Robot-as-a-Service’](https://blog.aira.life/how-can-you-hire-a-robot-176ba29da565). Robonomics support Web3 technologies that implement the exchange of technical and economic information between humans and machines. Robonomics is a purely technical and open source project.\\n\\nhttps://www.youtube.com/watch?v=IEgvXcj3nSo\"}},{\"node\":{\"id\":\"acf573ae9783f464eb74aeeadbbfbd64\",\"title\":\"Playground Overview\",\"path\":\"/docs/es/playground-overview/\",\"content\":\"\\nRobonomics allows to use robots as autonomous agents that receive commands from a human or another robot and do some useful work, storing a report of their actions in Blockchain. The interaction between the robot and the Robonomics platform is quite simple with a [Robonomics IO](/docs/rio-overview).\\n## What Robots You Can Control\\nThe playground section contains examples of connecting different robots to Robonomics which everyone can try to repeat step by step. In this section you can try to control:\\n* [an Unmanned Aerial Vehicle](/docs/iris-drone/)\\n* [a Mars Rover](/docs/connect-mars-curiosity-rover-under-robonomics-parachain-control/)\\n* [a Manipulator](/docs/kuka/)\\n* [an industrial Baxter Robot](/docs/baxter2/)\\n\\nSince all robots are available as simulation models, you don't need any special hardware. So you can try to connect the robot to Robonomics Network right now.\\n## How Do You Control the Robot\\nAll of our Demos are launched in a local network, however you can connect a robot to the live networks in the same way.\\n\\nAll Demos in this section follow a similar scenario. You [create an account](/docs/create-account-in-dapp/) for the robot and send him some units for paying transactions. Then the user sends an `ON/OFF` transaction to the robot's address, the robot receives it and starts working. After the job is done the telemetry is saved in IPFS and the file hash is sent to datalog. So at any time you can see how the robot performed its work.\\n## Connect Your Own Robot\\nIn addition you can create your own control package for any ROS-compatible device with [this](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) instruction.\\n\\n\"}},{\"node\":{\"id\":\"34476dbf1a4ed87df72a1262ab4f9d5e\",\"title\":\"Market messages\",\"path\":\"/docs/es/market-messages/\",\"content\":\"\\nMarket messages is used for exchange **Demand** and **Offer** information. It also used for delivery **Result** messages with liability execution reports.\\n\\n> This is spec for Robonomics `Generation 5`.\\n\\n- Currently for message delivery is used [IPFS PubSub](https://ipfs.io/blog/25-pubsub/) broadcaster.\\n- IPFS PubSub **topic** is set according to *Lighthouse [ENS](https://ens.domains/) name*.\\n\\n## Messages content\\n\\nRobonomics market message use [JSON](https://www.json.org/) data format.\\n\\n\\n### Demand\\n\\n| Field | ROS Type | Description |\\n|-------------- |-------------------------  |------------------------------------------------ |\\n| model | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model identifier |\\n| objective | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model parameters in rosbag file |\\n| token | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Operational token address |\\n| cost | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | CPS behavioral model execution cost |\\n| lighthouse | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Lighthouse contract address |\\n| validator | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Observing network address |\\n| validatorFee  | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Observing network fee |\\n| deadline | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Deadline block number |\\n| nonce | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Robonomics message counter |\\n| sender | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Message sender address |\\n| signature | std_msgs/UInt8[] | Sender’s Ethereum signature |\\n\\n### Offer\\n\\n| Field             | ROS Type                  | Description                                       |\\n|---------------    |-------------------------  |------------------------------------------------   |\\n| model             | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model identifier                   |\\n| objective         | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    |\\n| token             | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Operational token address                         |\\n| cost              | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | CPS behavioral model execution cost               |\\n| validator         | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Observing network address                         |\\n| lighthouse        | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Lighthouse contract address                       |\\n| lighthouseFee     | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Liability creation fee                            |\\n| deadline          | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Deadline block number                             |\\n| nonce             | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Robonomics message counter                        |\\n| sender            | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Message sender address                            |\\n| signature         | std_msgs/UInt8[]          | Sender’s Ethereum signature                       |\\n\\n### Result\\n\\n| Field         | ROS Type                  | Description                       |\\n|-----------    |-------------------------  |---------------------------------- |\\n| liability     | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Liability contract address        |\\n| result        | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | Liability result multihash        |\\n| success       | std_msgs/Bool             | Is liability executed successful  |\\n| signature     | std_msgs/UInt8[]          | Sender’s Ethereum signature       |\\n\\n## Messages signing\\n\\nBefore signing the messages is packed using [abi.encodePacked](https://solidity.readthedocs.io/en/latest/abi-spec.html#non-standard-packed-mode\\n) solidity finction and hashed by Keccak_256.\\n\\n```\\n   demandHash = keccak256(abi.encodePacked(\\n        _model\\n      , _objective\\n      , _token\\n      , _cost\\n      , _lighthouse\\n      , _validator\\n      , _validator_fee\\n      , _deadline\\n      , IFactory(factory).nonceOf(_sender)\\n      , _sender\\n      ));\\n```\\n\\n**`nonce` parameter is counted by factory smart contract and incremented for each created liability smart contract.**\\n\\nMessage hash are signed using Ethereum ``secp256k1`` [signature](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sign).\\n\"}},{\"node\":{\"id\":\"65a7879062175f4faae1d80dd6bcb90e\",\"title\":\"Control Kuka manipulator with robonomics\",\"path\":\"/docs/es/kuka/\",\"content\":\"\\nVideo with an example of work can be found here:\\n\\nhttps://youtu.be/z55HepXbHr8\\n\\n***\\n\\n## Requirements\\n* ROS melodic, Gazebo (installation instraction [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n* Some extra packages\\n```bash\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n* IPFS 0.4.22 (download from [here](https://www.npackd.org/p/ipfs/0.4.22) and install)\\n```bash\\ntar -xvzf go-ipfs_v0.4.22_linux-386.tar.gz\\ncd go-ipfs/\\nsudo bash install.sh\\nipfs init\\n```\\n* pip3\\n```bash\\nsudo apt-get install python3-pip\\n```\\n* ipfshttpclient\\n```bash\\npip3 install ipfshttpclient\\n```\\n* substrate-interface\\n```bash\\npip3 install substrate-interface\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n* IPFS browser extension (not necessary)\\n***\\n## Installation\\nInstall Kuka manipulator and control packages\\n```bash\\ncd catkin_wc/src/\\ngit clone https://github.com/orsalmon/kuka_manipulator_gazebo\\ngit clone https://github.com/LoSk-p/kuka_controller\\ncd ..\\ncatkin_make\\n```\\n***\\n## Running gazebo model\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch manipulator_gazebo manipulator_empty_world.launch\\n```\\nIn a new window\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun manipulator_gazebo move_arm_server\\n```\\n![model](../images/kuka-demo/1.png)\\n***\\n## Running robonomics\\nGo to the folder with robonomics file ad create a local robonomics network:\\n```bash\\n./robonomics --dev --tmp\\n```\\n\\n![robonomics](../images/kuka-demo/robonomics.png)\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node\\n\\n![local](../images/kuka-demo/local.png)\\n\\nThen go to Accounts and create `KUKA` account. Save account's mnemonic key, you will need it later. \\n\\n![acc](../images/kuka-demo/create_acc.png)\\n\\nSend some units to the new account from one of default accounts.\\n\\n![accs](../images/kuka-demo/send_money.png)\\n***\\n## Running ipfs\\nRun ipfs daemon:\\n```bash\\nipfs daemon\\n```\\n***\\n## Running control package\\nIn config directory in kuka_control package you need to create config file with this lines, where `<your_mnemonic>` is saved mnemonic seed:\\n```bash\\n{\\n    \\\"kuka_mnemonic\\\": \\\"<your_mnemonic>\\\",\\n    \\\"node\\\": \\\"ws://127.0.0.1:9944\\\"\\n}\\n```\\n\\nNow you can run control script:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun kuka_controller move_arm_client.py\\n```\\n![control](../images/kuka-demo/run.png)\\n\\n## Sending transaction\\nIn [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) go to `Developer/Extrinsics`, change `extrinsic` to `launch`. Chose your `KUKA` account in `robot` and change `param` to `Yes`. The press `Submit Transaction`\\n\\n![transaction](../images/kuka-demo/launch.png)\\n\\nIn the window with kuka_control package you will see:\\n\\n![done](../images/kuka-demo/res.png)\\n\\nThen go `Developer/Chain State` on the Robonomics portal, select `datalog` and `datalogItem((AccountId,u64)): RingBufferItem` in query and add `KUKA` datalog with button '+':\\n\\n![datalog](../images/kuka-demo/datalog.png)\\n\\nNow you can find robot's telemetry in IPFS via this link with your hash `https://gateway.ipfs.io/ipfs/<hash>`.\\n\\n## Troubleshooting\\n\\nIf `catkin_make` doesn't work with the message that it can't find MoveArm.h, try to remove last four lines in CMakeLists.txt in kuka_manipulator_gazebo package:\\n```\\ninclude_directories(include ${catkin_INCLUDE_DIRS})\\n\\nadd_executable(move_arm_server src/move_arm_server.cpp)\\ntarget_link_libraries(move_arm_server ${catkin_LIBRARIES})\\nadd_dependencies(move_arm_server beginner_tutorials_gencpp)\\n```\\nDo `catkin_make` without these lines, then returm them and do `catkin_make` again.\\n\"}},{\"node\":{\"id\":\"39a3cb11b7ee382066ce4aa3ad1b6a2b\",\"title\":\"Drone control with robonomics\",\"path\":\"/docs/es/iris-drone/\",\"content\":\"\\n**Drone starts moving after transcation and store file with the coordinates in IPFS. The control script is based on the [GAAS demo script](https://github.com/generalized-intelligence/GAAS)**  \\n\\nhttps://youtu.be/4CwtGAX1OwM\\n\\n## Requirements\\n* dependencies for control:\\n``` sh\\nsudo apt install -y \\\\\\n\\tpython3-pip \\\\\\n\\tninja-build \\\\\\n\\texiftool \\\\\\n\\tpython-argparse \\\\\\n\\tpython-empy \\\\\\n\\tpython-toml \\\\\\n\\tpython-numpy \\\\\\n\\tpython-yaml \\\\\\n\\tpython-dev \\\\\\n\\tpython-pip \\\\\\n\\tninja-build \\\\\\n\\tprotobuf-compiler \\\\\\n\\tlibeigen3-dev \\\\\\n\\tgenromfs\\n```\\n```sh \\npip3 install \\\\\\n\\tpandas \\\\\\n\\tjinja2 \\\\\\n\\tpyserial \\\\\\n\\tcerberus \\\\\\n\\tpyulog \\\\\\n\\tnumpy \\\\\\n\\ttoml \\\\\\n\\tpyquaternion\\n```\\n* ROS Melodic + Gazebo [installation tutorial](http://wiki.ros.org/melodic/Installation)\\n* extra packages: \\n``` bash \\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\nsudo apt-get install python-jinja2\\nsudo apt-get install python-catkin-pkg\\nsudo apt-get install python3-catkin-pkg-modules\\n```\\n* IPFS verson 0.4.22\\n```bash\\nwget https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-amd64.tar.gz\\ntar -xvzf go-ipfs_v0.4.22_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh\\nipfs init\\n```\\n* ipfshttpclient\\n```sh\\npip3 install ipfshttpclient\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n## Environment Setup\\n```bash \\nsudo apt-get install ros-melodic-mavros ros-melodic-mavros-extras\\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\\nsudo ./install_geographiclib_datasets.sh\\ncd ~/catkin_ws/src\\ngit clone https://github.com/PX4/Firmware.git\\ncd Firmware\\ngit checkout v1.9.0\\nbash ./Tools/setup/ubuntu.sh\\n```\\n```bash\\ncd ~/catkin_ws/src\\ngit clone https://github.com/generalized-intelligence/GAAS.git\\ncp -r ~/catkin_ws/src/GAAS/simulator/models/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/models/\\ncp -r ~/catkin_ws/src/GAAS/simulator/worlds/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/worlds/\\ncp -r ~/catkin_ws/src/GAAS/simulator/posix-config/* ~/catkin_ws/src/Firmware/posix-configs/SITL/init/ekf2/\\n```\\n\\nModifying your `.bashrc` file, adding the following lines to the bottom:  \\n\\n`source ~/catkin_ws/devel/setup.bash `  \\n`source ~/catkin_ws/src/Firmware/Tools/setup_gazebo.bash ~/catkin_ws/src/Firmware/ ~/catkin_ws/src/Firmware/build posix_sitl_default `   \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware/Tools/sitl_gazebo`  \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models:~/catkin_ws/src/GAAS/simulator/models`  \\n\\n  \\n## Control Package Installation\\nIn a new Terminal:\\n```bash\\ncd catkin_ws/src\\ngit clone https://github.com/tubleronchik/robonomics_drone_sim.git\\ncd ..\\ncatkin build\\n```\\n## Robonomics Network\\nTo create a local robonomics network go to the folder with the robonomic binary file and run:  \\n`./robonomics --dev --rpc-cors all`  \\n\\nAdd robonomic's path to `config.py`\\n\\n![IPFS](../images/iris-drone-demo/IPFS.jpg)\\n\\nGo to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node.\\n![localNode](../images/iris-drone-demo/localNode.jpg)\\n\\nGo to **Accounts** and create **DRONE** and **EMPLOYER** accounts. Save the account names and keys and path to **robonomics** to `~/catkin_ws/src/drone_sim/src/config.py`. Transfer some money into the accounts.\\n\\n![accounts](../images/iris-drone-demo/addingAcc.jpg)\\n\\n## Running Simulation\\nRun IPFS daemon\\n```bash\\ncd go-ipfs\\nipfs daemon\\n```\\nIn another terminal launch the simulation:\\n```bash\\nroslaunch px4 mavros_posix_sitl.launch\\ncd ~/catkin_ws/src/robonomics_drone_sim/src\\npython3 takeoff.py\\n```\\nWaiting till \\\"Waiting for payment\\\" \\n\\n![launch](../images/iris-drone-demo/launch.jpg)\\n\\nTo send a transaction run in another window:\\n`echo \\\"ON\\\" | ./robonomics io write launch -r <drone_addres> -s <employer_key>` - where **<drone_address>** and **<employer_key>** should be replaced with the strings from `config.py` accordingly.\\n\\nAfter data was pushed to IPFS, go to the **Chain State** in [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/). Select **datalog** in query and add DRONE datalog using `+` button.\\n\\n![datalog](../images/iris-drone-demo/datalog.jpg)\\n\\nYou can find drone's telemetry running `https://gateway.ipfs.io/ipfs/<hash>` inserting the hash from above.\\n\\n![output](../images/iris-drone-demo/output.jpg)\\n\\nIt's important to remove `db` derictory before next launches using  \\n` rm -rf ~/.local/share/robonomics/chains/dev/db`\\n\"}},{\"node\":{\"id\":\"ccf722d51a19b02425c149e5d13c1d07\",\"title\":\"IPFS Common\",\"path\":\"/docs/es/ipfs-common/\",\"content\":\"\\nThe package handle IPFS connections, provides useful services for working with IPFS Network. \\nIt's included in `robonomics_liability` launch file\\n\\n## ROS Parameters\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_file_providers\\n\\nA list of public nodes to pin result files. The type is `list of strings`, defaults to `[ipfs_public_providers]`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_swarm_connect_to\\n\\nA list of IPFS nodes to connect to. The type is `list of strings`, defaults to `[ipfs_swarm_connect_addresses]`\\n\\n## Subscribed topics\"}},{\"node\":{\"id\":\"23f5dc4e60e2a57bd6fc99d65bb5c9eb\",\"title\":\"IPFS Common Messages\",\"path\":\"/docs/es/ipfs-common-messages/\",\"content\":\"\\n## ipfs_common/Filepath.msg\\n\\n| Field         | Type                  | Description           |\\n|------------   |-------------------    |--------------------   |\\n| filepath      | std_msgs/String       | A path to a file      |\\n\\n## ipfs_common/Multihash.msg\\n\\n| Field         | Type              | Description                               |\\n|-----------    |-----------------  |------------------------------------------ |\\n| multihash     | std_msgs/String   | A wrapper for model and objective fields  |\\n\\n## ipfs_common/IpfsDownloadFile.srv\\n\\n**Request**\\n\\n| Field         | Type                                                  | Description               |\\n|-------------- |---------------------------------------------------    |------------------------   |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of a file       |\\n| file          | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)       | Where to save the file    |\\n\\n**Response**\\n\\n| Field         | Type              | Description           |\\n|-----------    |-----------------  |---------------------  |\\n| success       | std_msgs/Bool     | Status of execution   |\\n| error_msg     | std_msgs/String   | Error message         |\\n\\n## ipfs_common/IpfsUploadFile.srv\\n\\n**Request**\\n\\n| Field     | Type                                              | Description                               |\\n|-------    |-------------------------------------------------  |---------------------------------------    |\\n| file      | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)   | Path to a file to be uploaded to IPFS     |\\n\\n**Response**\\n\\n| Field         | Type                                                  | Description                   |\\n|-------------- |---------------------------------------------------    |----------------------------   |\\n| success       | std_msgs/Bool                                         | Status of execution           |\\n| error_msg     | std_msgs/String                                       | Error message                 |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of uploaded file    |\\n\"}},{\"node\":{\"id\":\"b35c34fd1b2448efc33573e17cccfe83\",\"title\":\"IoT Sensors Connectivity\",\"path\":\"/docs/es/iot-sensors-connectivity/\",\"content\":\"\\nRobonomics Network allows you to communicate with any sensor you wish and get data from the sensor all around the world. This data can be transferred to different destinations.\\n\\nOn this page you'll find step-by-step instructions to connect an ESP board to the connectivity server provided by AiraLab.\\n\\n## Requirements\\n\\n* ESP8266/ESP32 like board with WiFi\\n\\n## 1. Get the software\\n\\n### On Windows\\n\\nInstall [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\\n\\nInstall Ubuntu via Windows Store:\\n\\n![Windows Store](../images/windows_store.jpg \\\"Windows Store\\\")\\n\\nand clone the [package](https://github.com/airalab/sensors-connectivity)\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\n```\\n\\nThe next step is to install python and dependencies:\\n\\n```\\nsudo apt update && sudo apt install python3-pip\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n### On Ubuntu\\n\\n```\\nsudo apt update && sudo apt install python3-pip git\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n> You can ignore such warnings:\\n>\\n> ```\\n> The script ... is installed in '...' which is not on PATH.\\n> Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\n> ```\\n\\n### On NixOS\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\nnix build -f release.nix\\nsource result/setup.bash\\n```\\n\"}},{\"node\":{\"id\":\"c793a529194bc3d18d4ec28793c480fb\",\"title\":\"IoT Firmware Upload\",\"path\":\"/docs/es/iot-firmware-upload/\",\"content\":\"\\nThere are few firmwares for ESP like boards:\\n\\n* [Ping](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/ping)\\n* [TCP](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/tcp)\\n* [Mobile GPS](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/mobile_gps)\\n\\nThere is a script to upload a firmware for each one, called `flash_firmware.py`. It's located in the root of the repository\\n\\n> **Requirements**\\n> In order to install all dependencies run in the root of the repository folder:\\n>\\n> ```\\n> pip install -r requirements.txt\\n> ```\\n>\\n> Python3 is required!\\n\\nUsually in order to upload a firmware to your board follow these steps:\\n\\n1. Assemble the board and connect it to PC\\n2. Edit a `config.yaml` in a corresponding folder (e.g. `boards/esp/tcp/config.yaml`)\\n3. Run `python flash_firmware.py -s PATH_TO_FOLDER -c PATH_TO_CONFIG` where `PATH_TO_FOLDER` is a path to the desired firmware (e.g. `boards/esp/ping`) and `PATH_TO_CONFIG` is a path to the configuration file (e.g. `boards/esp/ping/config.yaml`)\\n\\n\"}},{\"node\":{\"id\":\"134170379c560c22dfe0da7a9f4d601e\",\"title\":\"Interactuar con AIRA\",\"path\":\"/docs/es/interact-with-aira/\",\"content\":\"\\nEn este punto, debe estar familiarizado con una [DApp](/docs/get-weather-on-fuji-mountain/) y cómo iniciar [la imagen AIRA](/docs/aira-installation-on-vb/). Ahora está listo para hacer cosas más complicadas como instalar un paquete e interactuar con él a través de DApp.\\n\\n> **Importante:**\\n> asegúrese de haber cubierto las lecciones anteriores antes de continuar.\\n\\n\\n> **Consejo:**\\n> durante la lección, escribirás algunos comandos en la terminal. La imagen AIRA no es compatible con el portapapeles, por lo que, para facilitar la vida, eche un vistazo a [Connect via SSH](/docs/aira-connecting-via-ssh/) e inicie sesión a través de SSH en la VM\\n\\nVideo tutorial:\\n\\nhttps://www.youtube.com/embed/QM06l07_wuA\\n\\n## Instalación del Paquete\\n\\nDespués de iniciar AIRA e iniciar sesión con su terminal, haga lo siguiente:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nEjecute uno por uno los comandos anteriores. Después del último, debería ver un enlace a DApp generado específicamente para su instancia.\\n\\n![Terminal con AIRA](../images/aira_hello_terminal.jpg \\\"Terminal con AIRA\\\")\\n\\nHaga clic en el enlace, debería mostrarse la DApp.\\n\\n## DApp \\n\\nConecte [MetaMask](http://metamask.io/) si se le solicita y haga clic en el botón.\\n\\n![Solicitar conexión en Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Solicitar conexión en Robonomics Dapp\\\")\\n\\nFirme el mensaje como de costumbre y espere el resultado.\\n\\n![Espere el resultado de la solicitud](../images/aira_hello_dapp_2.jpg \\\"Espere el resultado de la solicitud\\\")\\n\\nMientras tanto, echa un vistazo a la terminal. Deberías ver el saludo.\\n\\n![Saludo de AIRA en la terminal](../images/aira_hello_terminal_2.jpg \\\"Saludo de AIRA en la terminal\\\")\\n\\nAl final aparecerá el saludo en la DApp.\\n\\n![Saludo de la DApp de Robonomics para AIRA](../images/aira_hello_dapp_3.jpg \\\"Saludo de la DApp de Robonomics para AIRA\\\")\\n\\n## Solución de Problemas\\n\\n### Usted haga click en “Request Current Values” pero no ve el saludo\\n\\nProbablemente acaba de lanzar AIRA e IPFS no ha terminado de inicializarse. Espere un minuto y vuelva a intentarlo.\\n\\n### Si ves el Hash de respuesta pero los datos no aparecen\\n\\nLo más probable es que el problema provenga de la conexión IPFS. Haga clic en hash y verá el resultado. No es necesario descargar el archivo.\\n\\n## Tarea para el Hogar (Opcional)\\n\\nSi está familiarizado con [Python](https://www.python.org/), cambie el texto mostrado por algo diferente y complete la lección con su versión de `hello_aira`\\n\\n- Haz una bifurcación del [repositorio](https://github.com/vourhey/hello_aira)\\n- El texto de salida se encuentra [aquí](https://github.com/Vourhey/hello_aira/blob/master/scripts/hello_aira#L45)\\n\"}},{\"node\":{\"id\":\"df82612684f2641c2f206a4dbfd2c5e7\",\"title\":\"How to launch the Robonomics collator\",\"path\":\"/docs/es/how-to-launch-the-robonomics-collator/\",\"content\":\"\\nNote: In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is maintained by developers, but anyone can support the project. Every additional full node of the blockchain helps it to be more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it could be [built from source](/docs/how-to-build-collator-node/).\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nBut we recommend that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need use *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can simply launch a collator directly in the command line to check for errors.\\nAfter that we strongly recommend to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](../images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](../images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with : `journalctl -u robonomics.service -f` \\n\\nNow the robonomics collator is launched it will sync with the Kusama Relay Chain, this can take up quite some time depending on your network speed and system specifications, so we recommend to download a Kusama snapshot and use it. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the robonomics service. You can find more info about snapshots and usage instructions on the followin page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](../images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](../images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\"}},{\"node\":{\"id\":\"0d2d79e9cd354e38242b80de0e339be0\",\"title\":\"How to build collator node from source\",\"path\":\"/docs/es/how-to-build-collator-node/\",\"content\":\"\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](../images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v1.4.0:\\n\\n```\\n  rustup install nightly-2021-11-02\\n```\\n![Install nightly](../images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2021-11-02\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2021-11-02\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v1.4.0 robonomics-node\\n```\\n![Start build Robonomics](../images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](../images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"}},{\"node\":{\"id\":\"458be7ff8e857b8bd7b88bf79498a1b1\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/es/home-assistant-begin/\",\"content\":\"There are instructions on how to connect your smart home devices to the Robonomics network. You need Robonomics [accounts](/docs/create-account-in-dapp/) for each device, they will publish encrypted data in datalog. Also you need user account that will send commands to devices end encrypt/decrypt data.\\n\\nIn this video you can see the example of connecting temperature sensor:\\n\\nhttps://youtu.be/iB2Z8HtERgs\\n\\n# Requirements\\n\\n* Raspberry Pi 4 or 3\\n* SD card and SD adapter\\n* Temperature sensor - [Keen Home RS-THP-MP-1.0](https://www.zigbee2mqtt.io/devices/RS-THP-MP-1.0.html) (or another [supported device](https://www.zigbee2mqtt.io/information/supported_devices.html))\\n\\n### Method 1 (with SLS Gateway)\\n* [Robonomics SLS Gateway](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01)\\n\\n### Method 2 (with zigbee2MQTT)\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\n### Method 3 (with Xiaomi Gateway)\\n* Xiaomi Gateway (one of [supported](https://www.home-assistant.io/integrations/xiaomi_miio#xiaomi-gateway))\\n* [Mi Home app](https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&hl=ru&gl=US) or HomeKit app\\n\\nAlso you can connect some devices directly through Mi Home app (for example, Vacuum Cleaner).\\n\\n# Setup\\n\\n1. First you need to [setup Raspberry Pi](/docs/raspberry-setup/) (also you can [use prepared image](/docs/raspberry-image/)).\\n2. Then you need to connect devices to Home Assistant:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n3. And [connect them to Robonomics Network](/docs/add-smart-device-to-robonomics/).\\n\"}},{\"node\":{\"id\":\"3f4e86f7e342d09f48dccf5d8bbdc8ca\",\"title\":\"Passing dynamic parameters\",\"path\":\"/docs/es/hardware-passing-dynamic-parameters/\",\"content\":\"\\nIn [previous](/docs/connect-simple-cps/) example we discussed how to create a simple CPS with Arduino. Our first CPS is able to do only one task: to blink a led. We suggest you to get through the first lesson. Now let's expand the example and teach our board to blink blue or red led depending on objective parameter.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_with_args).\\n\\n\\n## Arduino\\n\\nThe only difference in Arduino source code is instead of subscribing to one topic now we subscribe to `/blink_red` and `/blink_blue` topics\\n\\n```c\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void blinkRedCb(const std_msgs::Empty& msg) {\\n    blink(13, 500);\\n    blink(13, 500);\\n    blink(13, 500);\\n  }\\n\\n  void blinkBlueCb(const std_msgs::Empty& msg) {\\n    blink(12, 500);\\n    blink(12, 500);\\n    blink(12, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> subRed(\\\"blink_red\\\", &blinkRedCb);\\n  ros::Subscriber<std_msgs::Empty> subBlue(\\\"blink_blue\\\", &blinkBlueCb);\\n\\n  void setup()\\n  {\\n    pinMode(13, OUTPUT);\\n    pinMode(12, OUTPUT);\\n\\n    nh.initNode();\\n    nh.subscribe(subRed);\\n    nh.subscribe(subBlue);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n<!-- Here is the diagram of all connections:\\n\\n.. image:: ../img/6.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\n\\n## ROS\\n\\nWe can pass arguments via objective which points to rosbag file. Have a look at `blink.py` script. The main difference is `blink()` method:\\n\\n```python\\ndef blink(self, data):\\n  if data.data == \\\"blue\\\":\\n      rospy.loginfo(\\\"Blinking blue...\\\")\\n      self.blink_blue.publish(Empty())\\n\\n  if data.data == \\\"red\\\":\\n      rospy.loginfo(\\\"Blinking red...\\\")\\n      self.blink_red.publish(Empty())\\n\\n  rospy.wait_for_service('/liability/finish')\\n  fin = rospy.ServiceProxy('/liability/finish', FinishLiability)\\n  fin(FinishLiabilityRequest(address=self.liability, success=True))\\n  rospy.loginfo(\\\"Finished\\\")\\n```\\n\\nNow `/blink` topic has a `String` type. You can find prepared rosbags in `rosbag` folder.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh/). Do not forget to add `COM1` port in settings. Run the following command:\\n\\n```\\n$ rosrun arduino_with_args blink.py\\n```\\n\\nAlso we need to add rosbag files to IPFS:\\n\\n```\\n$ ipfs add rosbag/blink_blue.bag\\n$ ipfs add rosbag/blink_red.bag\\n```\\n\\n**Before the next step you should approve XRT tokens on the Factory.**\\n\\nThe last step is to build Dapp and launch. Take a look at the previous [lesson](/docs/connect-simple-cps/). To make Arduino blink the blue led send blue demand and blue offer messages. For the red one send corresponding messages.\\n\\nThat's it! Now you are able to pass dynamic parameters to your cyber-physical system agent!\"}},{\"node\":{\"id\":\"9a3670eb9c42666458e7899b9ed4ee7d\",\"title\":\"Connect an Air Pollution Sensor\",\"path\":\"/docs/es/hardware-connect-sensor/\",\"content\":\"\\nIn this lesson you are going to learn how to connect your sensor to the network and make it publish data. You will see how it is easy to become a member of a global sensor network!\\n\\nSource code is located [here](https://github.com/airalab/robonomics_tutorials/tree/master/sensor_city).\\n\\nIn this section we are not going to create a liability contract. Instead we will teach Arduino with sensors to publish the data by a request. All measurements will be published as a Result message.\\n\\n## Arduino\\n\\nLet's begin with an Arduino circuit. You need the following components:\\n\\n* Arduino Uno\\n* Optical Dust Sensor Sharp GP2Y1010AU0F\\n* Gas Sensor MQ-2\\n* Gas Sensor MQ-7\\n* Resistor 150 Ohm\\n* Capacitor 220 uF\\n* Wires\\n\\nConnect all parts as described below:\\n\\n<!-- .. image:: ../img/7.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\nA firmware for Arduino Uno is in `sensor_city/scetches` folder. In order to upload it to the board use [Arduino IDE](https://www.arduino.cc/en/Main/Software).\\n\\n<!-- .. image:: ../img/8.png\\n   :alt: Arduino IDE\\n   :align: center\\n -->\\n\\n## Aira\\n\\nThe following steps are performed in Aira client. You can download the latest image from [this page](https://github.com/airalab/aira/releases). It's convenient to [connect via SSH](/docs/aira-connecting-via-ssh/).\\n\\nAfter you have imported the image to VirtualBox, connect Arduino via USB to your PC and enable serial port forwarding. You should check `Enable Serial Port` and assign `/dev/ttyACM0` in `Path/Address`. Inside the virtual machine `/dev/ttyS0` refers to your external Arduino.\\n\\n<!-- .. image:: ../img/9.png\\n   :alt: Set a port\\n   :align: center -->\\n\\nFinally launch the image and run these command:\\n\\n```\\n$ roslaunch sensor_city publish_data.launch\\n```\\n\\n**Check out the source code to learn how it works under the hood!**\\n\\nNow Aira patiently waits for a signal to publish the measurements. Go to [Dapp](https://dev.aira.life/smart-city/#/) and click on `Broadcast signal`. You should see the data!\"}},{\"node\":{\"id\":\"e390cc4cb37a25af354af247113244df\",\"title\":\"Glossary\",\"path\":\"/docs/es/glossary/\",\"content\":\"\\n## Agent\\n\\nIn terms of Robonomics Network agent is a program module that uses IPFS or blockchain or both interfaces of the network and does some actual work.\\nUsually it's represented as a ROS package and it may connect (but not necessarily) a real cyber-physical system to the Robonomics Network.\\n\\n## Cyber-physical system\\n\\nIt is a combination of a physical mechanism that is usually called a robot and a program algorithm that controls the behavior of the mechanism.\\n\\n## Dapp\\n\\nIt is a short form for Decentralized application. Usually it is a single page web based application that helps to interact with an agent.\\n\\n## IPFS\\n\\nAccording to the official [documentation](https://docs.ipfs.io/introduction/) \\\"IPFS is a distributed system for storing and accessing files, websites, applications, and data\\\".\\nFor more detail how it works go to the official website.\\n\\n## Lighthouse\\n\\nA lighthouse is an autonomous workflow that allows us to distribute the running time of providers that serve a single broadcast channel.\\n\\nFor more information read [Robonomics Whitepaper](https://static.robonomics.network/docs/whitepaper/Robonomics-whitepaper-en.pdf) section 5.2.\\n\\n## Sidechain\\n\\nEthereum based blockchain network with Proof-of-Authority consensus owned by Airalab.\\n\\n\"}},{\"node\":{\"id\":\"45c592eaab45cdb592f9b7e8e3add9c8\",\"title\":\"Getting Started\",\"path\":\"/docs/es/\",\"content\":\"\\n## What is Robonomics\\n\\nRobonomics platform provides tools for working with the robot economy network. Robonomics allow designers of smart cities and industry 4.0 zones to build trust among the [autonomous robots services](/docs/glossary#cyber-physical-system), provide [direct user access via dapp](/docs/glossary#dapp) for ordering products from autonomous factories and services of urban sensor networks. This in turn will allow us to put in place a decentralized system that globally monitors the activities of cyber physical systems.\\n\\nFind more in [Robonomics whitepaper](https://github.com/airalab/robonomics_specs/blob/master/pdf/whitepaper_en.pdf)\\n\\nThe following chart describes what place Robonomics takes in the scenario:\\n\\n![Robonomics Chart](../images/robonomics_network_basic_scheme.jpg \\\"Robonomics Network scenario\\\")\\n\\n## What the documentation contains\\n\\n### Robonomics Network quick start\\nStart with quick example of what Robonomics is able to do within 5 minutes: [DEMO \\\"Get Weather on Fuji Mountain\\\"](/docs/get-weather-on-fuji-mountain).\\n\\n### I'm interested in using Robonomics services\\n\\nTake a look at the [Robonomics Dapp](https://dapp.robonomics.network/#/). Get familiar with the statistic, average miner reward etc.\\nTry out existing [services](https://dapp.robonomics.network/#/services)\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"}},{\"node\":{\"id\":\"6f1a6922f41a3337c743c3ed44c3f870\",\"title\":\"DEMO \\\"Obtenga el clima en la montaña de Fuji\\\"\",\"path\":\"/docs/es/get-weather-on-fuji-mountain/\",\"content\":\"\\n**Comencemos con un ejemplo rápido de lo que Robonomics es capaz de hacer en 5 minutos. Requisitos: [extensión Metamask](https://metamask.io/)**\\n\\nPara obtener el clima del sensor en la montaña Fuji, abra la página del [Fuji Weather sensor](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/) en Robonomics dApp y siga las instrucciones a continuación.\\n\\nAquí hay un video tutorial:\\n\\nhttps://www.youtube.com/embed/t098NlMELk4\\n\\n## 1. Abra la DAPP\\n\\nEn caso de que no tenga la extensión MetaMask, verá la imagen a continuación. Vaya al enlace proporcionado arriba e instale uno.\\n\\n![\\\"Robonomics dApp si no hay MetaMask instalado\\\"](../images/sensor-demo/sensor-demo-1.png \\\"Robonomics dApp si no hay MetaMask instalado\\\")\\n\\n## 2. Permitir la conexión a la Extension\\n![\\\"Conexión a Robonomics dApp a través de Metamask\\\"](../images/sensor-demo/sensor-demo-2.png \\\"Conexión a Robonomics dApp a través de Metamask\\\")\\n\\n## 3. Presione “Request Current Values” (Solicitar Valores Actuales)\\n![\\\"Request sensor's data in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-3.png \\\"Request sensor's data in Robonomics network via dApp\\\")\\n\\n## 4. Firme el Mensaje, no se necesita ningun token ni Ether\\n![\\\"Firme el Mensaje en la red de Robonomics a través de dApp\\\"](../images/sensor-demo/sensor-demo-4.png \\\"Firme el Mensaje en la red de Robonomics a través de dApp\\\")\\n\\n## 5. Espere hasta que el agente agarre los datos y los envie\\n![\\\"Espere hasta que el agente en la red Robonomics a través de dApp\\\"](../images/sensor-demo/sensor-demo-5.png \\\"Espere hasta que el agente en la red Robonomics a través de dApp\\\")\\n\\n## 6. Espere hasta que la DAPP descargue el archivo final de IPFS\\n![\\\"Espere el archivo IPFS con resultados en la red Robonomics a través de dApp\\\"](../images/sensor-demo/sensor-demo-6.png \\\"Espere el archivo IPFS con resultados en la red Robonomics a través de dApp\\\")\\n\\n## 7. Ahora si, ya puede ver los datos del tiempo en la Montaña Fuji\\n![\\\"Los resultados de la red de sensores en Robonomics a través de dApp\\\"](../images/sensor-demo/sensor-demo-7.png \\\"Los resultados de la red de sensores en Robonomics a través de dApp\\\")\\n\\n¡Acaba de transmitir un mensaje de demanda y obtuvo un resultado de un agente autónomo! El archivo de resultados se almacena en IPFS, el mensaje de resultado se firma con la clave privada del agente.\"}},{\"node\":{\"id\":\"2e9901ec276b7c0607c24d7e58b6479a\",\"title\":\"How to Buy a Subscription\",\"path\":\"/docs/es/get-subscription/\",\"content\":\"\\nhttps://youtu.be/EsUiG_4ZGcw\\n\\nWe will use [Robonomics dev node](/docs/run-dev-node) to try the subscription, but in the production network everything works the same. \\n\\nIn `Developer/Chain state` you can see auctions for subscriptions (to get a subscription you need to win a fast auction). Choose `rws` and `auctionQueue` and press `+` button, you will see IDs of available auctions:\\n\\n![queue](../images/dev-node/queue.png)\\n\\nYou can see an information about any subscription with `rws` `auction` and ID of auction (the auction's ID in the picture is 0):\\n\\n![auction](../images/dev-node/auction.png)\\n\\nIn the information about the auction you can see `winner` field, at the moment it is `null` so nobody has this subscription and we can get it. For that go to `Developer/Extrinsic`, choose your account and `rws -> bid`. Also set auction ID (0) and the amount of units to bid (more than 1000000000 Wn):\\n\\n![bid](../images/dev-node/bid.png)\\n\\nSubmit the transaction and check the information about the auction with ID 0 (in `Chain state` choose `rws -> auction` and ID 0):\\n\\n![win](../images/dev-node/auc_win.png)\\n\\nNow in `winner` field you will see your account address, it means that this account has the subscription 0. An auction starts with the first bid and lasts a few blocks, so if somebody bids more tokens than you in the next few blocks one will be the winner and one will take the subscription.\\n\\nNow you can add devices. Devices are accounts that are able to use this subscription and send extrinsics with no fee. To test it lets create a new account with no tokens and add it to devices. \\n\\nTo add devices choose `rws -> setDevices` in `Developer/Extrinsic`. Then press `Add Item` button and choose recently created account with no tokens:\\n\\n![set_devices](../images/dev-node/set_devices.png)\\n\\nSubmit the transaction. Now you can check the list of devices in `Chain state` with `rws -> devices`. There you will see the address of your account without tokens. Choose the account that has bought the subscription and press `+`:\\n\\n![devices](../images/dev-node/devices.png)\\n\\nNow you can try to [send launch](/docs/subscription-launch) extrinsic using the subscription.\"}},{\"node\":{\"id\":\"be4c0d5977a0e3ed65555c7edea3087c\",\"title\":\"Gaka-Chu setup and software Installation\",\"path\":\"/docs/es/gaka-chu/\",\"content\":\"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](../images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](../images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"}},{\"node\":{\"id\":\"c53a8b64e574b08e488e9fcc668609b7\",\"title\":\"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\"path\":\"/docs/es/freertos-mqtt/\",\"content\":\"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](../images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](../images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](../images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](../images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](../images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"}},{\"node\":{\"id\":\"fbcf843d0741767d4b926086c1624fa7\",\"title\":\"Ethereum Common\",\"path\":\"/docs/es/ethereum-common/\",\"content\":\"\\nThe packages contains two launch files: `erc20.launch` and `signer.launch`. The last one is included in [Robonomics Liability](/docs/robonomics-liability).\\n\\nBelow is the description for `erc20` node which contains utils for convenient work with Ethereum accounts and XRT token.\\n\\n## ROS Parameters\\n\\n###  ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~erc20_token\\n\\nERC20 token to work with. Type is `string`, defaults to `xrt.5.robonomics.eth`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Published topics\\n\\n### /eth/event/transfer (ethereum_common/TransferEvent)\\n\\nThe event [ethereum_common/TransferEvent](/docs/ethereum-common-messages#ethereum_commontransfereventmsg) is emitted after the transfer of tokens was made\\n\\n### /eth/event/approval (ethereum_common/ApprovalEvent)\\n\\nThe event [ethereum_common/ApprovalEvent](/docs/ethereum-common-messages#ethereum_commonapprovaleventmsg) is emitted after the approval of tokens was made\\n\\n## Services\\n\\n### /eth/accounts (ethereum_common/Accounts)\\n\\nList of available Ethereum accounts. See [ethereum_common/Accounts](/docs/ethereum-common-messages#ethereum_commonaccountssrv)\\n\\n### /eth/account_eth_balance (ethereum_common/AccountBalance)\\n\\nReturns the balance of the given address in Wei. See [ethereum_common/AccountBalance](/docs/ethereum-common-messages#ethereum_commonaccountbalancesrv)\\n\\n### /eth/eth_balance (ethereum_common/Balance)\\n\\nReturns the balance of the default address. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/current_block (ethereum_common/BlockNumber)\\n\\nReturns current block number. See :ref:`Ethereum-common-BlockNumber.srv`\\n\\n### /eth/transfer (ethereum_common/Transfer)\\n\\nTransfers tokens from the default account to a given one. See :ref:`Ethereum-common-Transfer.srv`\\n\\n### /eth/transfer_from (ethereum_common/TransferFrom)\\n\\nTransfers tokens from a given account to another one. See :ref:`Ethereum-common-TransferFrom.srv`\\n\\n### /eth/approve (ethereum_common/Approve)\\n\\nApproves tokens from the default account to a given one. See :ref:`Ethereum-common-Approve.srv`\\n\\n### /eth/account_xrt_balance (ethereum_common/AccountBalance)\\n\\nReturns the XRT balance of a given account. See :ref:`Ethereum-common-AccountBalance.srv`\\n\\n### /eth/xrt_balance (ethereum_common/Balance)\\n\\nReturn the XRT balance of the default account. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/account_xrt_allowance (ethereum_common/AccountToAddressAllowance)\\n\\nReturns how much one account is allowed to spend from another account. See :ref:`Ethereum-common-AccountToAddressAllowance.srv`\\n\\n### /eth/xrt_allowance (ethereum_common/Allowance)\\n\\nReturns how much the Factory is allowed to spend from the default account. See :ref:`Ethereum-common-Allowance.srv`\"}},{\"node\":{\"id\":\"65474c4ebc14e3809b294ff690e1df72\",\"title\":\"Ethereum Common Messages\",\"path\":\"/docs/es/ethereum-common-messages/\",\"content\":\"\\n## ethereum_common/Address.msg\\n\\n| Field   \\t| Type            \\t| Description                    \\t|\\n|---------\\t|-----------------\\t|--------------------------------\\t|\\n| address \\t| std_msgs/String \\t| Address in Ethereum blockchain \\t|\\n\\n## ethereum_common/UInt256.msg\\n\\n| Field   \\t| Type            \\t| Description                \\t|\\n|---------\\t|-----------------\\t|----------------------------\\t|\\n| uint256 \\t| std_msgs/String \\t| A wrapper for big integers \\t|\\n\\n## ethereum_common/TransferEvent.msg\\n\\n| Field      \\t| Type                                                  \\t| Description      \\t|\\n|------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_from  \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Sender address   \\t|\\n| args_to    \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Receiver address \\t|\\n| args_value \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/ApprovalEvent.msg\\n\\n| Field        \\t| Type                                                  \\t| Description      \\t|\\n|--------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_owner   \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Owner address    \\t|\\n| args_spender \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Spender address  \\t|\\n| args_value   \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/AccountBalance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field   \\t| Type                                                  \\t| Description    \\t|\\n|---------\\t|-------------------------------------------------------\\t|----------------\\t|\\n| balance \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wei \\t|\\n\\n## ethereum_common/AccountToAddressAllowance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n| to      \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field  \\t| Type                                                  \\t| Description   \\t|\\n|--------\\t|-------------------------------------------------------\\t|---------------\\t|\\n| amount \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wn \\t|\\n\\n## ethereum_common/Accounts.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------- |-------------------------------------------------------    |----------------------------   |\\n| accounts  | [ethereum_common/Address[]](#ethereum_commonaddressmsg)     | List of available accounts    |\\n\\n## ethereum_common/Allowance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                                       |\\n|--------   |-------------------------------------------------------    |-----------------------------------------------    |\\n| amount    | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | Amount of XRT the Factory is allowed to spend     |\\n\\n## ethereum_common/Approve.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------  |-------------------------------------------------------    |-----------------------------  |\\n| spender   | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Who is allowed to spend       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | How much tokens are allowed   |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/Balance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                       |\\n|---------  |-------------------------------------------------------    |--------------------------------   |\\n| balance   | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The balance of default account    |\\n\\n## ethereum_common/BlockNumber.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type              | Description           |\\n|--------   |-----------------  |---------------------- |\\n| number    | std_msgs/Uint64   | Current block number  |\\n\\n## ethereum_common/Transfer.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Ethereum address      |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/TransferFrom.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| owner     | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Owner's address       |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Another account       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\"}},{\"node\":{\"id\":\"660ecba2847e6181e891dfd115884f16\",\"title\":\"Cómo editar WIKI\",\"path\":\"/docs/es/edit-wiki/\",\"content\":\"\\n**Robonomics WIKI es de código abierto. Cualquier corrección es bienvenida: corrección de errores, errores tipográficos, información poco clara o desactualizada, traducción a cualquier idioma. Necesitará una cuenta de [GitHub](https://github.com/).** \\n\\n## Editar documento existente\\n\\n1. Elija la página\\n2. Haga clic en el botón \\\"Editar página\\\" marcado con el logotipo de Github en la página que desea editar.\\n3. Al hacer clic en el botón, accederá al archivo .md.\\n4. Por favor, siga las reglas comunes para editar [archivos Markdown](https://en.wikipedia.org/wiki/Markdown), teniendo en cuenta algunas características del WIKI:\\n\\n### Frontmatter\\nLos documentos de Robonomics WIKI contienen un bloque de frontmatter. Debe estar en la parte superior del archivo Markdown y debe tener la forma de un YAML válido establecido entre líneas de tres puntos. Entre las líneas de tres puntos, puede configurar o editar las siguientes opciones:\\n\\n```YAML\\n---\\ntitle: How to contribute # Title for the page, you do not need to duplicate it in text\\ncontributors: [positivecrash] # Main contributors (who actively curates this page). GitHub nickname required, without any additional symbols\\ntranslated: true # \\\"true\\\" if it has been translated in current language (see locale folder name of doc)\\n---\\n```\\n\\n### Imágenes\\n1. Cargue la imagen en la carpeta `/docs/images/url-of-your-doc`\\n* Si la imagen necesita ser localizada, insértelas todas en una carpeta\\n* Use el apéndice de configuración regional en el nombre de las imágenes si está localizado, p. Ej. `image_en.jpg`\\n* Asegúrese de que su imagen esté optimizada para la web y, al mismo tiempo, se vea bien\\n2. Inserte imágenes de forma estándar para archivos Markdown.\\n\\n### Videos de Youtube\\nPuede incrustar cualquier video de YouTube en el documento insertando el enlace para compartir como un párrafo separado sin comillas o etiquetas adicionales, por ejemplo: `https://youtu.be/kQaSwNYHJQ8`\\n\\n### Asciinema\\nRobonomics WIKI tiene soporte para Asciinema. Para insertar Asciinema, siga estas instrucciones:\\n* Importar componente después del bloque de frontmatter `importar Asciinema desde '~/components/Asciinema.vue'`\\n* Insertar como párrafo separado `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, donde vid es el ID de una asciicast \\n\\n> Puede obtener el script del widget para una asciicast específica haciendo clic en el enlace \\\"Insertar\\\" en la página de asciicast.\\n> Se parece a esto:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Asciinema docs](https://asciinema.org/docs/embedding)\\n\\nEn el ejemplo anterior, vid es 14.\\n\\n## Agregar nuevo documento\\n\\nSi necesita agregar una nueva página en los documentos de Robonomics WIKI, siga estos pasos:\\n\\n1. Busque la carpeta con la configuración regional que coincida con el idioma del artículo que está agregando, p. Ej. `/docs/en/`\\n2. 2. Cree un archivo .md, utilizando caracteres latinos en el nombre y siga las reglas comunes para [estructura de URL](https://developers.google.com/search/docs/advanced/guidelines/url-structure)\\n3. Edite el archivo como se describe arriba\\n4. Duplique el archivo en otras carpetas de configuración regional, incluso si no planea traducirlas. No olvide marcar en la parte delantera las páginas no traducidas como `translated: false`\\n5. Agregar documento en el menú:\\n* Abra el archivo `/data/sidebar_docs.yaml`\\n* Decide dónde colocar tu documento\\n* Si desea crear una nueva sección, proporcione el título con el apéndice de configuración regional, utilizando solo las configuraciones regionales, su sección está traducida\\n* Agregue un documento con un enlace. El enlace debe ser solo uno y no debe contener caracteres de configuración regional. Correcto es `/docs/url-of-your-doc`, incorrecto es `/docs/en/url-of-your-doc`\\n* Use YAML válido para  `/data/sidebar_docs.yaml` y confíe en la estructura de archivo existente\\n\\n## Enviar solicitud de extracción\\n\\n[Hacer solicitud de extracción](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) para cualquier contenido que haya cambiado, incluidos errores tipográficos, traducciones, información desactualizada o enlaces rotos.\\n\\nDecisiones sobre Solicitudes de extracción individuales tomadas por el equipo central de Robonomics. Las subvenciones especiales en [XRT](https://robonomics.network/community#token) también son posibles para contribuciones extendidas 🤖💙💛💚💎🍭🎉🔌\\n\"}},{\"node\":{\"id\":\"eb55457b8956323549602c26f137e545\",\"title\":\"Digital Twins\",\"path\":\"/docs/es/digital-twins/\",\"content\":\"\\n## Requirements\\n- `robonomics` [executable][ln1]\\n- Be familiar with [parachain.robonomics][ln2]\\n\\n## Digital Twins Schema\\n\\nDigital twins have the following structure:\\n\\n| DT id \\t| Topic Name \\t| Source    \\t|\\n|-------\\t|------------\\t|-----------\\t|\\n| 0     \\t| 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1     \\t| 0x00...001 \\t| 4GVi...Bn \\t|\\n|       \\t| 0x00...002 \\t| 4Hm...vLS \\t|\\n|       \\t| 0x00...... \\t| 4HQ...RQY \\t|\\n|       \\t| 0xFF...FFF \\t| 4Hw...CyK \\t|\\n| 2     \\t| 0x00...000 \\t| 4HJ...k3o \\t|\\n\\n Where:\\n* **DT id** - is unsigned integer unique number.\\n* **Topic name** - is 0x prefixed `H256 hex` or `ascii data` with 32 bytes length. For example: `0x1234....FF` and  `hello.parachain.robonomics.world`.\\n* **Source** - is Account address.\\n\\n## Create Digital Twin\\nGo to ***Developer -> Extrinsics*** and choose `digitalTwin.create()` extrinsic.\\n![digital Twin create][im1]\\n\\n Submit transaction and go to ***Network -> Explorer*** and in the **recent events** you will see information about digital twin.\\n ![digital Twin create info][im2]\\n\\n## Add DT Topic\\n\\nYou can create multiple topics for one digital twin. for creating topic you need go to ***Developer -> Extrinsics*** and choose `digitalTwin.setSource(id,topic,source)` extrinsic. Fill in the fields and submit transaction.\\n![DT topic fields][im3]\\n\\nAgain go to **Network -> Explorer*** and in the **recent events** you will see information about created topic.\\n![info about topic][im4]\\n\\nYou can create several topics for one twin.\\n![topics][im5]\\n\\n## Chain State\\n\\nYou can find all information about existing *digital twins in* ***Developer -> Chain state*** such as:\\n- Total number of Digital twins - total()\\n- Information about owner of digital twin - owner(u32)\\n- Information about topics in digital twin - digitalTwin(u32)\\n![chain info][im6]\\n\\n\\n[ln1]: <https://github.com/airalab/robonomics/releases>\\n[ln2]: </docs/create-account-in-dapp>\\n[im1]: <../images/digital-twin/twin-create.jpg>\\n[im2]: <../images/digital-twin/create-log.jpg>\\n[im3]: <../images/digital-twin/fields.jpg>\\n[im4]: <../images/digital-twin/topic.jpg>\\n[im5]: <../images/digital-twin/topics.jpg>\\n[im6]: <../images/digital-twin/chain-state.jpg>\\n\"}},{\"node\":{\"id\":\"7bfa56915f3c32408e86ff863a095656\",\"title\":\"Cross-chain Message\",\"path\":\"/docs/es/cross-chain-messages/\",\"content\":\"\\nXCM (Cross-chain Message) allows sending messages between parachains. You can send launchXcm transaction to run/stop your robot or datalogXcm transaction to save data to blockchain.\\n\\nhttps://www.youtube.com/watch?v=a6XrqoaYhK8&feature=emb_logo\\n\\n## Create Account\\n\\nLets try to send message from Earth to Mars.\\nGo to [parachain.robonomics.network](https://parachain.robonomics.network/#/explorer) and choose `Airalab Rococo` testnet:\\n\\n![testnets](../images/cross-chain/testnet.jpg)\\n\\nIn `Network/Parachains` you will see two parachains with their id:\\n\\n![ids](../images/cross-chain/Parachains_id.jpg)\\n\\nThen go to Earth parachain and [create](https://wiki.robonomics.network/docs/create-account-in-dapp/) two accounts (for example `ROBOT` and `EMPLOYER`). In a new tab go to Mars parachain.\\n\\n## LaunchXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `EMPLOYER` account and launchXcm. Then write Mars parachain id (2000) and choose the `ROBOT` account:\\n\\n![launch](../images/cross-chain/launch.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nTo see your transaction in Mars parachain go to `Network/Explorer` and look at Recent Events.\\n\\n![recent_launch](../images/cross-chain/recent_launch.jpg)\\n\\n## DatalogXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `ROBOT` account and datalogXcm. Write Mars parachain id (2000) and the message:\\n\\n![datalog](../images/cross-chain/datalog.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nYou can see your transaction in Recent Events in Mars parachain:\\n\\n![recent_datalog](../images/cross-chain/recent_datalog.jpg)\\n\\n\\n\"}},{\"node\":{\"id\":\"e1b763c02a7968fa73fa077bbacdacc8\",\"title\":\"Create digital identity run by Ethereum\",\"path\":\"/docs/es/create-digital-identity-run-by-ethereum/\",\"content\":\"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](../images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](../images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](../images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](../images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](../images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](../images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"}},{\"node\":{\"id\":\"b03e427fc99f8ace4b50713de815d64b\",\"title\":\"Create Account for Robonomics Parachain\",\"path\":\"/docs/es/create-account-in-dapp/\",\"content\":\"\\n**In order to interact and operate with Robonomics Parachain, developers and users need to create an account on the Polkadot / Substrate Portal. The account performs basic functions for the network: your public network address(the public key), the access control to the address and funds (the private key), sending transactions to the network, showing your tokens and their amount, etc. Below are two main ways to create an account for Robonomics Parachain.**\\n\\n## 1. Using Polkadot{.js} Browser Extension\\n\\nThe Polkadot Extension provides a mechanism to generate the account and interact with all Polkadot / Kusama projects including Robonomics Parachain. This is not the safest way to manage your account, but it is the most convenient in terms of security / usability balance.\\n\\n## 1.1. Install Browser Extension\\n\\nThe browser extension is available for [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) and [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=en) (plus Chromium-based browsers).\\n\\n![Browser Extension](../images/creating-an-account/1.1-polkadot-extension.png \\\"Browser Extension\\\")\\n\\n## 1.2. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. If this is the first time you entered the portal, it will request access to the browser extension, so allow access. \\n\\nOnce you've opened the app, take a look at the top left corner. The name of the network, its icon and the number of the last block are displayed there. Clicking on this area will open a list of all Polkadot / Kusama networks, including test networks and local nodes. You can switch between networks by selecting the required one and pressing the `Switch` button. **Make sure you are connected to Robonomics Parachain now**. \\n\\n![Robonomics Parachain app](../images/creating-an-account/1.2-robonomics-app.png \\\"Robonomics Parachain app\\\")\\n\\n## 1.3. Update Extension Metadata\\n\\nIt is very likely that the app will ask you to update the metadata for the extension to display the correct information about the chain you are connected to. Go to **Settings -> Metadata**, press `Update metadata` button and then, in the pop-up window, allow the extension to do it. \\n\\n![Updating metadata](../images/creating-an-account/1.3-metadata-update.png \\\"Updating metadata\\\")\\n\\n## 1.4. Create Account in Extension\\n\\nOpen the Polkadot{.js} browser extension. Click the big plus button or select `Create new account` from the small plus icon in the top right. You should see the following menu, with generated mnemonic seed in the form of twelve words and the address. \\n\\n![Account creation, step one](../images/creating-an-account/1.4-create-account-step-1.png \\\"Account creation, step one\\\")\\n\\nThe seed is your key to the account. Knowing the seed allows you (or anyone else who knows the seed) to get control on this account and even re-create it, if you forget the password. **It's very important to store it somewhere securely**, preferably on paper or other non-digital device, not in digital storage or on a computer. \\n\\nSave the seed and press `Next step`. You should see the following menu.\\n\\n![Account creation, step two](../images/creating-an-account/1.5-create-account-step-2.png \\\"Account creation, step two\\\")\\n\\n- *Network* allows you to choose which of the networks this account will be exclusively used for. You can use the same address on multiple networks, however, for privacy reasons, it is recommended that you create a new address for each network you use. \\nSelect the Robonomics network from the drop-down list. If you could not find the Robonomics network, then most likely you did not update the metadata, go back and do it.\\n\\n    - You will notice that the format of the address and the account icon will change — this is normal. Different network formats are merely other representations of the same public key. \\n\\n- *Name* is just account's name for your use only. It is not stored on the blockchain and will not be visible to other users. \\n\\n- *Password* is used to encrypt your account's information. You will need to re-enter it when signing transactions on the portal. Create one and remember it.\\n\\nAs a result, after creating an account, you will see it in the list of accounts in Polkadot{.js} extension. By clicking on three dots, you can rename the account, export it, remove it from the extension and change the network used for the account. \\n\\nAlso, the account will appear in the **Accounts -> Accounts** menu on the portal, where it will be noted that it was injected using the extension.\\n\\n![Successful account creation](../images/creating-an-account/1.6-account-injected.png \\\"Successful account creation\\\")\\n\\n\\n## 2. Directly on Robonomics Parachain App\\n\\nYou can use the user interface on the Polkadot / Substrate Portal to create an account, although this is not recommended as it is the less secure method for the account creation. It should be used when other methods are not applicable or for development and tests. \\n\\n## 2.1. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check at the top left corner that you are connected to Robonomics Parachain**.  \\n\\nGo to **Accounts -> Accounts** and press `Add account` button. \\n\\n![Robonomics Parachain App](../images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Robonomics Parachain App\\\")\\n\\n## 2.2. Create Account\\n\\nYou should see the following popup menu with account seed. \\n\\n![Generating account seed](../images/creating-an-account/2.2-robonomics-app-seed.png \\\"Generating account seed\\\")\\n\\nIt has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). Save the seed phrase securely and press `Next`.\\n\\nIn the next menu, you need to set the account name and password, similar to the extension instructions described above.\\n\\n![Generating account name and password](../images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Generating account name and password\\\")\\n\\nClicking on the `Next` button will take you to the last window. Click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n![Successful account creation](../images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Successful account creation\\\")\\n\\n## 3. Account Сreated Successfully \\n\\nNow you can fully operate with your fresh-created account. Send and receive tokens, messages, write datalog and more. Feel free to explore all the features of app. To copy your account's address simply click on its icon, address will be copied to clipboard. \\n\\nIf you would like to know more about Polkadot / Kusama accounts and additional ways to create them, more information can be found [here](https://wiki.polkadot.network/docs/learn-accounts) and [here](https://wiki.polkadot.network/docs/learn-account-generation).\\n\"}},{\"node\":{\"id\":\"df2b7e4e70929da97a4d369a0995ca25\",\"title\":\"Cómo Contribuir\",\"path\":\"/docs/es/contributing/\",\"content\":\"\\nLa red Robonomics es un proyecto de código abierto creado por mantenedores centrales de Airalab y colaboradores. Queremos que sea fácil para cualquiera contribuir. Puede contribuir al núcleo, sugerir cambios, mejorar la documentación o escribir una publicación de blog. Por favor, lea algunas reglas y sugerencias para contribuir.\\n\\n## Repositorios principales de Airalab\\n\\n- [aira](https://github.com/airalab/aira) - Cliente AIRA para la red Robonomics.\\n- [robonomics_comm](https://github.com/airalab/robonomics_comm) - Pila de comunicación de Robonomics\\n- [robonomics_contracts](https://github.com/airalab/robonomics_contracts) - Contratos inteligentes de la red Robonomics\\n\\n## Errores y propuestas de mejoras\\n\\nSi encuentra un error en el cliente AIRA, repositorios de Robonomics, esta documentación o le gustaría proponer una mejora, por favor, abra una nueva edición en el mismo repositorio, que quiera contribuir.\\n\\n### Reglas para reportar\\n\\nAl abrir un nuevo problema, no se olvide de algunas reglas básicas para reportar:\\n\\n1. Elija el repositorio exacto al que desea enviar un problema.\\n\\n2. Si está informando un error, asegúrese de que el error no haya sido informado antes.\\n\\n3. Asegúrese de incluir un título y una descripción clara, con tanta información relevante como sea posible.\\n\\n4. Por favor, anteponga a su problema uno de los siguientes: [BUG], [PROPOSAL], [QUESTION].\\n\\n\\n## Solicitudes de extracción\\n\\nCualquier repositorio de Airalab o de esta documentación pueden estar sujetos a solicitudes de extracción o cambios por parte de los colaboradores cuando crea que tiene algo valioso que agregar o cambiar. Por favor, no se olvide de las reglas básicas para los colaboradores. \\n\\n### Reglas para Contribuir\\n\\n1. Se prefieren las solicitudes de extracción para errores, si tiene algunas correcciones, especialmente para cambios pequeños como errores tipográficos.\\n\\n2. Asegúrese de que la descripción de la Solicitud de Extracción describa claramente el problema y la solución. Incluya el número de problema relevante si corresponde.\\n\\n3. Por favor, no corrija espacios en blanco, código de formato ni haga un parche puramente cosmético.\\n\\n4. Por favor, intente adherirse al estilo, lenguaje y diseño de Markdown predominantes.\\n\"}},{\"node\":{\"id\":\"233b28862991f1e3974075d5430e2a20\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/es/connectivity-terminal-readme/\",\"content\":\"\\n# Sensors-Connectivity Terminal Readme\\n\\n## Connection\\n\\nTo connect to the server:\\n\\n```bash\\nssh <user>@<address>\\n```\\nWhere user and address are replaced with user, which connectivity service runs under, and address of the VM respectively.\\n\\n## Installation\\n\\nInstallation guide can be found on this [page](https://wiki.robonomics.network/docs/en/sensors-connectivity-on-aira/).\\n\\n\\n## Status checking \\n\\nAssuming you launch the code as a systemd service. Therefore, to check service status:\\n\\n```bash\\nsystemctl status connectivity.service\\n```\\nThere you will find all necessary information about the service, including path to the log files.\\n\\n## Logs\\n\\nGeneral path for log files is: ` ~/.ros/log/latest/connectivity-worker-1.log` where `connectivity-worker-1.log` is the last recordered file.\\n\\nFor watching logs in real time:\\n```bash\\ntail -f  <path>\\n```\\nWhere path should be replced with the log path. To look through the whole file simply open the log file in your favourite editor.\\n\\nIt can be useful to copy log files to your local machine:\\n\\n```bash\\nscp -rv <user>@<address>: <path-to-log-files> <path-in-your-local-machine>\\n```\"}},{\"node\":{\"id\":\"2fbe5239d779b137136f6c6c20728097\",\"title\":\"Connect the simplest CPS\",\"path\":\"/docs/es/connect-simple-cps/\",\"content\":\"\\nIn this section we will build the simplest real cyber-physical system!\\n\\nWe will buy a \\\"wink\\\" from Arduino, e.g. make Arduino blink with its onboard led. The lesson is tested on Arduino Uno, but any other board with a led will do the job.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_blink).\\n\\n## Arduino\\n\\nThe firmware for the board is located in [arduino_blink/misc/arduino/arduino.ino](https://github.com/airalab/robonomics_tutorials/blob/master/arduino_blink/misc/arduino/arduino.ino). Use [Arduino IDE](https://www.arduino.cc/en/Main/Software) to load the code to your Arduino board.\\n\\nIn the code we subscribe for the ``/blink_led`` topic and set a callback. The type of the topic is ``Empty``, so the board waits until someone publishes to the topic and performs the LED blinking.\\n\\n```\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle  nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void messageCb( const std_msgs::Empty& toggle_msg){\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> sub(\\\"blink_led\\\", &messageCb );\\n\\n  void setup()\\n  {\\n    pinMode(LED_BUILTIN, OUTPUT);\\n    nh.initNode();\\n    nh.subscribe(sub);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n\\n## AIRA client\\n\\n> You can download the latest release from [here](https://github.com/airalab/aira/releases).\\n\\nSet up the COM port forwarding. You should forward your `/dev/ttyUSB0` or `/dev/ttyACM0` port (depending on the system) to `COM1`. In the client `/dev/ttyS0` will represent the board. After this launch the virtual machine.\\n\\n## ROS\\n\\nWhen new liability is created it goes to `/liability/ready` topic. We have to remember the address and call `/liability/start` service to get the data from objective.\\n\\n```\\n  def newliability(l):\\n    self.liability = l.address\\n    rospy.loginfo(\\\"Got new liability {}\\\".format(self.liability))\\n\\n    prefix = \\\"/liability/eth_\\\" + self.liability\\n    rospy.Subscriber(prefix + '/blink', Empty, self.blink)\\n\\n    rospy.wait_for_service(\\\"/liability/start\\\")\\n    rospy.ServiceProxy('/liability/start', StartLiability)(StartLiabilityRequest(address=self.liability))\\n  rospy.Subscriber(\\\"/liability/ready\\\", Liability, newliability)\\n```\\n\\nA message in the `/blink` topic come from the objective field. Have a look at [Basic usage](/docs/aira-basic-usage) page.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh). All tutorials are pre-installed. To launch the ros package run the following command:\\n\\n```\\n$ rosrun arduino_blink blink.py\\n```\\n\\nAlso we need to add a rosbag file to IPFS::\\n\\n```\\n$ ipfs add rosbag/blink.bag\\n```\\n\\n> Before the next step you should approve XRT tokens on the Factory.\\n\\nOn your host system build and launch an Dapp for the lesson:\\n\\n```\\n$ git clone https://github.com/airalab/robonomics_tutorials/\\n$ cd robonomics_tutorials/arduino_blink_dapp\\n$ npm i && npm run dev\\n```\\n\\nOpen [http://localhost:8000/](http://localhost:8000/) and press \\\"Demand\\\" then \\\"Offer\\\" buttons. Wait until a new liability is created and you should see the board blinking. Congratulations on the first agent!\\n\"}},{\"node\":{\"id\":\"f13553fe93323ed00030c001baa37097\",\"title\":\"Connect Sensor To Robonomics Network\",\"path\":\"/docs/es/connect-sensor-to-robonomics/\",\"content\":\"\\n## Hardware\\n\\nUniversal board for air quality sensor, based on ESP8266 allows to use the following modules: NODEMCU v3, NODEMCU v2, WEMOS D1 MINI. The device is designed for 6 - 24 volt power supply, using DC-DC converter DC MINI560.\\n\\n![plata](../images/sensors-connectivity/plata.png)\\n\\nThis board allows you to connect PM sensors:\\n\\n- [SDS011](https://cdn-reichelt.de/documents/datenblatt/X200/SDS011-DATASHEET.pdf)\\n- PMS1003-6003\\n- [PMS7003/G7](http://www.plantower.com/en/content/?110.html)\\n- [SPS 30 PM Sensor](https://sensirion.com/products/catalog/SPS30/)\\n\\nI2C connectivity:\\n\\n- [BMP180](https://cdn-shop.adafruit.com/datasheets/BST-BMP180-DS000-09.pdf) - temperature and humidity\\n- [BME/P280](https://www.mouser.com/datasheet/2/783/BST-BME280-DS002-1509607.pdf) - temperature, humidity, atmospheric pressure\\n- [HTU21D](https://eu.mouser.com/ProductDetail/Measurement-Specialties/HTU21D?qs=tx5doIiTu8oixw1WN5Uy8A%3D%3D) - temperature and humidity\\n- SHT3x(I2C) - temperature and humidity\\n- [CCS811 VOC SENSOR](https://www.sciosense.com/wp-content/uploads/documents/Application-Note-Baseline-Save-and-Restore-on-CCS811.pdf) - volatile Organic Compounds, CO2 equivalent\\n- LCD1602/ 2004 / OLED SSD1306 / SH1106 - supported displays\\n\\nPossibility of connection via 1 Wire interface:\\n\\n- DTH22(AM2302) - temperature and humidity\\n- DS18B20 - temperature.\\n\\nThere is also a smaller MINI model with a trimmed down list of connectable devices. The source circuits for both models can be found at [full model](https://oshwlab.com/ludovich88/aira_sensor_rev0-1) and [MINI model](https://oshwlab.com/ludovich88/aira_sensor_d1_mini).\\n\\n> To obtain a ready-made board, contact the developers at vm@multi-agent.io.\\n\\nAfter receiving/assembling the sensor, all that remains is to flash and configure it.\\n\\n## Firmware\\n\\nOur firmware is based on the firmware from [Sensor.Community](https://github.com/opendata-stuttgart/sensors-software), with some sensors added and the data sending scheme changed. The source code can be found [at the link](https://github.com/LoSk-p/sensors-software/tree/master/airrohr-firmware). \\n\\nTo flash the sensor you can use `airrohr-flasher`. Download the executable for your operating system from [latest release](https://github.com/airalab/sensors-connectivity/releases).\\n\\n### For Linux\\n\\nFirst you need to add a user to the `dialout` group (for Ubuntu) to gain access to the USB port:\\n\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\n\\nAfter that, reboot the computer. Next, change the permissions of the file and run it:\\n\\n```bash\\nchmod +x airrohr-flasher-linux\\n./airrohr-flasher-linux\\n```\\n\\n### For Windows:\\nUnzip the flasher and double-click to run it. You will also need to install drivers for USB2serial (Windows 10 should start automatically):\\n\\n* Drivers for NodeMCU v3 (CH340): [Windows](http://www.wch.cn/downloads/file/5.html) ([2018/09/04 v3.4 mirror](https://d.inf.re/luftdaten/CH341SER.ZIP))\\n\\n### For MacOS.\\nDownload the flasher and run it. You will also need to install the drivers for USB2serial: \\n* Drivers for NodeMCU v3 (CH340): [macOS](http://www.wch.cn/downloads/file/178.html) ([2018/09/04 v1.4 mirror](https://d.inf.re/luftdaten/CH341SER_MAC.ZIP))\\n\\n---\\n\\nSelect the firmware (in English or Russian) and click `Upload`. Uploading the firmware will take some time.\\n\\n![flasher](../images/sensors-connectivity/7_flasher.jpg)\\n\\n## Setup\\n\\nAfter downloading the firmware, reboot the ESP (just disconnect and reconnect the USB).\\n\\nAfter a while after the reboot, ESP will create a Wi-Fi network called RobonomicsSensor-xxxxxxxxx. Connect to it from your phone or computer, then an authorization window will open (if it doesn't open in any browser go to 192.168.4.1). Select your Wi-Fi network from the list (or write it yourself if it's not on the list) and fill in the password field. Also write the coordinates of the place where the sensor will be installed in the field below:\\n\\n![guest](../images/sensors-connectivity/guest.jpg)\\n\\nClick `Save and restart`.\\n\\nThe board will connect to the specified Wi-Fi network and in a couple of minutes you will be able to see the data on [map](https://sensors.robonomics.network/#/):\\n\\n![map](../images/sensors-connectivity/14_map.jpg)\\n\\n## Advanced Setup\\n\\nFor a more detailed setup (you may need it to connect additional sensors or send data to your own server) you need to find the address of the sensor in your Wi-Fi network. To do this, you can use `airrohr-flasher` (your computer must be on the same network as the sensor is connected to). Start it and go to the `Discovery` tab, then press `Refresh`, wait a moment and your sensor address will appear.\\n\\n![addr](../images/sensors-connectivity/11_flaser2.jpg)\\n\\nDouble-click on this address (or type it into your browser), you will get to the sensor menu:\\n\\n![home](../images/sensors-connectivity/home.png)\\n\\nUnder the `Configuration` tab you can configure the sensors used:\\n\\n![sensors](../images/sensors-connectivity/sensors.png)\\n\\nAnd also set up sending to your own server. To do this, in the tab `APIs` uncheck `Robonomics` and check `Send to own API` and specify the server address and port (65 for sensors connectivity):\\n\\n![apis](../images/sensors-connectivity/apis_en.png)\\n\\nClick `Save and restart` to save the settings.\\n\\n\\n\"}},{\"node\":{\"id\":\"d38ce67f7d8eec299032fcce2468d57c\",\"title\":\"Connect Mars Curiosity rover under Robonomics parachain control\",\"path\":\"/docs/es/connect-mars-curiosity-rover-under-robonomics-parachain-control/\",\"content\":\"\\n**Let's see how Robonomics Parachain control allows to make Mars Curiosity rover move. Requirements:**\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n- IPFS up to [0.6.0](https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz)\\n- [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases). This tutorial tested fine on v1.1)\\n\\nHere is the video showing successful launch:\\n\\nhttps://www.youtube.com/watch?v=6BSOyRbmac8\\n\\n### 1. Set up a simulation\\nDownload Curiosity rover package:\\n```shell\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src\\ngit clone https://bitbucket.org/theconstructcore/curiosity_mars_rover/src/master/\\ncd ..\\ncatkin build\\n```\\nWe need to adjust starting conditions to make our rover spawn smoothly:\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/worlds` and change line 14 of the file` mars_curiosity.world` to \\n`<pose>0 0 8 0 0 0</pose>`\\n\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/launch` and change line 4 of the file `mars_curiosity_world.launch` to \\n`<arg name=\\\"paused\\\" default=\\\"false\\\"/>`\\n\\nDon't forget to add source command to `~/.bashrc`\\n`source /home/$USER/robonomics_ws/devel/setup.bash`\\n\\n\\n- Reboot console and launch the simulation:\\n\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\n![Mars rover](../images/curiosity-demo/rover.jpg?raw=true \\\"Mars rover\\\")\\n\\nNote: if the image is dark, e.g. shadowed, change `Camera` to `Orthorgraphic` in Gazebo toolbar.\\nThe simulation can be closed for a while.\\n\\n------------\\n\\n### 2. Download Robonomics controller package\\nTo download a controller package for Rover type in terminal:\\n```shell\\ncd ~/robonomics_ws/src\\ngit clone https://github.com/PaTara43/robonomics_sample_controller\\ncd robonomics_sample_controller\\npip3 install -r requirements.txt\\npip3 install rospkg\\ncd ..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3 # The controller supports python3\\n```\\n\\n------------\\n\\n### 3. Manage accounts in DAPP\\nSince we are testing, let us create a local robonomics network with robonomics binary file:\\n```shell\\n./robonomics --dev --tmp\\n```\\n\\n![Running node](../images/curiosity-demo/robonomics.jpg?raw=true \\\"Running node\\\")\\n\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node \\n\\n![Local node](../images/curiosity-demo/local_node.jpg?raw=true \\\"Local node\\\")\\n\\n\\nGo to Accounts and create **CURIOSITY** and **EMPLOYER** accounts.\\n\\n**Important**! Copy each account's address (to copy address click on account's icon) and Curiosity's account **mnemonic seed** (obtained while creating the account)\\nTransfer some money (units) to these accounts. You can read more about accounts in Robonomics [here](https://wiki.robonomics.network/docs/en/create-account-in-dapp/)\\n\\n![Account creation](../images/curiosity-demo/account_creation.jpg?raw=true \\\"Account creation\\\")\\n\\n\\nAdd these addresses, seed and node address (defaults to `ws://127.0.0.1:9944` for developer node) in `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. No quotes.\\n\\n------------\\n\\n\\n### 4. Start Robonomics\\n\\nBefore going further, make sure that you have installed [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion).\\n\\nIn a separate terminal launch IPFS:\\n```shell\\nifps init #you only need to do this once per IPFS installation\\nipfs daemon\\n```\\n\\nIn another separate terminal launch Curiosity simulation if it's not live:\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\nWait till it stays still\\n\\nIn another terminal launch the controller:\\n```shell\\nrosrun robonomics_sample_controller sample_controller.py\\n```\\n![Controller](../images/curiosity-demo/controller.jpg?raw=true \\\"Controller\\\")\\n\\n\\nNow you can send a transaction triggering the Rover to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/).\\nGo to `Developer->Extrinsics` and select Curiosity's employer account, `launch` extrinsic, Curiosity's account as a target account and `yes` as a parameter.\\nSubmit the extrinsic.\\n\\n![Extrinsic](../images/curiosity-demo/extrinsic.jpg?raw=true \\\"Extrinsic\\\")\\n\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter. The rover will move around and collect data for about a minute.\\nLater, when the job is done:\\n\\n![Job done](../images/curiosity-demo/job_done.jpg?raw=true \\\"Job done\\\")\\n\\n\\nOn the Robonomics portal go to `Developer -> Chain state` and obtain a `CURIOSITY` datalog using “+” button with selected `datalog -> RingBufferItem` as query: \\n\\n![Datalog](../images/curiosity-demo/datalog.jpg?raw=true \\\"Datalog\\\")\\n\\nNow the IPFS hash of the telemetry is saved in the blockchain. To see the data simply copy the hash and find it on a gateway:\\n\\n![Data in IPFS](../images/curiosity-demo/data_in_ipfs.jpg?raw=true \\\"Data in IPFS\\\")\\n\\n\\nThis telemetry is kept in a decentralized storage, and it's hash is stored in a blockchain!\\n\"}},{\"node\":{\"id\":\"e4e38be1ae8a5591759af845206600f2\",\"title\":\"Connect any ROS-compatible robot under Robonomics parachain control. Part 2, IPFS\",\"path\":\"/docs/es/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/\",\"content\":\"\\n**In this article we will continue using Robonomics tools to make a drone be controlled by a parachain. This time we will add sending data to IPFS and hash storing in chain options. Below is the instruction and code snippets. Requirements:**\\n- [**Part 1 of this tutorial**](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1)\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- IPFS 0.4.22 (download from [here](https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-386.tar.gz) and install)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n- Python dependencies:\\n```\\npip install cv_bridge ipfshttpclient\\n```\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=dliLb6GHgpo&feature=youtu.be\\n\\n\\n## 1. Add dependencies\\nIf we launch a simulation and look at the topic list (see previous tutorial), we will see, that there is one topic containing front camera data and using `sensor_msgs/Image` message type:\\n\\n![front_camera](../images/drone-demo/front_camera.jpg \\\"front_camera\\\")\\n\\nLet's try to take a picture every 1 second and after the flight publish these photos to IPFS. If you have completed the first tutorial, you don't need to download anything else. It's the `drone_sample_controller_pictures.py` script.\\n## 2. Manage accounts in DAPP\\nAs done in a previous tutorial, create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 3. Launch\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nIn another one launch ipfs daemon:\\n```\\nifps init # you only need to do this once\\nipfs daemon\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller_pictures.py\\n```\\nNow you can send a transaction triggering the drone to start flying and taking pictures. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying and taking pictures:\\n\\n![flying_picturing](../images/drone-demo/flying_picturing.jpg \\\"flying_picturing\\\")\\n\\nLater, when the job is done, on the Robonomics portal go to `Developer` -> `Chain state` and add a `DRONE` datalog using `“+”` button with selected `datalog` as state query. The IPFS hash of the telemetry has been saved in the blockchain. To see the data simply copy the hash and add it to the local [gateway](https://gateway.ipfs.io/ipfs/QmeYYwD4y4DgVVdAzhT7wW5vrvmbKPQj8wcV2pAzjbj886/docs/getting-started/) address `localhost:8080/ipfs/`:\\n\\n![Voila](../images/drone-demo/datalog.jpg \\\"Voila\\\")\\n\"}},{\"node\":{\"id\":\"31bb3db895745db1cf06f22ca90d4af9\",\"title\":\"Connect ROS-compatibale Drone To Robonomics Parachain. Part 1. Launch by Transaction\",\"path\":\"/docs/es/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/\",\"content\":\"\\n**In this article we will show that with the help of Robonomics tools you can control any ROS-compatible device. We will find a random drone simulation package on the web and adjust it to run with Robonomics.**\\n**Requirements:**\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=fDpwhBasQ5o&feature=youtu.be\\n\\n## 1. Find a simulation\\nLet's surf the web. Google for `ROS drone simulator`. The first link will mostly likely show you the `tum_simulator` page on [http://wiki.ros.org/tum_simulator](http://wiki.ros.org/tum_simulator)\\n\\n![tum_simulator](../images/drone-demo/tum_simulator.jpg \\\"tum_simulator\\\")\\n\\nIt's pretty outdated, so we better find a fork for our system. Google for `tum_simulator Ubuntu 18 Gazebo 9 fork`. The first result is a GitHub [repo](https://github.com/tahsinkose/sjtu-drone) with an appropriate package. Dowload it\\n```\\nmkdir -p drone_simulator_ws/src\\ncd drone_simulator_ws/src\\ngit clone https://github.com/tahsinkose/sjtu-drone\\ncd ..\\ncatkin build\\n```\\nDon’t forget to add source command to `~/.bashrc`:\\n```\\necho \\\"source /home/$USER/drone_simulator_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource \\\"~/.bashrc\\\"\\n```\\nNow we can run the simulation to see what do we need to do to take the drone under parachain control.\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\n\\n## 2. Inspect ROS topics\\nWhen the simulation is runnung, in a new tab run the following command to see the list of topics used by the drone:\\n```\\nrostopic list\\n```\\nLet's take a look at `/cmd_vel`, `/drone/takeoff` and `/drone/land`:\\n```\\nrostopic info /cmd_vel\\nrostopic info /drone/takeoff\\nrostopic info /drone/land\\n```\\n\\n![topics_info](../images/drone-demo/topics_info.jpg \\\"topics_info\\\")\\n\\nAs may be seen, there should be messages of `Twist` and `Empty` types, they are parts of `std_msgs` and `geometry_msgs`, we'll use this in the controller. Shut the simulation for a while.\\n## 3. Download controller package\\nGlobally, the main difference from the casual ROS robot controller is a block of code, which checks all the transactions in the network using [Robonomics IO](https://wiki.robonomics.network/docs/rio-overview/). The package itself is available on GitHub. Download it and build the workspace:\\n```\\ncd ~/drone_simulator_ws/src\\ngit clone https://github.com/PaTara43/drone_simulator_controller\\ncd drone_simulator_controller/src\\nchmod +x *.py\\ncd ~/drone_simulator_ws/src\\ncatkin build\\n```\\n## 4. Manage accounts in DAPP\\nSince we are testing, let's create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 5. Launching the drone under parachain control\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller.py\\n```\\n\\n![launched_drone](../images/drone-demo/launched_drone.jpg \\\"launched_drone\\\")\\n\\nNow you can send a transaction triggering the drone to start flying. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying:\\n\\n![flying](../images/drone-demo/flying.jpg \\\"flying\\\")\\n\\nThat's how any ROS-compatible robot can be controlled by Robonomics parachain control. Proceed to [part 2](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2) to learn more\\n\"}},{\"node\":{\"id\":\"29a3a773d0595bfe002851bc426d4dff\",\"title\":\"Configuration Options Description\",\"path\":\"/docs/es/configuration-options-description/\",\"content\":\"\\nBasically, you can think of the package as a black box with one input (sensor data) and many outputs.\\nFor now only SDS011 sensor is supported, but if you are familiar with Python it'd be easy to add other sensors as well.\\n\\nHave a look at [configuration](https://github.com/airalab/sensors-connectivity/blob/master/config/default.json) file:\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"port\\\": \\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\": 300,\\n      \\\"geo\\\": \\\"\\\",\\n      \\\"public_key\\\": \\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\nAt the moment it's possible to publish data to [Luftdaten](https://luftdaten.info/), [Robonomics Network](https://robonomics.network/) and [Datalog](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer).\\nThe last one is experimental!\\n\\n> DO NOT edit `config/default.json` file. Instead make a copy\\n\\nPlay around with the configuration!\\n\\nExplanation of options:\\n\\n| Field                         | Description                                                                                                                                                                                                                                           |\\n|------------------------------    |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |\\n| `general/publish_interval`         | integer number from 1 and above. Tells how often send measurements. Keep in mind that if measurements from sensors come less often than this number connectivity sends last data      |\\n| `general/db_path`                  |   path to the database (.db) file    |\\n| `comstation/enable`                | true/false. Enabling/disabling the station      |\\n| `comstation/port`                  | valid path to com port, for example `/dev/ttyUSB0`. It is where a sensor is connected to      |\\n| `comstation/work_period`           | integer from 0 to 1800. For SDS011 sensor 0 means continuous work. Recommended period is 300 seconds     |\\n| `comstation/geo`                   | `lat,lon` a string with two floats separated by a comma. It represents latitude and longitude of a sensor     |\\n| `comstation/public_key`            | Ed25519 verifying key in hex format. If not provided connectivity generates a new one      |\\n| `httpstation/enable`                | true/false. Enabling/disabling the station   |\\n| `httpstation/port`                  | what port listen to      |\\n| `mqttstation/enable`                | true/false. Enabling/disabling the station   |\\n|`mqttstation/host`                   | the hostname or IP address of the remote broker |\\n|`mqttstation/port`                   | the network port of the server host to connect to |\\n| `luftdaten/enable`                 | true/false. Whether or not publish data to [Luftdaten](https://devices.sensor.community/). Don't forget to register the sensor's mac address on the site         |\\n| `robonomics/enable`                | true/false. Whether or not publish data to IPFS topic according to Robonomics communication protocol      |\\n| `robonomics/ipfs_proveder`         | an endpoint for IPFS daemon. By default it's `/ip4/127.0.0.1/tcp/5001/http` that means local daemon. The endpoint must by in multiaddr format. For example for [Infura.io](https://infura.io/) it would be `/dns/ipfs.infura.io/tcp/5001/https`       |\\n| `robonomics/ipfs_topic`            | IPFS topic's name. If you want to use [DApp](https://sensors.robonomics.network) provided by Robonomics team leave it untouched                 |\\n| `datalog/enable`                   | true/false. Enable/Disable saving log to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)    |\\n| `datalog/suri`                     | a private key from robonomics parachain account  |\\n| `datalog/dump_interval`            | specify a period of time for collecting log in seconds                                      |\\n| `datalog/temporal_username`        | set username to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `detalog/temporal_password`        | set password to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `datalog/pinata_api`                | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) api key                      |\\n| `datalog/pinata_secret`            | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) secret api key                |\\n| `dev/sentry`                       | for development purpose. If you have a [Sentry.io](https://sentry.io/) account you can put sentry's credentials in here   |\\n| `frontier/enable`                  | true/false. Whether or not publish telemetry to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)   |\\n| `frontier/suri`                    | a private key from robonomics parachain account                                                       |\\n| `trackagro/enable`                 | true/false. Enabling/disabling the station from [TrackAgro](https://tmeteo.docs.apiary.io/#)          |\\n| `trackagro/token`                  | authorization token for [TrackAgro](https://tmeteo.docs.apiary.io/#)                                  |\\n\\n## Scenario #1: Connect SDS011 to serial port\\n\\nThe easiest and the most straightforward way to connect your sensor to the network is using the serial port\\n\\nConnect you SDS011 sensor to a USB port, let's assume it got `/dev/ttyUSB0` address\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #2: Connect SDS011 via HTTP\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n> Do not forget to open the port in system firewall\\n>\\n> On NixOS you can do:\\n> ```\\n> networking.firewall.allowedTCPPorts = [ 31313 ];\\n> ```\\n\\n## Scenario #3: Connect SDS011 via MQTT\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #4: Connect Multiple Sensors and Publish to Datalog\\n\\n### Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": true\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n\\n\"}},{\"node\":{\"id\":\"8332f5b88bb826b2a7bc3452ff171f40\",\"title\":\"Community\",\"path\":\"/docs/es/community/\",\"content\":\"\\n**Here you can learn how to get involved in the Robonomics Network Community.**\\n\\nThere are many ways to contribute to Robonomics Network: you can contribute directly based on your skills and professional background, you can attend an event, join the conversation online or watch for our latest news and release.\\n\\n## For Developers\\n\\n- [Robonomics' code base and new releases on GitHub](https://github.com/airalab)\\n- [Ask your technical question on Riot](https://riot.im/app/#/room/#robonomics:matrix.org)\\n\\n## For Researchers & Academics\\n\\n- [Read Robonomics White Paper and our scientific articles](https://robonomics.network/community/#science)\\n\\nIf you have a background in mathematics, cryptography, or economics you might be interested for collaboration with us, write us to [research@aira.life](mailto:research@aira.life)\\n\\n## For All, even non-technical\\n\\n- [Get familiar with Robonomics services and statistics in dApp - open in browser with Metamask](https://dapp.robonomics.network)\\n- [Read our blog](https://blog.aira.life)\\n- [Stay tuned by following us on Twitter](https://twitter.com/AIRA_Robonomics)\\n\\nIf you are not a developer or a researcher, you can start with other suggestions for getting involeved in Robonomics Network Community. If you want to organize a meetup in your city, write content about Robonomics, translate Robonomics content into your native language, write to [community@aira.life](mailto:community@aira.life)\\n\"}},{\"node\":{\"id\":\"55a55626a2e1b66e458182f1254f0df4\",\"title\":\"Changing Exodus Bridge Receiving Address\",\"path\":\"/docs/es/changing-exodus-receiving-address/\",\"content\":\"\\r\\nThis article will provide guidance on how you can change your Robonomics parachain receiving address in the event that you have input the wrong receiving address in the [Exodus bridge dapp](https://dapp.robonomics.network/#/exodus)\\r\\n\\r\\nPlease be aware that the process of changing the receiving address is not something that will be able to be carried out indefinitely, in fact the intervention of the development team is only possible during the early stages of the Robonomics parachain development, and eventually it will not be possible for the development team to conduct this kind of operation. **Please always ensure that you input the correct parachain address (i.e. one you have the seed phrase for) into the Exodus bridging application**.\\r\\n\\r\\n*Please be informed that the currently, if you input the wrong Robonomics parachain account address into the Exodus bridge dapp, then the process will be carried out as follows:*\\r\\n\\r\\n1. Complete the process as described in this article (i.e. signing the message & raising a GitHub issue).\\r\\n2. Bridged $XRT will be sent to the account originally input into the Exodus bridge dapp (i.e. the incorrect account).\\r\\n3. If no transactions are made on the incorrect account for 1 month, then the Robonomics team will transfer the $XRT tokens to the new address stipulated in the message (which you will sign as per the instructions below).\\r\\n\\r\\nOf course, the utmost priority for the Robonomics team is to ensure only valid changes of address are executed, as such you need to sign a message **from the Ethereum account which you originally deposited the $XRT tokens into the Exodus dapp**. We recommend that you utilize a site such as [MyCrypto](https://app.mycrypto.com/sign-message) to create this message (the following images will show how to conduct this process on MyCrypto).\\r\\n\\r\\nSelect the icon which corresponds to your web3 wallet, in our case we will choose MetaMask.\\r\\n\\r\\n![MyCrypto.com-Landing-Page](https://i.imgur.com/fyJyBG0.png)\\r\\n\\r\\nNow, click on the \\\"Connect to MetaMask\\\" button as shown above, and select the correct account (the account which you previously **sent $XRT tokens from**).\\r\\n\\r\\n![Page-after-selecing-metamask](https://i.imgur.com/1rd6izf.png)\\r\\n\\r\\nNow, we get the option to input a message, you shall follow the below template when inputting the message into this section, otherwise the process will not work. **These addresses relate to the Robonomics parachain addresses**.\\r\\n\\r\\n>Wrong target address: **WRONG_ADDRESS**. Right target address: **RIGHT_ADDRESS**\\r\\n\\r\\nSo, your message will look something like the message below (please make sure you input your own address, and not the one shown below). The message should all be on 1 line, don't use any line breaks (i.e. pressing enter). Afterwards, press the \\\"Sign Message\\\" button located under the message text.\\r\\n\\r\\n![example-of-how-the-message-should-look](https://i.imgur.com/jb1YqLs.png)\\r\\n\\r\\nNow you should get a notification on your web 3 wallet, click \\\"Sign\\\".\\r\\n\\r\\n![Example-metamask-notification](https://i.imgur.com/GTHEYTs.png)\\r\\n\\r\\nOnce signed, wait a few moments and then the MyCrypto page should change, and a signature shall appear.\\r\\n\\r\\n![signature-generated-from-signed-message](https://i.imgur.com/JemAEPm.png)\\r\\n\\r\\nNext, you need to head on over to the [Robonomics GitHub page](https://github.com/airalab/robonomics/issues/new), and open a new issue. The issue should have the title \\\"Robonomics exodus: a request to change the target address\\\", and the body / comment of the issue shall be the signature generated by MyCrypto. Afterwards, click \\\"Submit new issue\\\", and the Robonomics team will handle your issue and leave a reply to your issue regarding the status of your request.\\r\\n\\r\\n![example-of-GitHub-issue](https://i.imgur.com/6ZHSFRw.png)\"}},{\"node\":{\"id\":\"3fb9dae9aafbead5734aa732608060aa\",\"title\":\"Offsetting Service\",\"path\":\"/docs/es/carbon-footprint-service/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"}},{\"node\":{\"id\":\"6e0a0277cddc1dff798e2aac8071a2ef\",\"title\":\"Connect sensor\",\"path\":\"/docs/es/carbon-footprint-sensor/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"}},{\"node\":{\"id\":\"15c6cfe6de8d4524a770338780070ed6\",\"title\":\"Say \\\"Hello Baxter!\\\" with robonomics\",\"path\":\"/docs/es/baxter2/\",\"content\":\"Example of how it works:\\n\\nhttps://youtu.be/2Dvuv0ZE2Bw\\n\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```sh\\nsudo apt-get install ros-melodic-qt-build ros-melodic-driver-common ros-melodic-gazebo-ros-control ros-melodic-gazebo-ros-pkgs ros-melodic-ros-control ros-melodic-control-toolbox ros-melodic-realtime-tools ros-melodic-ros-controllers ros-melodic-xacro python-wstool ros-melodic-tf-conversions ros-melodic-kdl-parser python-wstool python-catkin-tools qt4-default\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```sh\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node (binary file) (download latest [release][db4] here)\\n - Create __Baxter__ and __Employer__ accounts  on **Robonomics Portal**  \\n (you can find tutorial [\\\"Create an Account on Robonomics Portal\\\"][db8] here).\\n - IPFS browser extension (not necessary)\\n\\n## 0. install CV Bridge extension for python3\\n\\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n## 1. Download simulation and controller packages\\nWe will need to create 2 workspaces - one for main Baxter's packages and other for main control programme.\\nFirst workspace. It's main control programme. It will run under python3.\\n\\n```sh\\ncd ~\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src/\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\npip3 install -r requirements.txt\\n```\\nSecond workspace. There will be all Baxter's packages. Simulation is very old, so it could run only under python2.\\n```shell\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src/\\nwstool init .\\nwstool merge https://raw.githubusercontent.com/RethinkRobotics/baxter_simulator/master/baxter_simulator.rosinstall\\nwstool update\\n```\\nThese packages were created for ROS indigo. We have to change some files to run them on ROS melodic.\\nWe will use **patch** files.\\n```sh\\npatch ./baxter_simulator/baxter_sim_io/include/baxter_sim_io/qnode.hpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/qnode_patch\\npatch ./baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/arm_patch\\npatch ./baxter_interface/src/baxter_interface/robot_enable.py ~/robonomics_ws/src/Baxter_simulation_controller/patch/interface_patch\\n```\\nAnd let's build  all our packages:  \\nFirst build Baxter's packages\\n```sh\\ncd ../\\ncatkin build\\n```\\nThen return to first workspace and build it too:\\n```sh\\ncd ~/Baxter_simulation_controller/\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\necho \\\"source /home/$USER/robonomics_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```  \\n\\n\\n## 2. Start simulation\\n### Let's start our simulation:\\nAt first go to `robot_ws` and copy and edit baxter.sh\\n```sh\\ncd ~/robot_ws/\\ncp src/baxter/baxter.sh .\\n```\\nFind your local ip address with command:\\n```\\nip a\\n```\\n![ip_a][im14]\\n\\nEdit the following values in `baxter.sh` :\\n```\\nnano baxter.sh\\n```\\n\\n- your_ip - put your local ip address. See `ip a`\\n- ros_version - for example \\\"melodic\\\"\\n\\n![baxtersh][im15]\\n\\nRun the baxter shell script with sim specified:\\n```sh\\n./baxter.sh sim\\nroslaunch baxter_gazebo baxter_world.launch\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp\\n```\\n![robonomics][im3]\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts.\\n\\nYou can find The manual \\\"Create an Account on Robonomics Portal\\\" [here][db8]\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\n\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n![create account2][im16]\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robonomics_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same portal [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nWhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL:  \\n#### gateway.ipfs.io/ipfs/< put your hash here>\\n\\n\\n\\nThat's all!\\n\\n![result1][im12]\\n![result2][im13]\\n\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/ip_a.png>\\n[im15]: <../images/baxter_demo/baxter_sh.jpg>\\n[im16]: <../images/baxter_demo/create_account2.jpg>\\n[db8]: <https://wiki.robonomics.network/docs/create-account-in-dapp/>\"}},{\"node\":{\"id\":\"875a30fdb13574ad02073435030cbd9e\",\"title\":\"Control Baxter robot with robonomics\",\"path\":\"/docs/es/baxter/\",\"content\":\"\\nExample of how it works:\\n\\nhttps://www.youtube.com/watch?v=JivTDhDJLHo\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-melodic-cv-bridge\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```shell\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node download latest [release][db4] here (last tested release v1.1)\\n - IPFS browser extension (not necessary)\\n## 0. install CV Bridge extension for python3\\n \\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\n\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n\\n## 1. Download simulation and controller packages\\nDownload packages:\\n```sh\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\ngit checkout old_version\\npip3 install -r requirements.txt\\ncd ../..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n## 2. Start simulation\\nLet's start gazebo world and put our baxter in it:\\n```sh\\nroslaunch gazebo_ros empty_world.launch\\n```\\n![empty world][im1]\\n\\nOpen one more window in terminal:\\n```sh\\nrosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp --rpc-cors all\\n```\\n![robonomics][im3]\\n\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts (__Robot__ is not necessary)\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n\\n![create account2][im14]\\n\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robot_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nwhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL: gateway.ipfs.io/ipfs/< put your hash here >\\n\\n![ipfs][im11]\\n\\nClick  __View on Gateway__ and that's all!\\n\\n![result1][im12]\\n\\n![result2][im13]\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/create_account2.jpg>\"}},{\"node\":{\"id\":\"cf303c5554d42be605c5e25884c096ec\",\"title\":\"AIRA Overview\",\"path\":\"/docs/es/aira-overview/\",\"content\":\"\\n## Introduction\\n\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It implements the standard of economic interaction between human-robot and robot-robot. AIRA makes it possible to connect a variety of different robots under decentralized computer's control (currently supported Ethereum and Polkadot/Substrate).\\n\\nBasically it is the client for Robonomics Network developed by [Airalab](https://aira.life).\\n\\nAIRA is NixOS based operating system and officially supports the following architectures: x86, Raspberry Pi 3 B+ and Raspberry Pi 4.\\n\\nThe most simple way to get familiar with AIRA is to try installing AIRA as a [virtual machine](/docs/aira-installation-on-vb/).\\n\\nAIRA comes with a few preinstalled and configured services to help you focus on [agent](/docs/glossary#agent) development.\\n\\nMeanwhile it's highly customizable, but it's recommended to understand [NixOS](http://nixos.org/) and [Nix](https://nixos.org/nix/) language.\\n\\n## What's included? \\n\\nThe following services are included in the default distribution:\\n\\n* [Robonomics communication stack](https://github.com/airalab/robonomics_comm)\\n* [IPFS](https://ipfs.io/)\\n* OpenSSH\\n* [cjdns](https://github.com/cjdelisle/cjdns)\\n* [Yggdrasil-go](https://yggdrasil-network.github.io/)\\n\\nBesides at the first launch AIRA [generates](/docs/aira-installation-on-vb#launch-the-machine) for you new Ethereum address and IPNS identifier.\\n\\nIt's possible to use AIRA as a virtual machine or install as a main operating system. Also you can install only the services you need.\\n\"}},{\"node\":{\"id\":\"485554d9085b01c42dbeddc124ac7fc9\",\"title\":\"AIRA Installation\",\"path\":\"/docs/es/aira-installation/\",\"content\":\"\\n- [**How to launch AIRA on VirtualBox**](/docs/aira-installation-on-vb/)\\n\\n- **The installation on Raspberry Pi** is as simple as writing an image of AIRA on SD card using `dd` or [Etcher](https://www.balena.io/etcher/), for example.\\n\\n\\n\"}},{\"node\":{\"id\":\"46c772c3bb327255baf4a520417f6de1\",\"title\":\"Instalación de AIRA en VirtualBox\",\"path\":\"/docs/es/aira-installation-on-vb/\",\"content\":\"\\nAIRA significa “Autonomous Intelligent Robot Agent”. Es el cliente de Robonomics Network desarrollado por [Airalab](https://aira.life). Es un sistema operativo basado en [NixOS](https://nixos.org/). Con AIRA puedes convertir cualquier sistema ciberfísico en un agente económico, donde los robots operan como un servicio por los pagos razonables. [Más informacion sobre AIRA aquí]((/docs/aira-overview))\\n\\nEs posible instalar AIRA en una x86_64 PC. También hay imágenes para Raspberry Pi 3 y 4 compatibles con el equipo.\\n\\nLa mejor manera de probar AIRA es comenzar desde instalarlo como una máquina virtual en [VirtualBox](https://www.virtualbox.org/).\\n\\n## Requerimientos\\n\\n* VirtualBox\\n* [Paquete de extensión de VirtualBox](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2Gb de RAM para la máquina\\n* 40Gb de espacio libre en disco\\n\\n## Obtener la Imagen\\n\\nAIRA tiene canales [estables](https://aira.life/channels/aira-stable/) e [inestables](https://aira.life/channels/aira-unstable/). Para obtener una imagen estable, descargue el archivo con la extensión `.ova`. El enlace para una imagen estable [está aquí](https://releases.aira.life/channels/aira/stable/862-aira-stable/nixos-20.03pre-git-x86_64-linux.ova).\\n\\nNo olvide comparar la suma de comprobación de la imagen descargada con el hash `SHA-256` de la última columna en [la página de descarga](https://aira.life/channels/aira-stable/). Debe ser igual a la salida del siguiente comando (es un ejemplo, primero verifique el nombre del archivo .ova descargado):\\n\\n```\\nsha256sum nixos-20.03pre-git-x86_64-linux.ova\\n```\\n\\nEs posible que desee ver el video tutorial:\\n\\nhttps://www.youtube.com/embed/cDcaypYPBhI\\n\\n## Solución de Problemas\\n\\nSi tiene VirtualBox recién instalado, debe instalar el pack de [extensión](https://www.virtualbox.org/wiki/Downloads) o deshabilitar el controlador USB 2.0.\\n\\nAdemás, VirtualBox puede mostrar una advertencia sobre `Display settings`. Considere cambiar el `Graphics Controller` en la configuración de la máquina virtual a `VMSVGA`.\\n\\n## Importar a VirtualBox\\n\\nAbra VirtualBox y presione `Ctrl+I` o `File > Import Applicance...`\\n\\n![Imagen VB de importación AIRA](../images/aira-installation/aira_import_vb_image.jpg \\\"Imagen VB de importación AIRA\\\")\\n\\nEn este momento, el siguiente paso no es necesario, pero te ayudará a conectarte a la VM a través de SSH fácilmente.\\n\\nPrimero agregue el adaptador `Host-Only` en el menú de VirtualBox `File > Host Network Manager...` o presionando `Ctrl+H`\\n\\n![Host Only](../images/aira-installation/host_only_adapter.jpg \\\"Host Only\\\")\\n\\nLuego vaya a la configuración de la imagen, Red y agregue el segundo adaptador de red.\\n\\n![Segundo adaptador](../images/aira-installation/add_second_adapter.jpg \\\"Segundo adaptador\\\")\\n\\nPara obtener más detalles, consulte [la lección](/docs/aira-connecting-via-ssh/) independiente.\\n\\nOpcionalmente, puede aumentar la cantidad de memoria de video y cambiar `Graphics Controller` a `VMSVGA`.\\n\\n## Iniciar la Maquina\\n\\nFinalmente presione `Start` y verá AIRA dándole la bienvenida con la dirección Ethereum generada y el identificador IPFS\\n\\n![Imagen AIRA lista, pantalla de bienvenida](../images/aira-installation/aira_image_ready.jpg \\\"Imagen AIRA lista, pantalla de bienvenida\\\")\\n\\nEn la primera inicialización, AIRA genera una nueva dirección Ethereum e identificador IPNS para usted.\\n\\n\"}},{\"node\":{\"id\":\"163fa3a4415473e2230c79894343b4ba\",\"title\":\"Frequently Asked Questions about AIRA\",\"path\":\"/docs/es/aira-faq/\",\"content\":\"\\n## How to see logs from main services?\\n\\nIPFS in real time:\\n\\n    journalctl -u ipfs -f\\n\\nand Liability::\\n\\n    journalctl -u liability -f\\n\\n## How to check the quantity of IPFS peers?\\n\\n    ipfs pubsub peers \\n\\n## IPFS can't connect to the daemon, what should I do?\\n\\nTry to specify `--api` option\\n\\n    ipfs swarm peers --api=/ip4/127.0.0.1/tcp/5001/\\n\\n## How to change ethereum address of AIRA?\\n\\nDelete `keyfile` and `keyfile-psk` in `/var/lib/liability` and restart the service\\n\\n```\\nsystemctl restart liability\\n```\\n\\n## IPFS daemon doesn't start\\n\\nThe error mostly occurs on single-board computers like Raspberry Pi or LattePanda after unexpected electricity lost.\\n\\nUsually the file `/var/lib/ipfs/api` is corrupted and one may see error:\\n\\n```\\nError: Failed to parse '/var/lib/ipfs/api' file.\\n  error: failed to parse multiaddr \\\"\\\": empty multiaddr\\nIf you're sure go-ipfs isn't running, you can just delete it.\\nOtherwise check:\\n  ps aux | grep ipfs\\n```\\n\\nYou can delete `/var/lib/ipfs/api` file and restart the service\\n\\n\"}},{\"node\":{\"id\":\"32ee662b61ab1efe0d77a1914c330239\",\"title\":\"Conexión de Aira a través de SSH\",\"path\":\"/docs/es/aira-connecting-via-ssh/\",\"content\":\"\\nEs más conveniente trabajar con una máquina virtual a través de una conexión SSH. En esta sección configuraremos VM.\\n\\n> **Se requiere tener su clave pública ssh en Github. En caso de que no tenga uno, siga [el enlace](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\nA continuación se muestra el video tutorial:\\n\\nhttps://www.youtube.com/embed/R6waDG5iwm0\\n\\n## Añadir el Adaptador Host\\n\\nVaya a `File` -> `Host Network Manager...` o presione `Ctrl+H`\\n\\n![Administrador de red de VirtualBox](../images/virtualbox_network_manager.png \\\"Administrador de red de VirtualBox\\\")\\n\\nClick en boton `Create`.\\n\\n## Añadir el segundo adaptador a la VM\\n\\nSeleccione la VM importada y haga clic en `Settings`. Vaya a la pestaña `Network` y habilite el segundo adaptador.\\n\\n![Añadir el segundo adaptador](../images/add_second_adapter_to_vm.png \\\"Añadir el segundo adaptador\\\")\\n\\n## Keys Autorizadas Pobladas\\n\\nInicie la VM y ejecute el siguiente comando reemplazando `<username>` con su nombre de usuario de Github:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nDescubra la dirección IP de la máquina virtual ejecutando:\\n\\n```\\nip a\\n```\\n\\nDebe buscar una dirección que comience con `192.168.xx.xx`\\n\\n## Iniciar Sesion a través de SSH\\n\\nAhora abra su terminal e inicie sesión a través de SSH como de costumbre usando la dirección del paso anterior:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n\"}},{\"node\":{\"id\":\"844872b5b5b148bd32571e745ad79b49\",\"title\":\"Basic usage of AIRA\",\"path\":\"/docs/es/aira-basic-usage/\",\"content\":\"\\nTo get familiar with AIRA, let's see what is under the hood.\\n\\nOnce you launch the client several ros nodes will already be on the run. Here's a list of robonomics communication stack nodes:\\n\\n```bash\\n$ rosnode list\\n/eth/erc20_token\\n/eth/eth_node\\n/graph/aira_graph\\n/liability/executor\\n/liability/infochan/eth/signer\\n/liability/infochan/ipfs_channel\\n/liability/persistence\\n/liability/listener\\n/rosout\\n```\\n\\n- `/eth/erc20_token`, `/eth/eth_node` - proved services for Ethereum blockchain and ERC20 tokens\\n- `/graph/aira_graph` - service node for exploring other AIRA instances\\n- `/liability/executor` - gets rosbag file from IPFS and plays it\\n- `/liability/infochan/ipfs_channel` - is responsible for offer, demand and result messages. It catches messages from the channel and sends signed messages back\\n- `/liability/infochan/eth/signer` - offers services for signing offer, demand and result messages\\n- `/liability/listener` - watches for a new liability contracts. When the event is received the node calls executor node\\n- `/liability/persistence` - helps to store incoming liabilities and restart them after shutdown\\n\\nAnd here's a list of robonomics stack topics.\\n\\n```bash\\n$ rostopic list\\n/eth/event/approval\\n/eth/event/transfer\\n/graph/greetings\\n/liability/complete\\n/liability/finalized\\n/liability/incoming\\n/liability/infochan/eth/sending/demand\\n/liability/infochan/eth/sending/offer\\n/liability/infochan/eth/sending/result\\n/liability/infochan/eth/signing/demand\\n/liability/infochan/eth/signing/offer\\n/liability/infochan/eth/signing/result\\n/liability/infochan/incoming/demand\\n/liability/infochan/incoming/offer\\n/liability/infochan/incoming/result\\n/liability/persistence/add\\n/liability/persistence/del\\n/liability/persistence/update_timestamp\\n/liability/ready\\n/liability/result\\n/rosout\\n/rosout_agg\\n```\\n\\nThe most important topics for us are:\\n\\n- `/liability/incoming` - when a new liability is created, this topic publishes Ethereum address of the contract\\n- `/liability/result` - this topic is for publishing results. But don't publish a result directly to this topic! Use a service instead\\n- `/liability/infochan/incoming/*` - a CPS gets information about offer, demand or result from corresponding topics\\n- `/liability/infochan/eth/signing/*` - a CPS sends offer, demand or result messages to corresponding topics\\n\\nFor the details check out the [API page](/docs/robonomics-liability/).\\n\\nLet's start with greetings - say hello to AIRA!\\n\\nYou should just launch a pre-installed package `hello_aira`:\\n\\n```\\n$ rosrun hello_aira hello_aira\\n```\\n\\nWe've launched our agent. It will wait for a demand message. Now it's time to send the message. Go to [dapp](https://airalab.github.io/robonomics_tutorials/) and press Order.\\nNow go back to the console and see the result!\"}},{\"node\":{\"id\":\"a70d1e9fa48be6a0d780b12a09066f26\",\"title\":\"Agent development examples\",\"path\":\"/docs/es/agent-development-examples/\",\"content\":\"\\nUseful pieces of code and a few scenarios. All source code is [here](https://github.com/vourhey/robonomics_tutorials).\\n\\n1. [Broadcast Demand](https://github.com/Vourhey/robonomics_tutorials/tree/master/01_broadcast_demand/)\\n2. [Broadcast Offer](https://github.com/Vourhey/robonomics_tutorials/tree/master/02_broadcast_offer/)\\n3. [Trader](https://github.com/Vourhey/robonomics_tutorials/tree/master/03_trader/)\\n4. [Trader with ACL](https://github.com/Vourhey/robonomics_tutorials/tree/master/04_trader_with_acl/)\\n5. [Open Sensor Data](https://github.com/Vourhey/robonomics_tutorials/tree/master/05_open_sensor_data/)\\n\\n\"}},{\"node\":{\"id\":\"114a2cfbd3a9c381057fc24ad70dd64d\",\"title\":\"Add Device to Robonomics\",\"path\":\"/docs/es/add-smart-device-to-robonomics/\",\"content\":\"For each device you need separate [Robonomics accounts](/docs/create-account-in-dapp/). After you've added your devices, you need to add them in a `config.config` file with their seeds. Firstly in `Configuration/Entities` tab in your Home Assistant find entity ids of your devices:\\n\\n![entity_id](../images/home-assistant/entity_id.png)\\n\\nOpen the configuration file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add there information of your devices in the following format:\\n\\n```\\n[device_name]\\nIDS = ['entity_id1', 'entity_id2']\\nSEED = word word word\\n```\\nWhere `device_name` is the name of your device (you can choose any name), `IDS` are entity ids of the data from the device (it may be one or more ids) and `SEED` is a mnemonic or raw seed from robonomics account to this device.\\n\\nAfter you fill the configuration file you need to get access token from Home Assistant. For that open your `profile` in the lower left corner:\\n\\n![profile](../images/home-assistant/profile.png)\\n\\nIn the end of the page find `Long-Lived Access Tokens` and press `create token`. Save it somewhere, you will not be able to see it again.\\n\\n![token](../images/home-assistant/token.png)\\n\\nNow run `create_config.py` script with your token:\\n\\n```bash\\ncd /srv/homeassistant\\nsource bin/activate\\npython3 python_scripts/create_config.py --token <access_token>\\n```\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\\n\\nYou can add the data from sensors to your homepage like in `Home Assistant setup` in the description to [Method 1](/docs/zigbee2-mqtt/).\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. Data looks like this:\\n\\n![datalog_data](../images/home-assistant/datalog_data.png)\\n\\nYou can decrypt it with script `decrypt.py`, run it with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"0da2c759a752e7ca8e141dd5b2e57454\",\"title\":\"Connect Sensors with Zigbee2MQTT\",\"path\":\"/docs/en/zigbee2-mqtt/\",\"content\":\"\\n## Mosquitto MQTT broker\\n\\nFor this method, you neet to install MQTT broker to the Raspberry Pi:\\n\\n```bash\\nsudo apt update\\nsudo apt install mosquitto mosquitto-clients\\n```\\nThe Mosquitto program will run automatically after installation.\\n\\n## Zigbee2MQTT setup\\n\\nIf you have the JetHome USB JetStick Z2 it will already have the necessary firmware so you don't need to flash it. However, if you have another adapter the first thing you need to flash it with zigbee2MQTT software. You can find instructions for your device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nThen we need to install the ziqbee2mqtt software on the  Raspberry PI. Connect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\nInstall zigbee2MQTT:\\n```bash\\n# Setup Node.js repository\\nsudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\\n\\n# NOTE 1: If you see the message below please follow: https://gist.github.com/Koenkk/11fe6d4845f5275a2a8791d04ea223cb.\\n# ## You appear to be running on ARMv6 hardware. Unfortunately this is not currently supported by the NodeSource Linux distributions. Please use the 'linux-armv6l' binary tarballs available directly from nodejs.org for Node.js 4 and later.\\n# IMPORTANT: In this case instead of the apt-get install mentioned below; do: sudo apt-get install -y git make g++ gcc\\n\\n# NOTE 2: On x86, Node.js 10 may not work. It's recommended to install an unofficial Node.js 14 build which can be found here: https://unofficial-builds.nodejs.org/download/release/ (e.g. v14.16.0)\\n\\n# Install Node.js;\\nsudo apt-get install -y nodejs git make g++ gcc\\n\\n# Verify that the correct nodejs and npm (automatically installed with nodejs)\\n# version has been installed\\nnode --version  # Should output v10.X, v12.X, v14.X or v15.X\\nnpm --version  # Should output 6.X or 7.X\\n\\n# Clone Zigbee2MQTT repository\\nsudo git clone https://github.com/Koenkk/zigbee2mqtt.git /opt/zigbee2mqtt\\nsudo chown -R ubuntu:ubuntu /opt/zigbee2mqtt\\n\\n# Install dependencies (as user \\\"ubuntu\\\")\\ncd /opt/zigbee2mqtt\\nnpm ci\\n```\\nThen you need to configure it. Open configuration file:\\n```bash\\nnano /opt/zigbee2mqtt/data/configuration.yaml\\n```\\nAnd paste this:\\n```\\npermit_join: true\\nmqtt:\\n  # MQTT base topic for Zigbee2MQTT MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://localhost'\\n```\\nNow you can run zigbee2mqtt:\\n```bash\\ncd /opt/zigbee2mqtt\\nnpm start\\n```\\n## Pairing device\\n\\nThen you need to pair your sensor. For that just long press the power button until it starts to blink (zigbee2MQTT must be launched). After sensor connects you will see the message like:\\n```\\nZigbee2MQTT:info  2019-11-09T12:19:56: Successfully interviewed '0x00158d0001dc126a', device has successfully been paired\\n```\\n> Remember this number `0x00158d0001dc126a` it will be the topic name for your sensor's data.\\nThen open configuration file again and set `permit_join: false`.\\n\\nThen lets make a service. Create the file:\\n```bash\\nsudo nano /etc/systemd/system/zigbee2mqtt.service\\n```\\nAdd the following to this file:\\n```\\n[Unit]\\nDescription=zigbee2mqtt\\nAfter=network.target\\n\\n[Service]\\nExecStart=/usr/bin/npm start\\nWorkingDirectory=/opt/zigbee2mqtt\\nStandardOutput=inherit\\n# Or use StandardOutput=null if you don't want Zigbee2MQTT messages filling syslog, for more options see systemd.exec(5)\\nStandardError=inherit\\nRestart=always\\nUser=pi\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nVerify that the configuration works:\\n\\n```bash\\nsudo systemctl start zigbee2mqtt\\n```\\n\\n```bash\\nsystemctl status zigbee2mqtt.service\\n```\\n\\nOutput should look like:\\n```\\npi@raspberry:/opt/zigbee2mqtt $ systemctl status zigbee2mqtt.service\\n● zigbee2mqtt.service - zigbee2mqtt\\n   Loaded: loaded (/etc/systemd/system/zigbee2mqtt.service; disabled; vendor preset: enabled)\\n   Active: active (running) since Thu 2018-06-07 20:27:22 BST; 3s ago\\n Main PID: 665 (npm)\\n   CGroup: /system.slice/zigbee2mqtt.service\\n           ├─665 npm\\n           ├─678 sh -c node index.js\\n           └─679 node index.js\\n\\nJun 07 20:27:22 raspberry systemd[1]: Started zigbee2mqtt.\\nJun 07 20:27:23 raspberry npm[665]: > zigbee2mqtt@1.6.0 start /opt/zigbee2mqtt\\nJun 07 20:27:23 raspberry npm[665]: > node index.js\\nJun 07 20:27:24 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Logging to directory: '/opt/zigbee2mqtt/data/log/2019-11-09.14-04-01'\\nJun 07 20:27:25 raspberry npm[665]: Zigbee2MQTT:info  2019-11-09T13:04:01: Starting Zigbee2MQTT version 1.6.0 (commit #720e393)\\n```\\n\\nNow that everything works, we want systemctl to start Zigbee2MQTT automatically on boot, this can be done by executing:\\n\\n```bash\\nsudo systemctl enable zigbee2mqtt.service\\n```\\n\\n## Home Assistant Setup\\n\\nOpen Home Assistant configuration file:\\n\\n```bash\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add the following to setup MQTT broker and sensor (replace `topic_name` with the topic name from previous step):\\n\\n```\\n# MQTT broker setup\\nmqtt:\\n  broker: localhost\\n  port: 1883\\n\\n# Sensor setup\\nsensor:\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Humidity\\\"\\n    unit_of_measurement: '%'\\n    value_template: \\\"{{ value_json.humidity }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Temperature\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.temperature }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Pressure\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.pressure }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Battery\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.battery }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Link Quality\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.linkquality }}\\\"\\n  - platform: mqtt\\n    state_topic: \\\"zigbee2mqtt/<topic_name>\\\"\\n    name: \\\"MQTT Climate Voltage\\\"\\n    unit_of_measurement: ''\\n    value_template: \\\"{{ value_json.voltage }}\\\"\\n\\n# Trigger on receiving data\\nautomation:\\n  - alias: \\\"send_datalog_climate\\\"\\n    trigger:\\n      platform: mqtt\\n      topic: \\\"zigbee2mqtt/0x00158d0006bcd022\\\"\\n    action:\\n      service: shell_command.send_datalog_climate\\n\\n# Shell command that will run on the trigger\\nshell_command:\\n  send_datalog_climate: 'python3 python_scripts/send_datalog.py temperature={{ states(\\\"sensor.mqtt_climate_temperature\\\")  }} humidity={{ states(\\\"sensor.mqtt_climate_humidity\\\") }} pressure={{ states(\\\"sensor.mqtt_pressure\\\") }} battery={{ states(\\\"sensor.mqtt_climate_battery\\\") }} linkquality={{ states(\\\"sensor.mqtt_climate_link_quality\\\") }} voltage={{ states(\\\"sensor.mqtt_climate_voltage\\\") }}'\\n```\\n\\nThen start Home Assistant with new configuration:\\n\\n```bash\\ncd /srv/homeassistant\\nhass\\n```\\n\\nTo see the sensor data in Home Assistant you need to add it. For that open the browser on your computer and go to:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nPress on three dots on the right side and choose `Edit Dashboard`\\n\\n![edit_dashboard](../images/home-assistant/dashboard.png)\\n\\nThen press `Add Card`\\n\\n![card](../images/home-assistant/card.png)\\n\\nGo to `By Entity` and tick all sensors that you need\\n\\n![sensors](../images/home-assistant/sensors.png)\\n\\nPress continue and you will be able to see sensor data at the homepage (you may see `unknown` before sensor send new data)\\n\\nIn a similar way you can add card for Robonomics Service. With this you can start or stop the servise or send current measurements with `run action` button.\\n\\n![action](../images/home-assistant/datalog.png)\\n\\nYou homepage will look like this\\n\\n![home](../images/home-assistant/home.png)\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. You can decrypt the data with script [decrypt.py](https://github.com/airalab/robonomics-smarthome/blob/main/python_scripts/decrypt.py), download it:\\n\\n```bash\\ncd /srv/homeassistant/python_scripts\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\n```\\nAnd run with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}},{\"node\":{\"id\":\"099130634e6c9f128e46db75273f4617\",\"title\":\"Connect Sensors with Xiaomi Gateway\",\"path\":\"/docs/en/xiaomi-gateway/\",\"content\":\"\\nYou need your Xiaomi gateway along with all the sensors to be connected to the Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your hub (it must be in connecting mode which is achieved via a long press of the power button) and follow instructions in the app. After you add the gateway, you need to add sensors: press on your gateway, then go to `Child device` and press `+`. Find required device and follow the instructions on the screen. For more details refer to the user manual of your Xiaomi Gateway hub.\\n\\n## Add Gateway to Home Assistant\\nBe sure that you're logged in you raspberry as `homeassistant` user, if not do the following:\\n```bash\\nsudo -u homeassistant -H -s\\n```\\n\\nIn your Home Assistant:\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations` and press `Add Intagration`. There you need to Find `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Hub (Aqara Hub in this example):\\n\\n![hub](../images/home-assistant/hub.png)\\n\\nPress `Submit` and you will be able to see your gateway in Integrations page.\\n\\n## Add Gateway to Home Assistant using Homekit Controller integration\\n\\nYou can also connect your hub to Aqara Home app on ios and then add it to Home Assistant through Homekit Controller integration. \\n\\nAdd your hub to the app using `add device` or `+` button. Right after your hub added to Aqara Home app you will be proposed to bind it with your Homekit account. \\n\\n![homekit](../images/home-assistant/homekit.png)\\n\\nWhen you see a menu like the picture, open your Home Assistant page:\\n\\n```\\nhttp://<raspberry_address>:8123\\n```\\nGo to `Configuration/Integrations`. Here you can find your device discovered and click `Configure` button to add it by Homekit Controller integration. You have to enter pairing code of your device, which you can find on the sticker on your device.\\n\\n![configure1](../images/home-assistant/configure1.png)\\n\\n![configure2](../images/home-assistant/configure2.png)\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"d28a9d1318a1398cab313120ffca01a1\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/en/xcm-robobank/\",\"content\":\"\\n\\nThe main goal of this project is the simplification of parachain runtime development, when cross-chain messages are used. \\nIt allows the development of runtime code with integration tests with high degree of repeatability and simple usage.\\nIt automates building, construction of pre-set network configuration (i.e. 1 relay chain + 2 parachains), setup message-passing channels between parachains and run messaging tests, sending messages, using call to runtime, all constructed and composed in Python.\\n\\nXCM Testsuite is used for testing the production cycle of Robobank - the set of Substrate pallets, which allow robots to register on external parachains, receive pre-paid orders, execute them and receive payments using external tokens. This allows robots to operate inside the Robonomics network with all required infrastructure, but at the same time, offer their services on any other parachain.\\n\\nAn example video is available on [YouTube](https://www.youtube.com/watch?v=S_bZgsxngiM)\\n\\nThe main steps in the demo scenario are:\\n- launch relay chain and two parachains in a pack of 6 processes\\n- setup XCM message channels between parachains\\n- register a robot in both parachains\\n- create an order for this robot in the client parachain (reserving payment for the completion of order)\\n- send XCM message to the Robonomics parachain\\n- creating the \\\"mirrored\\\" order record on the Robonomics parachain\\n- robot accepts the order on the Robonomics parachain\\n- send XCM message about the order acceptance back to the client parachain\\n- accept the order on the client parachain (reserving a penalty fee for lack-of-order-completion until the order deadline)\\n- robot completes the order on the Robonomics parachain\\n- send XCM message about the order completion to the client parachain\\n- settle all payments (client payment is transfered to the robot, as well as the unutilized penalty fee)\\n- close the order1\\n\\n\\n## Upstream\\nThis project is a fork of the\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template).\\nIt contains code of the runtime pallets being tested.\\nAs in original node code of the parachains is in \\\"./pallets\\\", \\\"./runtime\\\", \\\"./node\\\" catalogs.\\n\\nDifferences with original \\\"substrate-node-template\\\":\\n- this collator runtime has HRMP handler module and can handle messages from siblings parachains\\n- mock test runtime ready-made for internal XCM tests\\n\\n## Build & Run\\nRecommended(highly) setup: \\n```\\nUbuntu 20, 16 Gb RAM, 8 CPU, 120 Gb SSD\\n```\\n[NOTE] The first build can take a lot of time, up to several hours on suboptimal machines.\\n\\n[NOTE] The script works with the FIXED versions (commit hashes) of Polkadot(Rococo) in relay chain and parachains.\\n\\n[NOTE] By default the script re-creates the same environment every launch, by removing all previous states. This behaviour can be changed in \\\"config.sh\\\" using \\\"PERSISTENT\\\" param.\\n\\n\\nRun build and setup script.  \\n```bash\\ngit clone https://github.com/airalab/xcm-robobank-prototype.git\\ncd xcm-robobank-prototype\\n./scripts/init.sh\\n```\\n\\nBasic actions of \\\"init.sh\\\" script:\\n - read config (file \\\"config.sh\\\" with revision number, initial node keys and identifiers, chaindata persistence param, etc.)\\n - setup OS packets, Rust and Python\\n - bulds separate binaries for the relay chain and also for both parachains\\n    - binaries will be generated in ./bin subdirectory. \\n - (optional) removes all previous chain data for all chains\\n    - disabled if \\\"PERSISTENT=1\\\" is set in \\\"config.sh\\\"\\n - runs as separate processes (with separate PIDs and I/O pipes):\\n    - validators of relay chain (i.e. 4 validators of running a stable Rococo revision)\\n    - collators for parachain-100 (i.e. single collator for first parachain, that you're developing)\\n    - collators for parachain-200 (i.e. single collator for second parachain, that you're developing)\\n - prints all endpoints, ports to console, allowing you to study any chain using frontend apps (explorer, DApp)\\n - keep printing all the output data of all chains to console\\n\\n[WARNING] After launching, wait until the network is up, make sure that block finalization has started, and that the parachains are registered. These processes should require approximately 5 min (50 blocks x 6 sec).\\n\\n## Checking that initial setup works \\n\\nUse the standard Polkdot frontend and generated \\\"--ws-port\\\" endpoints to connect with each node.\\nOpen [Polkadot application](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/) to monitor the chains. \\n\\n### Example:\\nLocalhost, 4 relay chain validators, one parachain-100 collator, one parachain-200 collator:\\n- [Relay validator 1](https://polkadot.js.org/apps/?rpc=ws://localhost:9500/)\\n- [Relay validator 2](https://polkadot.js.org/apps/?rpc=ws://localhost:9501/)\\n- [Relay validator 3](https://polkadot.js.org/apps/?rpc=ws://localhost:9502/)\\n- [Relay validator 4](https://polkadot.js.org/apps/?rpc=ws://localhost:9503/)\\n- [Parachain-100 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10054/)\\n- [Parachain-200 collator](https://polkadot.js.org/apps/?rpc=ws://localhost:10055/)\\n\\n\\nIf everything works, and consensus started off, we can proceed to run our test cases (in a new terminal).\\n\\n### UMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\nIt creates a `Balance.transfer` message in `parachain-100` and passes it to the relay chain.\\nWhen the relay chain receives the message it will transfer 15 tokens from `para 100` account to the Charlie acount.\\n\\n\\n### HRMP message passing test\\n```bash\\n./scripts/init.sh ump\\n```\\n\\nIt creates a `Balance.transfer` message in `parachain-100` and passes it to the `sibling 200` one.\\nBefore that, it endows the`subl 100` account with 1000 tokens and  establish a communication channel between the parachains.\\n```bash\\n./scripts/init.sh hrmp\\n```\\nNext messages can be sent by running the `hrmpm` subcommand. It doesn't create a channel and so it runs faster.\\n```bash\\n./scripts/init.sh hrmpm\\n```\\n\\n### More options\\n```bash\\n./scripts/init.sh help\\n```\\n\\n## Local Testnet\\n\\n### Create customized chain spec\\n```\\n./bin/polkadot build-spec --chain rococo-local --disable-default-bootnode > rococo_local.json\\n```\\n\\nEdit rococo_local.json, replace the balances and authorities parameters with yours.\\n```json\\n  \\\"keys\\\": [\\n    [\\n      \\\"\\\",\\n      \\\"\\\",\\n      {\\n        \\\"grandpa\\\": \\\"\\\",\\n        \\\"babe\\\": \\\"\\\",\\n        \\\"im_online\\\": \\\"\\\",\\n        \\\"para_validator\\\": \\\"\\\",\\n        \\\"para_assignment\\\": \\\"\\\",\\n        \\\"authority_discovery\\\": \\\"\\\"\\n      }\\n    ]\\n```\\n\\nPolkadot address for //Alice//stash (sr25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice//stash\\n```\\n\\n```text\\nSecret Key URI `//Alice//stash` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot grandpa session key for //Alice (ed25519 cryptography).\\n```bash\\n$ polkadot key inspect-key --scheme ed25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nPolkadot address for //Alice (sr25519 cryptography).\\n```\\n$ polkadot key inspect-key --scheme sr25519 --network substrate //Alice\\n```\\n```text\\nSecret Key URI `//Alice` is account:\\nSecret seed:      \\n\\nPublic key (hex): \\n\\nAccount ID:       \\n\\nSS58 Address:     \\n```\\n\\nConvert rococo_local.json to the raw format.\\n```\\n./bin/polkadot build-spec --chain rococo_local.json --raw --disable-default-bootnode > rococo_local.json\\n```\\nTo use new chain spec replace rococo.json file in ./config/ directory this new one and rerun chain.\\n```bash\\n./scripts/init.sh run\\n```\\nYou can freely edit the code. The above command will rebuild the project and update the collator node before starting.\\nCumulus is pre-release software that is still under heavy development.\\nWe are using a specific commit of polkadot [46c826f595021475fa5dbcd0987ed53f104e6e15  18 mar 2021] (https://github.com/paritytech/polkadot/tree/46c826f595021475fa5dbcd0987ed53f104e6e15)\\n\\nYou can use more recent versions of the software. To do this, change  POLKADOT_COMMIT  in ./scipt/config.sh\\nto the latest commit of `rococo-v1` branch, delete ./bin/polkadot, and run \\n```bash\\n./scripts/init.sh run\\n```\\n\\nUpdate collator project dependencies \\n```bash\\ncargo update\\n./scripts/init.sh build\\n```\\nSome dependencies probably require new rust toolchain features. This project is based on rust `nightly-2021-01-26`\\nUpdate rust toolchain version in ./scripts/config.sh before build.\\n\\n## Hack parachain\\n[Add external pallet](https://substrate.dev/docs/en/tutorials/add-a-pallet/) - should it probably be in \\\"learn more\\\"?\\n## Learn More\\n\\nRefer to the upstream\\n[Substrate Developer Hub Node Template](https://github.com/substrate-developer-hub/substrate-node-template)\\nto learn more about the structure of this project, the capabilities it encapsulates and the way in\\nwhich those capabilities are implemented. You can learn more about\\n[The Path of Parachain Block](https://polkadot.network/the-path-of-a-parachain-block/) on the\\nofficial Polkadot Blog.\\n[Parity Cumulus Workshop](https://substrate.dev/cumulus-workshop/#/)\\n\"}},{\"node\":{\"id\":\"accf2ce5f73f81bf63e784a00c9dbb89\",\"title\":\"Lesson 4, Robonomics Parachain in Practice\",\"path\":\"/docs/en/wschool2021-robonomics-parachain-in-practice/\",\"content\":\"import Asciinema from '~/components/Asciinema.vue'\\n\\nAt the moment, Robonomics, in addition to the Ethereum network, also operates on the basis of the Polkadot ecosystem, which has greater scalability through the use of sharded blockchains. To do this, the ecosystem uses a [sharded model](https://wiki.polkadot.network/docs/getting-started), with the following elements:\\n\\n![Polkadot base scheme](../images/ws_lesson4/polkadot-base-scheme.png \\\"Polkadot base scheme (from Polkadot Wiki)\\\")\\n\\n* relay chain — central blockchain used by others for basic coordination of work;\\n* parachains — data structures (usually also blockchains) used for specific applications; Robonomics operates as a parachain;\\n* validators — nodes that create blocks in the relay chain and also verify new block candidates from parachains for inclusion to the shared state of Polkadot;\\n* collators — nodes that maintain a parachain by collecting its transactions and producing new block candidates to pass to validators;\\n* Cross-Consensus Messaging Format (XCM) — format that allows parachains to send messages of any type to each other.\\n\\nThe goal of this lesson is to get to know the basic elements of the Polkadot ecosystem and understand how they interact with each other. To do this, you will run your local relay chain and several Robonomics-based parachains.\\n\\n## Requirements\\n\\n* Docker, please [install it](https://docs.docker.com/engine/install/).\\n* Polkadot-launch, please [install it](https://github.com/paritytech/polkadot-launch#install) (optionally, if you don't want to use docker).\\n\\n## Launch the relay\\n\\nRun a local instance of Rococo (polkadot testnet) relay chain with two Robonomics-based parachains as the children. \\n<!-- I'll use prepared [Docker image tag: \\\"winter-school-2\\\"](https://hub.docker.com/layers/robonomics/robonomics/winter-school-2/images/sha256-92f4795262f3ded3e6a153999d2777c4009106a7d37fd29969ebf1c3a262dc85?context=explore) but all source code of examples\\navailable in [Robonomics GitHub](https://github.com/airalab/robonomics/tree/master/scripts/polkadot-launch). -->\\n\\nFirst, pull version 2 of WinterSchool Docker using the command below:\\n\\n```\\ndocker pull robonomics/robonomics:winter-school-2\\n```\\nNow run the docker using the command below:\\n\\n```\\ndocker run -ti --rm --network host robonomics/robonomics:winter-school-2 bash\\ncd polkadot-launch/\\n./launch.sh\\n```\\n\\nDepending on the specs of your machine, it can take up to several minutes, but be patient. As a result, you should have three chain instances.\\n\\nThe video below is a walk through the previous steps. Refer to the video if you would have problems with the chain instances.\\n<Asciinema vid=\\\"419Jrg22ziFfMFPZlh2WtiLvg\\\"/>\\n\\nOnce the instances are created, you can access them by their IDs. In our case, the IDs are as the following: \\n\\n* `9944` - local Rococo relay chain. (https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/explorer)\\n* `9988` - robonomics parachain with `id=100` (https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9988#/explorer)\\n* `9989` - robonomics parachain with `id=200` (https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9989#/explorer)\\n\\n<!-- If you use remote server, you need to create some ssh tunnels on local machine:\\n```\\nssh -f -N -L 9944:127.0.0.1:9944 root@REMOTE_SERVER_IP\\nssh -f -N -L 9988:127.0.0.1:9988 root@REMOTE_SERVER_IP\\nssh -f -N -L 9989:127.0.0.1:9989 root@REMOTE_SERVER_IP\\n```\\nAfter that, you can use `ws://127.0.0.1:9944` for relay chain, `ws://127.0.0.1:9988`and `ws://127.0.0.1:9989` for parachains in https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/explorer\\n\\n<!-- ![relay](../images/ws_lesson4/upcoming.jpg)\\n\\nSome time ago parachains should be registered.\\n\\n![relay2](../images/ws_lesson4/parachains.jpg)\\n\\nAnd start to produce blocks.\\n\\n![relay3](../images/ws_lesson4/parachains2.jpg) -->\\n\\nAs the next step, let's create an HRMP channel to pass messages between parachains. We would use `sudo` module to call on relay chain page. To do this, Open Rocco relay chain(https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/explorer) and switch to local node from the top left. Then, go to `Developer->Sudo`, fill in parts as shown in figure below and click on `Submit Sudo`.\\n\\n![hrmp](../images/ws_lesson4/hrmp.jpg)\\n\\nWhen the channel is created, the XCM calls would become available. Let's use `datalogXcm` pallet - a XCM version of `datalog` pallet in first parachain (9988).\\n\\nIn the next step, switch to the first parachain(https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9988#/explorer). Find `Settings->Developer`, paste the following configurations, and click on `Save`.\\n\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\nAfter saving the configurations, find `Extrinsics` under the `Developer` tab. Fill in the parts as shown in figure below and click on `Submit Transaction`. Wait for transaction to be finalized.\\n\\n![datalogXcmSend](../images/ws_lesson4/datalogXcmSend.jpg)\\n\\nAs a result of the above operation, the message on second parachain will call `datalog` pallet and write data onto the chain.\\n\\nTo view the message, go to the other parachain (https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9989#/explorer).\\n\\nYou should be able to see that your message has been sent from the first parachain (9998) to the second one (9999). The message will appear in the `Explorer` tab under `recent events`.\\n\\n![datalogXcmRecv](../images/ws_lesson4/datalogXcmRecv.jpg)\\n\\nThis example demonstrated that how XCM could be used for cross chain usage of standard Robonomics pallets.\\n\"}},{\"node\":{\"id\":\"3728ead98b03926b163404444cb7218d\",\"title\":\"Lesson 3, Robonomics IO in Practice\",\"path\":\"/docs/en/wschool2021-robonomics-io-in-practice/\",\"content\":\"\\nIn this lesson we will show you how to use Robonomics to connect to an I/O device. \\n\\nSince you might not necessarily have the real sensor, we have provided the procedure for using both the real and virtual sensors.\\n\\n<!-- In the first section, we assume that you do not have the actual hardware, thus we would initially provide you with a simulated sensor that gives you info about the air quality.\\n\\nIn the second section, we would follow the same procedure as in section one but with the real sensor. Therefore, if you want to get the best experience, prepare the sensor mentioned in the requirement and jump to section 2. -->\\n\\n## Requirements\\n\\n* Docker, please install it from [here](https://docs.docker.com/engine/install/)\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) sensor (optional).\\n\\n## Robonomics Docker Installation\\n\\nAfter installing the docker container, pull the Robonomics docker using the command below:\\n\\n```\\nsudo docker pull robonomics/robonomics\\n```\\n\\n## Running Docker Container\\n\\n* <font color=\\\"orange\\\">For using the virtual sensor:</font>\\n```\\nsudo docker run -ti --rm --network host  robonomics/robonomics:winter-school bash\\n```\\n\\n* <font color=\\\"orange\\\">For using the real sensor:</font>\\n\\nIf you have the connected SDS011 sensor, first check that it is available in `/dev` folder and has correct access rights by running the commands below:\\n\\n```\\nls -l /dev/ttyUSB0   ## Shows if the sensor is available in the /dev folder \\nsudo chmod 666 /dev/ttyUSB0  ## Gives correct access rights to the sensor\\n```\\n\\nAfter making sure that the sensor is connected and has the correct access rights, run the docker by using the command below:\\n\\n```\\nsudo docker run -ti --rm --network host --device /dev/ttyUSB0 robonomics/robonomics:winter-school bash\\n```\\n\\n## Testing Connection To Sensor\\n\\n* <font color=\\\"orange\\\">For the virtual sensor:</font>\\n\\nAfter running the docker, you should now launch `vsds011.sh` script to access the virtual/simulated sensor which gives you air quality updates. In order to do that, run the following command in the docker:\\n\\n```\\nvsds011.sh\\n\\n{\\\"timestamp\\\":\\\"1612837969\\\",\\\"pm25\\\":1.8,\\\"pm10\\\":5.7}    ## Sample output\\n```\\n\\n* <font color=\\\"orange\\\">For the real sensor:</font>\\n\\nRun the following command in the docker:\\n\\n```\\nrobonomics io read sds011\\n\\n{\\\"timestamp\\\":\\\"1612495226\\\",\\\"pm25\\\":0.6,\\\"pm10\\\":1.3}    ## Sample output\\n```\\n\\n<!-- After installing the docker, pull Robonomics docker image and run it using the commands below. Use `winter-school` tag during this lesson. -->\\n\\n\\n## Running IPFS\\n\\nWe use IPFS to write data to block chain. Thus in order to use Robonomics `read` and `write` subsystems and transfer data back and forth to blockchain, we need to run IPFS daemon.\\n\\nIn order to run IPFS daemon in the docker container, stop the scripts you ran in the previous section and run the following commands in the docker: \\n\\n```\\nipfs init\\nipfs daemon\\n```\\nYou should see a key-pair generated and IPFS daemon would be started.\\n\\n## Accessing Running Instance of Docker\\nNow that the daemon is launched, you need to connect to the docker in a separate terminal. In order to access the docker in a separate terminal, you first need to get the ID of the docker. Run the following the command in a new terminal window to get the ID of the running docker:\\n\\n```\\nsudo docker ps\\n```\\nCopy the ID of the docker from the output of the previous command and  run the following command. Replace the `<DOCKER-CONTAINER-ID>` with your ID.\\n\\n```\\nsudo docker exec -ti <DOCKER-CONTAINER-ID> bash\\n```\\nYou should now be connected to the docker in a separate terminal window.\\n\\n## Writing Data To IPFS Using Robonomics I/O\\n\\nThe Robonomics IO subsystem has two kinds of commands:\\n\\n* `read` - Get data from device that supports read access.\\n* `write` - Write data into device that supports write access.\\n\\nIn the new window for the docker, run the following command in order to write the output of the sensor into IPFS and subsequently to the blockchain.\\n\\n* <font color=\\\"orange\\\">For the virtual sensor:</font>\\n\\n```\\nvsds011.sh | robonomics io write ipfs\\n```\\n\\n* <font color=\\\"orange\\\">For the real sensor:</font>\\n\\n```\\nrobonomics io read sds011 | robonomics io write ipfs\\n```\\n\\n## Robonomics Datalog\\n\\n> The target of Robonomics [Datalog](https://crates.robonomics.network/robonomics_protocol/datalog/index.html) is data blockchainization. This pallet provides function to store custom data on blockchain to make it immutable, in other words, impossible to change in future.\\n\\nFor this section, we would need a running instance of the Robnomics binary. Development mode is preferred because of quick block time and already distributed balances on preset accounts. Let's launch the ***Robonomics*** binary in a separate terminal in the same docker container (Use the same procedure mentioned in ***Accessing Running Instance of Docker*** section to access the running docker in a new terminal window).\\n\\nIn the new docker window, launch the Robonomics binary in development mode by running the following:\\n\\n```\\nrobonomics --dev\\n```\\n\\nThe private seed is also required as an argument for `datalog` device. This seed is used to sign transactions and presents the account as a sender. To get the private seed, you can use `robonomics key` command.\\n\\nConnect to the docker in a separate terminal window and run the following command:\\n\\n```\\nrobonomics key generate\\n```\\nSample output:\\n\\n```\\nSecret phrase `rebel federal super deer dinosaur sick pledge hint truth wool input enjoy` is account:\\n  Secret seed:      0xf5a371d1b1ae8279c4c950cb39a4070b0a17c7cee016e59506d177e433db842c\\n  Public key (hex): 0x088ccc48a72db4f056e24a67fc8b7676403593010aa5b2c06ebeff4a1151e930\\n  Account ID:       0x088ccc48a72db4f056e24a67fc8b7676403593010aa5b2c06ebeff4a1151e930\\n  SS58 Address:     5CFv4nCHq53hT963smDJsYqiujdT5HGaTjCztuqhprbXcTxK\\n```\\n **Note:** Save the generated address and seed for later use.\\n\\nInitially, balance of the account at the generated address is zero, thus the network does not allow sending transactions from this address. To fix this, you need to transfer some tokens from an account like `Alice` to the account at the generated address. Use [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for making the transfer.\\n\\n![portal transfer](../images/ws_lesson3/transfer_funds.jpg)\\n\\nAfter token addition is done, `datalog` device could be used for saving any data on blockchain. The argument `-s` is used to set secret seed of account. Remember, the account should have non-zero balance to send transactions.\\n\\n**Note:** In case you have problems adding funds, make sure the development setting is set according to [this](https://wiki.robonomics.network/docs/en/troubleshooting/#couldnt-send-tokens-between-accounts). A step by step guide for adding funds to an account can be found [here](https://wiki.robonomics.network/docs/en/adding-funds-to-account-in-dapp/).\\n\\nIf you everything is set correctly,  you should see `datalog` event on `Explorer` page of Robonomics portal.\\n\\n![portal datalog](../images/ws_lesson3/datalog_image.jpg)\\n\\n\\n## Read Data From Sensor and Save In Blockchain\\n\\nAs the final step of this lesson, let's write a command that collects data from the sensor, packs it into IPFS and then sends `datalog` transaction to be saved as a hash on blockchain.\\n\\nThe pipeline would be like the following:\\n```\\nSensor -> IPFS -> Blockchain\\n```\\nIn order to achieve this, run the following command in the docker.\\n\\n* <font color=\\\"orange\\\">For the virtual sensor:</font>\\n```\\nvsds011.sh | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n\\n* <font color=\\\"orange\\\">For the real sensor:</font>\\n\\n```\\nrobonomics io read sds011 | robonomics io write ipfs | robonomics io write datalog -s <private_key>\\n```\\n**Note:** For these commands to work, the IPFS and Robonomics binary should be running in the docker as well.\\n\\nIf everything goes well, the `datalog` event with IPFS hash should be presented in the ***recent events*** section. \\n\\n![portal datalog complex](../images/ws_lesson3/datalog_combined.jpg)\\n\\n\"}},{\"node\":{\"id\":\"c2660bc3293b4f9225a0cea6e66b6d5c\",\"title\":\"Lesson 2, Robonomics AIRA Overview\",\"path\":\"/docs/en/wschool2021-robonomics-github-overview/\",\"content\":\"In this lesson you will learn about Autonomous Intelligent Robot Agent (AIRA). \\n\\nAIRA is a NixOS-based operating system that implements an economic standard for human-robot and robot-robot interactions. AIRA makes it possible to connect a variety of different robots under decentralized computer control (currently supports Ethereum, Polkadot, and Substrate).\\n\\nTowards learning how to leverage AIRA, in this lesson, you would install AIRA, ssh into it and interact with it by runnig a simple example.\\n\\n\\n## Part 1: AIRA Installation on VirtualBox\\n\\n### **Requirements**\\n\\n* [VirtualBox](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack) 6.1 or higher\\n* [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2GB of RAM for the machine\\n* 20GB of free disk space\\n\\n> You can follow the procedure mentioned [here](https://computingforgeeks.com/install-virtualbox-6-on-ubuntu-linux/) to install VirtualBox and its extension.\\n\\n> After successfully installing VirtualBox download the WinterSchool AIRA image from [here](https://static.aira.life/ova/airaos-21.11_robonomics-winter-school.ova).\\n\\n### **Import AIRA to VirtualBox**\\n\\nOpen VirtualBox and press `Ctrl+I` or go to `File > Import Applicance...` and choose the previously downloaded image to be imported.\\n\\n![AIRA import VB image](../images/aira-installation/aira_import_vb_image.jpg \\\"AIRA import VB image\\\")\\n\\n## **Launch the machine**\\n\\nOnce the importing is over, press on Start button and you'll see AIRA welcoming you with generated Ethereum address and IPFS identifier\\n\\n![AIRA image ready, Welcome screen](../images/aira-installation/aira_image_ready.jpg \\\"AIRA image ready, Welcome screen\\\")\\n\\n> In case of any problems, a detailed walk-through video of this section can be [here](https://youtu.be/ISKilRfY3Ow).\\n\\n## Part 2: Connecting to Aira via SSH\\n\\nIn order to easily interact with AIRA without frequently switching between your host machine and the virtual machine (VM), you can simply ssh to the AIRA, and run everything on AIRA from the terminal on your host machine. Here we show you how to setup a password-less ssh for AIRA.\\n\\n> **It's required to have your ssh public key on Github. In case you don't have one, please follow the [link](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\n### **Add Host Adapter**\\n\\nGo to `File` -> `Host Network Manager...` or press `Ctrl+H`\\n\\nClick on `Create` button. You should see a new adapter created such as `vboxnet#`.\\n\\n### **Add the adapter to the VM**\\n\\nSelect imported VM and click `Settings`. Go to `Network` tab and enable the adapter you just created. (e.g. in the figure below the new adapter name is  `vboxnet1`)\\n\\n![Add Second Adapter](../images/add_second_adapter_to_vm.png \\\"Add Second Adapter\\\")\\n\\n### **Populate Authorized Keys**\\n\\nLaunch the VM and run the following command replacing `<username>` with your Github user name:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nFind out the VM's IP address by running:\\n\\n```\\nip a\\n```\\n\\nYou should look for an address which starts with `192.168.xx.xx`\\n\\n### **Log in via SSH**\\n\\nNow open your terminal and log in via SSH as usual using the address from the previous step:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n> In case of any problems, a detailed walk-through video of this section can be [here](https://youtu.be/W0rOcRA2sEc).\\n## Part 3: Interact with AIRA\\n\\nAt this point you should be familiar with a [DApp](/docs/get-weather-on-fuji-mountain/) from lesson 1 and also how to launch [AIRA image](/docs/aira-installation-on-vb/).\\nNow you are ready to do more complicated stuff like installing a package and interacting with it via DApp\\n\\n\\n### **Package installation**\\n\\nAfter you launched AIRA and logged in via SSH using your terminal, run the following commands:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nUpon running the last command, you should see a link to DApp generated specifically for your instance.\\n\\n![Terminal with AIRA](../images/aira_hello_terminal.jpg \\\"Terminal with AIRA\\\")\\n\\nClick on the link, the DApp should be shown.\\n\\n### **DApp** \\n\\nConnect [MetaMask](http://metamask.io/) if prompted and click on the button\\n\\n![Request connection in Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Request connection in Robonomics Dapp\\\")\\n\\nSign the message and wait for the result\\n\\n![Wait for Result of request](../images/aira_hello_dapp_2.jpg \\\"Wait for Result of request\\\")\\n\\nMeanwhile have a look at the terminal. You should see the greeting\\n\\n![AIRA greeting in terminal](../images/aira_hello_terminal_2.jpg \\\"AIRA greeting in terminal\\\")\\n\\nAt the end, the greeting will appear in the DApp\\n\\n![Robonomics DApp Greeting for AIRA](../images/aira_hello_dapp_3.jpg \\\"Robonomics DApp Greeting for AIRA\\\")\\n\\n### **Troubleshooting**\\n\\n### You click \\\"Request current values\\\" but see no greeting\\n\\nProbably you have just launched AIRA and IPFS hasn't finished initialization. Wait a minute or so and try again.\\n\\n### I see response hash but the data doesn't appear\\n\\nAgain most probably the issue comes from IPFS connection. Click and the hash and you'll see the result. It's not necessary to download the file.\\n\\n> In case of any problems, a detailed walk-through video of this section can be [here](https://youtu.be/fhRTF2mddfU).\\n\"}},{\"node\":{\"id\":\"07d29afc221735d0307cc4254dfd0b86\",\"title\":\"Robonomics Winter School 2021 introduction\",\"path\":\"/docs/en/wschool2021-intro/\",\"content\":\"\\nRobonomics Winter School 2021 is held from 10 to 24 February **online**. It's **free**.\\n\\nWe are publishing **lessons** online in different ways: text here in Wiki, video on our [YouTube channel](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ), announce in [Twitter account](https://twitter.com/AIRA_Robonomics). Please, keep in mind, that video lessons and text lessons are not the same. For the start we plan to publish two language versions: English and Russian. \\n\\nJoin us, take your steps through the lessons, **discuss and ask questions** in [Discord](https://discord.gg/5UWNGNaAUf).\\n\\n## Watch opening ceremony\\n\\nhttps://youtu.be/kQaSwNYHJQ8\\n\\n## Basic information\\n\\nTake a look at [page about school](https://robonomics.network/blog/winter-robonomics-school/) on our website. We are collecting there all basic information: shedule, infopartners, links.\\n\\n## Links, links, links\\n\\nLets repeat what links do we have for following Robonomics Winter School 2021:\\n\\n- [Summary on website](https://robonomics.network/blog/winter-robonomics-school/)\\n- Wiki for text lessons, YOU ARE HERE 🤓\\n- [Video lessons](https://www.youtube.com/channel/UCrSiho1uB-1n6F8cZpCLhjQ)\\n- [Fast announce on Twitter](https://twitter.com/AIRA_Robonomics)\\n- [Questions, Discussions, Quizes in Discord](https://discord.gg/5UWNGNaAUf)\\n\\n**Lets start learn Robonomics!**\"}},{\"node\":{\"id\":\"3849d5eb0258718426e2447e80611911\",\"title\":\"Lesson 5, Connectivity\",\"path\":\"/docs/en/wschool2021-connectivity-service/\",\"content\":\"\\nThis lesson will show you how to build a large scale network of sensors using the `sensors-connectivity` module from Robonomics. The idea is that usually the devices are very low-powered and unable to send transactions to the blockchain on their own. It is not safe to use one central server due to failures and hacks, so we suggest using the module to create servers that maintain several hundred devices and exchange data through decentralized channels. This allows to achieve a balance between security and scalability of the network.\\n\\nDuring the lesson, you will learn how to set up and connect a small sensor using this module.\\n\\n## IoT as a Multiple Pie\\n\\n* Device Software\\n    * FreeRTOS\\n    * ESP/Arduino\\n    * Single-board computers (RPi, LattePanda etc)\\n* Connectivity\\n    * IoT Hub\\n    * IoT Manager\\n* Analytics Services\\n    * AWS\\n    * Google Cloud IoT Core\\n    * ThingsBoard\\n\\nAs a rule, most are not interested in sensors and servers, but data analytics.\\nTo get it, you need to decide which device to use, how to work with it and where to connect\\n\\n## Device Software\\n\\nConsider the example of a home weather station. It is necessary to collect data on air pollution (SDS011), temperature and humidity (BME). The ESP8266 microcontroller can handle this task.\\n\\nRequirements:\\n\\n* Correctly read data from sensors\\n* Have a unique identifier\\n* Transfer data to a known server\\n* Provide digital signature of data (optional)\\n\\nYou can find the current firmware [here](https://github.com/LoSk-p/sensors-software/tree/366b19bf447a5fc19220ef89eab0f2440f8db1c2)\\n\\n## What is Connectivity? \\n\\nIn the IoT world, connectivity refers to the connection of various IoT devices to the Internet to send data and / or control the device.\\n\\nWell-known architectural solutions can be roughly divided into 3 groups:\\n\\n* Fully decentralized. For example, devices are connected by a mesh network. Not suitable for wide area networks due to high hardware requirements\\n* Centralized. For example, AWS. Provides a single entry point and ease of connection, but there is a high risk of failure in case of server problems\\n* Hybrid. For example, [Robonomics Connectivity](https://github.com/airalab/sensors-connectivity). Provides an address for devices on a \\\"local\\\" network and publishes data to a distributed IPFS message channel\\n\\n## Comparison of AWS and Robonomics Connectivity\\n\\n| Management services \\t| AWS                               \\t|               Robonomics              \\t|\\n|---------------------\\t|-----------------------------------\\t|---------------------------------------\\t|\\n| Transaction type    \\t| Technical                         \\t| Technical and economic                \\t|\\n| Security            \\t| IT-company cloud control          \\t| Polkadot and Ethereum                 \\t|\\n| Protocol            \\t| HTTPS, MQTT                       \\t| IPFS, Robonomics                      \\t|\\n| Ecosystem           \\t| Private                           \\t| Shared                                \\t|\\n| Access to DeFi      \\t| No                                \\t| Yes                                   \\t|\\n| Costs               \\t| Pushing data - $1-2 a sensor      \\t| Pushing data - $0                     \\t|\\n|                     \\t| Shadow         - from $10 a month \\t| Digital Twin    - $0,01 a transaction \\t|\\n\\n## Installing Connectivity on Aira\\n\\nhttps://www.youtube.com/watch?v=JbBNMHAzJKM\\n\\n### Requirements\\n\\n* [VirtualBox 6.1](https://www.virtualbox.org/wiki/Downloads) and above\\n* [Aira OS ova image](https://static.aira.life/ova/airaos-21.03_robonomics-winter-school.ova)\\n\\nImport Aira image in VirtualBox as described [here](/docs/aira-installation-on-vb/)\\n\\nSet up a connection over [SSH](/docs/aira-connecting-via-ssh/)\\n\\nWhen everything is set and you successfully log in via SSH, let's clone the main package and build it \\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\ngit checkout v0.9\\nnix build -f release.nix\\n```\\n\\nNow let's create a copy of the default configuration file for later usage. \\nTo learn about all the options check [this article](/docs/configuration-options-description/) out.\\nThen launch the package with `roslaunch`\\n\\n```\\ncp config/default.json config/my.json\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\n## Connect Sensor to Connectivity\\n\\nhttps://www.youtube.com/watch?v=yxqxBk-6bpI\\n\\n### Requirements\\n\\n* [Nova SDS011](https://aqicn.org/sensor/sds011) sensor \\n* [Yarn Packet Manager](https://yarnpkg.com/getting-started/install)\\n\\nNow let's connect a real sensor, forward USB port to the virtual machine, set up a map and look at our own measurements\\n\\nFirst, stop the Aira OS if it was running and add a corresponding USB device\\n\\n![VB USB Forwarding](../images/vb_forward_usb.jpg)\\n\\nStart the VM, connect via SSH and set `comstation/port` option according to your USB device in the VM. Also enable `comstation` and set your latitude and longitude. In the end `config/my.json` should look like this:\\n\\n```\\n{\\n   \\\"general\\\":{\\n      \\\"publish_interval\\\":30\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":0,\\n      \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"connectivity.robonomics.network\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\":{\\n      \\\"enable\\\":false\\n   },\\n   \\\"robonomics\\\":{\\n      \\\"enable\\\":true,\\n      \\\"ipfs_provider\\\":\\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\":\\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\":{\\n      \\\"enable\\\":false,\\n      \\\"path\\\":\\\"\\\",\\n      \\\"suri\\\":\\\"\\\",\\n      \\\"remote\\\":\\\"wss://substrate.ipci.io\\\",\\n      \\\"dump_interval\\\":3600,\\n      \\\"temporal_username\\\":\\\"\\\",\\n      \\\"temporal_password\\\":\\\"\\\"\\n   },\\n   \\\"dev\\\":{\\n      \\\"sentry\\\":\\\"\\\"\\n   }\\n}\\n```\\n\\n> If you don't have a real sensor, you can use `sensors-connectivity/utils/virtual-sensor.py` script to emulate one\\n> \\n> Enable `HTTPStation` and disable `COMStation` by changing the configuration file as:\\n> ```\\n> {\\n>    \\\"general\\\":{\\n>       \\\"publish_interval\\\":30\\n>    },\\n>    \\\"comstation\\\":{\\n>       \\\"enable\\\":false,\\n>       \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n>       \\\"work_period\\\":0,\\n>       \\\"geo\\\":\\\"59.944917,30.294558\\\",\\n>       \\\"public_key\\\":\\\"\\\"\\n>    },\\n>    \\\"httpstation\\\":{\\n>       \\\"enable\\\":true,\\n>       \\\"port\\\":8001\\n>    },\\n>    ...\\n> }\\n> ```\\n>\\n> and launching `utils/virtual-sensor.py` in a dedicated terminal in the VM\\n\\nSave the file and launch connectivity from `sensors-connectivity` folder:\\n\\n```\\nsource result/setup.zsh\\nroslaunch sensors_connectivity agent.launch config:=$PWD/config/my.json\\n```\\n\\nYou should see first measurements in the console output\\n\\nLook for your IPFS ID in the VM. It appears right after booting the image or via `ipfs id` command. We will need it later.\\n\\nNow let's set up our own instance of the map. On your laptop (not in the VM) clone [this](https://github.com/airalab/sensors.robonomics.network) repository and build the app:\\n\\n```\\ngit clone https://github.com/airalab/sensors.robonomics.network\\ncd sensors.robonomics.network\\nyarn install\\n```\\n\\nEdit `src/agents.json` file and put your IPFS ID. For example:\\n\\n```\\n[\\n  \\\"12D3KooWSCFAD3Lpew1HijniE6oFTuo4jsMwHzF87wNnXkpCRYWn\\\"\\n]\\n```\\n\\nLaunch the map:\\n\\n```\\nyarn serve\\n```\\n\\nGo to [http://localhost:8080/](http://localhost:8080/) or the address yarn gave you and look for the sensor.\\n\\n## Practice\\n\\n### Trajectory 1. Flash a sensor ESP + SDS011\\n\\nRequirements:\\n\\n* ESP8266\\n* At least one of sensors SDS011, BME280, HTU21D\\n\\nUse the [instruction](https://wiki.robonomics.network/docs/connect-sensor-to-robonomics/) to connect a sensor to Robonomics Connectivity. \\n\\nCheck that your sensor appears on our [map](https://sensors.robonomics.network/#/).\\n\\n### Trajectory 2. Launch Connectivity\\n\\nRequirements:\\n\\n* ROS\\n* Python\\n* Nix (optional)\\n\\nBuild and launch [sensors-connectivity](https://github.com/airalab/sensors-connectivity#get-a-package-and-build)\\n\\n> How it build, install [here](https://wiki.robonomics.network/docs/iot-sensors-connectivity/) and configure [here](https://wiki.robonomics.network/docs/configuration-options-description/)\\n\\nGeneral scheme of the package:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nThe choice is proposed to implement either a new station, for example, a random number generator, or a new feeder, for example, displaying a string on the screen.\\n\\nInterface `IStation` [here](https://github.com/airalab/sensors-connectivity/blob/master/src/stations/istation.py#L73).\\n\\nInterface `IFeeder` [here](https://github.com/airalab/sensors-connectivity/blob/master/src/feeders/ifeeder.py#L5)\\n\\n\"}},{\"node\":{\"id\":\"d5fe1ca3f70b5407d1ed7b384a5b99ca\",\"title\":\"Lesson 1, Connect Robotics to User App\",\"path\":\"/docs/en/wschool2021-connect-robotics-to-user-app/\",\"content\":\"\\n**In this lesson, we will show you how to connect to a sensor on top of Fuji Mountain in Japan to get actual data through Robonomics DAPP.**\\n\\nBefore going further, make sure that you have created MetaMask account and installed its extension on your browser. You can do this by following the procedure in [MetaMask](https://metamask.io/) website.\\n\\nIn order to connect to the sensor on top Fuji Mountain, follow the steps below: \\n\\n## 1. Access  Weather Sensor\\n\\nTo access the weather sensor, you should first navigate to Robonomics Services webpages from DAPP. \\n\\n- Go to DAPP [webpage](https://dapp.robonomics.network/#/).\\n- From left sidebar, under market place section, click [Services](https://dapp.robonomics.network/#/services) and choose [\\\"FUJI WEATHER\\\"](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/)\\n![FUJI-SENSOR](../images/connecting-to-fuji-sensor/services-fuji-sensor.jpg \\\"FUJI-SENSOR\\\")\\n\\n\\n## 2. Connect to MetaMask Account\\nIf you're not connected to your MetaMask account already, you should now get connected to be able to retrieve the sensor data. In order to do that, follow the steps below:\\n- Click on \\\"Connect account\\\" in the up-right part of the DAPP webpage.\\n![FUJI-SENSOR](../images/connecting-to-fuji-sensor/connect-button.jpg \\\"FUJI-SENSOR\\\")\\n- In the prompted window, choose your account, click \\\"Next\\\" and finally press \\\"Connect\\\"\\n\\n<img alt= \\\"choose-account\\\" src=\\\"../images/connecting-to-fuji-sensor/choose-account.jpg\\\" width=\\\"325\\\"/>\\n<img alt= \\\"choose-account\\\" src=\\\"../images/connecting-to-fuji-sensor/connect-to-account.jpg\\\" width=\\\"325\\\"/>\\n\\n## 3. Send Request and Sign\\nAfter getting connected to your MetaMask account, click on \\\"Sign with ethereum account\\\" and finally sign it in the prompted window. You should receive the sensor data after signing the request.\\n\\n<p align=\\\"center\\\">\\n<img alt=\\\"sign-button\\\" src=\\\"../images/connecting-to-fuji-sensor/sign-button.jpg\\\" width=\\\"655\\\"/>\\n<img alt= \\\"sign-prompt\\\" src=\\\"../images/connecting-to-fuji-sensor/connect-to-account.jpg\\\" width=\\\"325\\\"/>\\n<img alt= \\\"sensor-data\\\" src=\\\"../images/connecting-to-fuji-sensor/sensor-data.jpg\\\" width=\\\"325\\\"/>\\n</p>\\n\\nThe following video further illustrates getting data from weather sensor on top of the Fuji Mountain.\\n\\nhttps://youtu.be/NOQxyojvaao\\n\\n- [Reference tutorial on Wiki](https://wiki.robonomics.network/docs/get-weather-on-fuji-mountain/)\\n- [Dapp](https://dapp.robonomics.network/#/)\"}},{\"node\":{\"id\":\"16ae56d2ed3604ed41b92ecb8330e2dc\",\"title\":\"Lesson 6.2, Build IoT Dapps For End Users\",\"path\":\"/docs/en/wschool2021-build-dapp-interface/\",\"content\":\"\\nThis lesson continues the previous one, where you have already built simple application and were focused on connecting an account to a node, sending transactions and other vital functions of the dapp. Now we will **build user-friendly interface** for this application.\\n\\n![Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot](../images/build-dapp-interface/sum.gif \\\"Building User Interface for Decentralized Applications, on top of Robonomics and Polkadot\\\")\\n\\n## Prerequisites\\n\\nThis lesson is designed for people who are familiar with **HTML, CSS, JavaScript** a bit and want to learn how to apply these skills for decentralized applications.\\n\\nFor building your dapp's interface you can choose any JavaScript framework which is comfortable for you or even try to build interface without any framework. In Robonomics 2021 we use [Vue.js](https://vuejs.org) as it is quite scalable and easy to use.\\n\\n## Set up\\n\\nIf you start with this step and prefer to **learn by doing**, please, follow this to-do list to launch the resulting dapp from the previous lesson:\\n\\n\\n1. Download a local Robonomics node v 0.22 from [releases page](https://github.com/airalab/robonomics/releases/tag/v0.22.0) that fits your OS. If you do not find your system in the latest release, please, find the most recent version in the previous releases.\\n\\n2. Launch the Robononomics node in the Developer mode by typing `./robonomics --dev --tmp` in your terminal.\\n\\n3. Download the Polkadot Extension for Chrome or Firefox [here](https://polkadot.js.org/extension/)\\n\\n4. Clone [this repository](https://github.com/vol4tim/example-robonomics-dapp/).\\n\\n5. Install [Yarn](https://yarnpkg.com).\\n\\n6. Install [@vue/cli](https://cli.vuejs.org/guide/installation.html)\\n\\n7. Start developing dapp with  commands in your terminal:\\n```shell\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n\\n**You should get this screen in your browser:**\\n\\n![Dapp Start](../images/build-dapp-interface/dapp-start.png \\\"Dapp Start\\\")\\n\\n\\n<details>\\n\\n  <summary>Some additional tips for launching</summary>\\n\\n  - Make sure your **node is running**:\\n    ![Example of running a Robonomics node](../images/build-dapp-interface/robonomics-node-launch.png \\\"Example of running Robonomics node\\\")\\n\\n  - In **macOS** you may need to change the **access permissions** `chmod +x robonomics`\\n\\n  - Make sure you allowed **access for Polkadot Extension**:\\n    ![Polkadot Extension giving access](../images/build-dapp-interface/polkadot-permission.png \\\"Polkadot Extension giving access\\\")\\n\\n  - If you have errors in log of the running node and dapp is not loading correctly, please, try to delete data base of dev chain: `sudo rm -rf <YOUR LOCAL PATH>/robonomics/chains/dev/db/` and restart the node. If it does not help, restart your machine.\\n\\n</details>\\n\\n## Inspecting the code\\n\\nLet's inspect the structure of the dapp to clear up what and where we can fix in order to change UI.\\n\\n```\\n.\\n├── public/\\n│   ├── favicon.ico           # Icon for your dapp\\n│   └── index.html            # The template file (injects icons links, JavaScript and CSS files for the app)\\n├── src/\\n│   ├── assets/               # Folder for images and global styles\\n│   ├── components/           # Folder with components\\n│   │   ├── Datalog.vue       # Tab 'Datalog' in dapp\\n│   │   ├── Demo.vue          # Tab 'Demo' in dapp\\n│   │   ├── Launch.vue        # Tab 'Launch' in dapp\\n│   ├── utils/                # Folder with important for app js functions (we will touch api.js in this lesson)\\n│   ├── App.vue               # The root of our app, contains HTML, CSS, JS for the whole page. In fact it is Vue Component also\\n│   ├── main.js               # The app’s entry file, we will import here global styles\\n├── ...                       # There are config files and dependencies files, that we will not change mannually\\n├── README.md                 # You can write here any instructions for your dapp\\n\\n```\\n\\n> **The code of the lesson is in this [repository](https://github.com/positivecrash/wscool21-ui-dapp)**\\n\\n## CSS-in-JS VS. Global stylesheets\\n\\nIn this lesson I show how to change the interface of a small dapp from scratch without any stable library of UI components. So I will import and create not only different Vue components, but also write my own styles.\\n\\nIf your application is big or your project has the whole bunch of dapps, in future you'd better look for building library of components specifically for your project to make UI more organized and efficient ([for example, here is a tool for organizing components](https://storybook.js.org)). Or if you are okay with standart interface themes, you can use any UI Libraries of third party ([for example](https://vuetifyjs.com/)).\\n\\n## First import or where to start\\n\\nI don't have any specific design for this dapp, but I have [Brandbook](https://static.robonomics.network/assets/Robonomics-Visual-Identity.pdf) and [quit well-established](https://robonomics.network) typography, fonts, button styles etc. So for the start I will import the following css files globally:\\n\\n```\\n...\\n├── src/\\n│   ├── assets/\\n│   │   ├── styles/\\n│   │   │   ├── reset.css         # The goal is to reduce browser inconsistencies\\n│   │   │   ├── variables.css     # Contains specific values to be reused such as colors, font-names, space values etc.\\n│   │   │   ├── typography.css    # Global typography for the whole dapp\\n│   │   │   ├── animation.css     # Keyframe animations used throughout the dapp\\n...\\n\\n```\\n\\nThe content of any of these files you can write in App.vue instead, if it fits your perception better. But I recommend to import some CSS files globally for this example to keep App.vue a little bit more clear.\\n\\nImport these CSS files into your app by editing **main.js** file:\\n\\n![Import global CSS in Vue app](../images/build-dapp-interface/import-css-vue-1.png \\\"Import global CSS in Vue app\\\")\\n\\n```JS\\nimport './assets/styles/reset.css'\\nimport './assets/styles/variables.css'\\nimport './assets/styles/typography.css'\\nimport './assets/styles/animation.css'\\n```\\n\\n**Check if fonts have been changed in the dapp:**\\n\\n![Dapp Interface changing step 1](../images/build-dapp-interface/dapp-1.png \\\"Dapp Interface changing step 1\\\")\\n\\n\\n## Change layout and prettify the title\\n\\nLet's change layout of the application. As I mentioned earlier, you can write your styles directly in App.vue, but for this example I prefer to separate this process.\\n\\n- Comment or delete styles from tag `<style>` in **App.vue**\\n\\n- Create css file **app.css** in styles folder for this application and import it into **main.js**\\n\\n```JS\\nimport './assets/styles/app.css'\\n```\\n\\n<details>\\n\\n<summary>Write in app.css first basic styles for the app:</summary>\\n\\n```css\\n#app {\\n  display: grid;\\n  grid-template-rows: auto 1fr;\\n  align-items: stretch;\\n\\n  text-align: center;\\n}\\n\\nbody {\\n  background-color: var(--color-gray-light);\\n}\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Change the title of the app [App.vue]</summary>\\n\\n```html\\n<div class=\\\"top\\\">\\n    <h1>dApp Robonomics Demo</h1>\\n    <i>Winter School 2021</i>\\n    <img class=\\\"label\\\" alt=\\\"\\\" src=\\\"./assets/images/robonomics-winter-school-2021-logo.png\\\"/>\\n</div>\\n```\\n\\n</details>\\n\\n\\n\\n<details>\\n\\n<summary>Write styles for the title [app.css]</summary>\\n\\n```css\\n.top {\\n  position: relative;\\n  padding-top: var(--space);\\n  padding-bottom: calc(var(--space)*2);\\n\\n  border-bottom: 2px solid var(--color-dark);\\n  background-color: var(--color-light);\\n}\\n\\n.top h1 {\\n  font-size: 1.8rem;\\n}\\n\\n.top i {\\n  display: block;\\n}\\n\\n.top .loader-label {\\n  display: block;\\n  margin: calc(var(--space)/3) auto;\\n  max-width: 150px;\\n\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.5s FadeIn 0.3s ease forwards, 0.5s ScaleDown 0.1s ease forwards;\\n}\\n\\n.top .label {\\n  position: absolute;\\n  width: 100px;\\n  bottom: -50px;\\n  left: calc(50% - 50px);\\n  display: block;\\n\\n  transform: translateY(1rem);\\n  visibility: hidden;\\n  opacity: 0;\\n  animation: 0.7s FadeIn 0.5s ease forwards, 1s ScaleUp 0.5s ease forwards;\\n}\\n```\\n\\n</details>\\n\\n- Place a file with the logo of the Robonomics winter school 2021 in the folder **./src/assets/images**\\n\\n**You will get the following screen:**\\n![Dapp Interface changing step 2](../images/build-dapp-interface/dapp-2.png \\\"Dapp Interface changing step 2\\\")\\n\\n## Define styles according to the dapp's data\\n\\nNow I will wrap the app's content in `<div>` element. Also I will need different styles for different states of the dapp (loaded or not loaded).\\n\\n- Open the **App.vue** and write a wrapping element:\\n```html\\n<div class=\\\"content\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\n- Find the variable `load`, it has already been defined in `<script>`.\\n- Pass an object to `v-bind:class` to dynamically toggle classes (I use shortened version `:class`):\\n```html\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <!--here is everything going after the title-->\\n</div>\\n```\\nThat's how you can easily toggle styles in your app according to the data you get. You will see the usage of this class below.\\n\\n## Define views according to the dapp's data\\n\\nLet's change the loader for the app.\\n- For this purpose I will import my component from another Robonomics project \\n\\n<details>\\n\\n<summary>./src/components/AnimatedRobonomicsLogo.vue</summary>\\n\\n```HTML\\n<template>\\n  <div class=\\\"logo-animated\\\" :style=\\\"{transform: 'scale('+scale+')'}\\\">\\n      <svg version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" width=\\\"196.9px\\\" height=\\\"170.3px\\\" viewBox=\\\"0 0 196.9 170.3\\\" style=\\\"enable-background:new 0 0 196.9 170.3;\\\" xml:space=\\\"preserve\\\">\\n\\t\\t<g transform=\\\"translate(2530 155)\\\">\\n            <path class=\\\"line\\\" d=\\\"M-2523.4,7.9l184.2,0.5l-91.7-158.1L-2523.4,7.9z\\\"/>\\n\\n            <circle class=\\\"dot\\\" cx=\\\"-2339.7\\\" cy=\\\"8.7\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2523.4\\\" cy=\\\"8.2\\\" r=\\\"6.6\\\"/>\\n            <circle class=\\\"dot\\\" cx=\\\"-2430.8\\\" cy=\\\"-148.4\\\" r=\\\"6.6\\\"/>\\n            \\n            <path class=\\\"triangle-1\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-45.8-79L-2477.3-18.3z\\\"/>\\n            <path class=\\\"triangle-2\\\" d=\\\"M-2431.2-18.1l46,0.1l-45.8-79L-2431.2-18.1z\\\"/>\\n            <path class=\\\"triangle-3\\\" d=\\\"M-2477.3-18.3l92.1,0.3l-46-20.3L-2477.3-18.3z\\\"/>\\n          </g>\\n\\t</svg>\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style scoped>\\n    /*\\n    Global styles required:\\n    FadeIn - keyframe animation from animation: .css\\n    all --color- variables from variables.css\\n    */\\n\\n    .logo-animated {\\n        transform-origin: 0 0;\\n    }\\n\\n    .logo-animated .dot {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 1s FadeIn 0.3s ease forwards;\\n    }\\n\\n    .logo-animated .line {\\n        fill: transparent;\\n        stroke: var(--color-blue);\\n        stroke-miterlimit:10;\\n        stroke-dasharray: 700;\\n        stroke-dashoffset: 700;\\n        animation: 1s DrawSvgPath 0.5s ease-in-out forwards; \\n    }\\n\\n    .logo-animated .triangle-1 {\\n        fill: var(--color-blue);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-1 0.1s linear infinite;\\n    }\\n\\n    .triangle-2 {\\n        fill: var(--color-violet-light);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-2 0.1s linear infinite;\\n    }\\n\\n    .triangle-3 {\\n        fill: var(--color-violet-mid);\\n        visibility: hidden;\\n        opacity: 0;\\n        animation: 0.5s FadeIn 0.3s ease forwards, 5s logo-triangle-3 0.1s linear infinite;\\n    }\\n\\n\\n    @keyframes DrawSvgPath\\n        {\\n        to {\\n            stroke-dashoffset: 0;\\n        }\\n        }\\n\\n    @keyframes logo-triangle-1\\n    {\\n        0% { fill: var(--color-blue); }\\n        25% { fill: var(--color-blue); }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-violet-light); }\\n        100% { fill: var(--color-blue); }\\n    }\\n\\n    @keyframes logo-triangle-2\\n    {\\n        0% { fill: var(--color-violet-light); }\\n        25% { fill: #E0BDED; }\\n        50% { fill: var(--color-blue); }\\n        75% { fill: var(--color-blue); }\\n        100% { fill: var(--color-violet-light); }\\n    }\\n\\n    @keyframes logo-triangle-3\\n    {\\n        0% { fill: var(--color-violet-mid); }\\n        25% { fill: var(--color-violet-light); }\\n        50% { fill: var(--color-violet-light); }\\n        75% { fill: var(--color-violet-dark); }\\n        100% { fill: var(--color-violet-mid); }\\n    }\\n</style>\\n```\\n\\n</details>\\n\\n- Register this component in **App.vue**\\n```JS\\nexport default {\\n  components: {\\n    Loader: () => import(\\\"./components/AnimatedRobonomicsLogo\\\")\\n  }\\n}\\n```\\n- Insert it with conditional Vue directive `v-if`, using the already known variable `load`:\\n```HTML\\n<div class=\\\"content\\\" :class=\\\"{ load: load }\\\">\\n  <Loader v-if=\\\"load\\\" />\\n  <template v-else>\\n    <!-- here will be main content of loaded dapp -->\\n  </template>\\n</div>\\n```\\n- Watch the result in browser. It has some issues that we will fix now:\\n\\n1. Loader pops up to the title (it should be in the center). Let's insert these lines to **app.css**:\\n```css\\nbody, html, #app {\\n  height: 100%;\\n  position: relative;\\n}\\n```\\n2. If your connection goes too fast, you will see just blinking loader for a moment. It may confuse a lot. Let's set a timeout for the app's responce. To do that open **api.js** and find in the function `initAccount` this code:\\n```JS\\nconst timeout = new Promise(resolve => {\\n  setTimeout(resolve, 300);\\n});\\n```\\nI set `1700` instead of `300` and check the result:\\n\\n![Dapp Interface changing step 3](../images/build-dapp-interface/dapp-3.gif \\\"Dapp Interface changing step 3\\\")\\n\\n\\n## Using reusable components\\n\\nYou have already watched how to register and use a component in the previous section about Loader, but now I want to focus on it more carefully.\\n\\nLet's change the Account section. Here I will use self-written components (box, button, icon) and the third party's one ([from Vue Polkadot Library](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon )).\\n\\n### Adding the box\\n\\n<details>\\n\\n<summary>Create Box component in ./src/components/Box.vue file </summary>\\n\\n```HTML\\n<template>\\n    <section class=\\\"box\\\" :class=\\\"classList\\\">\\n        <slot />\\n    </section>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    classList: {\\n      type: String\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .box {\\n        background-color: var(--color-light);\\n        border: 1px solid var(--color-dark);\\n        padding: calc(var(--space)*0.5) var(--space);\\n        box-shadow: 2px 2px 0 var(--color-dark);\\n        margin-bottom: calc(var(--space)*1.5);\\n    }\\n</style>\\n```\\n</details>\\n\\nNow we can use it many times throught out the dapp. Let's see this on the Account section example:\\n\\n- Register component (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Box: () => import(\\\"./components/Box\\\")\\n  }\\n}\\n```\\n\\n- Use it for the Account section with an additional class passed with prop `classList`:\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }} |\\n  <button @click=\\\"faucet\\\">\\n    faucet\\n  </button>\\n</Box>\\n```\\n\\n**Check the result:**\\n![Dapp Interface changing step 4](../images/build-dapp-interface/dapp-4.png \\\"Dapp Interface changing step 4\\\")\\n\\n### Adding the button\\n\\nYou may even not notice the button in the box that we have added. Let's fix it and add a component for buttons as it is not the only button in the app.\\n\\n<details>\\n\\n<summary>Create Button component in ./src/components/Button.vue file </summary>\\n\\n```HTML\\n<template>\\n  <button type=\\\"button\\\" :class=\\\"classList\\\" @click=\\\"onClick\\\" :disabled=\\\"disabled\\\" class=\\\"inline-block\\\">\\n    {{ label }}\\n  </button>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  components: {\\n    Icon: () => import(\\\"./Icon\\\")\\n  },\\n\\n  props: {\\n    label: {\\n      type: String,\\n    },\\n    type: {\\n      type: String,\\n      default: 'primary',\\n      validator: function (value) {\\n        return ['primary', 'secondary'].indexOf(value) !== -1;\\n      }\\n    },\\n    disabled: {\\n      type: Boolean,\\n      default: false,\\n    },\\n    size: {\\n      type: String,\\n      default: 'medium',\\n      validator: function (value) {\\n        return ['small', 'medium', 'large'].indexOf(value) !== -1;\\n      }\\n    }\\n  },\\n\\n  computed: {\\n    classList() {\\n      return {\\n        'button': true,\\n        [`${this.type}`]: true,\\n        [`button__${this.size}`]: true,\\n      };\\n    },\\n  },\\n\\n  methods: {\\n    onClick() {\\n      this.$emit('onClick');\\n    },\\n  },\\n\\n};\\n</script>\\n\\n<style>\\n    /*\\n    Global styles required for css variables from variables.css\\n    */\\n\\n    .button {\\n        appearance: none;\\n        -webkit-appearance: none;\\n        outline: 0;\\n        border: 0;\\n\\n        transition: 0.1s all linear;\\n\\n        padding: .15rem 0.6rem;\\n        border-width: 1px;\\n        border-style: solid;\\n        border-radius: .25rem;\\n  \\n        cursor: pointer;\\n\\n        font-family: var(--font-family);\\n        font-size: calc(var(--font-size)*0.9);\\n        line-height: 1;\\n        font-weight: 500;\\n\\n        text-transform: uppercase;\\n        letter-spacing: 1px;\\n    }   \\n\\n    .button:not([disabled]):hover {\\n    filter: saturate(1.5);\\n    }\\n\\n    .button[disabled] {\\n        cursor: default;\\n        opacity: 0.6;\\n    }\\n\\n    button.primary {\\n        border-color: var(--color-green);\\n        background-color: var(--color-green);\\n        color: var(--color-light);\\n    }\\n\\n    button.secondary {\\n        border-color: var(--color-blue);\\n        color: var(--color-blue);\\n    }\\n\\n    button.secondary:not([disabled]):hover {\\n        background-color: var(--color-blue);\\n        color: var(--color-light);\\n    }\\n\\n    .button__small {\\n        font-size: .85rem;\\n        padding: .1rem 0.45rem;\\n    }\\n\\n    .button__large {\\n        font-size: 1.2rem;\\n        padding: .5rem 1.7rem;\\n    }\\n\\n</style>\\n```\\n</details>\\n\\n\\n- Register the component (**App.vue**):\\n\\n```JS\\nexport default {\\n  components: {\\n    Button: () => import(\\\"./components/Button\\\")\\n  }\\n}\\n```\\n\\n- Use it for the 'Faucet' button with props defined in the 'Button' component\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n  Account: <b>{{ account }}</b> {{ balance }}\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n</Box>\\n```\\n\\n**We get this view:**\\n![Dapp Interface changing step 5](../images/build-dapp-interface/dapp-5.png \\\"Dapp Interface changing step 5\\\")\\n\\nFor the Button component we have emited the click from prop with `@onClick`, so I will pay attention if the faucet function is working correctly now (the balance should change on click):\\n\\n![Dapp Interface changing step 6](../images/build-dapp-interface/dapp-6.gif \\\"Dapp Interface changing step 6\\\")\\n\\n### Adding the icon\\n\\nLet's add an icon to this button to attract more attention to this element of the interface, as user can't interact with the dapp properly without units and clicking on this button.\\n\\nFor this purpose you can use any ready Vue library for icons, I will create my own component with the icon.\\n\\n- I found an appropriate icon on [the big online archive of icons](https://www.flaticon.com).\\n- Downloaded .svg file and edited it in the vector graphics editor to make the proper size.\\n- Inserted svg as a text in the Icon.vue component.\\n\\n<details>\\n\\n<summary>Here is what I got as the Icon.vue component</summary>\\n\\n```JS\\n<template>\\n  <div class=\\\"icon inline-block\\\" :class=\\\"classList\\\">\\n    <svg v-if=\\\"icon == 'faucet'\\\" class=\\\"icon-fill\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" xmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\" x=\\\"0px\\\" y=\\\"0px\\\" :width=\\\"SvgWidth(20)\\\"  viewBox=\\\"0 0 20 24.9\\\" style=\\\"enable-background:new 0 0 20 24.9;\\\" xml:space=\\\"preserve\\\">\\n      <path d=\\\"M2.7,24.9c0.2,0,2.4,0,2.4-2.4c0-2-2.2-5.2-2.2-5.2s-2.5,3.3-2.5,5.3C0.4,24.6,2.4,24.9,2.7,24.9z M20,10.8V7.2V3.1h-2.6v2.6h-3.1V1.5h2.6c0.4,0,0.8-0.3,0.8-0.8S17.3,0,16.9,0h-6.7C9.8,0,9.5,0.3,9.5,0.8s0.3,0.8,0.8,0.8h2.6v4.1H7.9c-4.7,0-6.2,3.2-6.3,4.8c0,0,0,0.1,0,0.1v2.8H0v2.1h6.2v-2.1H4.6v-2.7c0-0.3,0.4-1.9,3.3-1.9h9.6v2.1L20,10.8L20,10.8z\\\"/>\\n    </svg>\\n\\n  </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n  props: {\\n    icon: {\\n      type: String\\n    },\\n    classList: {\\n      type: String\\n    },\\n    scale: {\\n      type: String,\\n      default: '1'\\n    },\\n  },\\n\\n  methods: {\\n    SvgWidth(SvgWidth) {\\n      return `${SvgWidth * this.scale}px`;\\n    }\\n  }\\n};\\n</script>\\n\\n<style>\\n.icon {\\n    line-height: 1;\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\nTo use it with the button, edit the Button component.\\n\\nImport the Icon in **Button.vue**:\\n\\n```JS\\ncomponents: {\\n    Icon: () => import(\\\"./Icon\\\")\\n}\\n```\\n\\nRegister prop:\\n\\n```JS\\nprops: {\\n  icon: {\\n    type: String,\\n    default: 'none'\\n  }\\n}\\n```\\n\\nAdd the Icon to the button (we can specify different templates with `v-if` condition):\\n\\n```HTML\\n<template v-if=\\\"icon != 'none'\\\">\\n  <Icon :icon=\\\"icon\\\" />\\n  <span v-if=\\\"label != ''\\\" class=\\\"inline-block\\\">{{ label }}</span>\\n</template>\\n<template v-if=\\\"icon == 'none' & label != ''\\\">\\n  {{ label }}\\n</template>\\n```\\n\\nAdd styles:\\n\\n```CSS\\n.button .icon-fill path {\\n  fill: var(--color-light);\\n}\\n\\n.button > *:not(:last-child) {\\n  margin-right: calc(var(--space)/2);\\n}\\n\\n```\\n\\nAdd the icon prop into the button in **App.vue**:\\n\\n```HTML\\n<Button label=\\\"Faucet\\\" size=\\\"large\\\" icon=\\\"faucet\\\" @onClick=\\\"faucet\\\" />\\n```\\n\\n**Check:**\\n\\n![Dapp Interface changing step 7](../images/build-dapp-interface/dapp-7.png \\\"Dapp Interface changing step 7\\\")\\n\\n### Add the Polkadot avatar\\n\\n- Install [@vue-polkadot/vue-identicon](https://vue-polkadot.js.org/vue-ui/vue-identicon/#vue-polkadot-vue-identicon)\\n\\n- Import to App.vue:\\n```JS\\ncomponents: {\\n    Identicon: () => import(\\\"@vue-polkadot/vue-identicon\\\")\\n}\\n```\\n\\n- Insert the avatar instead of the word 'Account', pass props according to the documentation, use `account` data as a value prop:\\n```HTML\\n<Identicon\\n  :value=\\\"account\\\"\\n  :theme=\\\"'polkadot'\\\"\\n  :size=\\\"40\\\"\\n  :class=\\\"'inline-block'\\\"\\n/>\\n```\\n\\n**Check:**\\n\\n![Dapp Interface changing step 8](../images/build-dapp-interface/dapp-8.png \\\"Dapp Interface changing step 8\\\")\\n\\n## Data manipulation for the better view\\n\\nLet's cut the account address:\\n\\n- Wrap the variable `account` in the computed property:\\n\\n```JS\\ncomputed: {\\n  AccountAddress() {\\n    return this.account.slice(0, 6) + \\\"...\\\" + this.account.slice(-4);\\n  }\\n}\\n```\\n\\n- Replace the variable `account` with `AccountAddress` in the template\\n\\n**Check:**\\n\\n![Dapp Interface changing step 9](../images/build-dapp-interface/dapp-9.png \\\"Dapp Interface changing step 9\\\")\\n\\n## CSS magic\\n\\nLet's prettify the account section a little bit more:\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<Box :classList=\\\"'account'\\\">\\n              \\n  <div class=\\\"account__address\\\">\\n    <Identicon\\n      :value=\\\"account\\\"\\n      :theme=\\\"'polkadot'\\\"\\n      :size=\\\"40\\\"\\n      :class=\\\"'inline-block'\\\"\\n    />\\n\\n    <code class=\\\"inline-block\\\">{{ AccountAddress }}</code>\\n  </div>\\n  \\n  <div class=\\\"account__balance\\\">{{ balance }}</div>\\n\\n  <Button label=\\\"Faucet\\\" size=\\\"large\\\" @onClick=\\\"faucet\\\" />\\n  \\n</Box>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.account {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  align-items: center;\\n  justify-items: stretch;\\n  column-gap: var(--space);\\n}\\n\\n.account__balance {\\n    font-size: 150%;\\n    font-weight: 500;\\n    font-family: var(--font-family-code);\\n    white-space: nowrap;\\n}\\n\\n.account__address > *:not(:last-child) {\\n    margin-right: calc(var(--space)/2);\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 10](../images/build-dapp-interface/dapp-10.gif \\\"Dapp Interface changing step 10\\\")\\n\\nLet's edit styles for the tabs:\\n\\n<details>\\n\\n<summary>Styles (in app.css)</summary>\\n\\n```CSS\\n.tabs {\\n  display: grid;\\n  grid-template-columns: repeat(3, 1fr);\\n  margin-top: calc(var(--space)*2.5);\\n}\\n\\n.tabs button {\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  border-width: 0 0 1px;\\n  font-family: var(--font-family);\\n  font-size: calc(var(--font-size)*1.5);\\n  font-weight: 300;\\n  cursor: pointer;\\n  transition: 0.2s all linear;\\n}\\n\\n.tabs button:not(.active) {\\n  opacity: 0.5;\\n  border-color: var(--color-gray)\\n}\\n\\n.tabs-content {\\n  padding-top: var(--space);\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>Minimal template changes:</summary>\\n\\n```HTML\\n<div class=\\\"tabs-content\\\">\\n  <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" /> \\n</div>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 11](../images/build-dapp-interface/dapp-11.gif \\\"Dapp Interface changing step 11\\\")\\n\\n> Let me remind you that the finished code for this lesson is in [this](https://github.com/positivecrash/wscool21-ui-dapp) repository. And let's shift to the next steps :)\\n\\n## Datalog\\n\\nStart with fixing UI elements that are already known in the dapp: buttons (same as we have done for the 'Faucet', but with different props).\\n\\nThen I will wrap these elements in `<fieldset>` to separate them by meaning. And I will write my own styles for the fieldset and input elements.\\n\\n<details>\\n\\n<summary>Template in Datalog.vue:</summary>\\n\\n```HTML\\n<div class=\\\"tools\\\">\\n  <fieldset>\\n    <Button label=\\\"Read data\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"read\\\" />\\n  </fieldset>\\n\\n  <fieldset>\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" class=\\\"large\\\" />\\n    <Button label=\\\"Write\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" type=\\\"secondary\\\" @onClick=\\\"write\\\" />\\n  </fieldset>\\n</div>\\n```\\n\\n</details>\\n\\n\\n<details>\\n\\n<summary>Styles for input elements in app.css - it's supposed to be global:</summary>\\n\\n```CSS\\ninput, select{\\n  padding: .3rem 0.6rem;\\n  border: 1px solid var(--color-gray);\\n  background-color: var(--color-light);\\n  border-radius: var(--radius);\\n  font-size: var(--font-size);\\n  font-family: var(--font-family-code);\\n  border-radius: .25rem;\\n  transition: 0.2s ease all;\\n}\\n\\ninput:focus {\\n  border-color: var(--color-dark);\\n}\\n\\ninput.large, select.large {\\n  font-size: 1.2rem;\\n  padding: .35rem 1rem;\\n}\\n\\n\\n.tools *, .tools fieldset:not(:last-child):after {\\n  display: inline-block;\\n  vertical-align: middle;\\n  vertical-align: -moz-middle-with-baseline;\\n  vertical-align: -webkit-baseline-middle;\\n}\\n\\n.tools fieldset {\\n  border: 0;\\n}\\n\\n.tools fieldset:not(:last-child):after {\\n  content: \\\"•\\\";\\n}\\n\\n.tools fieldset > *,  .tools > * {\\n  margin-right: calc(var(--space)/2)\\n}\\n```\\n\\n</details>\\n\\n**Let's check that everything works fine after updates:**\\n\\n![Dapp Interface changing step 12](../images/build-dapp-interface/dapp-12.gif \\\"Dapp Interface changing step 12\\\")\\n\\nWe have a datalog section through out the dapp, so I'll make a component for it.\\n\\n<details>\\n\\n<summary>I have got the following code for a new component DatalogSection.vue</summary>\\n\\n```HTML\\n<template>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <h4 class=\\\"log-title\\\">Datalog</h4>\\n\\n        <div class=\\\"log-content\\\">\\n\\n          <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n\\n          <details v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"box\\\" :open=\\\"k === 0\\\">\\n              <summary>{{ item[0] }}</summary>\\n              <pre>{{ item[1] }}</pre>\\n          </details>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\nexport default {\\n\\n  props: {\\n    log: {\\n      type: Array\\n    }\\n  },\\n\\n}\\n\\n</script>\\n\\n<style>\\n\\n.log {\\n  text-align: left;\\n  margin: var(--space) auto;\\n  width: 100%;\\n}\\n\\n.log-content {\\n  border: 1px solid var(--color-gray);\\n  max-height: 500px;\\n  overflow-y: auto;\\n  padding: var(--space);\\n  background-color: var(--color-gray-middark);\\n  outline: 1px solid #fff;\\n  box-shadow: 0 0 60px 20px #fff inset;\\n}\\n\\n.log-title {\\n  color: var(--color-gray-dark);\\n  font-weight: 300;\\n  font-family: var(--font-family-code);\\n\\n  border-bottom: 1px solid var(--color-gray);\\n}\\n\\n.log .box {\\n  margin-bottom: var(--space);\\n}\\n\\ndetails {\\n  transition: 0.2s all ease;\\n}\\n\\ndetails summary {\\n  cursor: pointer;\\n}\\n\\ndetails.box {\\n  padding-top: 0;\\n  padding-bottom: 0;\\n}\\n\\ndetails.box[open] {\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box:focus {\\n  box-shadow: 0 0 5px var(--color-gray)\\n}\\n\\ndetails.box summary {\\n  padding-top: calc(var(--space)*0.5);\\n  padding-bottom: calc(var(--space)*0.5);\\n}\\n\\ndetails.box[open] summary {\\n  border-bottom: 1px solid var(--color-dark);\\n  margin-bottom: calc(var(--space)*0.5);\\n  font-weight: 500;\\n}\\n\\n.log details.box summary {\\n  font-family: var(--font-family-code);\\n}\\n\\n</style>\\n```\\n\\n</details>\\n\\nWhat you should pay attention to here: we pass prop `log` as an array. I assume that this multidimensional array will contain log of entries and every entry has a title (I wrote there date for all logs in the dapp) and content. We need to reformat arrays in components **Datalog.vue** and **Launch.vue**.\\n\\nNow edit **Datalog.vue**. Find method, where we get the log:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n}\\n```\\n\\nNow we have to format data in **Datalog.vue**, and pass ready log array for **DatalogSection.vue**. So let's map the log array:\\n```JS\\nasync read() {\\n  this.log = (await this.api.query.datalog.datalog(this.account)).toArray().map((item) => {\\n    return [new Date(Number(item[0])).toLocaleString(), u8aToString(item[1])]\\n  });\\n}\\n```\\n\\nWe don't need this code anymore:\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return u8aToString(v);\\n  }\\n}\\n```\\n\\n**Let's check the datalog section in Datalog tab:**\\n\\n![Dapp Interface changing step 13](../images/build-dapp-interface/dapp-13.gif \\\"Dapp Interface changing step 13\\\")\\n\\n## Launch\\n\\nFor this step, most of improvements have already been done, we just need to apply them to the template: import Button and Datalog components, remove the excessive title:\\n\\n![Dapp Interface changing step 14](../images/build-dapp-interface/dapp-14.gif \\\"Dapp Interface changing step 14\\\")\\n\\nLet's replace `select` control element with `checkbox`.\\n\\nInstead of this:\\n```HTML\\n<select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n  <option value=\\\"ON\\\">ON</option>\\n  <option value=\\\"OFF\\\">OFF</option>\\n</select>\\n```\\n\\nWrite this:\\n```HTML\\n<div class=\\\"toggler inline-block\\\">\\n  <input v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\" type=\\\"checkbox\\\" id=\\\"robot-switch\\\" />\\n  <label for=\\\"robot-switch\\\"><span></span></label>\\n</div>\\n```\\n\\n<details>\\n\\n<summary>Styles in app.css:</summary>\\n\\n```CSS\\n.toggler input { display: none; }\\n.toggler label {\\n  position: relative;\\n  display: block;\\n  width: 60px;\\n  height: 40px;\\n  border-radius: 4px;\\n  font-weight: 500;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  cursor: pointer;\\n  background-color: var(--color-gray);\\n  color: var(--color-light);\\n  text-align: center;\\n}\\n\\n.toggler label:before {\\n  content: 'Off';\\n  width: 100%;\\n  text-align: center;\\n  line-height: 40px;\\n}\\n\\n.toggler label:after {\\n  content: '';\\n  display: block;\\n  width: 6px;\\n  height: 100%;\\n  border-radius: 10px;\\n  background-color: var(--color-gray-dark);\\n\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n  z-index: 10;\\n\\n  transition: 0.3s ease-out all;\\n}\\n\\n.toggler input:checked + label {\\n  background-color: var(--color-green);\\n}\\n\\n.toggler input:checked + label:before {\\n  content: 'On';\\n}\\n\\n.toggler input:checked + label:after {\\n  transform: translateX(54px);\\n  background-color: #007038;\\n}\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 15](../images/build-dapp-interface/dapp-15.gif \\\"Dapp Interface changing step 15\\\")\\n\\nI want to clarify something with the interface: with these elements we start some device. Let's visualize it. I've chosen a drone, so I will toggle classes according to `item.parameter`.\\n\\nCreate a new property in `data`:\\n```JS\\ndata() {\\n  status: false\\n}\\n```\\n\\nAssign value of `parameter` to `status` after button is clicked and tx is sent to the block:\\n```JS\\nmethods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n            this.status = this.parameter; // new line here\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n```\\n\\nWrite styles for the drone in **Launch.vue**. Don't forget `scoped` for `<style>` tag, to apply styles only for this component.\\n\\n<details>\\n\\n<summary>CSS for drone:</summary>\\n\\n```CSS\\n<style scoped>\\n.tools {\\n  position: relative;\\n  padding-left: 120px;\\n  text-align: left;\\n  display: inline-block;\\n}\\n\\n.launch-drone {\\n  position: absolute;\\n  width: 100px;\\n  left: 0;\\n  filter: grayscale(1);\\n  transition: 1s all ease-in;\\n}\\n\\n.launch-drone.on {\\n  filter: grayscale(0);\\n  animation: DroneLaunch 10s linear infinite;\\n}\\n\\n@keyframes DroneLaunch {\\n  0%, 20%, 40%, 60%, 80%, 100% {\\n    transform: translateY(0);\\n  }\\n  10%, 30%, 50%, 70%, 90% {\\n    transform: translateY(-20%);\\n  }\\n}\\n</style>\\n```\\n\\n</details>\\n\\n![Dapp Interface changing step 16](../images/build-dapp-interface/dapp-16.gif \\\"Dapp Interface changing step 16\\\")\\n\\nNow let's add the **DatalogSection.vue** component.\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\nReformat the log array from:\\n\\n```JS\\nthis.log.push({\\n  sender,\\n  robot,\\n  parameter\\n});\\n```\\n\\nto (for structure like `[[\\\"entry 1 date\\\", \\\"entry 1 content\\\"], [\\\"entry 2 date\\\", \\\"entry 2 content\\\"]]`):\\n\\n```JS\\nthis.log.push([new Date().toLocaleString(), {\\n  sender,\\n  robot,\\n  parameter\\n}]);\\n```\\n\\nReplace the code from the template:\\n\\n```HTML\\n<div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    sender: <b>{{ item.sender }}</b>\\n    <br />\\n    robot: <b>{{ item.robot }}</b>\\n    <br />\\n    parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n  </div>\\n</div>\\n```\\n\\nwith this:\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\n**Check:**\\n![Dapp Interface changing step 17](../images/build-dapp-interface/dapp-17.gif \\\"Dapp Interface changing step 17\\\")\\n\\nSometimes you get some errors, it's almost inevitable. Something can go wrong with the connection or anything else can happen. So we have fallbacks with error messages through out the dapp, I haven't changed them from the start, in the code they look like:\\n\\n```HTML\\n<div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n```\\n\\nOn the interface errors look this way now:\\n\\n![Dapp Interface changing step 18](../images/build-dapp-interface/dapp-18.png \\\"Dapp Interface changing step 18\\\")\\n\\nAdd styles for the `.error` in **app.css**:\\n\\n```CSS\\n.error {\\n  font-weight: 400;\\n  text-transform: uppercase;\\n  letter-spacing: 1px;\\n  color: var(--color-red);\\n}\\n```\\n\\nAnd I will fix a space between the `.tools` section and other content from the bottom as well in **app.css**:\\n\\n```CSS\\n.tools {\\n  margin-bottom: var(--space);\\n}\\n```\\n\\nWe get:\\n\\n![Dapp Interface changing step 19](../images/build-dapp-interface/dapp-19.png \\\"Dapp Interface changing step 19\\\")\\n\\nNow on this page we have to \\\"primary\\\" buttons. Technically it is okay, but this is not okay from the above user experience. It's better not to use more than one prevailing button on the screen. So let's fix it and add for the `Button` in **Launch.vue** with property `type=\\\"secondary\\\"`:\\n\\n![Dapp Interface changing step 20](../images/build-dapp-interface/dapp-20.png \\\"Dapp Interface changing step 20\\\")\\n\\nGreat, now I'll fix some issues with my node and go to the Demo step.\\n\\n## Demo\\n\\nFor the start, I'd like to swap tabs, to pay more attention to the most relevant one, but this is not the first step that we do to practice. Reverse tabs in **App.vue**.\\n\\nDon't forget to replace the default data:\\n\\n```JS\\ndata() {\\n    return {\\n      ...\\n      tab: \\\"demo\\\"\\n    };\\n},\\n```\\n\\n![Dapp Interface changing step 21](../images/build-dapp-interface/dapp-21.png \\\"Dapp Interface changing step 21\\\")\\n\\nAs usual let's start with changing what we have already got.\\n\\n- Remove the title `<h2>Demo</h2>` as in the previous steps\\n- Find UI elements that we have already learn – datalog, buttons, account address. But not so fast. Now we'll change the datalog only.\\n\\nAdd the component to **Demo.vue**:\\n\\n```JS\\ncomponents: {\\n  DatalogSection: () => import(\\\"./DatalogSection\\\")\\n}\\n```\\n\\n```HTML\\n<DatalogSection :log=\\\"log\\\"/>\\n```\\n\\nWe've got raw data in the log, so we need to reformat the array with the log to pass in the component ready-view data as in the previous steps. Find the line `return [item[0], item[1]];` in `async created()` and replace it with:\\n\\n```JS\\nreturn [new Date(Number(item[0])).toLocaleString(), JSON.parse(u8aToString(item[1]))];\\n```\\n\\nRemove the unused code from the log:\\n\\n```HTML\\n<div v-if=\\\"log\\\" class=\\\"log\\\">\\n  <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n  <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n    <b>{{ item[0] | dateFormat }}</b>\\n    <pre>{{ item[1] | dataFormat }}</pre>\\n  </div>\\n</div>\\n```\\n\\nand:\\n\\n```JS\\nfilters: {\\n  dateFormat: function(v) {\\n    return new Date(Number(v)).toLocaleString();\\n  },\\n  dataFormat: function(v) {\\n    return JSON.parse(u8aToString(v));\\n  }\\n},\\n```\\n\\n**Check:**\\n![Dapp Interface changing step 22](../images/build-dapp-interface/dapp-22.png \\\"Dapp Interface changing step 22\\\")\\n\\nFor customization of this demo example with launching a robot, you are free to come up with any idea. Personally, I started with this town:\\n\\n![Dapp Interface changing step 23](../images/build-dapp-interface/dapp-23.gif \\\"Dapp Interface changing step 23\\\")\\n\\nI won't show the whole code for this not to confuse you at all, but schematically there will be something like this:\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back\\\"></div>\\n  <div class=\\\"demo-city\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n</div>\\n```\\n\\nThan within the element `.demo.play` write styles for moving the city backward, and the car forward.\\n\\nWhile working on this, I came up with the idea of realization the CyberPunk city. As I have no any particullar task, so the car became a taxi, driver became a passenger, and now on the interface we have an AI robot hologram welcoming the passenger (these all are just CSS and graphics tweaks&&tricks).\\n\\n**The code for the Cyberpunk city demo:**\\n\\n<details>\\n\\n<summary>Template</summary>\\n\\n```HTML\\n<div class=\\\"demo\\\" :class=\\\"[robot.state ? 'play' : 'stop']\\\">\\n  <div class=\\\"demo-back-1\\\"></div>\\n  <div class=\\\"demo-back-2\\\"></div>\\n  <div class=\\\"demo-city-1\\\"></div>\\n  <div class=\\\"demo-car\\\"></div>\\n\\n  <div class=\\\"demo-data\\\">\\n    <div class=\\\"demo-data-driver inline-block\\\">\\n      <img alt=\\\"Driver's avatar\\\" src=\\\"../assets/images/cabman.png\\\" v-if=\\\"robot.state\\\"/>\\n    </div>\\n    <div class=\\\"demo-data-lines inline-block\\\">\\n      <div class=\\\"demo-data-line\\\">\\n          <div>Robot</div>\\n          <div>[ {{ addressShort(robot.address) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-line\\\" v-if=\\\"robot.state\\\">\\n          <div>Passenger</div>\\n          <div>[ {{ addressShort(robot.driver) }} ]</div>\\n      </div>\\n\\n      <div class=\\\"demo-data-welcome\\\" v-if=\\\"robot.state\\\">\\n          <span>Hello, passenger. </span>\\n          <span>I've linked to the vehicle. </span>\\n          <span>Your ride begins, congrats! </span>\\n      </div>\\n    </div>\\n\\n  </div>\\n\\n  <Button :label=\\\"robot.state ? 'stop' : 'run'\\\" :disabled=\\\"isWrite\\\" size=\\\"large\\\" @onClick=\\\"run\\\" />\\n</div>\\n```\\n\\n</details>\\n\\nThere are more than one hash address that should be shortenned, so I added the method:\\n\\n```JS\\nmethods: {\\n  addressShort(address) {\\n    return address.slice(0, 6) + \\\"...\\\" + address.slice(-4);\\n  }\\n}\\n```\\n\\nDon't forget to register the Button component\\n\\n```JS\\ncomponents: {\\n  Button: () => import(\\\"./Button\\\")\\n}\\n```\\n\\n<details>\\n\\n<summary>Styles</summary>\\n\\n```CSS\\n<style scoped>\\n.demo {\\n    --h: 120px;\\n    --color-yellow: #F2F209;\\n\\n    background-color: #AFCCD3;\\n\\n    background: linear-gradient(#010123, #4baac7);\\n\\n    position: relative;\\n    height: 500px;\\n    overflow: hidden;\\n\\n    border-width: 2px 2px 2px 15px;\\n    border-style: solid;\\n    border-color: var(--color-yellow);\\n    \\n}\\n\\n.demo:before {\\n    content: '[ Delamain cabs rental DEMO ]';\\n    background-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    padding: .5rem 1rem;\\n\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 300;\\n\\n    border-width: 0 6px 2px 0;\\n    border-style: solid;\\n    border-color: #7B186E;\\n}\\n\\ndiv[class^=demo-back-], div[class^=demo-city-] {\\n    position: absolute;\\n    left: 0;\\n    width: 100%;\\n    z-index: 2;\\n}\\n\\ndiv[class^=demo-back-]{\\n    border-top: 1px solid #364444;\\n}\\n\\ndiv[class^=demo-city-] {\\n    background-repeat: repeat-x;\\n    background-size: cover;\\n    background-position: 100% 0;\\n\\n    height: 300px;\\n    bottom: var(--h);\\n\\n    animation: 50s MoveCity infinite linear 1.5s;\\n}\\n\\ndiv.demo-back-1 {\\n    background-color: #060236;\\n    background: linear-gradient(#7B186E, #060236);\\n    height: var(--h);\\n    bottom: 0;\\n}\\n\\ndiv.demo-back-2 {\\n    background-color: #c515ae;\\n    border-width: 2px 0;\\n    border-style: solid;\\n    border-color: #69045c;\\n\\n    height: 20px;\\n    bottom: var(--h);\\n    z-index: 10;\\n}\\n\\ndiv.demo-city-1 {\\n    background-image: url(../assets/images/city-1.png);\\n}\\n\\n.demo-car {\\n    background-image: url(../assets/images/car.png);\\n    background-size: contain;\\n    background-repeat: no-repeat;\\n    background-position: 100% 0;\\n\\n    width: calc(508px * 0.5);\\n    height: calc(257px * 0.5);\\n    position: absolute;\\n    bottom: calc(var(--h) + 4px);\\n    z-index: 10;\\n\\n    transform: translateX(-100px);\\n    animation: MoveCar 50s infinite 1.5s linear;\\n}\\n\\n.demo.play div[class^=demo-city-], .demo.play .demo-car { animation-play-state: running; }\\n.demo.stop div[class^=demo-city-], .demo.stop .demo-car { animation-play-state: paused; }\\n\\n.demo.play .demo-car {\\n    background-image: url(../assets/images/car-ride.png);\\n}\\n\\n\\n.demo button {\\n    background-color: var(--color-yellow);\\n    border-color: var(--color-yellow);\\n    color: #000;\\n\\n    position: absolute;\\n    bottom: 30px;\\n    right: 30px;\\n    z-index: 1000;\\n}\\n\\n.demo-data {\\n    position: absolute;\\n    bottom: 30px;\\n    left: 30px;\\n    z-index: 1000;\\n\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    padding: .5rem;\\n    font-family: var(--font-family-code);\\n\\n    transition: 0.2s all ease;\\n}\\n\\n.demo-data-lines {\\n    max-width: 400px;\\n}\\n\\n.demo-data-line {\\n    display: grid;\\n    grid-template-columns: 100px auto;\\n    gap: .5rem;\\n    text-align: left;\\n}\\n\\n.demo-data-line div:first-child {\\n    text-transform: uppercase;\\n    letter-spacing: 1px;\\n    font-weight: 700;\\n}\\n\\n.demo-data-driver {\\n    margin-right: 1rem;\\n}\\n\\n.demo-data-driver img {\\n    display: block;\\n    max-width: 100px;\\n\\n    visibility: hidden;\\n    opacity: 0;\\n    animation: FadeInBlink .3s cubic-bezier(0.075, 0.82, 0.165, 1) 0.6s forwards;\\n}\\n\\n.demo-data-welcome {\\n    text-align: left;\\n    padding-top: .5rem;\\n}\\n\\n.demo-data-welcome span {\\n    visibility: hidden;\\n    opacity: 0;\\n\\n    animation-name: FadeIn;\\n    animation-timing-function: cubic-bezier(0.075, 0.82, 0.165, 1);\\n    animation-duration: 0.6s;\\n    animation-fill-mode: forwards;\\n}\\n\\n.demo-data-welcome span:nth-child(1) { animation-delay: 1.5s; }\\n.demo-data-welcome span:nth-child(2) { animation-delay: 2.5s; }\\n.demo-data-welcome span:nth-child(3) { animation-delay: 3.2s; }\\n\\n\\n@keyframes MoveCity\\n{\\n  100% {\\n    background-position: -1000px 0;\\n  }\\n}\\n\\n@keyframes MoveCar\\n{\\n    0% {\\n        transform: translateX(-100px);\\n    }\\n    100% {\\n        transform: translateX(960px);\\n    }\\n}\\n</style>\\n\\n```\\n\\n</details>\\n\\n**Result:**\\n\\n![Dapp Interface changing step 25](../images/build-dapp-interface/dapp-25.gif \\\"Dapp Interface changing step 25\\\")\\n\\n## Conclusion\\n\\nCongratulations! Now you have redesigned the dapp and clues how to start building your application's interface.\\n\\n### Checkout links\\n\\n- [Full code of this lesson](https://github.com/positivecrash/wscool21-ui-dapp)\\n- [Discuss in Discord](https://discord.gg/5UWNGNaAUf)\\n- [View the Robonomics Winter School 2021 schedule and summary](https://robonomics.network/blog/winter-robonomics-school/)\\n- [Github of contributor](https://github.com/positivecrash)\\n\\n### Practice\\n\\nIf you have some extra time or want to practice your skills, there are some ideas for improvements that you could make to this demo:\\n\\n- Adapt UI for narrow screens, make the dapp mobile-friendly\\n- Add the 'day/night' mode, by editing the **_variables.scss** file and the template file of the dapp\\n- Add 'Copy to clipboard' buttons for addresses\\n- Make delicate popus to inform users about changes (e.g. you can popup a message that units are received after clicking the 'Faucet' button, or you can move in the popup an error that we had in the 'Launch' section).\\n\\nPlease, fill free to ask questions and share your results in [Discord](https://discord.gg/5UWNGNaAUf), mark me in your message `@positivecrash`\\n\\n\\n\\n\\n\\n\\n\"}},{\"node\":{\"id\":\"c1b5b8acb186e3cbcaf0a6c6d0de0188\",\"title\":\"Lesson 6.1, Build IoT Dapps For End Users\",\"path\":\"/docs/en/wschool2021-build-dapp-for-end-users/\",\"content\":\"\\nHaving organized the connection of devices to the blockchain and set up their work, the next stage is the actual creation of a convenient and user-friendly application that performs the main functionality for the user, which would wrap the basic functions of Robonomics. For blockchain systems, the human-machine interface is provided by decentralized applications (dapps).\\n\\nIn this lesson, you will learn how to create a basic dapp for Robonomics Parachain, provide main functionality and connect the application to the parachain.\\n\\n## Getting ready\\n\\n### Robonomics node launch\\n\\nFor dApp development and testing, we will use a local Robonomics node. To do this, you need to download the compiled binary file v0.24 from https://github.com/airalab/robonomics/releases. I will be using Ubuntu, so I download the appropriate version.\\n\\nUnpack the archive\\n```sh\\nwget https://github.com/airalab/robonomics/releases/download/v0.24.0/robonomics-ubuntu-0.24.0-x86_64.tar.xz\\ntar -xvf robonomics-ubuntu-0.24.0-x86_64.tar.xz\\nchmod +x robonomics\\n```\\n\\nNow we can start the node in development mode. To do this, use the --dev flag\\n```sh\\n./robonomics --dev --tmp\\n```\\n\\n> Troubleshooting\\n```sh\\n./robonomics purge-chain --dev\\n```\\n\\n### Browser extension\\n\\nTo store keys in a browser, there is a `polkadot{.js} extension`. In dApp we will use it to sign transactions.\\n\\nThe extension is currently available for `Google chrome` and `Firefox` https://polkadot.js.org/extension/\\n\\nAfter installing the extension, create a new account.\\n![screen1](../images/build-iot-dapps/screen1.png)\\n\\n> The first step is completed.\\n\\n## DApp development\\n\\n### Step 1\\n\\n> We will write the dApp using the vue.js framework, although you can use whatever you like/can.\\n\\nLet's start developing the dApp by creating a startup application with vue.js And here you can do it in two ways.\\n\\nWay 1:\\n\\nUsing the `Vue cli` console utility.\\nTo do this, you need to install [it](https://cli.vuejs.org/guide/installation.html)\\nAlso we will need `yarn`. Install it from [here](https://yarnpkg.com)\\n\\nAfter installation, you can run the command in the terminal\\n\\n```sh\\nvue create mydapp\\n```\\n\\nAnswer a few questions of the setup wizard. We will be using version Vue 2, so we keep the default version `Default ([Vue 2] babel, eslint)`.\\n\\nWay 2:\\n\\nClone the prepared git repository with the example and switch to step 1\\n\\n```sh\\ngit clone https://github.com/airalab/example-robonomics-dapp.git mydapp\\ncd mydapp\\ngit checkout step-1\\n```\\n\\nAs a result, we will get a directory with the installed startup application, which can already be launched and opened in the browser.\\n\\n```sh\\nyarn\\nyarn serve\\n```\\n\\n### Step 2. Getting started with polkadot.js\\n\\n#### Installing dependencies\\n\\nTo connect the dApp to the Robonomics chain, there is the `@polkadot/api` library. And for interaction of dApp with an extension with keys, we have the `@polkadot/extension-dapp` library. We need to install them into our application.\\nMore details on using this library can be found in the documentation https://polkadot.js.org/docs/.\\n\\nWay 1:\\n\\n```sh\\nyarn add @polkadot/api @polkadot/extension-dapp\\n```\\n\\nYou also need to add the `vue.config.js` file to support `mjs` extension.\\n\\n`vue.config.js`\\n```js\\nmodule.exports = {\\n  publicPath: \\\"\\\",\\n  configureWebpack: {\\n    resolve: {\\n      extensions: [\\\"*\\\", \\\".mjs\\\", \\\".js\\\", \\\".vue\\\", \\\".json\\\", \\\".gql\\\", \\\".graphql\\\"]\\n    },\\n    module: {\\n      rules: [\\n        {\\n          test: /\\\\.mjs$/,\\n          include: /node_modules/,\\n          type: \\\"javascript/auto\\\"\\n        }\\n      ]\\n    }\\n  }\\n};\\n```\\n\\n#### Connecting to Robonomics\\n\\nFirst, let's create a configuration file with the parameters for connecting to the Robonomics node. In the demo repository, there is an example of this file `config.template.json`.\\n\\n`src/config.json`\\n```json\\n{\\n  \\\"endpoint\\\": \\\"ws://localhost:9944\\\",\\n  \\\"types\\\": {\\n    \\\"Record\\\": \\\"Vec<u8>\\\",\\n    \\\"Parameter\\\": \\\"Bool\\\",\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\"\\n  }\\n}\\n```\\n\\nIn this file, we indicate the node, which we are going to connect to, and custom types.\\n\\nNow we need to write a script to connect to our running node.\\n\\n`src/utils/api.js`\\n```js\\nimport { ApiPromise, WsProvider } from \\\"@polkadot/api\\\";\\nimport config from \\\"../config.json\\\";\\n\\nlet api;\\nexport async function initApi() {\\n  const provider = new WsProvider(config.endpoint);\\n  api = await ApiPromise.create({\\n    provider,\\n    types: config.types\\n  });\\n  return api;\\n}\\n\\nexport function getApi() {\\n  return api;\\n}\\n```\\n\\nSo that we can sign transactions with the key from the extension, let’s add two functions for connecting to the extension and the function for initializing the account.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport {\\n  web3Accounts,\\n  web3Enable,\\n  web3FromAddress\\n} from \\\"@polkadot/extension-dapp\\\";\\n\\nasync function getExtension() {\\n  const extensions = await web3Enable(\\\"demo\\\");\\n  if (extensions.length === 0) throw new Error(\\\"no extension\\\");\\n  return extensions[0];\\n}\\n\\nexport async function initAccount(index = 0) {\\n  const timeout = new Promise(resolve => {\\n    setTimeout(resolve, 300);\\n  });\\n  await timeout;\\n  await getExtension();\\n  const accounts = await web3Accounts();\\n  if (accounts.length > 0) {\\n    const injector = await web3FromAddress(accounts[index].address);\\n    api.setSigner(injector.signer);\\n    return accounts[index].address;\\n  }\\n  throw new Error(\\\"no accounts\\\");\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nOur account will have a zero balance, while we need a little funds. So we need to create another faucet function. As we launched Robonomics with the `--dev` flag, we have `Alice` account with a large balance, so we will request funds from there.\\n\\n`src/utils/api.js`\\n```js\\n...OTHER_CODE...\\n\\nimport { Keyring } from \\\"@polkadot/keyring\\\";\\n\\nexport function getBalance(account, cb) {\\n  api.query.system.account(account, ({ data: { free: currentFree } }) => {\\n    cb(currentFree);\\n  });\\n}\\n\\nexport const keyring = new Keyring({ type: \\\"sr25519\\\" });\\n\\nexport async function faucet(address) {\\n  keyring.setSS58Format(api.registry.chainSS58);\\n  const account = keyring.addFromUri(\\\"//Alice\\\");\\n  const tx = api.tx.balances.transfer(address, 1000000000000000);\\n  await tx.signAndSend(account);\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nThe full version of script https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/api.js\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then in order to complete these steps, it will be enough to switch to step 2 and install the rest of the dependencies.\\n\\n```sh\\ngit checkout step-2\\ncp src/config.template.json src/config.json\\nyarn\\nyarn serve\\n```\\n\\n### Step 3. Vue connecting component\\n\\n#### Connecting\\n\\nWe have already written a script for connecting. Now we can use it on our interface. It is enough to call the written `initApi` function in  the root component `App.vue`. And while the user is waiting for a connection, we will show him a small loader, for now in the form of an ellipsis.\\n\\nWay 1:\\n\\nComponent template and base styles.\\n\\n`src/App.vue`\\n```js\\n<template>\\n  <div id=\\\"app\\\">\\n    <h1>Robonomics dApp</h1>\\n    <div v-if=\\\"load\\\">...</div>\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api\\\">\\n        connected\\n      </template>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style>\\n#app {\\n  font-family: Avenir, Helvetica, Arial, sans-serif;\\n  -webkit-font-smoothing: antialiased;\\n  -moz-osx-font-smoothing: grayscale;\\n  text-align: center;\\n  color: #2c3e50;\\n  margin-top: 60px;\\n}\\nbutton {\\n  font-size: 14px;\\n  padding: 5px 12px;\\n}\\nbutton:hover {\\n  cursor: pointer;\\n}\\ninput {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nselect {\\n  font-size: 14px;\\n  padding: 5px;\\n}\\nbutton:focus,\\ninput:focus {\\n  outline: none;\\n}\\n.error {\\n  color: rgb(151, 31, 31);\\n  font-weight: bold;\\n  text-align: center;\\n  margin: 10px 0;\\n}\\n</style>\\n```\\n\\nThere is the component code where the  `initApi` function will be called\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi } from \\\"./utils/api\\\";\\n\\nexport default {\\n  name: \\\"App\\\",\\n  data() {\\n    return {\\n      load: false,\\n      api: null,\\n      error: null\\n    };\\n  },\\n  created() {\\n    this.init();\\n  },\\n  methods: {\\n    async init() {\\n      try {\\n        this.load = true;\\n        this.api = await initApi();\\n        this.load = false;\\n      } catch (error) {\\n        this.error = error.message;\\n        this.load = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\n#### Account with balance\\n\\nNow we can use our account, top up its balance and show it on the interface.\\n\\nLet’s add the appropriate markup to the template\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n  ...OTHER_CODE...\\n\\n    <template v-else>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <template v-else-if=\\\"api && account\\\">\\n        <p>\\n          Account: <b>{{ account }}</b> {{ balance }} |\\n          <button @click=\\\"faucet\\\">\\n            faucet\\n          </button>\\n        </p>\\n      </template>\\n    </template>\\n\\n  ...OTHER_CODE...\\n\\n</template>\\n```\\n\\nLet’s add new fields for account address and balance\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\ndata() {\\n  return {\\n\\n    ...OTHER_CODE...\\n\\n    account: null,\\n    balance: 0,\\n\\n    ...OTHER_CODE...\\n\\n  };\\n}\\n\\n...OTHER_CODE...\\n```\\n\\nWe need to add the account initialization to the `init` function and get its balance\\n\\n`src/App.vue`\\n```js\\n<script>\\nimport { initApi, initAccount, getBalance, faucet } from \\\"./utils/api\\\";\\nimport { formatBalance } from \\\"@polkadot/util\\\";\\n\\n...OTHER_CODE...\\n\\nasync init() {\\n\\n  ...OTHER_CODE...\\n\\n  this.api = await initApi();\\n  this.account = await initAccount();\\n  getBalance(this.account, balance => {\\n    this.balance = formatBalance(balance);\\n  });\\n\\n  ...OTHER_CODE...\\n\\n}\\n\\n...OTHER_CODE...\\n</script>\\n```\\n\\nIt remains to add the function of replenishing the balance, when clicking on the button\\n\\n`src/App.vue`\\n```js\\n\\n...OTHER_CODE...\\n\\n  methods: {\\n    faucet() {\\n      faucet(this.account);\\n    },\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/step-3/src/App.vue\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 3.\\n\\n```sh\\ngit checkout step-3\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen2](../images/build-iot-dapps/screen2.png)\\n\\n### Step 4. Datalog\\n\\nTo save and read any data in the chain, we use the `datalog` module.\\n\\nFor an example of how to use this module, let's make a `Datalog.vue` component.\\n\\nWay 1:\\n\\nIn the markup, we will have a button for reading data `read` with a block, where we will display a list in the form of a date and the data itself. And there will be a form with a text input, into which you can enter any data in the form of a string, and a `write` button.\\n\\n`src/components/Datalog.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Datalog</h2>\\n    <button @click=\\\"read\\\">read</button> |\\n    <input v-model=\\\"data\\\" :disabled=\\\"isWrite\\\" />\\n    <button @click=\\\"write\\\" :disabled=\\\"isWrite\\\">write</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log\\\" class=\\\"log\\\">\\n      <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        date: <b>{{ item[0] | dateFormat }}</b>\\n        <br />\\n        data: <b>{{ item[1] | dataFormat }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nComponent code. Here the main point in sending a transaction is to call the function, into which we transfer data and which we sign with our account, via api `this.api.tx.datalog.record(stringToHex(this.data)).signAsync(this.account);`\\n\\n`src/components/Datalog.vue`\\n```js\\n<script>\\nimport { stringToHex, u8aToString } from \\\"@polkadot/util\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      data: \\\"data string\\\",\\n      log: null,\\n      isWrite: false,\\n      error: \\\"\\\"\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return u8aToString(v);\\n    }\\n  },\\n  methods: {\\n    async read() {\\n      this.log = (await this.api.query.datalog.datalog(this.account)).toArray();\\n    },\\n    async write() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.datalog\\n          .record(stringToHex(this.data))\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.read();\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Datalog.vue\\n\\nTo switch between components, added to `App.vue` the output of our component\\n\\n`src/App.vue`\\n```js\\n...OTHER_CODE...\\n\\n<template v-else-if=\\\"api && account\\\">\\n  <p>\\n    Account: <b>{{ account }}</b> {{ balance }} |\\n    <button @click=\\\"faucet\\\">faucet</button>\\n  </p>\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\n\\n...OTHER_CODE...\\n\\nexport default {\\n  name: \\\"App\\\",\\n  components: {\\n    Datalog\\n  },\\n  data() {\\n    return {\\n      tab: \\\"datalog\\\"\\n\\n...OTHER_CODE...\\n</script>\\n\\n<style>\\n...OTHER_CODE...\\n\\n.tabs button {\\n  font-size: 14px;\\n  padding: 10px 20px;\\n  font-weight: bold;\\n  background: #ececec;\\n  border: 1px solid #aaa;\\n}\\n.tabs button:hover {\\n  background: #bfbfbf;\\n}\\n.tabs button:last-child {\\n  border-left: none;\\n}\\n.tabs button.active {\\n  background: #ced5e2;\\n}\\n</style>\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 4.\\n\\n```sh\\ngit checkout step-4\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen3](../images/build-iot-dapps/screen3.png)\\n\\n### Step 5. Launch\\n\\nThis function is used to start and stop the robot. To demonstrate how to use this module, let's write the `Launch.vue` component.\\n\\nWay 1:\\n\\nIn the component template, we will have a form where you can specify the address of the robot, the ON/OFF clicker and the button for sending.\\n\\n`src/components/Launch.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Launch</h2>\\n    <input v-model=\\\"robot\\\" :disabled=\\\"isWrite\\\" placeholder=\\\"Robot address\\\" />\\n    <select v-model=\\\"parameter\\\" :disabled=\\\"isWrite\\\">\\n      <option value=\\\"ON\\\">ON</option>\\n      <option value=\\\"OFF\\\">OFF</option>\\n    </select>\\n    <button @click=\\\"launch\\\" :disabled=\\\"isWrite\\\">launch</button>\\n    <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n    <div v-if=\\\"log.length > 0\\\" class=\\\"log\\\">\\n      <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n        sender: <b>{{ item.sender }}</b>\\n        <br />\\n        robot: <b>{{ item.robot }}</b>\\n        <br />\\n        parameter: <b>{{ item.parameter ? \\\"ON\\\" : \\\"OFF\\\" }}</b>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n}\\n.log .row {\\n  margin: 10px;\\n}\\n</style>\\n```\\n\\nThe code looks like the `Datalog.vue` component. The difference is just in reading. The robot will receive the command through events.\\n\\n`src/components/Launch.vue`\\n```js\\n<script>\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      robot: this.account,\\n      parameter: \\\"ON\\\",\\n      log: [],\\n      isWrite: false,\\n      error: \\\"\\\",\\n      unsubscribe: null\\n    };\\n  },\\n  async created() {\\n    this.unsubscribe = await this.api.query.system.events(events => {\\n      events.forEach(record => {\\n        const { event } = record;\\n        if (event.section === \\\"launch\\\" && event.method === \\\"NewLaunch\\\") {\\n          const sender = event.data[0].toString();\\n          const robot = event.data[1].toString();\\n          const parameter = event.data[2].toHuman();\\n          this.log.push({\\n            sender,\\n            robot,\\n            parameter\\n          });\\n        }\\n      });\\n    });\\n  },\\n  destroyed() {\\n    if (this.unsubscribe) {\\n      this.unsubscribe();\\n    }\\n  },\\n  methods: {\\n    async launch() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot, this.parameter === \\\"ON\\\")\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Launch.vue\\n\\nFor display, add a new component to `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 5.\\n\\n```sh\\ngit checkout step-5\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen4](../images/build-iot-dapps/screen4.png)\\n\\n### Step 6. Demo\\n\\nIn this demo, we will have a car that can be started and stopped through the dApp. The car collects a log during the trip, and after stopping, saves it to the chain. Here we will use both modules, which we tried separately, in conjunction.\\n\\nTo emulate the behavior of a robot (car), we will write a Robot class. We will use the `Alice` key as an account for this robot. The `Robot` class will watch for `NewLaunch` events to turn itself on and off. After turning on, it starts collecting data into the log, in terms of data it will be just a timestamp. And after shutdown, it saves this log to the `datalog` module.\\n\\nWay 1:\\n\\nCreate file `src/utils/robot.js`. The full code of the file https://github.com/airalab/example-robonomics-dapp/blob/master/src/utils/robot.js\\n\\nFor visualization, we will create a `Demo.vue` component, where we will have a start button, car animation and log output.\\n\\n`src/components/Demo.vue`\\n```js\\n<template>\\n  <div>\\n    <h2>Demo</h2>\\n    <template v-if=\\\"robot\\\">\\n      <h3>Robot: {{ robot.address }}</h3>\\n      <p v-if=\\\"robot.state\\\">Driver: {{ robot.driver }}</p>\\n      <button @click=\\\"run\\\" :disabled=\\\"isWrite\\\">\\n        <template v-if=\\\"!robot.state\\\">run</template>\\n        <template v-else>stop</template>\\n      </button>\\n      <div class=\\\"road\\\">\\n        <div\\n          class=\\\"robot\\\"\\n          :class=\\\"[robot.state ? 'robot-play' : 'robot-stop']\\\"\\n        ></div>\\n      </div>\\n      <div v-if=\\\"error\\\" class=\\\"error\\\">{{ error }}</div>\\n      <div v-if=\\\"log\\\" class=\\\"log\\\">\\n        <p v-if=\\\"log.length === 0\\\" class=\\\"error\\\">Not found</p>\\n        <div v-for=\\\"(item, k) in log\\\" :key=\\\"k\\\" class=\\\"row\\\">\\n          <b>{{ item[0] | dateFormat }}</b>\\n          <pre>{{ item[1] | dataFormat }}</pre>\\n        </div>\\n      </div>\\n    </template>\\n  </div>\\n</template>\\n\\n...OTHER_CODE...\\n\\n<style scoped>\\n.log {\\n  border: 1px solid #eee;\\n  text-align: left;\\n  width: 800px;\\n  margin: 20px auto;\\n  height: 500px;\\n  overflow-y: auto;\\n}\\n.log .row {\\n  margin: 10px;\\n  border-bottom: 1px solid #eee;\\n}\\n.road {\\n  width: 1000px;\\n  margin: 20px auto;\\n  background-color: #eee;\\n  padding: 20px 0;\\n  border: 5px solid #a5a5a5;\\n  border-left: 0;\\n  border-right: 0;\\n  position: relative;\\n}\\n.road::before {\\n  content: \\\" \\\";\\n  width: 1000px;\\n  border-top: 5px dashed #a5a5a5;\\n  position: absolute;\\n  top: 50%;\\n  left: 0;\\n}\\n@keyframes move {\\n  from {\\n    transform: translateX(0);\\n  }\\n  to {\\n    transform: translateX(100%);\\n  }\\n}\\n.robot {\\n  height: 100px;\\n  width: 100px;\\n  color: #fff;\\n  font-weight: bold;\\n  font-style: 14px;\\n  animation: move 30s linear infinite;\\n  border-radius: 0 10px 10px 0;\\n  background: url(\\\"../images/build-iot-dapps/car.png\\\") no-repeat 0 0;\\n  background-size: cover;\\n}\\n.robot-play {\\n  animation-play-state: running;\\n}\\n.robot-stop {\\n  animation-play-state: paused;\\n}\\n</style>\\n```\\n\\nComponent code. Here we need to create an instance of the `Robot` class and a launch/stop function.\\n\\n`src/components/Demo.vue`\\n```js\\n...OTHER_CODE...\\n\\n<script>\\nimport { u8aToString } from \\\"@polkadot/util\\\";\\nimport Robot from \\\"../utils/robot\\\";\\n\\nexport default {\\n  props: [\\\"api\\\", \\\"account\\\"],\\n  data() {\\n    return {\\n      isWrite: false,\\n      error: \\\"\\\",\\n      robot: null,\\n      log: []\\n    };\\n  },\\n  filters: {\\n    dateFormat: function(v) {\\n      return new Date(Number(v)).toLocaleString();\\n    },\\n    dataFormat: function(v) {\\n      return JSON.parse(u8aToString(v));\\n    }\\n  },\\n  async created() {\\n    this.robot = new Robot(\\\"//Alice\\\", this.api);\\n    await this.robot.subscribeLog(r => {\\n      this.log = r.reverse().map(item => {\\n        return [item[0], item[1]];\\n      });\\n    });\\n  },\\n  destroyed() {\\n    this.robot.destroy();\\n  },\\n  methods: {\\n    async run() {\\n      try {\\n        this.error = \\\"\\\";\\n        this.isWrite = true;\\n        const tx = await this.api.tx.launch\\n          .launch(this.robot.account.address, !this.robot.state)\\n          .signAsync(this.account);\\n        await tx.send(result => {\\n          if (result.status.isInBlock) {\\n            this.isWrite = false;\\n          }\\n        });\\n      } catch (error) {\\n        this.error = error.message;\\n        this.isWrite = false;\\n      }\\n    }\\n  }\\n};\\n</script>\\n\\n...OTHER_CODE...\\n```\\n\\nhttps://github.com/airalab/example-robonomics-dapp/blob/master/src/components/Demo.vue\\n\\n    Let's add another picture of our car to `src/images/build-iot-dapps/car.png` and to `src/assets/car.png`. Example https://github.com/airalab/example-robonomics-dapp/blob/master/src/assets/car.png\\n\\nFor display, add a new component to `App.vue`\\n\\n`src/App.vue`\\n```js\\n<template>\\n\\n...OTHER_CODE...\\n\\n  <div>\\n    <div class=\\\"tabs\\\">\\n      <button\\n        @click=\\\"tab = 'datalog'\\\"\\n        :class=\\\"{ active: tab === 'datalog' }\\\"\\n      >\\n        datalog\\n      </button>\\n      <button\\n        @click=\\\"tab = 'launch'\\\"\\n        :class=\\\"{ active: tab === 'launch' }\\\"\\n      >\\n        launch\\n      </button>\\n      <button @click=\\\"tab = 'demo'\\\" :class=\\\"{ active: tab === 'demo' }\\\">\\n        demo\\n      </button>\\n    </div>\\n    <Datalog v-if=\\\"tab === 'datalog'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Launch v-if=\\\"tab === 'launch'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n    <Demo v-if=\\\"tab === 'demo'\\\" :api=\\\"api\\\" :account=\\\"account\\\" />\\n  </div>\\n\\n...OTHER_CODE...\\n\\n</template>\\n\\n...OTHER_CODE...\\n\\n<script>\\nimport Datalog from \\\"./components/Datalog\\\";\\nimport Launch from \\\"./components/Launch\\\";\\nimport Demo from \\\"./components/Demo\\\";\\n\\n...OTHER_CODE...\\n\\ncomponents: {\\n  Datalog,\\n  Launch,\\n  Demo\\n},\\n\\n...OTHER_CODE...\\n```\\n\\nRun app\\n\\n```sh\\nyarn serve\\n```\\n\\nWay 2:\\n\\nIf you start the application with cloning the repository, then to complete these steps, you will just need to switch to step 6.\\n\\n```sh\\ngit checkout step-6\\nyarn serve\\n```\\n\\nAs a result we will get this picture in the browser\\n\\n![screen5](../images/build-iot-dapps/screen5.png)\\n\\nThis concludes our lesson.\\n\\nThanks!\\n\"}},{\"node\":{\"id\":\"b0c4d07f0660d45ee44cab8739b78129\",\"title\":\"Connect Vacuum Cleaner\",\"path\":\"/docs/en/vacuum-connect/\",\"content\":\"\\n## Connect to Home Assistant\\n\\nYou need your vacuum to be connected to Mi Home app. If you haven't done this yet press `+` button on the top right corner, find your vacuum (it must be in connecting mode via a long press of the power button) and follow instructions in the app. For more details look at the user manual of your vacuum.\\n\\nOpen Home Assistant web page with this address:\\n```\\nhttp://<raspberry_address>:8123\\n```\\n\\nGo to `Integrations` tab, press `Add integration` and choose `Xiaomi Miio`:\\n\\n![integration](../images/home-assistant/integration.png)\\n\\nThen fill your username (or phone) and password from Mi Home account and choose your country server:\\n\\n![auth](../images/home-assistant/auth.png)\\n\\nPress `Submit` and choose your Vacuum (Robot vacuum in this example):\\n\\n![vacuum](../images/home-assistant/vacuum_int.png)\\n\\nAfter that you can connect your device to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\\n\"}},{\"node\":{\"id\":\"fb7c7e30bde083a2cddff124a71b03ab\",\"title\":\"Troubleshooting\",\"path\":\"/docs/en/troubleshooting/\",\"content\":\"\\n## Couldn't create HRMP channel\\n\\nIt's not possible to create HRMP channel.\\n#### Solution\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n\\\"Address\\\": \\\"MultiAddress\\\",\\n\\\"LookupSource\\\": \\\"MultiAddress\\\",\\n\\\"AccountInfo\\\": \\\"AccountInfoWithRefCount\\\"\\n}\\n```\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n## Couldn't send XCM call with datalogXcm\\n If you try to send message between parachains and get error like this:\\n\\n![error_4lesson][im1]\\n\\n#### Solution\\n\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\n![XCM][im2]\\n\\nSave changes and then reload the page with `ctrl+F5` buttons.\\n\\n## Couldn't send tokens between accounts\\n\\nAfter submitting get error:\\n\\n![transfer][im3]\\n\\n#### Solution\\n\\nGo to **Settings -> Developer** and put next lines:\\n```\\n{\\n    \\\"Address\\\": \\\"AccountId\\\",\\n    \\\"LookupSource\\\": \\\"AccountId\\\",\\n    \\\"AccountInfo\\\": \\\"AccountInfoWithDualRefCount\\\"\\n}\\n```\\n\\n\\n\\n[im1]: <../images/troubleshooting/lesson4_error.jpg>\\n[im2]: <../images/troubleshooting/XCM.jpg>\\n[im3]: <../images/troubleshooting/transfer.jpg>\\n\"}},{\"node\":{\"id\":\"f5c94a3b79e2681c5a9b28f59ae56ea8\",\"title\":\"How to participate in the Wiki translation\",\"path\":\"/docs/en/translate-wiki/\",\"content\":\"\\nEveryone can contribute to Robonomics. If you want to contribute to the translation of the documentation, you are on the right track: this article will tell you how to do it.\\n\\n## Editing an article\\n\\nIf support for your language has already been added to the site, follow these steps:\\n\\n1. Click the \\\"Edit this page\\\" button on the article you would like to translate. Each article is duplicated in a supported language, even if it has not yet been translated from English.\\n2. Edit by sticking to the existing markup. You can read the article [How to edit WIKI](/docs/en/edit-wiki)\\n3. Submit [PR](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) with the changes you have made.\\n\\n## Adding a new language\\n\\nIf the language you would like to translate the article into has not yet been added, request it from the Robonomics root team by, [creating Issue](https://docs.github.com/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request) on GitHub.\\n\\nWhen we add support for the requested language to the site, we will close the Issue, commenting on it if necessary. You will be notified accordingly. This means you can translate pages (they will already be duplicated in English in a folder like `/docs/locale`)\\n\\n## Notes\\n* If you see a way to improve an existing translation of an article, you can also use the PR or Issue on GitHub to request changes\\n* If you make a significant contribution to the translation, you can participate in the rewards program\\n\"}},{\"node\":{\"id\":\"e28f1d5d3c257bc30236173316944688\",\"title\":\"How the technical committee is fast-tracking the democracy proposals\",\"path\":\"/docs/en/technical-committee-fast-track/\",\"content\":\"\\nNote: The screenshots contained in this article were taken using v1.9.0 of Robonomics node implementation, launched in **dev** mode.\\n\\nThe Robonomics Technical Committee can use the **fast-track** function to speed up the proposals enacting in the Democracy module.\\n\\nIf you want to learn more about how Polkadot ecosystem Governance works, then we strongly recommend reading [this article](https://polkadot.network/blog/polkadot-governance/) on the Polkadot blog.\\n\\nThere are six members who make up the Technical Committee for the Robonomics parachain. For our example, let's create the same setup in our dev mode environment:\\n![Techcomm membership](../images/technical-committee-fast-track/techcomm_membership.png)\\n\\nBriefly, the process of fast-tracking a proposal involves a few steps:\\n1. Creating the proposal preimage\\n2. Creating the proposal using the created preimage hash\\n3. Technical committee votes on the created proposal\\n4. Initiating proposal fast-tracking \\n5. Technical committee votes regarding fast-tracking the proposal\\n6. Voting on enacted proposal in the Democracy pallet\\n\\nFor example, let's set the free balance for the account *4EnEc9ZD1jpA1H3HpVzr1v6SGGYGrue2k9Ny5KzFHhti5xQv* to 10 XRT\\n\\n## 1. Creating the proposal preimage\\nOpen the **Governance -> Democracy** page and click the **Submit preimage** button, and then input the required parameters:\\n![Creating preimage](../images/technical-committee-fast-track/creating_preimage.png)\\n\\nAfter all fields are filled, then we need to save generated preimage hash (*0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b* in this example). As we will need it in the next step.\\n\\nAfter saving the preimage hash we can click the **Submit preimage** button in this window and sign the transaction:\\n![Sign submitting preimage](../images/technical-committee-fast-track/sign_submitting_preimage.png)\\n\\n\\n## 2. Creating proposal using created preimage hash\\nOpen the **Governance -> Tech. comm.** page and go to the **Proposals** tab:\\n![Techcomm proposals interface](../images/technical-committee-fast-track/techcomm_proposals_interface.png)\\n\\nThen click **\\\"Submit proposal\\\"** button and create *democracy.externalProposeMajority(0x691405ef2f4ee0aee5bfb9d1ac3d98413e528eb211d2b914aed980370b57822b)* using your technical committee account and the preimage hash from earlier:\\n![Create techcomm proposal 1](../images/technical-committee-fast-track/create_techcomm_proposal_1.png)\\n\\nAfter signing transaction, the proposal will appear on this page:\\n![Created techcomm proposal 1](../images/technical-committee-fast-track/created_techcomm_proposal_1.png)\\n\\n## 3. Technical committee voting for created proposal\\nOn this step the majority of the technical committee members need to vote **Aye** in this poll. For example:\\n![First vote result](../images/technical-committee-fast-track/first_vote_result.png)\\n\\nThen we can decide to close this vote/poll using the **Close** button. After this action the proposal will appear on the **Democracy** page on the **external** table. You may wonder how can you see the **Fast track** button. This button appears and is active ONLY if we used the **democracy.externalProposeMajority** function:\\n![Created democracy proposal](../images/technical-committee-fast-track/created_democracy_proposal.png)\\n\\n\\n## 4. Initiating proposal fast-tracking\\nGo to the **Governance -> Democracy** page and click on the **Fast track** button. In this newly opened window set the required parameters and click **Fast track**.\\n![Fast track interface](../images/technical-committee-fast-track/fast_track_interface.png)\\n\\nAfter this, the fast-track proposal should now appear on the Technical Committee proposals page:\\n![Techcomm fast-track proposal](../images/technical-committee-fast-track/techcomm_fasttrack_proposal.png)\\n\\n\\n## 5. Technical committee voting for fast-track the proposal\\nNow the technical committee need to vote unanimously for fast-tracking the earlier created proposal. It means that all six members need to vote **Aye**:\\n![Fast-track vote result](../images/technical-committee-fast-track/fasttrack_vote_result.png)\\n\\nAfter this anyone can **Close** this voting, and the proposal will be enacted and moved from **external** table to active **referenda**:\\n![Democracy enacted proposal](../images/technical-committee-fast-track/democracy_enacted_proposal.png)\\n\\n\\n## 6. Voting on enacted proposal in Democracy\\nNow at least one account needs to vote **Aye** on the referenda:\\n![Voting for enacted proposal](../images/technical-committee-fast-track/voting_for_enacted_proposal.png)\\n\\nAs a result we'll get the active referenda with one positive vote on it:\\n![Positive voted referenda](../images/technical-committee-fast-track/positive_voted_referenda.png)\\n\\nAfter the voting period ends, this democracy proposal will be executed. In current example this will be happen in block #3351. Let's wait for this block and check it:\\n![Result](../images/technical-committee-fast-track/result.png)\\n\"}},{\"node\":{\"id\":\"abb223dbb0552eeea3e64db85485eac2\",\"title\":\"How to Send Launch with Subscription\",\"path\":\"/docs/en/subscription-launch/\",\"content\":\"\\nIf your address has an active subscription, then any devices set up with that account's secret can send extrinsics with no fee. \\nLet's try to send the `launch` command.\\n\\nGo to the `Developer/Extrinsics` page, then choose your account (our acount is named `MAIN` in the picture) and select `rws -> call(subscriptionId, call)`. Then in `subscriptionId` field write the subscription's owner address (this account is named `SUBSCRIPTION OWNER` in the picture) and in the next field choose `launch -> launch(robot, param)`. In the `robot` field write the address you want to send `launch` transaction to (this account is named`LIGHTBULB (EXTENTION)` in the picture) and choose the parameter `Yes` or `No`. Then submit transaction:\\n\\n![launch](../images/dev-node/launch.png)\\n\\n\\nNow go to the `Network/Explorer` page, and in the `Recent Events` area you will see two events that you created; `rws.NewCall` and `launch.NewLaunch`:\\n\\n![events](../images/dev-node/events.png)\\n\"}},{\"node\":{\"id\":\"0384b7507f47245623848a069d1923e1\",\"title\":\"Try It Out\",\"path\":\"/docs/en/spot-try-it-out/\",\"content\":\"\\nWith this tutorial you will be able to see in simulation what real Spot did.\\n\\n## Requirements\\n\\n* ROS melodic desktop (installation instructions [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n\\n## Install package\\n\\nCreate workspace and clone packages:\\n```bash\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/src\\ngit clone https://github.com/clearpathrobotics/spot_ros.git\\ngit clone https://github.com/ros/geometry2 --branch 0.6.5\\n```\\nOpen the `view_model.launch` file:\\n```bash\\nnano ~/catkin_ws/src/spot_ros/spot_viz/launch/view_model.launch\\n```\\n\\nAnd set `use_sim_time` parameter to `true`, file must look like this:\\n```xml\\n<launch>\\n  <param name=\\\"/use_sim_time\\\" value=\\\"true\\\"/>\\n  <include file=\\\"$(find spot_description)/launch/description.launch\\\"/>\\n\\n  <node name=\\\"joint_state_publisher_gui\\\" pkg=\\\"joint_state_publisher_gui\\\" type=\\\"joint_state_publisher_gui\\\" />\\n\\n  <node name=\\\"rviz\\\" pkg=\\\"rviz\\\" type=\\\"rviz\\\" args=\\\"-d $(find spot_viz)/rviz/model.rviz\\\" />\\n</launch>\\n```\\n\\nThen install dependencies:\\n```bash\\ncd ~/catkin_ws/\\nrosdep install --from-paths src --ignore-src -y\\ncatkin_make\\n```\\n\\n## Run\\n\\nGet example rosbag file:\\n```bash\\nwget -O spot_rosbag.bag https://gateway.ipfs.io/ipfs/QmTDrfMy7Zs7uDLN3KPBC1UYqXNMXBKEwX7ggVmJKAm7Ef\\n```\\n\\nRun rviz with the Spot model:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_model.launch\\n``` \\nThen in a new terminal:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch spot_viz view_robot.launch\\n``` \\n![spot_viz](../images/spot/spot.jpg)\\n\\n\\nPlay rosbag file and you will see the robot move:\\n```bash\\nrosbag play spot_rosbag.bag\\n```\\n![spot_viz](../images/spot/spot2.jpg)\"}},{\"node\":{\"id\":\"58cc404ac7baaff9de3ffd8dcb938f0e\",\"title\":\"Troubleshooting\",\"path\":\"/docs/en/spot-troubleshooting/\",\"content\":\"\\n### Admin socket already exists \\n\\nIf you can't run yggdrasil with this error:\\n```bash\\nAdmin socket /var/run/yggdrasil.sock already exists and is in use by another process\\n```\\nTry to remove file yggdrasil.sock and run it again:\\n```bash\\nsudo rm /var/run/yggdrasil.sock\\n```\\n\\n### Can't get lease\\n\\nIf you can't get lease with this error:\\n```python\\nGeneric exception during check-in:\\nNo lease for resource \\\"body\\\"\\n    (resuming check-in)\\n```\\nOr this error:\\n```python\\nGeneric exception during check-in:\\nbosdyn.api.RetainLeaseResponse (LeaseUseError): \\n    (resuming check-in)\\n```\\n\\nYou need to acquire lease (if you have already done it, try again):\\n```python\\nlease = lease_client.acquire()\\n```\\n\"}},{\"node\":{\"id\":\"c0555ab4f55f5565f3ad3dba98a1ff45\",\"title\":\"Lesson 5. Robot service. Camera calibration and \\\"Spot check\\\" procedure\",\"path\":\"/docs/en/spot-lesson5/\",\"content\":\"\\nIn this lesson you will learn what should you do if you just got the robot: the first run and network setup. Also you will learn how to run the calibration process that should be run monthly.\\n\\n## The challenge\\n\\nCreate and execute Python script implements behaviors described.\\n\\n1. Run \\\"spot check\\\" and save the result of the calibration in a `/home/student/result` directory as a text file.\\n2. Run camera calibration procedure.\\n\\n## Theory\\n\\n### First Run\\n\\nLook at [Startup Procedure](https://support.bostondynamics.com/s/article/Startup-Procedure) page in Documentation.\\n\\n### Networking\\n\\nSpot offers a variety of networking options to support a diverse set of applications and environments. Options include:\\n\\n* Spot as a connected peer. Physicall connection to Spot.\\n\\n* Spot as a WiFi access point. \\n\\n* Spot as a WiFi client. Spot can join an existing WiFi network, and applications can also join the same WiFi network to talk to Spot.\\n\\nFor more information look at [Networking page](https://dev.bostondynamics.com/docs/concepts/networking).\\n\\nSpot Core is connected to the Spot via payload port. Spot Core can be connected to the Internet with Wi-Fi dongle. The setup instructions you can find at [Spot Core Cockpit](https://dev.bostondynamics.com/docs/payload/spot_core_cockpit.html?highlight=spot%20check) page.\\n\\n### Calibration\\n\\nSpot Check is a full calibration of the robot. Also you can run the camera calibration \\n\\n* [run_spot_check](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L164) runs full spot check routine. The robot should be sitting on flat ground when this routine is started. This routine calibrates robot joints and checks camera health.\\n\\n* [run_camera_calibration](https://github.com/boston-dynamics/spot-sdk/blob/master/python/bosdyn-client/src/bosdyn/client/spot_check.py#L204). Run full camera calibration routine for robot. This function blocks until calibration has completed. This function should be called once the robot is powered on and standing with his back to the calibration stand at a distance of 1 meter. Calibation process takes about 20 minutes.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"43f7560b062bf3ca022b08600307bc21\",\"title\":\"Lesson 4. GraphNav service. Mapping and navigating on the map\",\"path\":\"/docs/en/spot-lesson4/\",\"content\":\"\\nIn the fourth lesson you will learn how to record and play autonomous missions with GraphNav service.\\n\\n## The challenge\\n\\nThis lesson you can solve the challenge without writing your own Python script.\\n\\n1. Record a map avioding obstacles. You can use WASD remote control tool. Save your mission in `/home/student/result`.\\n2. Move Spot through recorded waypoints. You can use GraphNav service command line tool.\\n\\n## Theory\\n\\nThe Spot SDK includes APIs, client libraries, and examples that support the development of autonomous navigation behaviors for the Spot robot. Collectively, this service is referred to as GraphNav. Maps are recorded and saved and later can be replayed with any robot in your fleet. During the map recording process, you can assign actions and API callbacks to waypoints along the map route.\\n\\nRead [GraphNav Tech Summary](https://dev.bostondynamics.com/docs/concepts/autonomy/graphnav_tech_summary) to learn how it works. [Initialisation](https://dev.bostondynamics.com/docs/concepts/autonomy/initialization) is also important part, it will be usefull in this lesson.\\n\\n> You can view recorded maps with [View Map](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_view_map) example. For that you need to copy the map to your computer:\\n> ```bash\\n> scp -r student@strelka.ygg.merklebot.com:<path_to_the_map_on_spot> <path_to_the_map_to_download>\\n> ```\\n> Also you need [install spot packages](https://github.com/boston-dynamics/spot-sdk/blob/master/docs/python/quickstart.md#install-spot-python-packages).\\n\\nStudy [recording and playing missions](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/graph_nav_command_line) examples in order to use it to record the map and playback the mission recorded.\\nUse [wasd](https://github.com/boston-dynamics/spot-sdk/tree/master/python/examples/wasd) example to move robot while recording the map.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\\nYou can run remote control tool from examples directory.\\n\\n```console\\ncd ~/spot-sdk/python/examples/wasd\\npython3 wasd.py --username <SPOT_AUTH_USERNAME> --password <SPOT_AUTH_PASSWORD> <SPOT_ADDRESS>\\n```\\n\\nGraphNav command line tool is located at `~/spot-sdk/python/examples/graph_nav_command_line`.\\n\"}},{\"node\":{\"id\":\"6c272e3f17738631f8842f1deafcb8f2\",\"title\":\"Lesson 3. Find and follow an object, navigate between them\",\"path\":\"/docs/en/spot-lesson3/\",\"content\":\"\\nIn the third lesson you will learn how to find World Objects and go to them.\\n\\n## The challenge\\n\\nYou start with Spot in the place with some fiducials (a mark on the object) around. Create and execute Python script detects at least two fiducials and moves Spot to each of them within 1 m.\\n\\n## Theory\\n\\nSpot has the World Object Service that provides a way to track and store objects detected in the world around Spot. A world object is considered a higher-level item in the scene that has some amount of semantic information associated with it. More information you can find in [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services#world-object) tab in Spot SDK documentation.\\n\\nUsing world object service you can find fiducials near the Spot. \\n\\n> Spot can find objects around faster if he stands.\\n\\nIn the task you will need find fiducials' coordinates and go to them. You already know how to move to the local coordinates from the [Lesson 2](/docs/en/spot-lesson2.md). The example of how to find a fiducial and it's coordinates is in [fiducial_follow example](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/examples/fiducial_follow/fiducial_follow.py).\\n\\nIn your script, firstly, you need to find fiducial object with World Object Service:\\n\\n```python\\nfiducial_objects = world_object_client.list_world_objects(\\n            object_type=[world_object_pb2.WORLD_OBJECT_APRILTAG]).world_objects\\n```\\n\\nThen get fiducial coordinates in a visual frame:\\n\\n```python\\nfiducial = fiducial_objects[0]\\nvision_tform_fiducial = get_a_tform_b(fiducial.transforms_snapshot, VISION_FRAME_NAME,fiducial.apriltag_properties.frame_name_fiducial.to_proto()\\n```\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"7913917deb4dce48f681d8d385a7d7d1\",\"title\":\"Lesson 2. Remote controlled and programmed motion\",\"path\":\"/docs/en/spot-lesson2/\",\"content\":\"\\nIn the second lesson you will learn how to use Spot Command services and walk with Spot.\\n\\n## The challenge\\n\\nYou have a list of points with their local coordinates in the `/home/student/lessons` directory. Spot should go through these points. The origin of the local coordinates is in the place where Spot was turned on. On each point Spot should make one of the motions from the following list, then go to the next point. \\n\\nThe list of moves:\\n* To turn around himself\\n* To lie down in pose to change battery\\n* To nod\\n* To change the stance of robot's legs\\n* To go sideways to the next point\\n\\nCreate and execute a Python script that implements behavior described.\\n\\n> You can find Spot local coordinates with:\\n> ```python\\n> get_vision_tform_body(robot_state_client.get_robot_state().kinematic_state.transforms_snapshot)\\n> ```\\n\\n## Theory\\n\\nYou can control Spot with `Robot Command Service`. Firstly you need to build a command to supply it to the command service.\\nSpot SDK has a `RobotCommandBuilder` class for it.\\nFull list of methods and its descriprions you can find [here](https://github.com/boston-dynamics/spot-sdk/blob/7ce5c5f31f4e1e45e9ff4be29fb097e258b75919/python/bosdyn-client/src/bosdyn/client/robot_command.py#L593). \\n\\nIn this lesson you may need to use:\\n\\n* Stand Command\\n\\n```python\\ndef stand_command(params=None, body_height=0.0, \\n                footprint_R_body=geometry.EulerZXY())\\n```\\n\\n* Go to point\\n\\n```python\\ndef synchro_se2_trajectory_point_command(goal_x, goal_y, goal_heading,      \\n                                    frame_name, params=None,\\n                                    body_height=0.0,\\n                                    locomotion_hint=spot_command_pb2.HINT_AUTO,\\n                                    build_on_command=None)\\n```\\n\\nCheck usage example [here](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/frame_trajectory_command/frame_trajectory_command.py).\\n\\n* Velocity Command\\n\\n```python\\ndef synchro_velocity_command(v_x, v_y, v_rot, params=None, body_height=0.0,\\n                            locomotion_hint=spot_command_pb2.HINT_AUTO, \\n                            frame_name=BODY_FRAME_NAME)\\n```\\n\\n* Stance Command\\n\\n```python\\ndef stance_command(se2_frame_name, pos_fl_rt_frame, pos_fr_rt_frame, \\n                        pos_hl_rt_frame,\\n                        pos_hr_rt_frame, accuracy=0.05, \\n                        params=None, body_height=0.0,\\n                        footprint_R_body=geometry.EulerZXY(), \\n                        build_on_command=None)\\n```\\n\\nThe example of use is [here](https://github.com/boston-dynamics/spot-sdk/blob/91ed30607264e795699995d6d7834ba0c8a94d36/python/examples/stance/stance_in_place.py)\\n\\n* Pose to change battery\\n\\n```python\\ndef battery_change_pose_command(dir_hint=1)\\n```\\n\\nExample of building and running velocity command:\\n\\n```python\\nfrom bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder\\nimport time\\n\\ncommand_client = robot.ensure_client(RobotCommandClient.default_service_name)\\ncmd = RobotCommandBuilder.velocity_command(0.5, 0, 0.5)\\ncommand_client.robot_command(cmd, end_time_secs=time.time() + 2)\\n```\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to Spot from a terminal or using your development environment remote execution function.\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Develop and demonstrate your solution to the challenge.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file.\\nSpot address is `192.168.50.3`.\\n\"}},{\"node\":{\"id\":\"6c3f6e0eca3e8abe8212e2c2b93e0d5d\",\"title\":\"Lesson 1. Emergency stop, initialization, body position control\",\"path\":\"/docs/en/spot-lesson1/\",\"content\":\"\\nWelcome to the first lesson!\\n\\nDuring this lesson you will learn how to authorize yourself as a user, get motor power control and send basic commands to Spot.\\n\\nWatch our introductory video if you haven't seen it already:\\n\\nhttps://youtu.be/qdk7BjWJprc\\n\\n## The challenge\\n\\nCreate a Python script controls robot body position. Run your script on Spot to let it execute a sequence of motions:\\n\\n1. Stand-up,\\n2. Trace your initials with it's face (one letter, at least 3 points),\\n3. Sit-down.\\n\\n## Theory\\n\\nRead [Understanding Spot Programming](https://dev.bostondynamics.com/docs/python/understanding_spot_programming) page in Spot SDK documentation.\\nYou need to understand what is `E-Stop` and how make initialization in your Python script in order to to let the robot execute commands.\\n\\nYou can find more detailed information for this lesson in [Base Services](https://dev.bostondynamics.com/docs/concepts/base_services), [Geometry and Frames](https://dev.bostondynamics.com/docs/concepts/geometry_and_frames), [Robot Services](https://dev.bostondynamics.com/docs/concepts/robot_services) and [E-Stop](https://dev.bostondynamics.com/docs/concepts/estop_service) sections of the Spot SDK documentation.\\n\\n## Practice\\n\\n> Ensure you have Yggdrasil Network software running and configured as described in the [Lesson 0](/docs/spot-lesson0). Otherwise you will not have connection to the robot.\\n> On macOS you may need to launch Yggdrasil Network in the terminal:\\n> ```bash\\n> sudo yggdrasil -useconffile /etc/yggdrasil.conf\\n> ```\\n\\n1. Connect to SpotCORE by SSH from the terminal,\\n\\n```console\\nssh student@strelka.ygg.merklebot.com\\n```\\n\\n2. Create a script can authenticate in Spot, acquire control (lease) and power on the robot.\\n\\nWe create [E-Stop endpoint](https://dev.bostondynamics.com/python/examples/estop/readme) for you, so you should not create it.\\nFor Spot authentication use username and password from `/home/student/credentials` file. Spot address is `192.168.50.3`.\\n\\n> In [Taking ownership of Spot (Leases)](https://dev.bostondynamics.com/docs/python/understanding_spot_programming#taking-ownership-of-spot-leases) section use `lease = lease_client.acquire()` before `lease_keep_alive = bosdyn.client.lease.LeaseKeepAlive(lease_client)`\\n\\n3. Try your script with stand-up and sit-down commands. Ensure robot moves as expected,\\n\\n> Make sure you run your script by Python 3 with `python3` command. Command `python` refers to an obsolete Python 2 interpreter.\\n\\n4. Add body position control to your script. Experiment with `bosdyn.geometry.EulerZXY` robot command argument builder in order to identify what yaw, roll and pitch parameters you need to set to solve the challenge. The range of Pitch, Yaw and Roll is from -0.5 to 0.5.\\n\"}},{\"node\":{\"id\":\"cf7bcac7631009c5e6ae579461ec3d16\",\"title\":\"Lesson 0. Configure and test connection to Spot\",\"path\":\"/docs/en/spot-lesson0/\",\"content\":\"\\nLet's start establishing connection to the robot.\\nOur goal is to get answers from Spot to our [ping](https://en.wikipedia.org/wiki/Ping_(networking_utility)) signals.\\nWe use Yggdrasil Network to expose Spot to the internet, that means we will need to configure Yggdrasil Network support on your computer first.\\n\\n## 1. Yggdrasil Installation \\n\\nYggdrasil is an early-stage implementation of a fully end-to-end encrypted IPv6 network. Before startitng the lessons you need to install it on your computer.\\n\\n### For Linux: \\nInstallation instructions [here](https://yggdrasil-network.github.io/installation-linux-deb.html).\\n\\n### For MacOS: \\nDownload .pkg file from [here](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4.0-macos-amd64.pkg).\\n\\nLocate the downloaded file in Finder. Right-click it and click Open. Step through the installer as usual.\\n\\n### For Windows:\\nDownload .msi file for [x64 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x64.msi) or for [x32 system](https://github.com/yggdrasil-network/yggdrasil-go/releases/download/v0.4.0/yggdrasil-0.4-x86.msi) and run it with double click.\\n\\n## 2. Open configuration file\\n\\nYou need to add a list of peers (public nodes) to configuration file so that you will be able to connect to Spot. \\n\\n### For MacOS and Linux:\\nFor that, edit the `yggdrasil.conf` file with this command in a terminal:\\n\\n```bash\\nsudo nano /etc/yggdrasil.conf\\n```\\n\\n### For Windows:\\nRun `updateconfig.bat` in `C:/Program Files/Yggdrasil`. \\n\\nThen in `C:/ProgramData/Yggdrasil` open `yggdrasil.conf` with any text editor.\\n\\n> `ProgramData` is a hidden folder, so you need to show hidden data.\\n\\n## 3. Write peers\\n\\nIn the file that you opened find line `Peers:` (it is at the beginning of the file) add 5-6 peers geografically near to you (write them inside the brackets). You can find list of available peers [here](https://github.com/yggdrasil-network/public-peers) or add peers from example below. Example in yggdrasil.conf:\\n\\n```bash\\n  Peers:\\n  [\\n    tcp://213.188.199.150:10010\\n    tcp://213.188.210.9:10010\\n    tcp://[2a09:8280:1::3:312]:10010\\n    tcp://[2a09:8280:1::a:2e2]:10010\\n    tcp://46.151.26.194:60575\\n    tcp://ygg-ru.cofob.ru:18000\\n    tcp://ygg.tomasgl.ru:61933\\n    tls://185.22.60.71:8443\\n    tcp://51.15.118.10:62486\\n    tls://ygg.loskiq.dev:17314\\n    tls://longseason.1200bps.xyz:13122\\n  ]\\n  ```\\nCheck if the peers online in [Puplic Peers](https://publicpeers.neilalexander.dev/).\\n\\n## 4. Save and close configuration file\\n\\n### For Linux and MacOS:\\n\\nPress `Ctrl+x`, then press `y` to save changes and press `Enter`.\\n\\n### For Windows:\\n\\nSave and close file.\\n\\n## 5. Restart service\\n\\n### For Linux:\\n\\nThen restart Yggdrasil using this command:\\n\\n```bash\\nsystemctl restart yggdrasil\\n```\\n### For macOS:\\n\\nUnload the service and run Yggdrasil with changed config file:\\n\\n```bash\\nsudo launchctl unload /Library/LaunchDaemons/yggdrasil.plist\\nsudo yggdrasil -useconffile /etc/yggdrasil.conf\\n```\\n> You will need to do that before every lesson.\\n\\n### For Windows:\\n\\nPress win + r and type `services.msc`, find Yggdrasil service, open it and restart (press Stop and Start).\\n\\n![win-service](../images/spot/spot-windows.jpg)\\n\\n## 6. Check Connection\\n\\nCheck if Yggdrasil works well.\\n\\nFor that try to ping Spot address:\\n```bash\\nping strelka.ygg.khassanov.xyz\\n```\\n> To open terminal in Windows press `Win+R`, type `cmd` and press `Enter`.\\n\\n> On MacOS use `ping6` instead of `ping`.\\n\\nIf you can't ping Spot or you had any errors during the Yggdrasil setup look in [Troubleshooting page](/docs/spot-troubleshooting). If you can't find the solution there, please email spot@robonomics.network.\\n\\n## 7. Create ssh key\\n\\nYou will connect to Spot via ssh, so you need to create ssh keys which you will use in booking lessons.\\n\\nRun following command in the terminal:\\n```bash\\nssh-keygen -t rsa\\n```\\n> SSH Client is available by default only in Windows 10, so if you use older versions you need to install it. For example you can use [PuTTY](https://www.putty.org/).\\n\\nRemember the path to your key (by default it is `/home/<user>/.ssh/id_rsa.pub` or `C:\\\\Users\\\\<user>\\\\.ssh\\\\id_rsa.pub`).\\n\"}},{\"node\":{\"id\":\"eb1b633902f7d1558010109404f662f3\",\"title\":\"Setup SLS Gateway\",\"path\":\"/docs/en/sls-setup/\",\"content\":\"\\nYou can use [SLS Gateway from Robonomics](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01) instead of Xiaomi/Aqara gateways. It works only in your local network and don't send any data to external servers, so you can control all data about your home.\\n\\n1. Ensure that the switches on the back of the gateway are properly positioned. Switches 5 (RX Zigbee to ESP) and 6 (TX Zigbee to ESP) must be in the ON position, the others must be off. \\n\\n2. Connect the type C power cable. The indicator light in the center should turn green.\\n\\n3. The first time it starts up, the gateway will begin distributing Wi-Fi with the SSID 'zgw****' to set up the SLS gateway connection. Connect to this network. Keep in mind that the signal may be quite weak, so it is best to keep the SLS Gateway closer to your computer. \\n\\n4. If the connection is successful, the web interface will open (or you can find it on 192.168.1.1 address). Configure the SLS Gateway to connect to your Wi-Fi by entering the user / pass. After that the gateway's Wi-Fi will shut down. \\n\\n5. Find the local IP of the SLS gateway to access the web interface. You can use the command 'arp -a' or 'nmap'. The resulting link should look like this: 'http://192.168.xxx.xxx'.\\n\\n6. Go to Setting/Hardware and make sure that the settings look like this. Correct the settings if necessary and reboot the gateway:\\n\\n![sls-hardware](../images/home-assistant/sls-hardware.jpg)\\n\\n7. Configure automatically adding devices to Home Assistant. Go to `Zigbee/Config` then tick `Home Assistant MQTT Discovery` and `Clear States`:\\n\\n![sls-hass](../images/home-assistant/sls-hass.png)\\n\\n8. Connect your devices by going to Zigbee/Join. Press the Enable Join button to connect and put your sensors in pairing mode. \\n\\nAfter that connect it to Home Assistant with the following [guide](/docs/sls-gateway-connect)\"}},{\"node\":{\"id\":\"e1593946a6cc3fcde76a311c78a7e62f\",\"title\":\"Connect SLS Gateway to Home Assistant\",\"path\":\"/docs/en/sls-gateway-connect/\",\"content\":\"\\n## MQTT Brocker\\n\\nFirst, you need to run MQTT brocker on your raspberry with Home Assistant. Connect to it under `ubuntu` login. Then install [Mosquitto Brocker](https://mosquitto.org/):\\n\\n```bash\\nsudo apt update -y && sudo apt install mosquitto mosquitto-clients -y\\n```\\nConfigure username (you can use any username you want) and password (you will be asked to enter the password after the command):\\n```bash\\nsudo mosquitto_passwd -c /etc/mosquitto/passwd <username>\\n```\\nThen edit configuration file:\\n```bash\\nsudo nano /etc/mosquitto/mosquitto.conf\\n```\\nAdd the following at the end of the file:\\n```\\nlistener 1883\\nallow_anonymous false\\npassword_file /etc/mosquitto/passwd\\n```\\n\\nThen restart the service:\\n\\n```bash\\nsudo systemctl restart mosquitto\\n```\\n\\nAnd check the brocker status:\\n```bash\\nsystemctl status mosquitto\\n```\\n\\n![mosquitto](../images/home-assistant/mosquitto.png)\\n\\n## MQTT Integration\\n\\nThen you need to add MQTT integration to Home Assistant. Open web interface then go to `Configuration/Integrations` page and press `Add Integration` button. Find MQTT:\\n\\n![mqtt](../images/home-assistant/mqtt.png)\\n\\nPress on it and set up your brocker with address (localhost), port (1883) and your username and password, then press `submit`:\\n\\n![mqtt1](../images/home-assistant/mqtt1.png)\\n\\nThen press on three dots on MQTT integration and choose `System Options`:\\n\\n![mqtt_options](../images/home-assistant/mqtt_conf.png)\\n\\nAnd check if automatically adding new devices is enabled:\\n\\n![mqtt_dev](../images/home-assistant/add_dev.png)\\n\\n## MQTT on SLS Gateway\\n\\nAlso you need to configure MQTT on SLS Gateway. On your SLS Gateway go to `Settings/Link` -> `MQTT Setup`:\\n\\n![sls-mqtt](../images/home-assistant/sls-mqtt.png)\\n\\nAnd add your brocker address (address of the raspberry with Home Assistant in local network) and port (1883). Also write the topic name (you can choose any). Don't forget to tick `Enable` and `Retain states`:\\n\\n![sls-mqtt1](../images/home-assistant/sls-mqtt1.png)\\n\\nSave changes. Now devices will be automatically shown in Home Assistant.\\n\\nAfter that you can connect your devices to Robonomics with this [instruction](/docs/add-smart-device-to-robonomics).\"}},{\"node\":{\"id\":\"0151ed1155f5d7f4577a5955788d9402\",\"title\":\"Introduction\",\"path\":\"/docs/en/sensors-network-introduction/\",\"content\":\"\\n## What is Sensors Robonomics Network?\\n\\nThe Sensors Robonomics Network is a civilian network of sensors to monitor air quality. Anyone can build their own sensor or use an off-the-shelf solution from the development team and set it up in their home. The sensors use open source software and component wiring diagrams. One of the main sensors used is the PM10 and PM2.5 fine particulate sensor.\\n\\n## What is PM10 and PM2.5?\\n\\nPM10 is a particle of a substance 10 microns or smaller, PM2.5 is a particle 2.5 microns in diameter or smaller. They are constantly floating in the air and do not settle due to their small size, for comparison, the thickness of a human hair is 100 microns. These particles can appear for a variety of reasons, including industrial processes involving the handling of bulk materials or the burning and processing of minerals. They are also emitted after forest fires and dust storms. In addition, they can come from conventional transport when burning fuel or from wear and tear on tires and pavement. Car tires are wiped out into fine crumbs and the wind blows them from the roads all over the city.\\n\\n## Why do we need to measure them?\\n\\nPM10 and PM2.5 are the most dangerous because their size allows them to penetrate the lungs, whereas larger particles tend to linger in the nose or throat. Larger PM10 particles irritate the airways, nose, throat, and eyes. Particles smaller than 2.5 microns can penetrate deep into the lungs and even enter the bloodstream. The effects of these particles on the human body can be devastating:\\n- poisoning by harmful substances entering the bloodstream\\n- allergic reactions\\n- bacterial and fungal infections\\n- cancer\\n- mucous membrane irritation\\n- exacerbation of respiratory symptoms\\n\\n## Why the Sensors Robonomics Network?\\n\\nIn Russia there are other public monitoring networks, such as [Breathe Moscow](https://breathe.moscow/), which are based on the German project [sensor.community](https://sensor.community/ru/). But they use the usual client-server architecture, which in this case is a drawback. Data from all sensors together with user requests go to one server, which cannot always handle such load. So there are situations when the map with data is not available at the most responsible moments. With Sensors Robonomics Network, sensors send data to several different servers, and any user can bring up the Sensors Connectivity server for their sensor and see it on the map. The map itself is not overloaded because it is a decentralized application (DApp) that works directly from your browser with the data that the servers send to the IPFS pub-sub channel.\\n\\n## Sources\\n\\nhttp://www.npi.gov.au/resource/particulate-matter-pm10-and-pm25\\n\\nhttps://habr.com/ru/company/tion/blog/396111/\"}},{\"node\":{\"id\":\"1fc1dc2dbf767f7998053575aa8cf958\",\"title\":\"Sensors Connectivity\",\"path\":\"/docs/en/sensors-connectivity-on-aira/\",\"content\":\"\\nThe Sensors Robonomics Network uses the sensors community module from Robonomics to receive and process data. This module allows any user to raise his own server to receive data from sensors and process it further. Now the developers have launched several such servers and any sensor can send data to them. Running several servers allows to avoid data loss in case of problems with one of them, because sensors from a non-working server will switch to a working one.\\n\\nSensors Connectivity schematic:\\n\\n```\\n    station1 \\\\                        / feeder1\\n    station2 -  sensors-connectivity  - feeder2\\n    station3 /                        \\\\ feeder3\\n```\\n\\nSensors Connectivity is a set of stations (station1, station2...), which receive various data, including data from sensors via http protocol. But also it can be sensors connected to the computer via USB or any other data source.\\n\\nData received from the stations are processed by Sensors Connectivity and passed to feeders (feeder1, feeder2...). Feeders send the processed data to the user. In our case the data is sent to the decentralized IPFS channel.\\n\\nMap [sensors.robonomics.network](https://sensors.robonomics.network/) is a decentralized application (DApp) running on your computer. It reads data from the IPFS channel and outputs them to the map. So there is no direct connection between the server collecting the data from the sensors and the map the user sees, the data transfer between them is done via IPFS pubsub, which reduces the load on the servers.\\n\\nIn addition, every once in a while, a file with data from the last time period is saved in IPFS, and the hash of that data is further written to the blockchain. Since IPFS is a content-addressable network, storing data in it guarantees that any change in the data will not go unnoticed, because the address of the desired file contains a hash of its content, which will change if any change in the data occurs. The blockchain is used to pass the hash on to the user, who can use it to retrieve the desired data from the IPFS (which is what happens when requesting to view the history on [sensors.robonomics.network](https://sensors.robonomics.network/)). Since the transaction made cannot be changed, we can be sure that it is the correct hash.\\n\\nThe source code for Sensors Connectivity is available at [link](https://github.com/airalab/sensors-connectivity). To see the data from your server on the map, you need to contact the development team at vm@multi-agent.io and send the ipfs id of your server. \\n\\n# Run your own Sensors Connectivity\\n\\n## Pre-requirements\\n\\nTo build a python package IPFS daemon should be installed. Assyming, you work with linux:\\n\\n```\\nwget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_linux-amd64.tar.gz\\ntar -xzf go-ipfs_v0.8.0_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh \\nipfs init\\n```\\nYou can get IPFS ID with the following command after running IPFS daemon (it is in the `ID` column):\\n\\n```console\\n$ ipfs id\\n{\\n\\t\\\"ID\\\": \\\"QmUZxw8jsRpSx5rWkTpJokPGKvWihTrt5rbRCFXzJ4eCAP\\\",\\n\\t\\\"PublicKey\\\": \\\"CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC/uMV3rLM/C+LOh2DGPo3chr+VM+vyYMKi...\\n    ...\\n```\\n\\n## Installation as PyPi package\\n\\n```\\npip3 install py-sr25519-bindings\\npip3 install sensors-connectivity\\n```\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config is set, you can run the service: (in another terminal)\\n\\n```\\nsensors_connectivity \\\"path/to/your/config/file\\\"\\n```\\n\\nYou will be able to see logs in your console and in `~/.logs`.\\n\\n## Build from source\\n### Requirements\\n\\nTo build a python package fron source [poetry](https://python-poetry.org/docs/#osx--linux--bashonwindows-install-instructions) should be also installed. Assyming, you work with linux:\\n\\n```\\ncurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -\\n```\\n\\n### Get a Package And Installing dependencies\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npoetry install\\n```\\n\\n### Documentation\\n\\nTo prepare a sensor for the work with the package follow instructions on [Robonomics Wiki](/docs/connect-sensor-to-robonomics/).\\n\\n### Configuration\\n\\n[Here](/docs/configuration-options-description/) you can find an article to set a proper configuration for your instance.\\n\\nMake a copy of `default.json` and fill it using description from the article.\\n\\nYou also can set a logging file. The default file for logs is `logging.py`, which uses `console` and `file` handler by default. Pay attention for the `file` handler. The template is stored in `connectivity/config/logging_template.py`. You can cpecify the path (`filename`), where your logs will be stored in (do not forget to create this directory if it doesn't exist). Default path for logs is `~/.logs`. You can figure any other handlers from the [library](https://docs.python.org/3.8/library/logging.html).\\n\\n### Running\\n\\nFirst, launch IPFS daemon:\\n\\n```\\nipfs daemon --enable-pubsub-experiment\\n```\\nAfter config and log files are setted, you can run the service: (in another terminal)\\n\\n```\\npoetry run sensors_connectivity \\\"path/to/your/config/file\\\"  \\n```\\n\\nIf your log file is setted with `console` handler, you will be able to see logs in your console.\\n\\n### Example of logs:\\n\\n```\\n2022-02-17 19:30:51,248 - INFO - Getting data from the stations...\\n2022-02-17 19:30:51,443 - INFO - airalab-http-v0.8.0: [[], [{MAC: c8e2650f254e, Uptime: 0:00:14.010502, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:30:51,443 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:07,517 - INFO - Frontier Datalog: Data sent to Robonomics datalog and included in block 0x04baf3d81c6d31ec6f3ca3e515b9a6920666ee17cbd66f57130eaa000bad2cd4\\n2022-02-17 19:31:07,519 - INFO - RobonomicsFeeder: {\\\"0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a\\\": {\\\"model\\\": 2, \\\"geo\\\": \\\"53.518475,49.397178000000004\\\", \\\"measurement\\\": {\\\"airtemp\\\": -8.0, \\\"windang\\\": 45.0, \\\"windspeed\\\": 0.13, \\\"windspeedmax\\\": 0.13, \\\"pm10\\\": \\\"\\\", \\\"pm25\\\": \\\"\\\", \\\"timestamp\\\": 1645113602.0}}}\\n2022-02-17 19:31:07,523 - INFO - Checking data base...\\n127.0.0.1 - - [17/Feb/2022 19:31:13] \\\"POST / HTTP/1.1\\\" 200 -\\n2022-02-17 19:31:21,248 - INFO - Getting data from the stations...\\n2022-02-17 19:31:21,429 - INFO - airalab-http-v0.8.0: [[{MAC: c8e2650f254e, Uptime: 0:00:43.818101, M: {Public: 133b761496539ab5d1140e94f644e2ef92c7ac32446dc782bfe1a768379a669a, geo: (1,200), measurements: {'pm10': 27.58, 'pm25': 15.02, 'temperature': 22.93, 'pressure': 758.0687068706872, 'humidity': 39.44, 'timestamp': 1645115473}}}], [{MAC: c8e2650f254e, Uptime: 0:00:43.996539, M: {Public: 0be87b58e87599a85dc79bf14731cc9ad547411e9b10c883e29f78fc2c67206a, geo: (53.518475,49.397178000000004), measurements: {'airtemp': -8.0, 'windang': 45.0, 'windspeed': 0.13, 'windspeedmax': 0.13, 'pm10': '', 'pm25': '', 'timestamp': 1645113602.0}}}]]\\n2022-02-17 19:31:21,444 - INFO - Sending result to the feeders...\\n2022-02-17 19:31:51,249 - INFO - Getting data from the stations...\\n```\\n\\n## Troubleshooting\\n\\n### Python.h: No such file or directory\\n\\nIf during running `poetry install` comand you get such error, you need to install the header files and static libraries for python dev. Use your package manager for installation. For example, for `apt` you need to run\\n```\\nsudo apt install python3-dev\\n```\\n> Note:\\npython3-dev does not cover all versions for python3. The service needs at least python3.8, for that you may need to specify the version `sudo apt install python3.8-dev`.\\n\\n[Here](https://stackoverflow.com/a/21530768) you can find examples for other package managers.\\n\\n### Python versions mismatch\\n\\nIf during running `poetry install` comand you get `SolverProblemError`, which says \\\"The current project's Python requirement (3.6.9) is not compatible with some of the required packages Python requirement:..\\\", even though you have older version of python (e.g. python3.8), you may need to specify the python version poetry is using:\\n\\n```\\npoetry env use python3.8\\n```\\n\\n\"}},{\"node\":{\"id\":\"cdc2788c8edc2811a0b228606e7bfa73\",\"title\":\"How to contribute\",\"path\":\"/docs/en/sensors-connectivity-contribution/\",\"content\":\"\\nIf you find any bugs or would like to propose an improvement, please, open a new issue in one of tre repositories, that you want to contribute.\\n\\n## Main Repositories\\n\\n- [sensors-connectivity](https://github.com/airalab/sensors-connectivity/issues) - Sensors Connectivity server\\n- [sensors-software](https://github.com/LoSk-p/sensors-software/issues) - firmware for the sensor\\n- [airrohr-firmware-flasher](https://github.com/LoSk-p/airrohr-firmware-flasher/issues) - application for microcontroller firmware\\n\"}},{\"node\":{\"id\":\"2d49e0624e276ebb84f44de715aec0bb\",\"title\":\"Securely connect cloud AI to the factory floor\",\"path\":\"/docs/en/securely-connect-cloud-ai-to-the-factory-floor/\",\"content\":\"\\nRobonomics technologies can already solve the challenges that Industry 4.0 faces and they are already applied to real-world scenarios in the industrial environment.\\n\\nA large number of AI companies are building solutions to optimize the processes on the factory floor, allowing plants to produce more with less cost. However, most plants are hesitant to connect their infrastructure to the cloud directly since this results in potential cybersecurity risks, which could lead to million-dollar losses and even the loss of human life.\\n\\n[MerkleBot](https://merklebot.com) has used [Robonomics Network](https://robonomics.network) to build a solution for industrial clients to connect their factory to the cloud-based AI in a secure way.\\n\\nThis article is written in the wake of an experiment we conducted with [Veracity Protocol](https://www.veracityprotocol.org/) that uses algorithms to create non-invasive protection of any physical item based on the photographs from a mobile device.\\n\\nThis use case shows the process of scanning the industrial parts using a robotic arm.\\n\\n[Demo video](https://youtu.be/8AL70LFVX5w)\\n\\n## Step-by-step process\\n\\n### DApp as user interface\\n\\n![](../images/google-play-store.gif)\\n\\nDApp acts as a user interface for the operator. It is used to request the launch of the robot to collect the photographs and its purpose is to allow secure communication between the factory environment and cloud-based AI.\\n\\n### Launching the robot\\n\\n![](../images/Veracity_Protocol_Transaction.gif)\\n\\nThe operator launches the robotic scan by signing the transaction in the DApp. This step guarantees that the process on the factory floor can only start based on the transaction in the public blockchain.\\n\\nThe robot receives a command from the blockchain through the Robonomics Network and begins the scan. Robonomics Network technologies allow us to close the gap between the business objective and robotics operation.\\n\\n### Data collection and sending to cloud-based AI\\n\\nIn the DApp the operator sees the confirmation and the robot begins to scan the items placed on the table, such as in this use case, or on the factory line directly if the need arises.\\n\\n![](../images/Veracity_Protocol_Launch.gif)\\n\\nWhen the robot collects the data, it stores it locally and makes it available to cloud-based AI through IPFS protocol. By encrypting the data and organizing the data exchange through a blockchain transaction as well, we can authorize access to cloud-based AI while making sure that the data remains secure and in place.\\n\\nThe security mechanism built into Robonomics based on the shared security of public blockchains allows gaining the level of security that is prohibitively expensive for most factories to organize on their own.\\n\\n### Digital passport creation\\n\\nWhen the cloud-based AI analyses the data, the log file and recommendations are recorded as a [Digital Passport](https://wiki.robonomics.network/docs/create-digital-identity-run-by-ethereum/) automatically. Every operation and scan can be traced back since the blockchain record has the hash to all these files through IPFS protocol.\\n\\n## Comments about the use case\\n\\nIn this use case, Universal Robot UR3 industrial arm was used. But thanks to Robonomics support for ROS, most major industrial manipulators can be used and connected to cloud-based AI securely, including KUKA, Fanuc, and Yaskawa.\\n\\nIf you are interested to learn more about the deployment and integration of cloud-based AI instruments securely please [reach out](mailto:v@merklebot.com)\\n\"}},{\"node\":{\"id\":\"448531373693dcd02c1165a6a94fad9d\",\"title\":\"How to Run Robonomics Dev Node\",\"path\":\"/docs/en/run-dev-node/\",\"content\":\"\\nFor testing your applications on Robonomics you may want to need to run it in the dev mode.\\n\\nhttps://youtu.be/04GsVkZ7aVg\\n\\n## Run\\n\\n1. First, you need a binary file, download the archive with it from the latest [release](https://github.com/airalab/robonomics/releases).\\n\\n2. Unpack it and change permissions:\\n\\n```bash\\ntar xf robonomics-1.7.0-x86_64-unknown-linux-gnu.tar.gz\\nchmod +x robonomics\\n```\\n\\n3. And run in the dev mode:\\n\\n```bash\\n./robonomics --dev\\n```\\nYou will see the following output:\\n\\n![robonomics](../images/dev-node/robonomics.png)\\n\\n## Get tokens\\n\\nNow you can connect to your local node through the [Polkadot Portal](https://polkadot.js.org/apps/#/explorer).\\n\\nChange the network to `Local Node` in the upper left corner and press `Switch`.\\n\\n![local_node](../images/dev-node/portal.png)\\n\\nThen go to `Accounts`:\\n\\n![accs](../images/dev-node/accs.png)\\n\\nYou can create a new account with the button `Add Account`.\\n\\n![add_acc](../images/dev-node/add_acc.png)\\n\\nDon't forget to save your seed phrase somewhere.\\n\\nAnd use one of existing accounts to send tokens to your new one. Choose for example Alice and press `Send`. Then choose your new account and write the amount of units you want to send and press `Make Transfer`:\\n\\n![send](../images/dev-node/send.png)\"}},{\"node\":{\"id\":\"984b10e2502a3cabb83f289b3bf40b19\",\"title\":\"ROS-based Projects for Smart Spaces\",\"path\":\"/docs/en/ros-smart-projects/\",\"content\":\"\\nThroughout its 15 years of development, the Robot Operating System framework was integrated with dozens of [various robotic devices](https://robots.ros.org/), and there are even more packages with algorithms and tools developed by the community. Truth be told, there are now so many projects, and the chaoticness of the description style of their repositories grew so much that it is currently quite problematic to find projects dedicated to a specific subject topic. \\n\\nHere, you’ll find a modest list of ROS-based projects that are dedicated to robots and IoT-devices that are meant for use in a home or office environment. This subject matter is one of the pillars of the Robonomics platform. Our goal is to try and bring these projects on track with Robonomics, from both a technical integration point of view and the perspective of an interesting application of these devices in a robot economy. Feel free to use this list in your search for ideas and inspiration.\\n\\nYou can check out some examples of ROS-projects integrated with Robonomics in the [Playground Overview page](https://wiki.robonomics.network/docs/en/playground-overview/). New projects, including those described here, will be added to the Wiki with time.\\n\\nAs of right now (**April 2021**), Robonomics is oriented towards ROS **Melodic** and **Noetic** versions. Older versions can also work, but there may be additional integration work needed. In the future, support for ROS version 2 will be added.\\n\\nThe main resources to search for ROS repositories and packages can be accessed [here](https://index.ros.org/).\\n\\n## Simulation\\n\\nBefore shifting our attention solely to devices, it’s worth remembering that for a large quantity of ROS projects, there exists an option to test them in a simulation. The most popular tool for the 3D modeling of various robots under ROS is the [Gazebo](http://gazebosim.org/) simulator and its offshoot project, [Ignition](https://index.ros.org/r/ros_ign/). Both simulators allow to model devices in various difficult indoor and outdoor environments, alter the model and environment itself, test control algorithms and debug before moving over to the real device. Also, this is an excellent tool for training and situations when a real device is absent.\\n\\nOverall, this is one of the best options for trying to integrate Robonomics with a ROS device without any expenditures at all. A real scenario would merely require slight code modifications. For Gazebo, Robonomics has a detailed guide that consists of two parts that cover [settings](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) and [integrations](https://wiki.robonomics.network/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/) (using a drone as an example). The main challenge is in finding a ready model (for example, [here](https://github.com/osrf/gazebo_models)) for Gazebo or trying to create your own model using the [SDFormat](http://sdformat.org/) developed for simulators. \\n\\n## Single-board computers and other boards\\n\\nSuch boards act as a base component for connecting other devices to ROS, primarily sensors and recording devices (audio, photo, and video recorders, cameras, temperature, pressure, and substance concentration sensors.) because the concept of a smart space implies the creation of a [digital twin](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf) of infrastructure objects. Also, boards can act as the main computing device and controller for constructing a robotic mobile device. A list of boards that support ROS is presented below:\\n\\n| Name and link                                                                                         |                                    Description                                  | ROS version | Last update |\\n|:-----------------------------------------------------------------------------------------------------:|---------------------------------------------------------------------------------|:-----------:|:-----------:|\\n|  [Raspberry Pi](http://wiki.ros.org/ROSberryPi/Installing%20ROS%20Melodic%20on%20the%20Raspberry%20Pi)| single board computer; RaspPi versions 2, 3 and 4 are available                 |   melodic   |     2020    |\\n|    [Arduino](http://wiki.ros.org/rosserial_arduino)                                                   | single board computer                                                           |    noetic   |     2021    |\\n|    [Phidgets](http://wiki.ros.org/phidgets)                                                           | sets of boards, various sensors and devices: Ph sensor, LED, RFID, motor control|    noetic   |     2020    |\\n|   [Sense HAT](https://wiki.ros.org/sensehat_ros)                                                      | shield for RaspPi with a set of sensors and LED                                 |    noetic   |     2020    |\\n|     [Navio2](https://navio2.emlid.com/)                                                               | autopliot shield for RaspPi 2,3,4                                               |    noetic   |     2020    |\\n|     [OpenCR](http://wiki.ros.org/opencr)                                                              | robot controller                                                                |    noetic   |     2021    |\\n\\n## Smart home devices and household robots\\n\\nPresented here are ROS devices whose initial use was for smart homes or offices. The list varies widely, from vacuum cleaners and robotic assistance to home control systems.\\n\\n| Name and link                                             | Description                                                 |          ROS version          | Last update |\\n|:---------------------------------------------------------:|-------------------------------------------------------------|:-----------------------------:|:-----------:|\\n|  [Care-O-bot 4](http://wiki.ros.org/care-o-bot)           | household robot-assistant; a simulation is available        |            melodic            |     2021    |\\n|     [Kobuki](http://wiki.ros.org/kobuki)                  | mobile platform with different use cases (e.g. a waiter)    |            melodic            |     2020    |\\n|    [QTrobot](http://wiki.ros.org/Robots/qtrobot)          | humanoid social robot                                       | kinetic (melodic can be used) |     2020    |\\n|      [Nao](http://wiki.ros.org/nao)                       | humanoid robot; a simulation is available                   |            Melodic            |     2020    |\\n|     [TIAGo](http://wiki.ros.org/Robots/TIAGo)             | service robot with a manipulator; a simulation is available |            kinetic            |     2020    |\\n|     [Roomba](https://github.com/AutonomyLab/create_robot) | robot vacuum cleaner                                        |            melodic            |     2020    |\\n|    [OpenHAB](http://wiki.ros.org/iot_bridge)              | home automation system                                      |            kinetic            |     2017    |\\n|     [Sesame](https://index.ros.org/p/sesame_ros/)         | smart lock                                                  |            melodic            |     2021    |\\n\\n## Mobile platforms and manipulators\\n\\nFirst and foremost, ROS is known for supporting mobile robotics, from drones to industrial manipulators, for which many packages were created that realize simultaneous localization and mapping ([SLAM](http://wiki.ros.org/rtabmap_ros)), solve the direct and inverse task of kinematics, [trajectory planning](https://moveit.ros.org/), and etc. Mobile robotics are gradually penetrating into everyday life, which is why it is certainly interesting to test existing ROS-robots in their use within a smart space. The general list of ROS-based mobile platforms is rather large, which is why here we have selected those that are potentially convenient to operate in a home or office space. \\n\\n| Name and link                                             | Description                                | ROS version | Last update |\\n|:---------------------------------------------------------:|--------------------------------------------|:-----------:|:-----------:|\\n|   [turtlebot](http://wiki.ros.org/turtlebot3)             | mobile platform tailored for ROS           |    noetic   |     2020    |\\n|    [GoPiGo3](http://wiki.ros.org/Robots/gopigo3)          | mobile robot based on RaspPi               |   melodic   |     2020    |\\n|    [LoCoBot](http://wiki.ros.org/locobot)                 | mobile manipulator                         |   kinetic   |     2020    |\\n|   [ROSbot 2.0](http://wiki.ros.org/Robots/ROSbot-2.0)     | mobile platform; a simulation is available |    noetic   |     2021    |\\n|     [VOLTA](http://wiki.ros.org/Robots/Volta)             | mobile platform; a simulation is available |   melodic   |     2021    |\\n|    [evarobot](http://wiki.ros.org/Robots/evarobot)        | mobile platform; a simulation is available |    noetic   |     2020    |\\n|    [Freight](http://wiki.ros.org/Robots/freight)          | mobile platform; a simulation is available |   melodic   |     2021    |\\n|      [PR2](http://wiki.ros.org/Robots/PR2)                | mobile platform; a simulation is available |   melodic   |     2021    |\"}},{\"node\":{\"id\":\"3076c8d4aa1150ab281a796b0573acd5\",\"title\":\"Manual start of the Robonomics network, consisting of 3 nodes\",\"path\":\"/docs/en/robonomics-test-network-manual/\",\"content\":\"\\n**Need to start Robonomics network of N (N> = 2) nodes**\\n\\n## Requirements\\n- Robonomics binary, download latest here: https://github.com/airalab/robonomics/releases/\\n- Subkey tool, download latest here: https://github.com/airalab/robonomics/releases/\\n- 3 servers with root shell. Their ip-addresses in the current instruction will be `165.227.171.127`, `159.89.25.75` and `159.89.30.50`\\n\\n## Introduction\\nIn this tutorial, we will first create all key files locally, and then upload them to their corresponding nodes. \\n\\n## Prepare directories\\nDownload 2 archives from the links above and open the folder with them in the terminal.\\nThen create a directory for the project, unpack the archives into it and go to the created folder:\\n```\\n$ mkdir robonomics_test_network\\n$ tar -xf ./robonomics-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ tar -xf ./subkey-ubuntu-0.21.0-x86_64.tar.xz -C ./robonomics_test_network/\\n$ cd ./robonomics_test_network/\\n```\\n\\nNext, create a separate **uploads** directory and the necessary subdirectories for each server. All files intended for uploading to a specific server will be stored in these subdirectories:\\n```\\n$ mkdir -p uploads/165.227.171.127/keystore && mkdir -p uploads/165.227.171.127/network\\n$ mkdir -p uploads/159.89.25.75/keystore && mkdir -p uploads/159.89.25.75/network\\n$ mkdir -p uploads/159.89.30.50/keystore && mkdir -p uploads/159.89.30.50/network\\n```\\n\\nAlso, create a **local** folder with **validators** and **sudo** folders, which will store the validators and sudo keys locally.\\n```\\n$ mkdir -p local/validators && mkdir -p local/sudo\\n```\\n\\n## Prepare spec.json\\nUsing the robonomics binary, generate a **spec.json** file, which will use as the basis:\\n```\\n$ ./robonomics build-spec --chain dev > uploads/spec.json\\n```\\n\\nNext, edit this file. At first correct the first three fields, make them look like this:\\n```\\n\\\"name\\\": \\\"Test Robonomics Network\\\",\\n\\\"id\\\": \\\"dev\\\",\\n\\\"chainType\\\": \\\"Live\\\",\\n```\\n\\n### bootNodes\\nThe **bootNodes** field is a list of strings of special format. For each of the bootnodes must write the corresponding string here.\\nTo do this, first create a key file for each bootnode using **subkey**:\\n```\\n$ ./subkey generate-node-key uploads/165.227.171.127/network/secret_ed25519  \\n12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\n$ ./subkey generate-node-key uploads/159.89.25.75/network/secret_ed25519\\n12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\n$ ./subkey generate-node-key uploads/159.89.30.50/network/secret_ed25519\\n12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\n```\\n\\nEach command creates a key file in the specified directory and outputs to stdout the string that will be needed to fill in the **bootNodes** field in the **spec.json** file. As a result, the **bootNodes** section should look like following example:\\n```\\n\\\"bootNodes\\\": [\\n\\\"/ip4/165.227.171.127/tcp/30333/p2p/12D3KooWBPq1fDLQC2iqQ4FpM2mUpiXjBRcb8ptk7tbaqr2B6HZN\\\",\\n\\\"/ip4/159.89.25.75/tcp/30333/p2p/12D3KooWRbGmdpbz6o1fe66wFs7nJsUYfBp2f3W7J1uDXj3gt4Bh\\\",\\n\\\"/ip4/159.89.30.50/tcp/30333/p2p/12D3KooWMuTrL9CmJxj8LjH43s4hsJMsyuMdbuB86zCaAf9VCwFf\\\"\\n],\\n```\\nThe next 3 fields (telemetryEndpoints, protocolId, properties) can be filled like this:\\n```\\n \\\"telemetryEndpoints\\\": [\\n     [\\n       \\\"/dns4/telemetry.polkadot.io/tcp/443/x-parity-wss/%2Fsubmit%2F\\\",\\n       0\\n     ]\\n ],\\n\\\"protocolId\\\": \\\"txrt\\\",\\n\\\"properties\\\": {\\n    \\\"ss58Format\\\": 32,\\n    \\\"tokenDecimals\\\": 9,\\n    \\\"tokenSymbol\\\": \\\"TXRT\\\"\\n},\\n```\\nFurther up to the **palletBalances** field leave unchanged.\\n\\n\\n### palletBalances\\nTo fill the palletBalances field create **the number of nodes + 1** (the last key is for **sudo**) keys. This can be done using **subkey**, in the file name must specify **SS58 Address** from the generated key, in the file content must specify **seed** phrase in quotes. \\n\\nExample creating one key.\\n - Generate key:\\n    ```\\n    $ ./subkey -n robonomics generate\\n    Secret phrase `display cargo domain april joy still bundle notice bridge pencil fat approve` is account:\\n      Network ID/version: substrate\\n      Secret seed:        0x0275ab9bce53e4359184f02112943162c708f483009e0b7b3ba63549c5c2e514\\n      Public key (hex):   0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      Account ID:         0xd0996b85dd1b2876080b26123f9c27097d698f871c5978c3cb9c299253e7a530\\n      SS58 Address:       4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n - Create key file:\\n    ```\\n    $ touch ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx && echo '\\\"display cargo domain april joy still bundle notice bridge pencil fat approve\\\"' | tee ./local/validators/4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ```\\n  \\nCommand template for creating a validator key file:  \\n`touch ./local/validators/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/validators/**SS58_Address**`\\n\\nCommand template for creating a sudo key file:   \\n`touch ./local/sudo/**SS58_Address** && echo '\\\"**seed**\\\"' | tee ./local/sudo/**SS58_Address**`\\n\\nThree keys are stored in the **local/validators** folder and one in the **local/sudo** folder. As a result, the following content should appear in the **local** directory:\\n```\\n./local/\\n├── sudo\\n│   └── 4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\n└── validators\\n    ├── 4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\n    ├── 4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\n    └── 4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\n```\\n\\nNow fill the palletBalances section in the spec.json file with these keys.\\nAs a result, it should look like this:\\n```\\n\\\"palletBalances\\\": {\\n  \\\"balances\\\": [\\n    [\\n      \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Generated validator 1 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Generated validator 2 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Generated validator 3 key\\n      1000000000000000000\\n    ],\\n    [\\n      \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\",    <-- Generated sudo key\\n      1000000000000000000\\n    ],\\n  ]\\n},\\n```\\nThe values that were previously presented in the palletBalances section must be deleted.\\n\\n### palletSession\\nNext step is the **palletSession** section in file **spec.json**. First let's describe its format. \\nThis section contains the \\\"keys\\\" field, that contains a list of three lists (equals of nodes count). Each of these lists looks like follows:\\n```\\n[\\n    \\\"%validator_SS58_address%\\\",\\n    \\\"%validator_SS58_address%\\\",\\n    {\\n        \\\"babe\\\": \\\"%sr25519_babe_SS58_address%\\\",\\n        \\\"im_online\\\": \\\"%sr25519_im_online_SS58_address%\\\"\\n        \\\"authority_discovery\\\": \\\"%sr25519_authority_discovery_SS58_address%\\\",\\n        \\\"grandpa\\\": \\\"%ed25519_grandpa_SS58_address%\\\",\\n    }\\n]\\n```\\n**%validator_SS58_address%** is the validator key that was generated for each node in the **palletBalances** section of this manual. Just copy it twice for each node.\\n\\nTo fill in the remaining 4 lines for each node, you need to create 4 key files for each node and store them in the **keystore** folders.\\nAs key files are generated, you can fill **palletSession**.\\n\\nEach key file must contain a **seed** phrase in quotes.\\nMaking of the name of each key file require separate consideration.\\nThe name of each key file is formed as **prefix** + **account_id without leading hexadecimal zero**.\\n\\nPrefixes matching:  \\n>      grandpa: '6772616e'  \\n>      babe: '62616265'\\n>      im_online: '696d6f6e'  \\n>      authority_discovery: '61756469'  \\n\\nAn example of creating keys for one node:\\n- Creating a **babe** (prefix *62616265*) key file.   \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  >  Secret phrase **cover once garment syrup income chair elder business diary frozen rack damage** is account:  \\n  >\\n  >  Network ID/version: `substrate`\\n  >\\n  >  Secret seed:        `0x90ddeee3a9a0c464572021d311c245eefc41f9a59c739faefda47efcf4755677`\\n  >\\n  >  Public key (hex):   `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  >\\n  >  Account ID:         `0xfa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`\\n  > \\n  >  SS58 Address:       `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`\\n  \\n ```\\n $ touch uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 && echo '\\\"cover once garment syrup income chair elder business diary frozen rack damage\\\"' | tee ./uploads/165.227.171.127/keystore/62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43 \\n ```\\n This command creates a **babe** key file for the `165.227.171.127` node. To fill in **spec.json**, need to take from this output the value **SS58 Address**: `4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C`. This address need to insert instead of `%sr25519_babe_SS58_address%` in the above **palletSession** template.\\n   \\n **babe** key file creation command template:  \\n`touch ./uploads/[node_ip]/keystore/62616265+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/62616265+[Account_ID]`  \\n\\nAs you can see, the name of the babe key file is the sum of two substrings: `babe prefix ('62616265')`, and the `account_id` of the generated key, without the leading zero (`fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43`). \\n  Note that the keys `babe, im_online, authority_discovery` are generated with the indication `--sr25519`.  \\n  **grandpa** key have to generate with the indication `--ed25519`.\\n \\n\\n- Creating an **im_online** (prefix *696d6f6e*) key file.  \\n  ```\\n  $ ./subkey --sr25519 -n robonomics generate\\n  ```\\n  > Secret phrase **envelope truly balance turkey undo casual waste skill average ordinary gun split** is account:\\n  >\\n  >   Network ID/version: `substrate`\\n  > \\n  >   Secret seed:        `0x8a19df08feeff9f1fa3581902ca22a305252aea32e284d32f10e990d00bb8926`\\n  > \\n  >   Public key (hex):   `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   Account ID:         `0x6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09`\\n  >  \\n  >   SS58 Address:       `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt`\\n   \\n  ```\\n  $ touch uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09 && echo '\\\"envelope truly balance turkey undo casual waste skill average ordinary gun split\\\"' | tee uploads/165.227.171.127/keystore/696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n  ```\\n  **im_online** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/696d6f6e+[Account_ID]`\\n  \\n  **spec.json**: `4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt` need to insert instead of `%sr25519_im_online_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating an **authority_discovery** (prefix *61756469*) key file.\\n   ```\\n   $ ./subkey --sr25519 -n robonomics generate\\n   ```\\n   > Secret phrase **boy harsh because omit equip atom apart spring undo explain walnut crystal** is account:\\n   >\\n   > Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0x27838c9ea0524353da3717862ef0ecef123f40e81b73bb5ef377d12b47d1c543`\\n   > \\n   >   Public key (hex):   `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   > \\n   >   Account ID:         `0x4e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07`\\n   >  \\n   >   SS58 Address:       `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t`\\n   \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07 && echo '\\\"boy harsh because omit equip atom apart spring undo explain walnut crystal\\\"' | tee uploads/165.227.171.127/keystore/617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n   ```\\n  **authority_discovery** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/61756469+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/61756469+[Account_ID]` \\n  \\n   **spec.json**: `4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t` need to insert instead of `%sr25519_authority_discovery_SS58_address%` in the above **palletSession** template.\\n\\n\\n- Creating a **grandpa** (prefix *6772616e*) key file.\\n   ```\\n   $ ./subkey --ed25519 -n robonomics generate\\n   ```\\n   > Secret phrase **squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle** is account:\\n   > \\n   >   Network ID/version: `substrate`\\n   >\\n   >   Secret seed:        `0xef0a9f51a4da7b789c0a25d39b44428d4da7262cc3fe013d4383b45216e8b83e`\\n   >  \\n   >   Public key (hex):   `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   >  \\n   >   Account ID:         `0x7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009`\\n   > \\n   >   SS58 Address:       `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa`\\n    \\n   ```\\n   $ touch uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009 && echo '\\\"squeeze nature off vendor comic pause tattoo seek omit spatial regular cattle\\\"' | tee uploads/165.227.171.127/keystore/6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n   ```\\n   **grandpa** key file creation command template:  \\n  `touch ./uploads/[node_ip]/keystore/6772616e+[Account_ID] && echo '\\\"[seed]\\\"' | tee ./uploads/[node_ip]/keystore/6772616e+[Account_ID]`\\n   \\n   **spec.json**: `4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa` need to insert instead of `%sr25519_grandpa_SS58_address%` in the above **palletSession** template.\\n   \\n   \\n**Now 4 key files have been created for one node. Need to repeat this actions for the remaining two nodes.**\\n\\nYou should get the following **uploads** directory structure after creating all the keys:\\n```\\n./uploads/\\n├── 165.227.171.127\\n│   ├── keystore\\n│   │   ├── 617564694e33ccfd4105d30dfd93c5ef4658e2585a749508ea7c7abe754efc36dd634c07\\n│   │   ├── 62616265fa44d96e310cf68350dd855c745794f7c1afa63089ebdb2c96bff3797972bb43\\n│   │   ├── 6772616e7ea1beed13fb66a333b50b1ae417ebfd152bab99b223be2d4d886adb5fa7f009\\n│   │   └── 696d6f6e6c13ff8e37d91b80fe3b03f9b92a91a1ef7db741434cf12cc44d5ed29257ab09\\n│   └── network\\n│       └── secret_ed25519\\n├── 159.89.25.75\\n│   ├── keystore\\n│   │   ├── 617564692ac9bd30c0168fa623cfd66abb4327992d900a652bcbb238b740bdde497a565f\\n│   │   ├── 626162657cd666bb540c41cb33896a34d7413ffb86fcef1eddddfcd4edb325166df6335d\\n│   │   ├── 6772616e084402349bc08ef90c2837e8e3f12ebe8bd4ab86809e9ee5f4f8ca26e73a0518\\n│   │   └── 696d6f6e6ed2d507c0283ae869ba6514975bd8765eb8e06abd22afc09e8f36ef3950a116\\n│   └── network\\n│       └── secret_ed25519\\n└── 159.89.30.50\\n|   ├── keystore\\n|   │   ├── 61756469f20a4e16a0ee79431d6f9a70c38892c7532ad1347c2226d43ef6ffe8966e9b30\\n|   │   ├── 62616265e695aa459dbfd42bea7ed3b87970f164f34b6fee4d5a831ffbecd89eb9769b26\\n|   │   ├── 6772616eadef59f896ea6b94bcd4519be8cc4b70263fc318cec1a3be14850bbc22117c34\\n|   │   └── 696d6f6e2cb4dc8f8a67f477da15045ca40ef3861a2a6b2034ae0c64a179b4431341ea2c\\n|   └── network\\n|       └── secret_ed25519\\n└── spec.json\\n```\\n\\nThe palletSession section should look like this:\\n```\\n\\\"palletSession\\\": {\\n    \\\"keys\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",    <-- Validator 1 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4DqEyoefRSz746sjaonxJ7KZQz8MUq4cKFA87DfoLzQgWk8t\\\",\\n                \\\"babe\\\": \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",\\n                \\\"grandpa\\\": \\\"4EvjwRdgUg6YtdUDjq6Z3PoTKtzH5cgFgwnzArMSbw3RzYTa\\\",\\n                \\\"im_online\\\": \\\"4EWQyBRoucH4Wjd4JtGoSEYYCw4bbkonjoFy9hNUX5fbmMEt\\\"\\n            }\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",    <-- Validator 2 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4F6daoG2gBXRLvbT4mVRajExZdZBHH7APmX3wDuLYJyzxHSS\\\",\\n                \\\"babe\\\": \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",\\n                \\\"grandpa\\\": \\\"4G3Ai6BGUjqtCoM2aTvWyR19gQ8WZiNnh1KFM47RyiYTwkE6\\\",\\n                \\\"im_online\\\": \\\"4FHA7gzKfSLvd8jP85JUCWV6RyeRLm331KHcjnynGx7TWm7D\\\"\\n            }\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address                        \\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",    <-- Validator 3 SS58 Address\\n            {\\n                \\\"authority_discovery\\\": \\\"4CqzJFkdSZg52PfV6Fd4gJ3vPLmRu1HGuPvNivjJ8dDWaz1a\\\",\\n                \\\"babe\\\": \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",\\n                \\\"grandpa\\\": \\\"4Cqi4rG3CzWRZairhZX4isT8qG2jyz9fGDXJMrP6uBYkrft5\\\",\\n                \\\"im_online\\\": \\\"4C7V6R59cZVbabExqgWvHVE1vj1E1cV42SZr8d8zZD3gmsqk\\\"\\n            }\\n        ]\\n    ]\\n},\\n```\\n\\n### palletStaking\\n**palletStaking** must be filled in as follows:\\n```\\n\\\"palletStaking\\\": {\\n    \\\"historyDepth\\\": 84,\\n    \\\"validatorCount\\\": 10,\\n    \\\"minimumValidatorCount\\\": 2,\\n    \\\"invulnerables\\\": [\\n        \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",     <-- Validator 1 SS58 Address\\n        \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",     <-- Validator 2 SS58 Address\\n        \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\"      <-- Validator 3 SS58 Address\\n    ],\\n    \\\"forceEra\\\": \\\"NotForcing\\\",\\n    \\\"slashRewardFraction\\\": 100000000,\\n    \\\"canceledPayout\\\": 0,\\n    \\\"stakers\\\": [\\n        [\\n            \\\"4CnxYUugEzLQ8Re2d5P2Jso25pe8PBttcVjc3VdNL2V9shVx\\\",  <-- Validator 1 SS58 Address\\n            \\\"4HirHF5BVHxkRBtqptFxBSmnAiZir1qQLs6pL9Utmm4eF77C\\\",  <-- Validator 1 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4EeMi84pk5P5nQpyupQeCZ1C4NhUFtMF7Xh1MXJLANkZ3BTd\\\",  <-- Validator 2 SS58 Address\\n            \\\"4C7vBVHUYKqApCywqGsuap6XhjZ3gdYnW4YYP2mMyvYctLqT\\\",  <-- Validator 2 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ],\\n        [\\n            \\\"4FPRYfSVqwaX39vXZ78tT3DPBT9FmFXvdQDD7y5UQKncJGu1\\\",   <-- Validator 3 SS58 Address\\n            \\\"4EComk8TsrT399xT6MPhGnhbZEif6U6cny8DiyZ3zezo9b5f\\\",   <-- Validator 3 babe address\\n            1000000,\\n            \\\"Validator\\\"\\n        ]\\n    ]\\n},\\n```\\nThe example specified in which fields what values should be substituted.\\n\\n### palletSudo\\nIn the rest of the **spec.json** file, you need to change only the contents of **palletSudo**, substituting the previously generated **sudo** address there:\\n```\\n            \\\"palletBabe\\\": {\\n                \\\"authorities\\\": []\\n            },\\n            \\\"palletGrandpa\\\": {\\n                \\\"authorities\\\": []  \\n            },\\n            \\\"palletImOnline\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletAuthorityDiscovery\\\": {\\n                \\\"keys\\\": []\\n            },\\n            \\\"palletTreasury\\\": {},\\n            \\\"palletElectionsPhragmen\\\": {\\n                \\\"members\\\": []\\n            },\\n            \\\"palletCollectiveInstance1\\\": {\\n                \\\"phantom\\\": null,\\n                \\\"members\\\": []\\n            },\\n            \\\"palletSudo\\\": {\\n                \\\"key\\\": \\\"4Dy6bzrvoApwjLaAjfrtvtX3tthCw6fnCU1Ym5KNyRGt3kKb\\\"   <-- sudo address\\n            }\\n        }\\n    }\\n}\\n```\\n\\n## systemd unit file\\nNow create systemd unit file:\\n```\\n$ touch ./uploads/robonomics.service\\n```\\n\\nAnd fill it like this:\\n```\\n[Unit]\\nDescription=robonomics\\nAfter=network.target\\n\\n[Service]\\nUser=root\\nGroup=root\\nType=users\\nWorkingDirectory=/root\\nRestart=on-failure\\nExecStart=/usr/bin/robonomics  --chain /etc/substrate/spec.json --name ${HOSTNAME} --validator\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\nAs you can see from the \\\"ExecStart\\\" line, the **robonomics** binary is stored in the **/usr/bin/** directory, and the **spec.json** file is stored in the **/etc/substrate/** directory.\\n\\n## Uploading files\\nThe following one-line command uploads all files to the required directories on the servers. It is important that there are no other folders in the **uploads** directory, except for the folders with the ip-addresses of the nodes:\\n```\\n$ \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n    ssh root@\\\"$IP\\\" \\\"mkdir -p /root/.local/share/robonomics/chains/dev\\\" && \\\\\\n    scp -r ./uploads/$IP/* root@$IP:/root/.local/share/robonomics/chains/dev/ && \\\\\\n    scp ./uploads/robonomics.service root@$IP:/etc/systemd/system/ && \\\\\\n    scp ./robonomics root@$IP:/usr/bin/ && \\\\\\n    ssh root@$IP \\\"mkdir -p /etc/substrate\\\" && \\\\\\n    scp ./uploads/spec.json root@$IP:/etc/substrate/ \\\\\\n; done\\n```\\n\\n## Network launch\\nNow connect to all nodes, enable and start the **robonomics.service** unit:\\n```\\n$  \\\\\\nfor IP in `ls -l ./uploads/ | grep '^d' | awk '{print $9}'`; do \\\\\\n   ssh root@$IP \\\"systemctl enable robonomics.service && systemctl start robonomics.service\\\" \\\\\\n; done\\n```\\nAfter starting the service on all three nodes, you can view the node logs using **journalctl**. \\nTo do this, you can connect to any existing server via ssh and run the following command:\\n```\\n$ journalctl -u robonomics.service -f\\n```\\n![Robonomics Chart](../images/robonomics-test-network-manual/result-journalctl.jpg \\\"Robonomics Network journalctl stdout\\\")\\n\"}},{\"node\":{\"id\":\"0d26b6d8338c38dd7345c5b9a7b86289\",\"title\":\"Robonomics + Prometheus + Grafana\",\"path\":\"/docs/en/robonomics-prometheus-grafana/\",\"content\":\"\\n**The following instruction is provided by [Hubo Bubo](https://github.com/hubobubo)**\\n\\n**The original article is located [here](https://github.com/hubobubo/robonomics/wiki/Robonomics-(XRT)-metrics-using-Prometheus-and-Grafana)**\\n\\n## Introduction\\nTo better monitor and maintain Robonomics node(s) it's good to setup a monitoring based on Prometheus Server and Grafana. This doc will show how to configure each one of it to fully monitor your node.\\n\\n##  Prerequisites\\n* [Server Setup with Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04) \\n* [Robonomics parachain collator installed](https://blog.aira.life/installing-and-running-the-robonomics-validator-in-the-polkadot-network-487ad4c1a567)\\n* Make sure you have robonomics.service working on your machine and port 9615 is reachable \\n\\n## Step 1 — Creating Service Users\\n\\nFor security purposes, we’ll begin by creating two new user accounts, prometheus and node_exporter. Create these two users, and use the _--no-create-home_ and _--shell /bin/false_ options so that these users can’t log into the server.\\n```\\nsudo useradd --no-create-home --shell /bin/false prometheus\\nsudo useradd --no-create-home --shell /bin/false node_exporter\\n```\\n\\nBefore we download the Prometheus binaries, create the necessary directories for storing Prometheus’ files and data. Following standard Linux conventions, we’ll create a directory in _/etc_ for Prometheus’ configuration files and a directory in _/var/lib_ for its data.\\n```\\nsudo mkdir /etc/prometheus\\nsudo mkdir /var/lib/prometheus\\n```\\nNow, set the user and group ownership on the new directories to the prometheus user.\\n```\\nsudo chown prometheus:prometheus /etc/prometheus\\nsudo chown prometheus:prometheus /var/lib/prometheus\\n```\\n## Step 2 — Downloading Prometheus\\n\\nFirst, download and unpack the current stable version of Prometheus into your home directory. You can find the latest binaries on the [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf prometheus-2.21.0.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called prometheus-2.21.0.linux-amd64 containing two binary files (prometheus and promtool), _consoles_ and _console_libraries_ directories containing the web interface files, a license, a notice, and several example files.\\n\\nCopy the two binaries to the _/usr/local/bin_ directory.\\n\\n```\\nsudo cp prometheus-2.21.0.linux-amd64/prometheus /usr/local/bin/\\nsudo cp prometheus-2.21.0.linux-amd64/promtool /usr/local/bin/\\n\\n```\\nSet the user and group ownership on the binaries to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /usr/local/bin/prometheus\\nsudo chown prometheus:prometheus /usr/local/bin/promtool\\n\\n```\\nCopy the consoles and _console_libraries_ directories to _/etc/prometheus_.\\n\\n```\\nsudo cp -r prometheus-2.21.0.linux-amd64/consoles /etc/prometheus\\nsudo cp -r prometheus-2.21.0.linux-amd64/console_libraries /etc/prometheus\\n\\n```\\nSet the user and group ownership on the directories to the prometheus user. Using the -R flag will ensure that ownership is set on the files inside the directory as well.\\n\\n```\\nsudo chown -R prometheus:prometheus /etc/prometheus/consoles\\nsudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\\n\\n```\\nNow that Prometheus is installed, we’ll create its configuration and service files in preparation of its first run.\\n\\n## Step 3 — Configuring Prometheus\\n\\nIn the _/etc/prometheus_ directory, use nano or your favorite text editor to create a configuration file named _prometheus.yml_.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nIn the global settings, define the default interval for scraping metrics. Note that Prometheus will apply these settings to every exporter unless an individual exporter’s own settings override the globals.\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\n```\\nThis scrape_interval value tells Prometheus to collect metrics from its exporters every 15 seconds, which is long enough for most exporters.\\nNow, add Prometheus itself to the list of exporters to scrape from with the following scrape_configs directive:\\n\\n```\\n...\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nPrometheus uses the _job_name_ to label exporters in queries and on graphs, so be sure to pick something descriptive here.\\n\\nAnd, as Prometheus exports important data about itself that you can use for monitoring performance and debugging, we’ve overridden the global scrape_interval directive from 15 seconds to 5 seconds for more frequent updates.\\n\\nLastly, Prometheus uses the _static_configs_ and _targets_ directives to determine where exporters are running. Since this particular exporter is running on the same server as Prometheus itself, we can use localhost instead of an IP address along with the default port, 9090.\\n\\nYour configuration file should now look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n```\\nSave the file and exit your text editor.\\n\\nNow, set the user and group ownership on the configuration file to the prometheus user created in Step 1.\\n\\n```\\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\\n\\n```\\nWith the configuration complete, we’re ready to test Prometheus by running it for the first time.\\n\\n## Step 4 — Running Prometheus\\n\\nStart up Prometheus as the _prometheus_ user, providing the path to both the configuration file and the data directory.\\n\\n```\\nsudo -u prometheus /usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nThe output contains information about Prometheus’ loading progress, configuration file, and related services. It also confirms that Prometheus is listening on port _9090_.\\n\\n```\\n_log output_\\nSep 14 17:55:53 robonomics systemd[1]: Started Prometheus.\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.347Z caller=main.go:310 msg=\\\"No time or size retention was set so using the default time retention\\\" duration=15d\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.350Z caller=main.go:346 msg=\\\"Starting Prometheus\\\" version=\\\"(version=2.21.0, branch=HEAD, revision=e83ef207b6c2398919b69cd87d2693cfc2fb4127)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:347 build_context=\\\"(go=go1.15.2, user=root@a4d9bea8479e, date=20200911-11:35:02)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:348 host_details=\\\"(Linux 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 robonomics (none))\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:349 fd_limits=\\\"(soft=1024, hard=4096)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.351Z caller=main.go:350 vm_limits=\\\"(soft=unlimited, hard=unlimited)\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.357Z caller=main.go:701 msg=\\\"Starting TSDB ...\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.368Z caller=web.go:523 component=web msg=\\\"Start listening for connections\\\" address=0.0.0.0:9090\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.372Z caller=head.go:644 component=tsdb msg=\\\"Replaying on-disk memory mappable chunks if any\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:658 component=tsdb msg=\\\"On-disk memory mappable chunks replay completed\\\" duration=12.659µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.373Z caller=head.go:664 component=tsdb msg=\\\"Replaying WAL, this may take a while\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.380Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=0 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:716 component=tsdb msg=\\\"WAL segment loaded\\\" segment=1 maxSegment=1\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.381Z caller=head.go:719 component=tsdb msg=\\\"WAL replay completed\\\" checkpoint_replay_duration=48.125µs wal_replay_duration=8.253748ms total_replay_duration=8.343335ms\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.383Z caller=main.go:721 fs_type=EXT4_SUPER_MAGIC\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:724 msg=\\\"TSDB started\\\"\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:850 msg=\\\"Loading configuration file\\\" filename=/etc/prometheus/prometheus.yml\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:881 msg=\\\"Completed loading of configuration file\\\" filename=/etc/prometheus/prometheus.yml totalDuration=908.135µs remote_storage=6.693µs web_handler=819ns query_engine=1.383µs scrape=400.232µs scrape_sd=41.679µs notify=1.1µs notify_sd=1.847µs rules=1.522µs\\nSep 14 17:55:53 robonomics prometheus[29488]: level=info ts=2020-09-14T15:55:53.384Z caller=main.go:673 msg=\\\"Server is ready to receive web requests.\\\"\\n```\\nIf you get an error message, double-check that you’ve used YAML syntax in your configuration file and then follow the on-screen instructions to resolve the problem.\\n\\nNow, halt Prometheus by pressing _CTRL+C_, and then open a new _systemd_ service file.\\n\\n```\\nsudo nano /etc/systemd/system/prometheus.service\\n\\n```\\nThe service file tells _systemd_ to run Prometheus as the prometheus user, with the configuration file located in the _/etc/prometheus/prometheus.yml_ directory and to store its data in the _/var/lib/prometheus_ directory.Copy the following content into the file:\\n\\n```\\n[Unit]\\nDescription=Prometheus\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=prometheus\\nGroup=prometheus\\nType=simple\\nExecStart=/usr/local/bin/prometheus \\\\\\n    --config.file /etc/prometheus/prometheus.yml \\\\\\n    --storage.tsdb.path /var/lib/prometheus/ \\\\\\n    --web.console.templates=/etc/prometheus/consoles \\\\\\n    --web.console.libraries=/etc/prometheus/console_libraries\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nFinally, save the file and close your text editor. To use the newly created service, reload systemd.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now start Prometheus using the following command:\\n\\n```\\nsudo systemctl start prometheus\\n\\n```\\nTo make sure Prometheus is running, check the service’s status.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nThe output tells you Prometheus’ status, main process identifier (PID), memory use, and more.\\n\\nIf the service’s status isn’t active, follow the on-screen instructions and re-trace the preceding steps to resolve the problem before continuing the tutorial.\\n\\n```\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:59:48 CEST; 24h ago\\n Main PID: 29650 (prometheus)\\n    Tasks: 9 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-29650 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWhen you’re ready to move on, press _Q_ to quit the status command. Lastly, enable the service to start on boot.\\n\\n```\\nsudo systemctl enable prometheus\\n\\n```\\n\\nNow that Prometheus is up and running, we can install an additional exporter to generate metrics about our server’s resources.\\n\\n## Step 5 — Downloading Node Exporter\\n\\nTo expand Prometheus beyond metrics about itself only, we’ll install an additional exporter called Node Exporter. Node Exporter provides detailed information about the system, including CPU, disk, and memory usage. Download the current stable version of Node Exporter into your home directory. You can find the latest binaries on [Prometheus download page.](https://prometheus.io/download/)\\n\\n```\\nwget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nNow, unpack the downloaded archive.\\n\\n```\\ntar xvf node_exporter-1.0.1.linux-amd64.tar.gz\\n\\n```\\nThis will create a directory called _node_exporter-1.0.1.linux-amd64_ containing a binary file named _node_exporter_, a license, and a notice.\\n\\nCopy the binary to the _/usr/local/bin_ directory and set the user and group ownership to the node_exporter user that you created in Step 1.\\n\\n```\\nsudo cp node_exporter-1.0.1.linux-amd64/node_exporter /usr/local/bin\\nsudo chown node_exporter:node_exporter /usr/local/bin/node_exporter\\n\\n```\\nNow that you’ve installed Node Exporter, let’s test it out by running it before creating a service file for it so that it starts on boot.\\n\\n## Step 6 — Running Node Exporter\\n\\nThe steps for running Node Exporter are similar to those for running Prometheus itself. Start by creating the Systemd service file for Node Exporter.\\n\\n```\\nsudo nano /etc/systemd/system/node_exporter.service\\n\\n```\\nCopy the following content into the service file:\\n\\n```\\n[Unit]\\nDescription=Node Exporter\\nWants=network-online.target\\nAfter=network-online.target\\n\\n[Service]\\nUser=node_exporter\\nGroup=node_exporter\\nType=simple\\nExecStart=/usr/local/bin/node_exporter --collector.systemd\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nSave the file and close your text editor. Finally, reload systemd to use the newly created service.\\n\\n```\\nsudo systemctl daemon-reload\\n\\n```\\nYou can now run Node Exporter using the following command:\\n\\n```\\nsudo systemctl start node_exporter\\n\\n```\\nVerify that Node Exporter’s running correctly with the status command.\\n\\n```\\nsudo systemctl status node_exporter\\n\\n```\\nLike before, this output tells you Node Exporter’s status, main process identifier (PID), memory usage, and more. If the service’s status isn’t active, follow the on-screen messages and re-trace the preceding steps to resolve the problem before continuing.\\n\\n```\\n_Output_\\n* node_exporter.service - Node Exporter\\n   Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2020-09-14 17:58:25 CEST; 1 day 1h ago\\n Main PID: 29612 (node_exporter)\\n    Tasks: 7 (limit: 4915)\\n   CGroup: /system.slice/node_exporter.service\\n           `-29612 /usr/local/bin/node_exporter --collector.systemd\\n```\\nLastly, enable Node Exporter to start on boot.\\n\\n```\\nsudo systemctl enable node_exporter\\n\\n```\\nWith Node Exporter fully configured and running as expected, we’ll tell Prometheus to start scraping the new metrics.\\n\\n## Step 7 — Configuring Prometheus to Scrape Node Exporter\\n\\nBecause Prometheus only scrapes exporters which are defined in the scrape_configs portion of its configuration file, we’ll need to add an entry for Node Exporter, just like we did for Prometheus itself. Open the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called node_exporter.\\n\\n```\\n...\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nBecause this exporter is also running on the same server as Prometheus itself, we can use localhost instead of an IP address again along with Node Exporter’s default port, 9100. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n```\\nSave the file and exit your text editor when you’re ready to continue. Finally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nIf the service’s status isn’t set to active, follow the on screen instructions and re-trace your previous steps before moving on.\\n\\n```\\nOutput\\n* prometheus.service - Prometheus\\n   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Tue 2020-09-15 19:06:56 CEST; 2s ago\\n Main PID: 19725 (prometheus)\\n    Tasks: 8 (limit: 4915)\\n   CGroup: /system.slice/prometheus.service\\n           `-19725 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries\\n```\\n\\nWe now have Prometheus and Node Exporter installed, configured, and running.\\n\\n## Step 8 - Adding Robonomic build in node_exporter\\n\\nAfter successfully installed Prometheus and node_exporter we will have to use build in prometheus exporter in every substrate project. To make this happen we have to add additional entry to _/etc/prometheus/prometheus.yml_. \\nOpen the configuration file.\\n\\n```\\nsudo nano /etc/prometheus/prometheus.yml\\n\\n```\\nAt the end of the scrape_configs block, add a new entry called robonomic_exporter.\\n\\n``` \\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\nSave the file and exit your text editor. Your whole configuration file should look like this:\\n\\n```\\nglobal:\\n  scrape_interval: 15s\\n\\nscrape_configs:\\n  - job_name: 'prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9090']\\n  - job_name: 'node_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9100']\\n  - job_name: 'robonomics_exporter'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: ['localhost:9615']\\n```\\n\\nFinally, restart Prometheus to put the changes into effect.\\n\\n```\\nsudo systemctl restart prometheus\\n\\n```\\nOnce again, verify that everything is running correctly with the status command.\\n\\n```\\nsudo systemctl status prometheus\\n\\n```\\nWe now have _Prometheus_ and _Node Exporter_ as well as _Robonomic Exporter_ installed, configured, and running. Now move on to Grafana\\n\\n## Step 9 - Setting up Grafana\\n\\nThe last step is to connect Prometheus as a Data Source in Grafana. For purpose of this tutorial we will use free cloud-based grafana which allow to have up to 5 dashboards as well as dedicated [Robonomics dashboard](https://grafana.com/grafana/dashboards/13015). Simply go to [grafana.com](https://grafana.com/) create new account and login to your newly created grafana instance.\\n\\nAt the beginning we must add to Grafana new _**Data Source**_ which in our case will be Prometheus server.\\nGo to Data Source:\\n\\n>![DataSource](../images/prometheus-grafana/grafana-6-2020-09-15-19-18-50-Window.png)\\n\\nThen click **_Add data source_**\\n\\n>![DataSource](../images/prometheus-grafana/grafana-7-2020-09-15-19-18-50-Window.png)\\n\\nNext select _**Prometheus**_\\n\\n>![DataSource](../images/prometheus-grafana/grafana-8-2020-09-15-19-18-50-Window.png)\\n\\nIn new screen put your **_Prometheus server IP adress with 9090 port_**\\n\\n> ![DataSource](../images/prometheus-grafana/grafana-9-2020-09-15-19-18-50-Window.png)\\n\\nAfter that _**Save & Test**_ if you did all steps you should be green and ready to go for importing dashboard. On the main site click to **+** and then **Import** as shown on the pic below:\\n\\n> ![Import dashboard](../images/prometheus-grafana/grafana-1-2020-09-15-19-18-50-Window.png)\\n\\nThen you should see Import page:\\n\\n> ![Import page](../images/prometheus-grafana/grafana-2-2020-09-15-19-18-50-Window.png)\\n\\nIn the _Grafana.com dashboard url or id_ write _**13015**_ (as this is ID of the Robonomic dashboard)\\n\\n> ![Import Robonomic dashboard](../images/prometheus-grafana/grafana-3-2020-09-15-19-18-50-Window.png)\\n\\nAfter loading external dashboard you will get this screen:\\n\\n> ![XRT 13015 dashboard import](../images/prometheus-grafana/grafana-4-2020-09-15-19-18-50-Window.png)\\n\\nThe last step is to choose previously created **_Data Source_** and click _**Import**_\\n\\n> ![Prometheus as a DataSource](../images/prometheus-grafana/grafana-5-2020-09-15-19-18-50-Window.png)\\n\\nTHAT'S IT ! At this point you should see imported dashboard. \\n\\n\\n## References\\n\\n* [How To Install Prometheus on Ubuntu 16.04](https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-on-ubuntu-16-04)\\n* [Build A Monitoring Dashboard by Prometheus + Grafana](https://medium.com/htc-research-engineering-blog/build-a-monitoring-dashboard-by-prometheus-grafana-741a7d949ec2)\\n* [Grafana support for Prometheus](https://prometheus.io/docs/visualization/grafana/)\\n* [Monitoring Linux host metrics with the node exporter](https://prometheus.io/docs/guides/node-exporter/)\\n* [Querying Prometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/)\\n* [Visualizing Node Metrics](https://substrate.dev/docs/en/tutorials/visualize-node-metrics/)\\n* [Substrate Prometheus Exporter](https://github.com/paritytech/substrate/tree/master/utils/prometheus)\\n* [polkadot-dashboard](https://github.com/w3f/polkadot-dashboard)\\n* [Polkadot node metric](https://grafana.com/grafana/dashboards/12425)\\n* [Node Exporter for Prometheus Dashboard](https://grafana.com/grafana/dashboards/11074)\\n* [Grafana ROBONOMICS (XRT) Metrics](https://grafana.com/grafana/dashboards/13015)\\n\\n\"}},{\"node\":{\"id\":\"4a7244db5ca97f6d22655107b0c4a99c\",\"title\":\"Robonomics Liability\",\"path\":\"/docs/en/robonomics-liability/\",\"content\":\"\\nThe package is responsible for receiving `New Liability` events (`listener` node) and playing topics from `objective` field (`executor` node).\\nThe launch file also include `ipfs_channel` node and `signer` node.\\n\\n## ROS Parameters\\n\\n### ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~web3_ws_provider\\n\\nWeb3 WebSocket provider address. The type is `string`, defaults to `ws://127.0.0.1:8546`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~enable_executor\\n\\nEnable or disable executor node. If it's `false`, no topics from objective would be published. The type is `boolean`, defaults to `true`\\n\\n### ~master_check_interval\\n\\nPeriod (in seconds) to check master for new topic publications. It's necessary for the Recorder, which records all the topics a CPS publishes. The type is `double`, defaults to `0.1`\\n\\n### ~recording_topics\\n\\nList of topics name separated by comma. It allows you to specify which topics would be recorded. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Subscribed topics\\n\\n### /liability/infochan/eth/signing/demand (robonomics_msgs/Demand)\\n\\n[robonomics_msgs/Demand](/docs/market-messages#demand) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/offer (robonomics_msgs/Offer)\\n\\n[robonomics_msgs/Offer](/docs/market-messages#offer) message to sign and send further to IPFS channel\\n\\n### /liability/infochan/eth/signing/result (robonomics_msgs/Result)\\n\\n[robonomics_msgs/Result](/docs/market-messages#result) message to sign and send further to IPFS channel\\n\\n\\n## Published topics\\n\\n### /liability/infochan/incoming/demand (robonomics_msgs/Demand)\\n\\nContains a [robonomics_msgs/Demand](/docs/market-messages#demand) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/offer (robonomics_msgs/Offer)\\n\\nContains a [robonomics_msgs/Offer](/docs/market-messages#offer) message which was read from IPFS channel\\n\\n### /liability/infochan/incoming/result (robonomics_msgs/Result)\\n\\nContains a [robonomics_msgs/Result](/docs/market-messages#result) message which was read from IPFS channel\\n\\n### /liability/incoming (robonomics_liability/Liability)\\n\\nContains all the information about the last created [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)\\n\\n### /liability/ready (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg)is ready for execution\\n\\n### /liability/complete (robonomics_liability/Liability)\\n\\nSignals when a [robonomics_liability/Liability](/docs/robonomics-liability-messages#robonomics_liabilityliabilitymsg) has done its job\\n\\n### /liability/finalized (std_msgs/String)\\n\\nSignals when a liability has been finalized\\n\\n## Services\\n\\n### /liability/start (robonomics_liability/StartLiability)\\n\\nThe service tells executor to play topics from the objective. It's required to pass a liability address ([robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)), which you can get from `/liability/ready` topic\\n\\n### /liability/finish (robonomics_liability/FinishLiability)\\n\\nCPS should call the service after performing the task. The input is [robonomics_liability/FinishLiability](/docs/robonomics-liability-messages#robonomics_liabilityfinishiabilitysrv)\\n\\n### /liability/restart (robonomics_liability/StartLiability)\\n\\nThe service allows to restart a liability after the system shutdown. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/resume (robonomics_liability/StartLiability)\\n\\nThe service allows to resume a liability from the last timestamp available in the persistence store. The input is [robonomics_liability/StartLiability](/docs/robonomics-liability-messages#robonomics_liabilitystartliabilitysrv)\\n\\n### /liability/read (robonomics_liability/ReadLiability)\\n\\nThe service returns all the data about a liability by its address. The input is [robonomics_liability/ReadLiability](/docs/robonomics-liability-messages#robonomics_liabilityreadliabilitysrv)\\n\"}},{\"node\":{\"id\":\"fce34887415c5ceb488e44edf59d3421\",\"title\":\"Robonomics Liability Messages\",\"path\":\"/docs/en/robonomics-liability-messages/\",\"content\":\"\\n## robonomics_liability/Liability.msg\\n\\n| Field        \\t| Type                                                                         \\t| Description                                    \\t|\\n|--------------\\t|------------------------------------------------------------------------------\\t|------------------------------------------------\\t|\\n| address      \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The Liability’s address                        \\t|\\n| model        \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model Identifier                \\t|\\n| objective    \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| CPS behavioral model parameters in rosbag file \\t|\\n| result       \\t| [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)         \\t| Liability result hash                          \\t|\\n| promisee     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisee address                           \\t|\\n| promisor     \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The promisor address (usually CPS)             \\t|\\n| lighthouse   \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| The address of lighthouse your CPS works on    \\t|\\n| token        \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Operational token address                      \\t|\\n| cost         \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| CPS behavioral model implementation cost       \\t|\\n| validator    \\t| [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) \\t| Observing network address                      \\t|\\n| validatorFee \\t| [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) \\t| Observing network commission                   \\t|\\n\\n## robonomics_liability/StartLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                                           |\\n|---------  |-----------------  |-----------------------------------------------------  |\\n| address   | std_msgs/String   | The address of Liability you are willing to execute   |\\n\\n**Response**\\n\\n| Field     | Type              | Description                               |\\n|---------  |-----------------  |------------------------------------------ |\\n| success   | std_msgs/Bool     | Weather or not the Liability was started  |\\n| msg       | std_msgs/String   | Status of launch                          |\\n\\n## robonomics_liability/FinishLiability.srv\\n\\n**Request**\\n\\n| Field     | Type              | Description                           |\\n|---------  |-----------------  |------------------------------------   |\\n| address   | std_msgs/String   | The address of Liability to finish    |\\n| success   | std_msgs/Bool     | The status of execution               |\\n\\n**Response**\\n\\nThe response is empty\\n\\n## robonomics_liability/ReadLiability.srv\\n\\n**Request**\\n\\n| Field     | Type                                                                          | Description                   |\\n|---------  |------------------------------------------------------------------------------ |----------------------------   |\\n| address   | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)  | The address of a liability    |\\n\\n**Response**\\n\\n| Field         | Type                                                                  | Description           |\\n|-----------    |---------------------------------------------------------------------  |---------------------  |\\n| read          | std_msgs/Bool                                                         | Status of execution   |\\n| liability     | [robonomics_liability/Liability](#robonomics_liabilityliabilitymsg)   | Liability             |\\n\"}},{\"node\":{\"id\":\"9f53197d65fea5ff3ea4d0b315e078d1\",\"title\":\"Robonomics-js\",\"path\":\"/docs/en/robonomics-js/\",\"content\":\"\\n[Robonomics-js](https://github.com/airalab/robonomics-js) is a simple Javascript library for working with Robonomics Network.\\n\\n## Installation\\n\\n```\\nnpm install robonomics-js --save\\n```\\n\\nor\\n\\n```\\nyarn add robonomics-js\\n```\\n\\n### Dependencies \\n\\n* [Web3](https://github.com/ethereum/web3.js/) version 1.2.4\\n* [Ipfs](https://github.com/ipfs/js-ipfs) version 0.34.0\\n\\n\\n## Usage \\n\\nCreates a Robonomics instance\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\n```\\n\\n### options\\n\\nThe object of properties:\\n\\n```\\noptions.web3\\n```\\n\\nAn instance of [web3.js](https://github.com/ethereum/web3.js/):\\n\\n```JavaScript\\n// metamask\\nconst options = {\\n  web3: new Web3(window.ethereum),\\n  ...\\n};\\n\\n// infura\\nconst options = {\\n  web3: new Web3(\\n    new Web3.providers.WebsocketProvider(\\n      \\\"wss://mainnet.infura.io/ws/v3/0b2f2a5026264b57b6d698b480332e89\\\"\\n    )\\n  ),\\n  ...\\n};\\n```\\n\\n```\\noptions.messageProvider\\n```\\n\\nThis is an instance of MessageProviderIpfs which uses a [js-ipfs](https://github.com/ipfs/js-ipfs) node with pubsub support\\n\\n```JavaScript\\nconst ipfs = new Ipfs({\\n  repo: 'robonomics-example',\\n  relay: {\\n    enabled: true,\\n    hop: {\\n      enabled: true\\n    }\\n  },\\n  EXPERIMENTAL: {\\n    pubsub: true\\n  },\\n  config: {\\n    Addresses: {\\n      Swarm: [\\n        '/dns4/ws-star.discovery.libp2p.io/tcp/443/wss/p2p-websocket-star',\\n        '/dns4/1.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/2.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/',\\n        '/dns4/3.wsstar.aira.life/tcp/443/wss/p2p-websocket-star/'\\n      ]\\n    },\\n    Bootstrap: [\\n      '/dns4/ams-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLer265NRgSp2LA3dPaeykiS1J6DifTC88f5uVQKNAd',\\n      '/dns4/lon-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLMeWqB7YGVLJN3pNLQpmmEk35v6wYtsMGLzSr5QBU3',\\n      '/dns4/nyc-1.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLueR4xBeUbY9WZ9xGUUxunbKWcrNFTDAadQJmocnWm',\\n      '/dns4/nyc-2.bootstrap.libp2p.io/tcp/443/wss/ipfs/QmSoLV4Bbm51jM9C4gDYZQ9Cy3U6aXMJDAbzgu2fzaDs64',\\n      '/dns4/node0.preload.ipfs.io/tcp/443/wss/ipfs/QmZMxNdpMkewiVZLMRxaNxUeZpDUb34pWjZ1kZvsd16Zic',\\n      '/dns4/node1.preload.ipfs.io/tcp/443/wss/ipfs/Qmbut9Ywz9YEDrz8ySBSgWyJk41Uvm2QJPhwDJzJyGFsD6',\\n      '/dns4/1.pubsub.aira.life/tcp/443/wss/ipfs/QmdfQmbmXt6sqjZyowxPUsmvBsgSGQjm4VXrV7WGy62dv8',\\n      '/dns4/2.pubsub.aira.life/tcp/443/wss/ipfs/QmPTFt7GJ2MfDuVYwJJTULr6EnsQtGVp8ahYn9NSyoxmd9',\\n      '/dns4/3.pubsub.aira.life/tcp/443/wss/ipfs/QmWZSKTEQQ985mnNzMqhGCrwQ1aTA6sxVsorsycQz9cQrw'\\n    ]\\n  }\\n})\\n\\nconst options = {\\n  messageProvider: new MessageProviderIpfs(ipfs),\\n  ...\\n};\\n```\\n\\n```\\noptions.account\\n```\\n\\nThis is an account object which will be used to sign messages. It's necessary to specify either account address (that one must be unlocked) or a private key (the address will be recovered from the given private key).\\n\\nOption `isSignPrefix` tells whether or not a prefix must be appended. Default is `true`.\\n\\n```JavaScript\\nconst options = {\\n  account: {\\n    address: '0x0000000000000000000000000000000000000000',\\n    privateKey: '0x0000000000000000000000000000000000000000000000000000',\\n    isSignPrefix: true\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.ens\\n```\\n\\nThis is a `ens` contract object. This one is not required. If it's necessary you may specify `address` of the contract if the network is not set to mainnet. `suffix` may be `sid` for sidechain or `eth` for mainnet. `eth` is default. `version` is the version of Robonomics Network. Default is the latest deployed version.\\n\\n```JavaScript\\nconst options = {\\n  ens: {\\n    address: '0x314159265dD8dbb310642f98f50C066173C1259b',\\n    suffix: 'eth',\\n    version: 5\\n  },\\n  ...\\n};\\n```\\n\\n```\\noptions.lighthouse\\n```\\n\\nENS name of a lighthouse, not required. Default is `airalab.lighthouse.5.robonomics.eth`. It's possible to specify only the first part of the name, like `airalab`.\\n\\n```JavaScript\\nconst options = {\\n  lighthouse: 'airalab.lighthouse.5.robonomics.eth',\\n  ...\\n};\\n```\\n\\nIt's necessary to wait until full initialization\\n\\n```JavaScript\\nconst options = {...};\\nconst robonomics = new Robonomics(options);\\nrobonomics.ready().then(() => {\\n  console.log('Robonomics instance ready')\\n})\\n```\\n\\n## API\\n\\n### Messages\\n\\n#### Demand \\n\\nThe message specification\\n\\n```JavaScript\\nconst demand = {\\n  // REQUIRED\\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost\\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED \\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  validatorFee: 0,                                              // validator fee \\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendDemand`\\n\\nSigning and broadcasting the demand message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendDemand(demand).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onDemand`\\n\\nListens to demand messages with a defined model. If model is `null` returns any demand message.\\n\\n```JavaScript\\nrobonomics.onDemand(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Offer \\n\\nThe message specification\\n\\n```JavaScript\\nconst offer = {\\n  // REQUIRED \\n  model: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf1M\\\",      // ipfs hash of the model \\n  objective: \\\"QmSt69qQqGka1qwRRHbdmAWk4nCbsV1mqJwd8cWbEyhf2M\\\",  // ipfs hash of the objective\\n  token: robonomics.xrt.address,                                // payment token address\\n  cost: 1,                                                      // cost \\n  deadline: 9999999,                                            // until which block demand is valid\\n\\n  // NOT REQUIRED\\n  lighthouse: \\\"0x0000000000000000000000000000000000000000\\\",     // lighthouse address, by default the initialization address\\n  lighthouseFee: 0,                                             // lighthouse fee\\n  validator: \\\"0x0000000000000000000000000000000000000000\\\",      // validator address if necessary\\n  nonce: 1                                                      // index number \\n};\\n```\\n\\n`robonomics.sendOffer`\\n\\nSigns and broadcasts an offer message. A liability is returned as promise\\n\\n```JavaScript\\nrobonomics.sendOffer(offer).then(liability => {\\n  console.log(liability.address);\\n});\\n```\\n\\n`robonomics.onOffer`\\n\\nListens to offer messages with a defined model. If model is `null` returns any offer message\\n\\n```JavaScript\\nrobonomics.onOffer(model, message => {\\n  console.log(message);\\n});\\n```\\n\\n#### Result \\n\\nThe message specification\\n\\n```JavaScript\\nconst result = {\\n  // REQUIRED \\n  liability: \\\"0x0000000000000000000000000000000000000000\\\",  // liability contract address\\n  success: true,                                            // status of the task\\n  result: \\\"QmWXk8D1Fh5XFJvBodcWbwgyw9htjc6FJg8qi1YYEoPnrg\\\"  // ipfs hash of the rosbag log file\\n};\\n```\\n\\n`robonomics.sendResult`\\n\\nSigns and broadcasts a result message\\n\\n```JavaScript\\nrobonomics.sendResult(result).then(() => {\\n  console.log(\\\"ok\\\");\\n});\\n```\\n\\n`robonomics.onResult`\\n\\nListens to result messages. These results may be not valid. Valid results are stored in a liability contract\\n\\n```JavaScript\\nrobonomics.onResult(result => {\\n  console.log(result);\\n});\\n```\\n\\n### Smart Contracts \\n\\n#### Liability \\n\\n`liability.getInfo`\\n\\nReturn a property object of the contract\\n\\n```JavaScript\\nliability.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    model,\\n    objective,\\n    result,\\n    token,\\n    cost,\\n    lighthouseFee,\\n    validatorFee,\\n    demandHash,\\n    offerHash,\\n    promisor,\\n    promisee,\\n    lighthouse,\\n    validator,\\n    isSuccess,\\n    isFinalized\\n  }\\n  */\\n});\\n```\\n\\n`liability.onResult`\\n\\nWaits until a liability is finished. Returns a result\\n\\n```JavaScript\\nliability.onResult().then(result => {\\n  console.log(result);\\n});\\n```\\n\\n#### Lighthouse \\n\\n`robonomics.lighthouse.getInfo`\\n\\nReturns a property object of the contract\\n\\n```JavaScript\\nrobonomics.lighthouse.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    minimalStake,\\n    timeoutInBlocks,\\n    keepAliveBlock,\\n    marker,\\n    quota\\n  }\\n  */\\n});\\n```\\n\\n`robonomics.lighthouse.getProviders`\\n\\nReturns a list of providers on the lighthouse\\n\\n```JavaScript\\nrobonomics.lighthouse.getProviders().then(list => {\\n  console.log(list);\\n});\\n```\\n\\n##### Creation of a new lighthouse\\n\\n```JavaScript\\nconst minimalFreeze = 1000      // Wn\\nconst timeout = 25              // blocks\\nconst name = 'mylighthouse'     // lighthouse name\\nrobonomics.factory.methods.createLighthouse(minimalFreeze, timeout, name).send({ from: robonomics.account.address })\\n    .then((tx) => console.log(tx))\\n\\nrobonomics.factory.onLighthouse((lighthouse) => {\\n    console.log(lighthouse.name)\\n})\\n```\\n\\n##### Become a provider \\n\\nPreliminarily you must call `approve` for the tokens `XRT`\\n\\n```JavaScript\\nconst name = \\\"mylighthouse\\\";    // lighthouse name\\nconst stake = 1000;             // Wn\\nrobonomics.lighthouse.methods\\n  .refill(stake)\\n  .send({ from: robonomics.account.address })\\n  .then(tx => console.log(tx));\\n```\\n\\n#### Token \\n\\n`robonomics.xrt.getInfo`\\n\\nReturns property object of the token\\n\\n```JavaScript\\nrobonomics.xrt.getInfo().then(data => {\\n  console.log(data);\\n  /*\\n  {\\n    name,\\n    totalSupply,\\n    decimals,\\n    symbol\\n  }\\n  */\\n});\\n```\\n\\n##### Check balance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .balanceOf(robonomics.account.address)\\n  .call()\\n  .then(balance => console.log(balance));\\n```\\n\\n##### Check allowance \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .allowance(robonomics.account.address, robonomics.factory.address)\\n  .call()\\n  .then(allowance => console.log(allowance));\\n```\\n\\n##### Approve \\n\\n```JavaScript\\nrobonomics.xrt.methods\\n  .approve(robonomics.lighthouse.address, 100)\\n  .send({\\n    from: robonomics.account.address\\n  })\\n  .then(tx => console.log(tx));\\n```\\n\\n## Links \\n\\n- [Website](https://robonomics.network/)\\n- [Minimal template of dApp](https://github.com/airalab/vue-dapp-robonomics-template)\\n- [dApp example](https://codesandbox.io/s/robonomics-vue-template-ewuiw)\\n\"}},{\"node\":{\"id\":\"36b6f6a903dee1ebbb9751409ed0db96\",\"title\":\"How Robonomics Network Works\",\"path\":\"/docs/en/robonomics-how-it-works/\",\"content\":\"\\nIn this section we will discuss the Robonomics Network scenario.\\n\\nThere are few main parts in the Robonomics network:\\n\\n- IPFS for the messages exchanging\\n- the Ethereum blockchain for storing new liability contracts\\n- a provider that is responsible for matching messages\\n- an agent\\n\\nLet's have a look at the following diagram that describes the scenario without any additional details:\\n\\n![The main scenario of Robonomics Network](../images/robonomics_network_scenario.jpg \\\"The main scenario of Robonomics Network\\\")\\n\\nThere are three types of [messages](/docs/market-messages) in IPFS: Demand, Offer, Result.\\n\\n**Below there is the specification for a Demand message:**\\n\\n| Field         | Type                      | Description                                       | Example                                           |\\n|-------------- |-------------------------  |------------------------------------------------   |------------------------------------------------   |\\n| model         | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model Identifier                   | QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC    |\\n| objective     | [ipfs_common/Multihash](/docs/robonomics-liability-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    | QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r    |\\n| token         | ethereum_common/Address   | Operational token address                         | 0xbD949595eE52346c225a19724084cE517B2cB735        |\\n| cost          | ethereum_common/UInt256   | CPS behavioral model implementation cost          | 1                                                 |\\n| lighthouse    | ethereum_common/Address   | Lighthouse address                                | 0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1       |\\n| validator     | ethereum_common/Address   | Observing network address                         | 0x0000000000000000000000000000000000000000        |\\n| validatorFee  | ethereum_common/UInt256   | Observing network commission                      | 0                                                 |\\n| deadline      | ethereum_common/UInt256   | Deadline block number                             | 6393332                                           |\\n| sender        | ethereum_common/Address   | Message sender address                            | 0x0000000000000000000000000000000000000000        |\\n| signature     | std_msgs/UInt8[]          | Sender’s digital signature                        | 0x23bc…c617                                       |\\n\\n<!--\\n=============== ============================================================== ================================================ ================================================\\n     Field                                   Type                                                Description                                        Example\\n=============== ============================================================== ================================================ ================================================\\n  model          :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model Identifier                  QmfXHZ2YkNC5vRjp1oAaRoDHD8H3zZznfhBPasTu348eWC\\n  objective      :ref:`ipfs_common/Multihash <IPFS-Common-Multihash.msg>`       CPS behavioral model parameters in rosbag file   QmUo3vvSXZPQaQWjb3cH3qQo1hc8vAUqNnqbdVABbSLb6r\\n  token          :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Operational token address                        0xbD949595eE52346c225a19724084cE517B2cB735\\n  cost           :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   CPS behavioral model implementation cost         1\\n  lighthouse     :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Lighthouse address                               0xa1b60ED40E5A68184b3ce4f7bEf31521A57eD2dB1\\n  validator      :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Observing network address                        0x0000000000000000000000000000000000000000\\n  validatorFee   :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Observing network commission                     0\\n  deadline       :ref:`ethereum_common/UInt256 <Ethereum-common-UInt256.msg>`   Deadline block number                            6393332\\n  sender         :ref:`ethereum_common/Address <Ethereum-common-Address.msg>`   Message sender address                           0x0000000000000000000000000000000000000000\\n  signature      std_msgs/UInt8[]                                               Sender's digital signature                       0x23bc...c617\\n=============== ============================================================== ================================================ ================================================\\n-->\\n\\nAn Offer message has the same fields but instead of `validatorFee` there is a `lighthouseFee` field. This field determines the amount of fee for a lighthouse.\\n\\nNow let's have a look at the following diagram and walk step by step from the moment of publishing messages to a liability finalization.\\n\\n![Robonomics Network detailed scenario](../images/robonomics_network_detailed_scenario.jpg \\\"Robonomics Network detailed scenario\\\")\\n\\nA liability contract is created only if the following fields match: `model`, `objective`, `token`, `cost`. A provider of Robonomics Network watches every message and finds those ones that have a match.\\nAfter the match is found the provider calls `createLiability(demand, offer)` method from the contract factory where `demand` and `offer` are serialized.\\n\\nBelow is the package diagram for the Robonomics communication stack:\\n\\n![Robonomics communication stack](../images/robonomics_network_communication_stack.jpg \\\"Robonomics communication stack\\\")\\n\\nThe factory deserializes arguments and recovers *promisee* and *promisor* addresses from signatures.\\n\\nNext step is token transfer. The factory transfers **cost** tokens from the *promisee* address and **validatorFee** and **lighthouseFee** from the *promisor* address to the new liability address.\\n\\n> - **You should approve sufficient amount of tokens for the factory.**\\n> - **It's not required to approve tokens from the *promisor* address if fees are null.**\\n\\nNow the factory emits a NewLiability event with the liability address. An agent gets the address, reads fields, perform a task and at the same time writes a log file in rosbag format.\\n\\nWhen the work is done the agent sends a Result message with the following fields: hash of the rosbag file, a success flag, a signature. If the **validator** field is not null it means that only validator is able to finalize the liability.\\n\\nAfter the successful liability finalization the agent gets **cost** tokens. Otherwise, the *promisee* gets tokens back.\"}},{\"node\":{\"id\":\"a66777c01631c978a37c64e440a5c26b\",\"title\":\"Robonomics DApp Overview\",\"path\":\"/docs/en/robonomics-dapp-overview/\",\"content\":\"\\nYou can operate with Robonomics Network using the interface of [Robonomics Network Dapp (decentralized application)](https://dapp.robonomics.network/#/). It is available in browsers with [Metamask extension](https://metamask.io). On the first page you will see the statistics of the network:\\n\\n![Robonomics DApp's first page](../images/robonomics_dapp_first_page.jpg \\\"Robonomics DApp's first page\\\")\\n\\nLet's have a look at the bottom table \\\"Robonomics Telemetry\\\".\\n\\nEvery time an instance of AIRA is launched it broadcasts a piece of information about itself. Usually it takes some time for the Dapp to receive data from an instance of AIRA.\\n\\nHave a brief look at the page [\\\"AIRA installation\\\"](/docs/aira-installation) to understand where `IPNS` and `Address Eth` came from.\\n\\n## IPNS\\n\\nYou can treat it as a unique identifier of your instance in IPFS network. Under that name AIRA publishes metadata about itself.\\n\\n## Address Eth\\n\\nBy default AIRA generates new Ethereum address for you (it's [possible](/docs/aira-faq#how-to-change-ethereum-address-of-aira) to generate new one).\\n\\nIt's mainly used to sign all the outcoming messages.\\n\\n## Lighthouse\\n\\nIn Robonomics Network an agent must choose a lighthouse to work on. By default it's `airalab.lighthouse.5.robonomics.eth`.\\n\\nYou can choose existing one or create your own on [Lighthouses](https://dapp.robonomics.network/#/lighthouse) page.\\n\\n## Peers\\n\\nThe amount of IPFS pubsub [peers](/docs/aira-faq#how-to-check-the-quantity-of-ipfs-peers).\\n\\n## Date\\n\\nThe date and time of last update\\n\\n## Network\\n\\nRobonomics Network officially works in Ethereum Mainnet.\\nThere is also [Sidechain](https://github.com/airalab/airalab-sidechain) which is mostly for testing purpose.\\n\\n\\n\"}},{\"node\":{\"id\":\"ed2fcf8244afd9c0bdfc979b0225ebe1\",\"title\":\"Contracts deployment\",\"path\":\"/docs/en/robonomics-contracts-deployment/\",\"content\":\"\\nRobonomics network works on top of the existing Ethereum network. The protocol is implemented by smart contracts. A source code is on [Github](https://github.com/airalab/robonomics_contracts). Airalab team deploys new version of contracts and supports a current one. \\n\\nIn this lesson we are going to learn more about these contracts. To do this we will deploy our test copy. Also we are going to use these contracts in the future lessons. \\n\\nYou need a client running Ethereum node. You can use either one of existing network (e.g. Mainnet, Ropsten, Kovan) or your local one. For testing purpose we suggest to use this [docker container](https://github.com/f-o-a-m/cliquebait) \\n\\n    $ docker run --rm -d -p 9545:8545 -p 9546:8546 foamspace/cliquebait:latest\\n\\nNext step is obtain a copy of robonomics contracts source code:\\n\\n    $ git clone --recursive https://github.com/airalab/robonomics_contracts\\n\\nA file truffle.js contains available networks for migration. We will work with development network. When you are in `robonomics_contracts` directory install dependencies and run a migration:\\n\\n    npm install // to install dependencies\\n    truffle migrate --network development\\n\\nIt's time to learn how to create a new lighthouse. For more information about Robonomics network and Lighthouse in particular read [white paper](http://static.robonomics.network/docs/book-the-economy-of-robots-1-2017/robonomics.network-book-the-economy-of-robots-1-2017-en.pdf). Briefly lighthouse o distributes the running time of providers. Every lighthouse serves its own broadcast channel. Ask and Bid messages come into this channel. XRT tokens are used as a payment. \\n\\nWhen XRT contracts was deployed some tokens were issued on our account. Let's check the balance:\\n\\n    $ truffle --network development console\\n    > xrt = XRT.at(XRT.address)\\n    > xrt.balanceOf(web3.eth.accounts[0])\\n\\nAnd that's how we create a lighthouse:\\n\\n    > factory = LiabilityFactory.at(LiabilityFactory.address)\\n    > tx = factory.createLighthouse(1000, 10, \\\"test\\\")\\n    > tx.then(x => {laddress = x.logs[0].args.lighthouse})\\n    > l = LighthouseLib.at(laddress)\\n\\nInstead of deploying a lighthouse contract every time we need a new one, we ask a factory to do this job. A `l` variable contains lighthouse instance. The lighthouse should be able to spend our tokens. Let's make an approve and check everything went well:\\n\\n    > xrt.approve(l.address,1000)\\n    > xrt.allowance(web3.eth.accounts[0],l.address)\\n\\nAnd a very important step is become a worker:\\n\\n    > l.refill(1000)\\n\\nEach worker has to put a stake. In this case it's 1000 Wn.\\n\\nBelow is a table of our addresses:\\n\\n| Contract          | Address                                       | ENS name                          |\\n|------------------ |--------------------------------------------   |---------------------------------- |\\n| ENSRegistry       | 0x80c77a7de64a15450bb8cf45ece4fbb7bae6fb49    |                                   |\\n| XRT               | 0x673583a369eb3a830a5571208cf6eb7ce83987f8    | xrt.3.robonomics.eth              |\\n| LiabilityFactory  | 0x1b3190e00c1903266862af1f31714d4b81ef59b2    | factory.3.robonomics.eth          |\\n| Lighthouse        | 0xd2b78c032b6c8851a8b6cbf950caa02a77618d8e    | test.lighthouse.3.robonomics.eth  |\\n\"}},{\"node\":{\"id\":\"62b821a14600939c8bfa0c644043fd11\",\"title\":\"Robonomics Coffee\",\"path\":\"/docs/en/robonomics-coffee/\",\"content\":\"\\n## About\\n\\n\\\"Robonomics coffee\\\" - is a smart coffee machine integrated in  [Robonomics Network](https://robonomics.network/).\\nThis project aims to show Robonomics potential in the IoT sphere by a real-world example.\\n\\nhttps://www.youtube.com/watch?v=Z8pXcLjlJnQ\\n\\n## How to make coffee?\\n\\nIn order to have a cup of delicious coffee, a customer should send some funds (1 Statemine's token \\n[ACT](https://statemine.statescan.io/asset/3077), id=3077) to the address of a coffee machine in Statemine parachain.\\nAfter that the pouring process is started and action log is published in the \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer) \\nvia Datalog function.\\n\\n**NOTE!** *You may use **any** token on Statemine, more on that [here](#things-to-point-out)*\\n\\n## How it works?\\n\\nThere is a single-board computer attached to the body of the coffee machine. This computer is the center of the entire\\nsystem, where all the processes are happening. The single-board (Raspberry Pi 4) is connected to the control panel of the \\ncoffee machine via jumper breadboard wires and GPIO interface. RPI is also the one interacting with Robonomics and\\nStatemine parachains. Sample flowchart of the workflow is presented below.\\n\\n![Workflow](../images/robonomics-coffee/workflow.png)\\n\\n## Tutorial\\n\\n### Used hardware\\n- Coffee machine  \\nThe very important criteria for a coffee machine was the ability to solder some wires to the control panel since GPIO\\nwas selected as a communication interface being the easiest one to implement. Several options were considered\\n([Saeco PicoBaristo HD 8925](https://www.philips.com/c-p/SM5478_10R1/picobaristo-super-automatic-espresso-machine),\\n[De'Longhi ESAM3200.S](https://www.delonghi.com/en/esam3200-s-ex-1-magnifica-automatic-coffee-maker/p/ESAM3200.S%20EX%3A1)). \\nAs may be seen, no touchscreen and no bells and whistles, just buttons and espresso. Finally,\\n[De’Longhi Magnifica ECAM 22.110](https://www.delonghi.com/en/ecam22-110-sb-magnifica-s-automatic-coffee-maker/p/ECAM22.110.SB) \\nwas chosen as it is cheap and has an easy-removed front panel.\\n- Single-board [Raspberry Pi 4B](https://www.raspberrypi.com/products/raspberry-pi-4-model-b/) (2 GB) with Ubuntu server\\ninstalled via [RPi Imager](https://www.raspberrypi.com/software/).\\n- 5V adapter and USB A to USB type C cable ([this](https://www.amazon.com/Charger-FOBSUNLAND-Universal-Adapter-S6-Note/dp/B073Q1N8FL/ref=sr_1_2_sspa?keywords=5v+adapter&qid=1636572682&sr=8-2-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExQ1JDSkQ5NlBGTFU2JmVuY3J5cHRlZElkPUEwODgwMDgzMUJKMU5YVEdXRjdBWCZlbmNyeXB0ZWRBZElkPUEwMTc3NjgwMldDQ1lJWUkwTVY4VSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=) and [this](https://www.amazon.com/Charger-Braided-Charging-Compatible-Samsung/dp/B0794M53HQ/ref=sr_1_1?keywords=usb+a+type+c+cable&qid=1636572602&sr=8-1) are examples)\\n- A set of F-M, M-M, F-F jumper wires, a breadboard (again, [this](https://www.amazon.com/Standard-Jumper-Solderless-Prototype-Breadboard/dp/B07H7V1X7Y/ref=sr_1_13?keywords=breadboard&qid=1636572396&sr=8-13) is just an example).\\n- Transistor and a resistor(optionally). More on that [later](#4-circuit).\\n\\n### Tools\\n- A set of screwdrivers.\\n- Soldering iron with some solder and resin.\\n- Multimeter.\\n\\n### Hardware installation\\n#### 1. Disassembly the coffee machine. \\nThere is a [sample tutorial](https://www.youtube.com/watch?v=7Y5NCePD0PM) \\non YouTube. Your goal is to remove the front panel (it won't be used anymore, so this is a thing to improve to hide all\\nthe wires) and detach the control PCB.\\n\\n![Detached PCB](../images/robonomics-coffee/detached_pcb.png)\\n\\n#### 2. Solder two wires to the button you need.\\nSolder them to the isolated contacts (in our case - two bottom contacts).\\nYou can use any wires, but keep im mind that in the end there should be an M-wire to put it into the breadboard.\\n\\n![Soldered Wires](../images/robonomics-coffee/soldered_wires.png)\\n\\n#### 3. Assemble the entire coffee machine back leaving the front panel removed.\\n\\n![Coffee machine Overview](../images/robonomics-coffee/coffee_machine_overview.png)\\n\\n#### 4. Circuit  \\nOverall circuit is presented below, this is a very simple transistor switch, we used **R<sub>1</sub>**=1k&Omega;, a npn \\ntransistor **Q<sub>1</sub>** (*h<sub>fe</sub>*=40, *U<sub>ce</sub>*>5V, *I<sub>c</sub>*>0.015A, sample [here](https://alltransistors.com/adv/pdfdatasheet_rca/2n1613.pdf), but almost any general \\ntransistor suites, since this is a switch) and a small 3.3V diode **D** in base circuit found in the storage of our lab:) One \\ncan use a MOSFET transistor as well.\\n\\n![Circuit](../images/robonomics-coffee/circuit.png)\\n\\n![Circuit Assembled](../images/robonomics-coffee/circuit_assembled.png)\\n\\n#### 5. Connect coffee machine and RPI\\nConnect wires marked as *RPI GND* and *RPI GPIO Pin* to pins **GND** and **21** respectively. RPI GPIO scheme is presented below.\\nWires marked as *Button+* and *Button-* should be connected to the left button contact and right button contact \\nrespectively.\\n\\n![RPI GPIO](../images/robonomics-coffee/rpi_gpio.png)\\n\\n### Software installation\\n\\nTime to turn the Raspberry Pi into blockchain-powered coffee maker!  \\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\n- Prepare the RPI for Substrate libs ([source](https://www.rust-lang.org/tools/install)):\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nrustup default nightly\\n```\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\n```\\n- Install project requirements\\n```bash\\npip3 install -r requirements.txt\\n```\\n\\n#### Option 2: Using Everscale Network.\\n\\n- Install gpiozero library ([source](https://gpiozero.readthedocs.io/en/stable/installing.html)) and reboot:\\n```bash\\nsudo apt update\\nsudo apt install python3-gpiozero\\nsudo pip3 install gpiozero\\nsudo reboot\\n```\\n\\n- Clone the repository\\n```bash\\ngit clone https://github.com/Multi-Agent-io/robonomics-coffee-maker\\ncd robonomics-coffee-maker\\n```\\n\\n- Install Node.js requirements\\n```bash\\nnpm install @eversdk/core\\nnpm install python-shell\\nmv eversdk.node ~/.tonlabs/binaries/1\\ngit clone https://github.com/tonlabs/ever-sdk-js\\ncd ever-sdk-js/packages/lib-node\\nnpm install -g\\n```\\n\\nThe reason why we can't just npm install @eversdk/lib-node is because this library is not compiled for the ARM architecture.\\n\\n\\n### Account management\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nOn your PC install [Polkadot Extension](https://polkadot.js.org/extension/) and register a coffee machine account there. **Save \\nmnemonic seed phrase as it is going to be used later.**\\n\\n![Coffee machine Account](../images/robonomics-coffee/account.png)\\n\\nLogging actions in Robonomics is optional, you will need XRT on \\n[Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) for coffee machine account (it is the same across\\nnetworks) for this. If not, there will simply be an error message *\\\"Balance too low.\\\"*\\n\\n#### Option 2: Using Everscale Network.\\n\\nCreate an account in the Everscale with, for example mobile app. Save seed and activate a coffee-machine address there.\\nInsert this address in `main.js`\\n\\n### Run Robonomics coffee\\n\\n#### Option 1: Using Robonomics Parachain in Kusama Network\\n\\nRun this in corresponding network repo folder:\\n```bash\\npython3 main.py <previously saved seed in quotes>\\n```\\nYou should see the program waiting for ACT incomes:\\n\\n![Waiting for ACT](../images/robonomics-coffee/waiting_for_act.png)\\n\\nYou can send tokens from another account created the same way via `assets:transfer` *extrinsic* on \\n[Statemine](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fstatemine-rpc.polkadot.io#/explorer).\\n\\nAs soon as there is an income (positive change in `assets:account` *storage function* for address \\nderived from seed and for token id `3077`) the RPI triggers GPIO pin 18 and coffee machine starts making coffee and \\nrecords a datalog!\\n\\n![Making coffee](../images/robonomics-coffee/making_coffee.png)\\n\\n![Recorded Datalog](../images/robonomics-coffee/datalog.png)\\n\\n#### Option 2: Using Everscale Network.\\n\\nRun poller by \\n```bash\\nnode main.js\\n```\\n\\nThen send 0.5 EVR to the address specified in the `main.js` file. Everscale use case does not imply Datalog recording.\\n\\n## Things to point out\\n- This is a POC of a blockchain-driven IoT device, it has things to improve, wires to hide and functionality to implement.\\n- Token ID, the one, coffee machine is waiting to receive, is set\\n[here](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L27), **so you can use your own token**,\\nexisting one or newly created. To create one, go to \\n[Statemine Kusama parachain page](https://github.com/airalab/robonomics-wiki), `Network -> Assets -> Create`.\\nSet an ID there, complete the procedure and paste ID in the code.\\n\\n![Creating Any Token for Paying](../images/robonomics-coffee/create_token.png)\\n\\n\\n- Right now the only thing that matters for income tracker is the positive difference between current and previous\\nasset balance. This may be filtered [code](https://github.com/Multi-Agent-io/robonomics-coffee-maker/blob/master/statemine_monitor.py#L59).\\n- One may use QR-code for mobile apps for convenient transfers.\\n\\n![QR-codes](../images/robonomics-coffee/qr_codes.png)\\n\\n- Powered by [Robonomics](https://robonomics.network/), made by [Multi-Agent.io](https://multi-agent.io/).\"}},{\"node\":{\"id\":\"38460669f3a4268c03596c87a93416ce\",\"title\":\"Become a Provider\",\"path\":\"/docs/en/robonomics-become-a-provider/\",\"content\":\"\\nThis page describes how to create a lighthouse and become a provider in the Robonomics network.\\n\\n## Prepare an address\\n\\nFirst of all, an Ethereum address is required. You must have access to a private key of the address. In case you don't have one, below are steps to create an address via [Parity](https://www.parity.io/ethereum/).\\n\\n```\\n$ sudo snap install parity\\n$ parity.ethkey generate random\\nsecret:  15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539\\npublic: 38b800bfd90d486c78c646da79bb94b9d038aca8aad221062ce1b148df7764bfef02f6b3cf931786b6997540b798ea226ae60bd201c222d8f702e408a1a5cbff\\naddress: c531fa8f141493df3da264a864bdcbec19695b4c\\n```\\n\\nThe `secret` field is a private key, you'll need it to run the provider client. Save it to a file:\\n\\n```\\n$ echo '0x15abe71557c07b69537bbe4352ed10a057be89037c69d4b35556112519911539' > private.key\\n```\\n\\nThe next step is to deposit some ethers and XRT tokens to the address which is held in the `address` field.\\n\\n## Create a lighthouse\\n\\nGo to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse) and fill in a name in the right side:\\n\\n![The Right Side](../images/become_a_provider_1.jpg \\\"The Right Side\\\")\\n\\nClick on the `Create lighthouse and connect to the network` button and sign a transaction. After a while you should see:\\n\\n![Success of Creating a Lighthouse](../images/become_a_provider_2.jpg \\\"Success of Creating a Lighthouse\\\")\\n\\nNow it's time to put a stake. Select the new lighthouse and click `Connect to the network`:\\n\\n![Selecting the Lighthouse](../images/become_a_provider_3.jpg \\\"Selecting the Lighthouse\\\")\\n\\nOn this page in the `Provider` section click the `Approve` button, sign a transaction. When it's mined click the `Refill` button and do the same.\\n\\n## Install the client\\n\\nNow you need to install [robonomics-tools](https://github.com/airalab/robonomics-tools) at least 0.4.2 version. You can build from the source or do the following steps:\\n\\n**Make sure you have Nix and Stack installed:**\\n    \\n```\\n$ curl -sSL https://get.haskellstack.org/ | sh\\n$ curl https://nixos.org/nix/install | sh\\n```\\n\\n* Setup Airalab binary cache at [https://aira.cachix.org](https://aira.cachix.org/)\\n* Import Airalab channel:\\n\\n```\\n$ nix-channel --add http://aira.life/channels/aira-unstable/ aira\\n$ nix-channel --update\\n```\\n* Install from the binary cache:\\n\\n```\\n$ nix-env -iA aira.robonomics-tools\\n```\\n* Run the client:\\n\\n```\\n$ xrtd --lighthouse mobilerobotics.lighthouse.5.robonomics.eth --private $(cat private.key)\\n```\\n\\n**Get familiar with the `xrtd` options via `xrtd --help`.**\\n\\n## Test the provider\\n\\nTo test your provider go again to the lighthouse [dapp](https://dapp.robonomics.network/#/lighthouse/) and connect to the just created lighthouse.\\n\\nAt the bottom you should see the `TEST LIGHTHOUSE` section.\\n\\nClick on the `Demand` button and then on the `Offer` one. You should see something similar to:\\n\\n![Demand and Offer messages](../images/provider_mobilerobotics_demand_offer.jpg \\\"Demand and Offer messages\\\")\\n\\nDon't forget to sign every message with the MetaMask extension.\\n\\nFinally you should see a new liability contract created:\\n\\n![Liability is created](../images/provider_mobilerobotics_liability.jpg \\\"Liability is created\\\")\\n\"}},{\"node\":{\"id\":\"2d12347845d967b80ccebe4a8dac412a\",\"title\":\"Robonomics IO Overview\",\"path\":\"/docs/en/rio-overview/\",\"content\":\"\\nThe [crate](https://crates.robonomics.network/robonomics_io/index.html) provides a convenient way to interact with blockchain and includes a set of tools. The latest release can be found [here](https://github.com/airalab/robonomics/releases)\\n\\n```\\n% ./robonomics io\\nrobonomics-io 0.21.0\\nRobonomics Framework I/O operations\\n\\nUSAGE:\\n    robonomics io [FLAGS] [OPTIONS] <SUBCOMMAND>\\n\\nFLAGS:\\n        --dev        Specify the development chain\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nOPTIONS:\\n    -d, --base-path <PATH>        Specify custom base path\\n        --chain <CHAIN_SPEC>      Specify the chain specification (one of dev, local, or staging)\\n    -l, --log <LOG_PATTERN>...    Sets a custom logging filter. Syntax is <target>=<level>, e.g. -lsync=debug\\n\\nSUBCOMMANDS:\\n    help     Prints this message or the help of the given subcommand(s)\\n    read     Read information from device\\n    write    Write information into device\\n```\\n\\n## The Pipeline Philosophy \\n\\nThe tool is designed in order to be included in a pipeline chain of processes. From Unix user experience everyone is familiar with commands like:\\n\\n```\\nps aux | grep robonomics\\n```\\n\\nIt means standard output produced by the `ps` program becomes standard input for the `grep` program. \\n\\nThe `robonomics io` consists of several subcommands with reading, writing abilities or both. It treats everything as a virtual or physical device ([everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file))\\n\\n## Read Overview\\n\\nIn general `read` means it reads data from a device or a network and prints it in `stdout`.\\n\\nHow to use it for:\\n\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io read\\nrobonomics-io-read 0.4.0\\nRead information from device\\n\\nUSAGE:\\n    robonomics io read <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    help      Prints this message or the help of the given subcommand(s)\\n    ipfs      Download data from IPFS storage\\n    launch    Robot launch request events\\n    pubsub    Subscribe for broadcasing data\\n    sds011    Nova SDS011 particle sensor\\n```\\n\\n## Write Overview\\n\\nUsually it writes data to blockchain or publishes to pubsub channel. \\n\\nHow to use it for:\\n\\n* [datalog](/docs/rio-datalog)\\n* [ipfs](/docs/rio-ipfs)\\n* [launch](/docs/rio-launch)\\n\\n```\\n% ./robonomics io write\\nrobonomics-io-write 0.4.0\\nWrite information into device\\n\\nUSAGE:\\n    robonomics io write <SUBCOMMAND>\\n\\nFLAGS:\\n    -h, --help       Prints help information\\n    -V, --version    Prints version information\\n\\nSUBCOMMANDS:\\n    datalog    Data blockchainization subsystem command\\n    help       Prints this message or the help of the given subcommand(s)\\n    ipfs       Upload data into IPFS storage\\n    launch     CPS launch subsystem command\\n    pubsub     Broadcast data into PubSub topic\\n```\\n\\n## Local Testnet\\n\\nFor testing purpose it's possible to run the development environment:\\n\\n```\\n% ./robonomics --dev --rpc-cors all\\n```\\n\\n`--rpc-cors all` allows the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) to be connected to local node. After launching the node, go to the dapp, click on Robonomics icon in the upper left corner, choose Development and put node's local address\\n\\n![Robonomics Dapp Connect to Local Node](../images/robonomics-dapp-connect-local.jpg \\\"Robonomics Dapp Connect to Local Node\\\")\\n\\nFinally click Switch and you should be connected to the local node. Check out Accounts tab. There you can create new accounts and transfer tokens.\\n\\n\"}},{\"node\":{\"id\":\"7884b4cc30c48b7ecb83c871b9ada04d\",\"title\":\"Robonomics IO Launch\",\"path\":\"/docs/en/rio-launch/\",\"content\":\"\\nA simple way to turn on and off an IoT device or a robot. Basically sending \\\"ON\\\" will result in `true` state for a device, anything else will result in `false`.\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Accounts on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Usage\\n\\nTo see the result of transaction first of all run `read` part:\\n\\n```\\n% ./robonomics io read launch\\n```\\n\\nNow let's turn a robot on:\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nThen you should see in the first terminal window:\\n\\n```\\n% ./robonomics io read launch\\n5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH >> 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL : true\\n```\\n\\nLet's describe all the accounts and options above.\\n\\n* `-r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL` means robot's address\\n* `-s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` private key of the account to launch from (must have tokens for a transaction)\\n* `5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH` address that launches a robot\\n* `true` turn it on\\n\\nIf we pass anything else but \\\"ON\\\" the state becomes `false`\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"ON\\\" | ./robonomics io write launch -r 5CiPPseXPECbkjWCa6MnjNokrgYjMqmKndv2rSnekmSK2DjL -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\\nand\\n\\n```\\n% ./robonomics io read launch --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"0968e8bef3bf20db256bc7f5494181d0\",\"title\":\"Robonomics IO IPFS\",\"path\":\"/docs/en/rio-ipfs/\",\"content\":\"\\nIt serves downloading and uploading files from/to IPFS network\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Running [IPFS](https://ipfs.io/#install) daemon \\n\\n## Write\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\n## Read\\n\\n```\\n% echo QmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy | ./robonomics io read ipfs\\nHello Robonomics\\n```\\n\\n## Remote IPFS node\\n\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write ipfs --remote https://ipfs.infura.io:5001/\\nQmQAcvgXmcZEjXGibXGFcqdsvvrnWp3BguuubWhzSBZMXy\\n```\\n\\nThe same applies for `read`\\n\\n\"}},{\"node\":{\"id\":\"3cca167666ccf714908c2933bef57949\",\"title\":\"Robonomics IO Datalog\",\"path\":\"/docs/en/rio-datalog/\",\"content\":\"\\nDatalog module allows you to store any string on blockchain\\n\\nhttps://www.youtube.com/watch?v=rs67AMyd-gE\\n\\nFor the examples the development network is used. Check [this](/docs/robonomics-test-network-manual/) out to set it up for yourself.\\n\\n## Requirements\\n\\n* `robonomics` [executable](https://github.com/airalab/robonomics/releases)\\n* Account on parachain\\n\\nYou can find instructions on how to create an account [here](/docs/create-account-in-dapp)\\n\\n## Write\\n\\nAssuming local node is running:\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6\\n```\\n\\nwhere `0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6` is a private key for the account with tokens.\\nIn this example the public key is 5H3iRnX16DH2sb2RLxMM8UhDZTvJjP84EhhKXv3sCiEDq6bH. Let's go to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/)\\nand see what happened.\\n\\nIn the Dapp go to Developer -> Chain state. In the \\\"selected state query\\\" list choose datalog and below choose your account. Click plus button on the right and you should see the following:\\n\\n![Robonomics Chain State Datalog](../images/robonomics-dapp-chain-state-datalog.jpg \\\"Robonomics Chain State Datalog\\\")\\n\\n## Remote\\nIf your local node is configured differently from defaults or you have a remote node, it's possible to specify it with `--remote` option\\n\\n```\\n% echo \\\"Hello Robonomics\\\" | ./robonomics io write datalog -s 0xb046fc3c322e91e14a61ad4f08a3809ee0de7092e73aa9b3c2b642a0f476d4d6 --remote https://ipfs.infura.io:5001/\\n```\\n\"}},{\"node\":{\"id\":\"947fe30f2e8a50514cd07903c220de4c\",\"title\":\"Raspberry Setup\",\"path\":\"/docs/en/raspberry-setup/\",\"content\":\"\\nFor both methods, the first thing you need to do is setup a Raspberry Pi.\\n\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Then, insert the SD card and run the Imager program. From the menu, select 64-bit Ubuntu Server as the operating system and ensure to select your SD card from the storage dropdown, and then press `write`.\\n\\n![pi](../images/home-assistant/pi.png)\\n\\nOpen the SD card's storage from your computer and navigate inside the root folder of the card. The name of the folder should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Copy the below text and paste it into the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end (also you can use `arp -a`):\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\n\\nIn this example we can see that the Raspberry Pi's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\".\\n\\n## Home Assistant\\n\\nNow we need to install Home Assistant to the Raspberry Pi. Detailed instructions can be found [here](https://www.home-assistant.io/installation/linux#install-home-assistant-core). You need to install `Home Assistant Core`. It's actual version is 2021.11.5 and instruction assumes that we already have installed Python 3.9 or newer.\\n\\nUpdate your system and install necessary packages:\\n```bash\\nsudo apt-get update\\nsudo apt-get upgrade -y\\nsudo apt-get install -y python3 python3-dev python3-venv python3-pip libffi-dev libssl-dev libjpeg-dev zlib1g-dev autoconf build-essential libopenjp2-7 libtiff5 tzdata libcurl4-openssl-dev\\n```\\n\\nCreate user `homeassistant` and the directory for homeassistant core:\\n```bash\\nsudo useradd -rm homeassistant\\nsudo mkdir /srv/homeassistant\\nsudo chown homeassistant:homeassistant /srv/homeassistant\\n```\\n\\nNext up is to create and change to a virtual environment for Home Assistant Core. This will be done as the homeassistant account.\\n```bash\\nsudo -u homeassistant -H -s\\ncd /srv/homeassistant\\npython3.9 -m venv .\\nsource bin/activate\\n```\\n![terminal1](../images/home-assistant/terminal1.png)\\n\\nThen install required Python packages:\\n```bash\\npython3 -m pip install wheel\\npip3 install homeassistant==2021.11.5\\n```\\n\\nStart Home Assistant Core for the first time. This will complete the installation for you, automatically creating the `.homeassistant `configuration directory in the `/home/homeassistant` directory, and installing any basic dependencies:\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant$ hass\\n```\\n\\nYou can now reach your installation via the web interface on `http://%RASPBERRY_IP_ADDRESS%:8123`. \\nIn this example: `http://192.168.43.56:8123`\\n\\n> You don't need to connect you raspberry to the screen, you can open Web UI from any computer connected to your local network\\n\\nCreate user and finish setup (first setup is described [here](https://www.home-assistant.io/getting-started/onboarding/) in more details), then stop Home Assistant with `Ctrl+C`.\\n\\nAfter this installation process has been completed, from the `python_scripts` folder import some necessary scripts:\\n\\n```bash\\nmkdir python_scripts\\ncd python_scripts/\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/send_datalog.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/control.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/utils.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/create_config.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/decrypt.py\\nwget https://raw.githubusercontent.com/airalab/robonomics-smarthome/main/python_scripts/encrypt.py\\n```\\n\\nTo use Robonomics you need account (instructions of how to create it are [here](/docs/create-account-in-dapp/)). Add mnemonic or raw seed from it in `config.config` file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\n\\nIn this format:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\n\\n## Substrate Interface\\n\\nTo pub data to Robonomics you need to install `substrate-interface` python package (you need to install RUST before) to your raspberry. \\n\\nInstall RUST:\\n```bash\\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\nsource $HOME/.cargo/env\\nrustup default nightly\\n```\\n\\nAnd install necessary python packages to the virtual environment:\\n```bash\\npip3 install pynacl==1.4.0 packaging pycurl\\npip3 install substrate-interface==1.1.2 --use-feature=2020-resolver\\npip3 install python-miio==0.5.8 --use-feature=2020-resolver\\n```\\nBe sure that you-re on virtual environment:\\n\\n![terminal1](../images/home-assistant/terminal2.png)\\n\\n## Systemd services\\n\\nNow change user (you can run under any user, which allows you to use sudo):\\n\\n```bash\\n(homeassistant) homeassistant@ubuntu:/srv/homeassistant/python_scripts$ exit\\n```\\n\\nCreate new service for home assistant start: \\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/home-assistant@homeassistant.service \\n```\\n\\nPaste the following:\\n\\n```\\n[Unit]\\nDescription=Home Assistant\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/hass -c \\\"/home/%i/.homeassistant\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nDo the same for robonomics control service:\\n\\n```bash\\nubuntu@ubuntu:~$ sudo nano /etc/systemd/system/robonomics-control@homeassistant.service \\n```\\n\\nWith:\\n```\\n[Unit]\\nDescription=Robonomics Control\\nAfter=network-online.target\\n[Service]\\nType=simple\\nUser=%i\\nWorkingDirectory=/srv/%i/\\nExecStart=/srv/homeassistant/bin/python3.9 \\\"/srv/%i/python_scripts/control.py\\\"\\nEnvironment=\\\"PATH=/srv/%i/bin\\\"\\n\\n[Install]\\nWantedBy=multi-user.target\\n```\\n\\nAnd enable both services:\\n```bash\\nubuntu@ubuntu:~$ sudo systemctl enable home-assistant@homeassistant.service\\nubuntu@ubuntu:~$ sudo systemctl enable robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\"}},{\"node\":{\"id\":\"5de0ead864ea17ef3e9941cdd5f74687\",\"title\":\"Setup with Prepared Image\",\"path\":\"/docs/en/raspberry-image/\",\"content\":\"## Image\\nWe prepared an image to make it easier to use the Home Assistant with Xiaomi Miio and Robonomics with the Raspberry Pi.\\n\\nYou can get it here: [download image](https://ipfs.io/ipfs/bafybeihzzqoyycflxzxlxy2aplkzxo537ggqatdlbr24b4dnlyrtpkp2eu)\\n\\nSHA256 checksum: `7ec5ea99d7e339b54cbeaaae58c8295411769d27732ec2b5464dbb495ba24120`\\n\\nWhat preinstalled in the image:\\n- Ubuntu Server 21.10 (3/4/400): 64-bit server OS for arm64 archtectures\\n- Python 3.9.7\\n- Home Assistant Core 2021.11.5\\n- rustc 1.59.0-nightly (efec54529 2021-12-04)\\n- substrate-interface 1.1.2\\n- python-miio 0.5.8\\n\\n## How To Use The Prepared Image\\nInstall [Raspberry Pi Imager](https://www.raspberrypi.com/software/) on your computer. Insert SD card into your PC and run the Imager program. In `Operating System` select `Use custom` and choose the previously downloaded `.img.gz` file. Then select your SD card in the `Storage` dropdown and click `WRITE`.\\n\\n![imager](../images/home-assistant/use_custom_image.png)\\n![imager](../images/home-assistant/imager_prep.png)\\n\\nAfter writing is comleted, open the SD card's files on your computer and navigate inside the root folder of the card. The name should be something similar to `system-boot`.\\n\\nFind the file named `network-config` and open it in a text editor. Write this to the file:\\n```\\nversion: 2\\nethernets:\\n  eth0:\\n    dhcp4: true\\n    optional: true\\nwifis:\\n  wlan0:\\n    dhcp4: true\\n    optional: true\\n    access-points:\\n      \\\"YOUR_WIFI_NAME\\\":\\n        password: \\\"YOUR_WIFI_PASSWORD\\\"\\n```\\n**Make sure that you input your actual wifi name and your wifi password.** Then you need to save the file, and insert the SD card to the Raspberry Pi and turn it on. It must connect to your wi-fi network, now you need to find its address. Firstly find your address in the local network with:\\n\\n```bash\\nip a\\n```\\nIt must look like `192.168.xx.xx` or `172.xx.xx.xx`.\\n\\nThen scan the network with your address and zero in the end:\\n\\n```bash \\n$ sudo nmap -sP 192.168.xx.0/24\\nStarting Nmap 7.80 ( https://nmap.org ) at 2020-06-26 13:50 CEST\\nNmap scan report for _gateway (192.168.43.1)\\nHost is up (0.015s latency).\\nMAC Address: 8E:F5:A3:DB:03:27 (Unknown)\\nNmap scan report for ubuntu (192.168.43.56)\\nHost is up (0.049s latency).\\nMAC Address: DC:A6:32:02:46:50 (Raspberry Pi Trading)\\nNmap scan report for LAPTOP-27UBLNO7 (192.168.43.234)\\nHost is up (0.00057s latency).\\nMAC Address: 7C:B2:7D:9E:95:DA (Intel Corporate)\\nNmap scan report for ed-vm (192.168.43.138)\\nHost is up.\\nNmap done: 256 IP addresses (4 hosts up) scanned in 2.07 seconds\\n```\\nThere raspberry's address is `192.168.43.56`. Now you can connect to it over ssh:\\n```bash\\nssh ubuntu@192.168.43.56\\n```\\nPassword is \\\"ubuntu\\\". Then follow the instructions to change the password.\\n\\nThen you need to write the seed from your Robonomics account to config file. Open it:\\n```bash\\nsudo -u homeassistant -H -s\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add mnemonic:\\n```\\n[user]\\nSEED = <your mnemonic or raw seed>\\n```\\nThen restart Robonomics Control service:\\n```bash\\nsystemctl restart robonomics-control@homeassistant.service\\n```\\n\\nAfter that you can connect your devices:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n\"}},{\"node\":{\"id\":\"376c7e94c7eeadf889cc04d7064c4bdf\",\"title\":\"R&D Based on Robonomics Network\",\"path\":\"/docs/en/r-and-d-based-on-robonomics-network/\",\"content\":\"\\nFor over 4 years, the Robonomics project participants completed 13 R&D projects in the process of writing the current version of the Robonomics platform, including:\\n\\n### Launching a drone under the control of a decentralized computer.\\n2016 - Successful field test of 3DR X8 drone compatibility with Drone Employee software.\\nBelow you can observe a workflow in which a person sends a Drone transaction through the Ethereum Blockchain.\\n\\nhttps://www.youtube.com/watch?v=V_3rcP2Duv0&t=1s\\n\\n### Management of a fleet of drones in a decentralized network.\\n[Distributed Sky](https://airmarket.io/wp-content/uploads/2018/09/Distributed-Sky-Whitepaper-v3.0.pdf) is the backbone of the Unmanned aircraft system traffic management (UTM). It uses a global network of computers to process and store identities, traffic and other sensitive information, and uses cryptography to make the UTM process secure and scalable.\\nBelow is the video of Drone Passport agent in action.\\n\\nhttps://www.youtube.com/watch?v=yxGTOkGkBJ8\\n\\n### Tokenization of data from IoT devices.\\n\\nThe 4th industrial revolution is flying the flag of CPSs’ total integration into mass production and rendering services. Machines do not engage in empty talk, they are honest in their work and can be an independent party supplying information, based on algorithmic analysis of which the network itself can emit new units of any value.\\nValues based on the labor of machines will be much more interesting for the new generation than other values, the emission of which is built on any other principle. More information available [here](https://blog.aira.life/tokenization-and-the-4th-industrial-revolution-3208022be747)\\n\\n### Digital markets for robots.\\n\\n### Industrial zone management with capital.\\n[The article](https://ieeexplore.ieee.org/abstract/document/8525391) presents the architecture of communication protocol for modern industrial processes and business based on cyber-physical systems - Industry 4.0. The main attention is paid to one of the key trends of this concept - to economical autonomous agents i.e. to robots or smart things, which are able to make decisions independently about their economic actions. Agents begin to fully participate in business processes, so it is important to automate the processes and ensure formal and secure communication between multiple heterogeneous agents, taking into account the economic component of the industry. The article shows how to organize economic interaction between agents using a peer-to-peer network based on decentralized Blockchain technology and smart contracts. More information about Industry 4.0 may be found in a video below.\\n\\nhttps://www.youtube.com/watch?v=yuxOF_z70us\\n\\n### Drones, sensors, and blockchain for monitoring the quality of water on the Volga.\\nAs part of [this river project](https://github.com/airalab/drone_on_volga), the drone offers its services through a web application allowing any user to request the service. Typically, the mission generates parameters such as drone position, travel speed, measured water quality parameters, and other minor requirements.\\nThe Robonomics network is used to communicate with the robot. With its help, the robot can offer its services, and citizens or government officials can order them by making a cryptocurrency payment through the website. The Robonomics network is built on the Ethereum blockchain platform and the IPFS protocol, which record the hash of sensor measurements in the public blockchain and thus protect historical data from possible falsification.\\nFascinating video about experiments with water drone is below.\\n\\nhttps://www.youtube.com/watch?v=Mtqm5y6Bolo\\n\\n### Civilian observatory networks.\\nIn August 2018 Airalab with support of Smart Distribution (Libelium distributor in Russia) [set up a measuring network in a living district in Tolyatti, Russia](https://www.libelium.com/libeliumworld/success-stories/preventing-asthsma-sensor-network-air-quality-pm10-dust-in-play-area/).\\nThe aim was to create the basis for the implementation of an air quality monitoring network in areas of special vulnerability (schools, playgrounds, nursing homes, hospitals, etc.) that can provide local authorities with information to take measures to protect their citizens.\\nAn example of using a sensor is shown in a video below. Also, source code may be found [here](https://github.com/airalab/sensors-connectivity).\\n\\nhttps://www.youtube.com/watch?v=shqey3tmNUk\\n\\n### Robot artist Gaka-chu.\\nModern technologies make human life more comfortable and more fun, freeing up time for reflection and experimentation.\\nIt was a series of reflections on the static nature of the industry that led the development team to the idea of ​​conducting an experiment showing the autonomous transformation of production for a specific type of product.\\nSuch an experiment became a [robot artist](https://github.com/airalab/robot_painter/) - a small, clumsy KUKA manipulator living in a large world of serious industrial robots. And his name is Gaka-chu. Why? Because of the love of drawing: \\\"gaka\\\" in Japanese is \\\"artist\\\". And \\\"chu\\\" was added for an inexplicable love for Pokemons.\\n\\nhttps://youtu.be/xSD_lsrAA0I\\n\\n### Issuance of green certificates based on the data from renewable energy sources.\\nThe conceptual goal of [DAO IPCI](https://ipci.io/ru/) is to provide a common space, common environment, tools and ecosystem that is universal, reliable, easy to use, allowing a variety of stakeholders, including businesses and people, to record quantitative impacts and quantitative commitments, invest in negative impact mitigation projects, offset the carbon footprint, acquire and trade mitigation results, join existing programs or launch new ones. Source code is provided [here](https://github.com/DAO-IPCI/DAO-IPCI).\\n\\nhttps://www.youtube.com/watch?v=q9plB0TjUnw&list=PLLepqB9oh7WvUVzbeaiwQojrip2tLPA6P\\n\\n### Roadspace negotiation for autonomous cars.\\nOur goal was to develop a [decentralized system](https://github.com/khssnv/mobi_grand_challenge) for road space negotiation where autonomous vehicles can pay for routes and right of way. We believe a market-based approach can be used to alleviate a traffic congestion problem.\\n\\nhttps://youtu.be/JFQTknMZOYg\\n\\n### Blockchain in the tasks of the chemical industry.\\nOriginally the following task was set: developing a [quality control system](https://github.com/Vourhey/chemistry-quality-control) for the production of a certain chemical product. Why is monitoring the quality so important here? The main active substance of this chemical product is chlorine dioxide. It is hazardous to health in high concentrations. And if the concentration is below normal, then this chemical product is useless.\\nAnd what does Blockchain have to do with it? Blockchain helps building trust to the manufacturing company. The consumer knows that no one can change the information in the Blockchain. That means that the manufacturing company can not forge the results of the audit.\\n\\n### Control of equipment maintenance process by supply chain participants based on IoT data.\\n\\n### Robot as a service in service robotics.\\nRobonomics is the ready-to-work and open-source platform which you can use to connect your robot as a service for end-users, they call it [‘Robot-as-a-Service’](https://blog.aira.life/how-can-you-hire-a-robot-176ba29da565). Robonomics support Web3 technologies that implement the exchange of technical and economic information between humans and machines. Robonomics is a purely technical and open source project.\\n\\nhttps://www.youtube.com/watch?v=IEgvXcj3nSo\"}},{\"node\":{\"id\":\"a4ca7d0ebae2846d3b73bee1f0778675\",\"title\":\"Playground Overview\",\"path\":\"/docs/en/playground-overview/\",\"content\":\"\\nRobonomics allows to use robots as autonomous agents that receive commands from a human or another robot and do some useful work, storing a report of their actions in Blockchain. The interaction between the robot and the Robonomics platform is quite simple with a [Robonomics IO](/docs/rio-overview).\\n\\n## Robonomics ROS playground overview \\n\\nhttps://youtu.be/mKr352z8vio\\n\\n## What Robots You Can Control\\nThe playground section contains examples of connecting different robots to Robonomics which everyone can try to repeat step by step. In this section you can try to control:\\n* [an Unmanned Aerial Vehicle](/docs/iris-drone/)\\n* [a Mars Rover](/docs/connect-mars-curiosity-rover-under-robonomics-parachain-control/)\\n* [a Manipulator](/docs/kuka/)\\n* [an industrial Baxter Robot](/docs/baxter2/)\\n\\nSince all robots are available as simulation models, you don't need any special hardware. So you can try to connect the robot to Robonomics Network right now.\\n## How Do You Control the Robot\\nAll of our Demos are launched in a local network, however you can connect a robot to the live networks in the same way.\\n\\nAll Demos in this section follow a similar scenario. You [create an account](/docs/create-account-in-dapp/) for the robot and send him some units for paying transactions. Then the user sends an `ON/OFF` transaction to the robot's address, the robot receives it and starts working. After the job is done the telemetry is saved in IPFS and the file hash is sent to datalog. So at any time you can see how the robot performed its work.\\n## Connect Your Own Robot\\nIn addition you can create your own control package for any ROS-compatible device with [this](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/) instruction.\\n\\n\"}},{\"node\":{\"id\":\"96e69227ca94bb46db93f811ad486b8d\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/en/notifications/\",\"content\":\"\\nYou can receive notifications on your smartphone with [notify](https://notify.events/). Girstly register there and on `Control Panel` creae new channel:\\n\\n![control_panel](../images/home-assistant/not_control_panel.png)\\n\\nAdd title and press `Save`:\\n\\n![channel](../images/home-assistant/not_create_chanell.png)\\n\\nThen press `Add Source` and choose `Home Assistant` in `IoT and Smart Home` tab:\\n\\n![source](../images/home-assistant/not_add_source.png)\\n\\nWrite title and press `Next`:\\n\\n![source_next](../images/home-assistant/not_add_source_next.png)\\n\\nThere you will see the token which you need to add to your configuration file for home Assistant. Save it somewhere and press `Done`:\\n\\n![token](../images/home-assistant/not_token.png)\\n\\nthen press `Subscribe` to add subscribers:\\n\\n![subscribe](../images/home-assistant/not_subscribe.png)\\n\\nChoose whatever subscriber you want and follow the instructions.\\n\\nNow you need to edit configuration on your compuer with Home Assistant. Under `homeassistant` user open `configuration.yaml` file:\\n\\n```bash\\nsudo -u homeassistant -H -s\\nnano ~/.homeassistant/configuration.yaml\\n```\\n\\nAnd add theese lines:\\n\\n```yaml\\nnotify_events:\\n    token: <your token from notify>\\n```\\nAlso add new automation after `automation:` line:\\n```yaml\\n- alias: notifications\\n  trigger:\\n  - entity_id: binary_sensor.contact_sensor_contact\\n    platform: state\\n    from: 'off'\\n    to: 'on'\\n  action:\\n  - service: notify.notify\\n    data:\\n      message: Door was changed to {{ states(\\\"binary_sensor.contact_sensor_contact\\\") }}\\n```\\nThis automation will send message `Door was changed to on/off` after sensor wit entity id `binary_sensor.contact_sensor_contact` change state from `off` to `on`.\\n\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\"}},{\"node\":{\"id\":\"3eda88f08d6b104fb3840468555c2abd\",\"title\":\"Market messages\",\"path\":\"/docs/en/market-messages/\",\"content\":\"\\nMarket messages is used for exchange **Demand** and **Offer** information. It also used for delivery **Result** messages with liability execution reports.\\n\\n> This is spec for Robonomics `Generation 5`.\\n\\n- Currently for message delivery is used [IPFS PubSub](https://ipfs.io/blog/25-pubsub/) broadcaster.\\n- IPFS PubSub **topic** is set according to *Lighthouse [ENS](https://ens.domains/) name*.\\n\\n## Messages content\\n\\nRobonomics market message use [JSON](https://www.json.org/) data format.\\n\\n\\n### Demand\\n\\n| Field | ROS Type | Description |\\n|-------------- |-------------------------  |------------------------------------------------ |\\n| model | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model identifier |\\n| objective | [ipfs_common/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg) | CPS behavioral model parameters in rosbag file |\\n| token | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Operational token address |\\n| cost | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | CPS behavioral model execution cost |\\n| lighthouse | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Lighthouse contract address |\\n| validator | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Observing network address |\\n| validatorFee  | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Observing network fee |\\n| deadline | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Deadline block number |\\n| nonce | [ethereum_common/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg) | Robonomics message counter |\\n| sender | [ethereum_common/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg) | Message sender address |\\n| signature | std_msgs/UInt8[] | Sender’s Ethereum signature |\\n\\n### Offer\\n\\n| Field             | ROS Type                  | Description                                       |\\n|---------------    |-------------------------  |------------------------------------------------   |\\n| model             | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model identifier                   |\\n| objective         | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | CPS behavioral model parameters in rosbag file    |\\n| token             | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Operational token address                         |\\n| cost              | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | CPS behavioral model execution cost               |\\n| validator         | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Observing network address                         |\\n| lighthouse        | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Lighthouse contract address                       |\\n| lighthouseFee     | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Liability creation fee                            |\\n| deadline          | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Deadline block number                             |\\n| nonce             | [ethereum_commom/UInt256](/docs/ethereum-common-messages#ethereum_commonuint256msg)   | Robonomics message counter                        |\\n| sender            | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Message sender address                            |\\n| signature         | std_msgs/UInt8[]          | Sender’s Ethereum signature                       |\\n\\n### Result\\n\\n| Field         | ROS Type                  | Description                       |\\n|-----------    |-------------------------  |---------------------------------- |\\n| liability     | [ethereum_commom/Address](/docs/ethereum-common-messages#ethereum_commonaddressmsg)   | Liability contract address        |\\n| result        | [ipfs_commom/Multihash](/docs/ipfs-common-messages#ipfs_commonmultihashmsg)     | Liability result multihash        |\\n| success       | std_msgs/Bool             | Is liability executed successful  |\\n| signature     | std_msgs/UInt8[]          | Sender’s Ethereum signature       |\\n\\n## Messages signing\\n\\nBefore signing the messages is packed using [abi.encodePacked](https://solidity.readthedocs.io/en/latest/abi-spec.html#non-standard-packed-mode\\n) solidity finction and hashed by Keccak_256.\\n\\n```\\n   demandHash = keccak256(abi.encodePacked(\\n        _model\\n      , _objective\\n      , _token\\n      , _cost\\n      , _lighthouse\\n      , _validator\\n      , _validator_fee\\n      , _deadline\\n      , IFactory(factory).nonceOf(_sender)\\n      , _sender\\n      ));\\n```\\n\\n**`nonce` parameter is counted by factory smart contract and incremented for each created liability smart contract.**\\n\\nMessage hash are signed using Ethereum ``secp256k1`` [signature](https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sign).\\n\"}},{\"node\":{\"id\":\"3690cbc34699303559f70e01b1c7613e\",\"title\":\"Ports mapping\",\"path\":\"/docs/en/lightsout-factory-ports/\",\"content\":\"\\n## PLC scheme\\n![PLC](../images/lightsout-factory/plc.png)<br>\\n<b>Notice! </b>AN ports are not represented on the scheme above. Check out table below to see description.<br><br>\\nMain PLC block has its own connection scheme. The rest of the blocks are all similar to each other.<br>\\nMore information about ports can be found [here](https://docs.google.com/spreadsheets/d/1g_LuqgdKADWxOYnbkcRyZtqtx3cMqh8EEH0UOrVdQ5M).<br>\\n\\n## Legend\\n- 0 - departure warehouse position (e.g. move to 0 means move towards the departure warehouse)\\n- 1 - arrival warehouse position (e.g. move to 1 means move towards the arrival warehouse)\\n- sensor M - magnetic sensor\\n- sensor L - light sensor\\n\\n## Ports mapping\\n| Port      | Description                |   | Port     | Description                  |\\n|-----------|----------------------------|---|----------|------------------------------|\\n| OUT_1-0.0 |                            |   | IN_1-0.0 | Modbus ON/OFF                |\\n| OUT_1-0.1 |                            |   | IN_1-0.1 |                              |\\n| OUT_1-0.2 |    Loader 0 - move to 1    |   | IN_1-0.2 | Warehouse 0 - pos. 01        |\\n| OUT_1-0.3 |    Loader 0 - move to 0    |   | IN_1-0.3 | Warehouse 0 - pos. 02        |\\n| OUT_1-0.4 |                            |   | IN_1-0.4 | Warehouse 0 - pos. 03        |\\n| OUT_1-0.5 |      Loader 0 - move ↑     |   | IN_1-0.5 | Warehouse 0 - pos. 04        |\\n| OUT_1-0.6 |      Loader 0 - move ↓     |   | IN_1-0.6 | Warehouse 0 - pos. 05        |\\n| OUT_1-0.7 |    Loader 0 - move ← (1)   |   | IN_1-0.7 | Warehouse 0 - pos. 06        |\\n| OUT_1-1.0 |    Loader 0 - move → (0)   |   | IN_1-1.0 | Warehouse 0 - pos. 07        |\\n| OUT_1-1.1 |                            |   | IN_1-1.1 | Warehouse 0 - pos. 08        |\\n|           |                            |   | IN_1-1.2 | Warehouse 0 - pos. 09        |\\n|           |                            |   | IN_1-1.3 | Warehouse 0 - pos. 10        |\\n|           |                            |   | IN_1-1.4 | Warehouse 0 - pos. 11        |\\n|           |                            |   | IN_1-1.5 | Warehouse 0 - pos. 12        |\\n| &nbsp;    |                            |   |          |                              |\\n| OUT_2-0.0 | Loader 1 - move to 0       |   | IN_2-0.0 |                              |\\n| OUT_2-0.1 | Loader 1 - move to 1       |   | IN_2-0.1 | Loader 0 - ⇵.1 (bottom)      |\\n| OUT_2-0.2 |                            |   | IN_2-0.2 | Loader 0 - ⇵.2               |\\n| OUT_2-0.3 | Loader 1 - move ↑          |   | IN_2-0.3 | Loader 0 - ⇵.3               |\\n| OUT_2-0.4 | Loader 1 - move ↓          |   | IN_2-0.4 | Loader 0 - ⇵.4               |\\n| OUT_2-0.5 | Loader 1 - move ← (1)      |   | IN_2-0.5 | Loader 0 - ⇵.5               |\\n| OUT_2-0.6 | Loader 1 - move → (0)      |   | IN_2-0.6 | Loader 0 - ⇵.6               |\\n| OUT_2-0.7 |                            |   | IN_2-0.7 | Loader 0 - ⇵.7               |\\n| OUT_2-1.0 | Conveyor 1.1 - move to 0   |   | IN_2-1.0 | Loader 0 - ⇵.8 (top)         |\\n| OUT_2-1.1 | Conveyor 1.1 - move to 1   |   | IN_2-1.1 | Loader 0 - ⟷.1 (warehouse)   |\\n| OUT_2-1.2 | Conveyor 1.2 - move to 0   |   | IN_2-1.2 | Loader 0 - ⟷.2 (neutral)     |\\n| OUT_2-1.3 | Conveyor 1.2 - move to 1   |   | IN_2-1.3 | Loader 0 - ⟷.3 (conveyor)    |\\n| OUT_2-1.4 | Handler 1 - move to 1      |   | IN_2-1.4 |                              |\\n| OUT_2-1.5 | Handler 1 - move to 0      |   | IN_2-1.5 |                              |\\n| OUT_2-1.6 | Handler 1 - move ↓         |   | IN_2-1.6 |                              |\\n| OUT_2-1.7 | Handler 1 - move ↑         |   | IN_2-1.7 |                              |\\n| &nbsp;    |                            |   |          |                              |\\n| OUT_3-0.0 | Handler 1 - on/off         |   | IN_3-0.0 | Conveyor 1.1 - sensor L      |\\n| OUT_3-0.1 | Handler signal 1 - red     |   | IN_3-0.1 | Conveyor 1.2 - sensor M      |\\n| OUT_3-0.2 | Handler signal 1 - green   |   | IN_3-0.2 | Handler 1 - ⟷.1              |\\n| OUT_3-0.3 | Handler signal 1 - yellow  |   | IN_3-0.3 | Handler 1 - ⟷.0              |\\n| OUT_3-0.4 | Conveyor 1.3 - rotate to 1 |   | IN_3-0.4 | Handler 1 - ↓                |\\n| OUT_3-0.5 | Conveyor 1.3 - rotate to 0 |   | IN_3-0.5 | Handler 1 - ↑                |\\n| OUT_3-0.6 | Conveyor 1.3 - move to 0   |   | IN_3-0.6 | Conveyor 1.3 - sensor M      |\\n| OUT_3-0.7 | Conveyor 1.3 - move to 1   |   | IN_3-0.7 | Conveyor 1.3 - rotate to 0   |\\n| OUT_3-1.0 | Conveyor 1.4 - move to 0   |   | IN_3-1.0 | Conveyor 1.3 - rotate to 1   |\\n| OUT_3-1.1 | Conveyor 1.4 - move to 1   |   | IN_3-1.1 | Conveyor 1.4 - sensor M      |\\n| OUT_3-1.2 |                            |   | IN_3-1.2 | Conveyor 2.1 - sensor L      |\\n| OUT_3-1.3 | Conveyor 2.1 - move to 0   |   | IN_3-1.3 | Conveyor 2.2 - sensor M      |\\n| OUT_3-1.4 | Conveyor 2.1 - move to 1   |   | IN_3-1.4 | Handler 2 - ⟷.1              |\\n| OUT_3-1.5 | Conveyor 2.2 - move to 0   |   | IN_3-1.5 | Handler 2 - ⟷.0              |\\n| OUT_3-1.6 | Conveyor 2.2 - move to 1   |   | IN_3-1.6 | Handler 2 - ↓                |\\n| OUT_3-1.7 | Handler 2 - move to 1      |   | IN_3-1.7 | Handler 2 - ↑                |\\n| &nbsp;    |                            |   |          |                              |\\n| OUT_4-0.0 | Handler 2 - move to 0      |   | IN_4-0.0 | Conveyor 2.3 - sensor M      |\\n| OUT_4-0.1 | Handler 2 - move ↓         |   | IN_4-0.1 | Conveyor 2.3 - rotate to 0   |\\n| OUT_4-0.2 | Handler 2 - move ↑         |   | IN_4-0.2 | Conveyor 2.3 - rotate to 1   |\\n| OUT_4-0.3 | Handler 2 - on/off         |   | IN_4-0.3 | Conveyor 2.4 - sensor M      |\\n| OUT_4-0.4 | Handler signal 2 - red     |   | IN_4-0.4 | Conveyor 3.1 - sensor L      |\\n| OUT_4-0.5 | Handler signal 2 - green   |   | IN_4-0.5 | Conveyor 3.2 - sensor M      |\\n| OUT_4-0.6 | Handler signal 2 - yellow  |   | IN_4-0.6 | Handler 3 - ⟷.1              |\\n| OUT_4-0.7 | Conveyor 2.3 - rotate to 0 |   | IN_4-0.7 | Handler 3 - ⟷.0              |\\n| OUT_4-1.0 | Conveyor 2.3 - rotate to 1 |   | IN_4-1.0 | Handler 3 - ↓                |\\n| OUT_4-1.1 | Conveyor 2.3 - move to 0   |   | IN_4-1.1 | Handler 3 - ↑                |\\n| OUT_4-1.2 | Conveyor 2.3 - move to 1   |   | IN_4-1.2 | Conveyor 3.3 - sensor M      |\\n| OUT_4-1.3 | Conveyor 2.4 - move to 0   |   | IN_4-1.3 | Conveyor 3.3 - rotate to 0   |\\n| OUT_4-1.4 | Conveyor 2.4 - move to 1   |   | IN_4-1.4 | Conveyor 3.3 - rotate to 1   |\\n| OUT_4-1.5 |                            |   | IN_4-1.5 | Conveyor 3.4 - sensor M      |\\n| OUT_4-1.6 | Conveyor 3.1 - move to 0   |   | IN_4-1.6 | Conveyor 4.1 - sensor L      |\\n| OUT_4-1.7 | Conveyor 3.1 - move to 1   |   | IN_4-1.7 | Conveyor 4.2 - sensor M      |\\n| &nbsp;    |                            |   |          |                              |\\n| OUT_5-0.0 | Conveyor 3.2 - move to 0   |   | IN_5-0.0 | Handler 4 - ⟷.1              |\\n| OUT_5-0.1 | Conveyor 3.2 - move to 1   |   | IN_5-0.1 | Handler 4 - ⟷.0              |\\n| OUT_5-0.2 | Handler 3 - move to 1      |   | IN_5-0.2 | Handler 4 - ↓                |\\n| OUT_5-0.3 | Handler 3 - move to 0      |   | IN_5-0.3 | Handler 4 - ↑                |\\n| OUT_5-0.4 | Handler 3 - move to ↓      |   | IN_5-0.4 | Conveyor 4.3 - sensor M      |\\n| OUT_5-0.5 | Handler 3 - move to ↑      |   | IN_5-0.5 | Conveyor 4.3 - rotate to 1   |\\n| OUT_5-0.6 | Handler 3 - on/off         |   | IN_5-0.6 | Conveyor 4.3 - rotate to 0   |\\n| OUT_5-0.7 | Handler signal 3 - red     |   | IN_5-0.7 |                              |\\n| OUT_5-1.0 | Handler signal 3 - green   |   | IN_5-1.0 | Conveyor 4.4 - sensor M      |\\n| OUT_5-1.1 | Handler signal 3 - yellow  |   | IN_5-1.1 | Conveyor 4.5 - sensor L      |\\n| OUT_5-1.2 | Conveyor 3.3 - rotate to 1 |   | IN_5-1.2 |                              |\\n| OUT_5-1.3 | Conveyor 3.3 - rotate to 0 |   | IN_5-1.3 | Warehouse 1 - pos. 01        |\\n| OUT_5-1.4 | Conveyor 3.3 - move to 0   |   | IN_5-1.4 | Warehouse 1 - pos. 02        |\\n| OUT_5-1.5 | Conveyor 3.3 - move to 1   |   | IN_5-1.5 | Warehouse 1 - pos. 03        |\\n| OUT_5-1.6 | Conveyor 3.4 - move to 0   |   | IN_5-1.6 | Warehouse 1 - pos. 04        |\\n| OUT_5-1.7 | Conveyor 3.4 - move to 1   |   | IN_5-1.7 | Warehouse 1 - pos. 05        |\\n| &nbsp;    |                            |   |          |                              |\\n| OUT_6-0.0 |                            |   | IN_6-0.0 | Warehouse 1 - pos. 06        |\\n| OUT_6-0.1 | Conveyor 4.1 - move to 0   |   | IN_6-0.1 | Warehouse 1 - pos. 07        |\\n| OUT_6-0.2 | Conveyor 4.1 - move to 1   |   | IN_6-0.2 | Warehouse 1 - pos. 08        |\\n| OUT_6-0.3 | Conveyor 4.2 - move to 0   |   | IN_6-0.3 | Warehouse 1 - pos. 09        |\\n| OUT_6-0.4 | Conveyor 4.2 - move to 1   |   | IN_6-0.4 | Warehouse 1 - pos. 10        |\\n| OUT_6-0.5 | Handler 4 - move to 1      |   | IN_6-0.5 | Warehouse 1 - pos. 11        |\\n| OUT_6-0.6 | Handler 4 - move to 0      |   | IN_6-0.6 | Warehouse 1 - pos. 12        |\\n| OUT_6-0.7 | Handler 4 - move ↓         |   | IN_6-0.7 |                              |\\n| OUT_6-1.0 | Handler 4 - move ↑         |   | IN_6-1.0 | Loader 1 - ⇵.1 (bottom)      |\\n| OUT_6-1.1 | Handler 4 - on/off         |   | IN_6-1.1 | Loader 1 - ⇵.2               |\\n| OUT_6-1.2 | Handler signal 4 - red     |   | IN_6-1.2 | Loader 1 - ⇵.3               |\\n| OUT_6-1.3 | Handler signal 4 - green   |   | IN_6-1.3 | Loader 1 - ⇵.4               |\\n| OUT_6-1.4 | Handler signal 4 - yellow  |   | IN_6-1.4 | Loader 1 - ⇵.5               |\\n| OUT_6-1.5 | Conveyor 4.3 - rotate to 0 |   | IN_6-1.5 | Loader 1 - ⇵.6               |\\n| OUT_6-1.6 | Conveyor 4.3 - rotate to 1 |   | IN_6-1.6 | Loader 1 - ⇵.7               |\\n| OUT_6-1.7 | Conveyor 4.3 - move to 0   |   | IN_6-1.7 | Loader 1 - ⇵.8 (top)         |\\n| &nbsp;    |                            |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|          |                              |\\n| OUT_7-0.0 | Conveyor 4.3 - move to 1   |   | IN_7-0.0 | Loader 1 - ⟷.1 (conveyor)   |\\n| OUT_7-0.1 |                            |   | IN_7-0.1 | Loader 1 - ⟷.2 (neutral)    |\\n| OUT_7-0.2 | Conveyor 4.4 - move to 0   |   | IN_7-0.2 | Loader 1 - ⟷.3 (warehouse)  |\\n| OUT_7-0.3 | Conveyor 4.4 - move to 1   |   | IN_7-0.3 | Conveyor 1.1 - stop Loader 0 |\\n| OUT_7-0.4 | Conveyor 4.5 - move to 0   |   | IN_7-0.4 | Conveyor 2.1 - stop Loader 0 |\\n| OUT_7-0.5 | Conveyor 4.5 - move to 1   |   | IN_7-0.5 | Conveyor 3.1 - stop Loader 0 |\\n| OUT_7-0.6 | Handler 4 - on/off         |   | IN_7-0.6 | Conveyor 4.1 - stop Loader 0 |\\n| OUT_7-0.7 |                            |   | IN_7-0.7 | Handler 4 - rotation         |\\n| OUT_7-1.0 |                            |   | IN_7-1.0 |                              |\\n| OUT_7-1.1 |                            |   | IN_7-1.1 |                              |\\n| OUT_7-1.2 |                            |   | IN_7-1.2 |                              |\\n| OUT_7-1.3 |                            |   | IN_7-1.3 |                              |\\n| OUT_7-1.4 |                            |   | IN_7-1.4 |                              |\\n| OUT_7-1.5 |                            |   | IN_7-1.5 |                              |\\n| OUT_7-1.6 |                            |   | IN_7-1.6 |                              |\\n| OUT_7-1.7 |                            |   | IN_7-1.7 |                              |\\n| &nbsp;    |                            |   |          |                              |\\n|           |                            |   |   AN_1   | Color Recognition Block      |\\n|           |                            |   |   AN_2   |                              |\\n\"}},{\"node\":{\"id\":\"025776cc5337e048501702a71a57ae6d\",\"title\":\"Lightsout Factory\",\"path\":\"/docs/en/lightsout-factory-about/\",\"content\":\"\\n![Lightsout Factory Preview](../images/lightsout-factory/factory_preview_numbers.jpg)\\n\\n## Project goal\\nProvide optimized and fully automated factory manufacturing depending on the specified requirements\\n\\n## Requirements\\n- FischerTechink factory\\n- Siemens PLC S7-1200\\n- 6 additional PLC blocks (SM-1223)\\n- LattePanda with [Ubuntu 20.04](https://releases.ubuntu.com/20.04/) and [ROS Noetic](http://wiki.ros.org/noetic/Installation) installed\\n- [modbus](https://github.com/HumaRobotics/modbus)\\n\\n## Legend\\n| Block number |           Description           | Amount, pcs |\\n|--------------|---------------------------------|-------------|\\n|     0.x      | Warehouse                       |      2      |\\n|      1       | Simple conveyor                 |      8      |\\n|      2       | Rotary conveyor                 |      2      |\\n|     3.1      | Arrival conveyor                |      4      |\\n|     3.2      | Departure conveyor              |      1      |\\n|     4.x      | Handler                         |      4      |\\n|     5.x      | Loader                          |      2      |\\n|      6       | Color Recognition Block         |      1      |\\n\\n## Rules\\n- Factory movement is organised from right to left side\\n- Right side stands for 0, left side stands for 1\\n- All handlers (4.x) are just models of various processing machines\\n- Each block has a tactile or light sensor (except of warehouse storage positioning)\\n\\n\"}},{\"node\":{\"id\":\"1728cb019b80fdaa683459a0197ec16c\",\"title\":\"Control Kuka manipulator with robonomics\",\"path\":\"/docs/en/kuka/\",\"content\":\"\\nVideo with an example of work can be found here:\\n\\nhttps://youtu.be/z55HepXbHr8\\n\\n***\\n\\n## Requirements\\n* ROS melodic, Gazebo (installation instraction [here](http://wiki.ros.org/melodic/Installation/Ubuntu))\\n* Some extra packages\\n```bash\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n* IPFS 0.4.22 (download from [here](https://www.npackd.org/p/ipfs/0.4.22) and install)\\n```bash\\ntar -xvzf go-ipfs_v0.4.22_linux-386.tar.gz\\ncd go-ipfs/\\nsudo bash install.sh\\nipfs init\\n```\\n* pip3\\n```bash\\nsudo apt-get install python3-pip\\n```\\n* ipfshttpclient\\n```bash\\npip3 install ipfshttpclient\\n```\\n* substrate-interface\\n```bash\\npip3 install substrate-interface\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n* IPFS browser extension (not necessary)\\n***\\n## Installation\\nInstall Kuka manipulator and control packages\\n```bash\\ncd catkin_wc/src/\\ngit clone https://github.com/orsalmon/kuka_manipulator_gazebo\\ngit clone https://github.com/LoSk-p/kuka_controller\\ncd ..\\ncatkin_make\\n```\\n***\\n## Running gazebo model\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nroslaunch manipulator_gazebo manipulator_empty_world.launch\\n```\\nIn a new window\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun manipulator_gazebo move_arm_server\\n```\\n![model](../images/kuka-demo/1.png)\\n***\\n## Running robonomics\\nGo to the folder with robonomics file ad create a local robonomics network:\\n```bash\\n./robonomics --dev --tmp\\n```\\n\\n![robonomics](../images/kuka-demo/robonomics.png)\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node\\n\\n![local](../images/kuka-demo/local.png)\\n\\nThen go to Accounts and create `KUKA` account. Save account's mnemonic key, you will need it later. \\n\\n![acc](../images/kuka-demo/create_acc.png)\\n\\nSend some units to the new account from one of default accounts.\\n\\n![accs](../images/kuka-demo/send_money.png)\\n***\\n## Running ipfs\\nRun ipfs daemon:\\n```bash\\nipfs daemon\\n```\\n***\\n## Running control package\\nIn config directory in kuka_control package you need to create config file with this lines, where `<your_mnemonic>` is saved mnemonic seed:\\n```bash\\n{\\n    \\\"kuka_mnemonic\\\": \\\"<your_mnemonic>\\\",\\n    \\\"node\\\": \\\"ws://127.0.0.1:9944\\\"\\n}\\n```\\n\\nNow you can run control script:\\n```bash\\nsource ~/catkin_ws/devel/setup.bash\\nrosrun kuka_controller move_arm_client.py\\n```\\n![control](../images/kuka-demo/run.png)\\n\\n## Sending transaction\\nIn [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) go to `Developer/Extrinsics`, change `extrinsic` to `launch`. Chose your `KUKA` account in `robot` and change `param` to `Yes`. The press `Submit Transaction`\\n\\n![transaction](../images/kuka-demo/launch.png)\\n\\nIn the window with kuka_control package you will see:\\n\\n![done](../images/kuka-demo/res.png)\\n\\nThen go `Developer/Chain State` on the Robonomics portal, select `datalog` and `datalogItem((AccountId,u64)): RingBufferItem` in query and add `KUKA` datalog with button '+':\\n\\n![datalog](../images/kuka-demo/datalog.png)\\n\\nNow you can find robot's telemetry in IPFS via this link with your hash `https://gateway.ipfs.io/ipfs/<hash>`.\\n\\n## Troubleshooting\\n\\nIf `catkin_make` doesn't work with the message that it can't find MoveArm.h, try to remove last four lines in CMakeLists.txt in kuka_manipulator_gazebo package:\\n```\\ninclude_directories(include ${catkin_INCLUDE_DIRS})\\n\\nadd_executable(move_arm_server src/move_arm_server.cpp)\\ntarget_link_libraries(move_arm_server ${catkin_LIBRARIES})\\nadd_dependencies(move_arm_server beginner_tutorials_gencpp)\\n```\\nDo `catkin_make` without these lines, then returm them and do `catkin_make` again.\\n\"}},{\"node\":{\"id\":\"8ef04d7a6ebb48a483aa351b739426cd\",\"title\":\"Drone control with robonomics\",\"path\":\"/docs/en/iris-drone/\",\"content\":\"\\n**Drone starts moving after transcation and store file with the coordinates in IPFS. The control script is based on the [GAAS demo script](https://github.com/generalized-intelligence/GAAS)**  \\n\\nhttps://youtu.be/4CwtGAX1OwM\\n\\n## Requirements\\n* dependencies for control:\\n``` sh\\nsudo apt install -y \\\\\\n\\tpython3-pip \\\\\\n\\tninja-build \\\\\\n\\texiftool \\\\\\n\\tpython-argparse \\\\\\n\\tpython-empy \\\\\\n\\tpython-toml \\\\\\n\\tpython-numpy \\\\\\n\\tpython-yaml \\\\\\n\\tpython-dev \\\\\\n\\tpython-pip \\\\\\n\\tninja-build \\\\\\n\\tprotobuf-compiler \\\\\\n\\tlibeigen3-dev \\\\\\n\\tgenromfs\\n```\\n```sh \\npip3 install \\\\\\n\\tpandas \\\\\\n\\tjinja2 \\\\\\n\\tpyserial \\\\\\n\\tcerberus \\\\\\n\\tpyulog \\\\\\n\\tnumpy \\\\\\n\\ttoml \\\\\\n\\tpyquaternion\\n```\\n* ROS Melodic + Gazebo [installation tutorial](http://wiki.ros.org/melodic/Installation)\\n* extra packages: \\n``` bash \\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\nsudo apt-get install python-jinja2\\nsudo apt-get install python-catkin-pkg\\nsudo apt-get install python3-catkin-pkg-modules\\n```\\n* IPFS verson 0.4.22\\n```bash\\nwget https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-amd64.tar.gz\\ntar -xvzf go-ipfs_v0.4.22_linux-amd64.tar.gz\\ncd go-ipfs\\nsudo bash install.sh\\nipfs init\\n```\\n* ipfshttpclient\\n```sh\\npip3 install ipfshttpclient\\n```\\n* Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n## Environment Setup\\n```bash \\nsudo apt-get install ros-melodic-mavros ros-melodic-mavros-extras\\nwget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\\nsudo ./install_geographiclib_datasets.sh\\ncd ~/catkin_ws/src\\ngit clone https://github.com/PX4/Firmware.git\\ncd Firmware\\ngit checkout v1.9.0\\nbash ./Tools/setup/ubuntu.sh\\n```\\n```bash\\ncd ~/catkin_ws/src\\ngit clone https://github.com/generalized-intelligence/GAAS.git\\ncp -r ~/catkin_ws/src/GAAS/simulator/models/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/models/\\ncp -r ~/catkin_ws/src/GAAS/simulator/worlds/* ~/catkin_ws/src/Firmware/Tools/sitl_gazebo/worlds/\\ncp -r ~/catkin_ws/src/GAAS/simulator/posix-config/* ~/catkin_ws/src/Firmware/posix-configs/SITL/init/ekf2/\\n```\\n\\nModifying your `.bashrc` file, adding the following lines to the bottom:  \\n\\n`source ~/catkin_ws/devel/setup.bash `  \\n`source ~/catkin_ws/src/Firmware/Tools/setup_gazebo.bash ~/catkin_ws/src/Firmware/ ~/catkin_ws/src/Firmware/build posix_sitl_default `   \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware`  \\n`export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/catkin_ws/src/Firmware/Tools/sitl_gazebo`  \\n`export GAZEBO_MODEL_PATH=:~/catkin_ws/src/simulator/models:~/catkin_ws/src/GAAS/simulator/models`  \\n\\n  \\n## Control Package Installation\\nIn a new Terminal:\\n```bash\\ncd catkin_ws/src\\ngit clone https://github.com/tubleronchik/robonomics_drone_sim.git\\ncd ..\\ncatkin build\\n```\\n## Robonomics Network\\nTo create a local robonomics network go to the folder with the robonomic binary file and run:  \\n`./robonomics --dev --rpc-cors all`  \\n\\nAdd robonomic's path to `config.py`\\n\\n![IPFS](../images/iris-drone-demo/IPFS.jpg)\\n\\nGo to the [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node.\\n![localNode](../images/iris-drone-demo/localNode.jpg)\\n\\nGo to **Accounts** and create **DRONE** and **EMPLOYER** accounts. Save the account names and keys and path to **robonomics** to `~/catkin_ws/src/drone_sim/src/config.py`. Transfer some money into the accounts.\\n\\n![accounts](../images/iris-drone-demo/addingAcc.jpg)\\n\\n## Running Simulation\\nRun IPFS daemon\\n```bash\\ncd go-ipfs\\nipfs daemon\\n```\\nIn another terminal launch the simulation:\\n```bash\\nroslaunch px4 mavros_posix_sitl.launch\\ncd ~/catkin_ws/src/robonomics_drone_sim/src\\npython3 takeoff.py\\n```\\nWaiting till \\\"Waiting for payment\\\" \\n\\n![launch](../images/iris-drone-demo/launch.jpg)\\n\\nTo send a transaction run in another window:\\n`echo \\\"ON\\\" | ./robonomics io write launch -r <drone_addres> -s <employer_key>` - where **<drone_address>** and **<employer_key>** should be replaced with the strings from `config.py` accordingly.\\n\\nAfter data was pushed to IPFS, go to the **Chain State** in [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/). Select **datalog** in query and add DRONE datalog using `+` button.\\n\\n![datalog](../images/iris-drone-demo/datalog.jpg)\\n\\nYou can find drone's telemetry running `https://gateway.ipfs.io/ipfs/<hash>` inserting the hash from above.\\n\\n![output](../images/iris-drone-demo/output.jpg)\\n\\nIt's important to remove `db` derictory before next launches using  \\n` rm -rf ~/.local/share/robonomics/chains/dev/db`\\n\"}},{\"node\":{\"id\":\"a0c236441cc3a242f9f97b670461cd82\",\"title\":\"IPFS Common\",\"path\":\"/docs/en/ipfs-common/\",\"content\":\"\\nThe package handle IPFS connections, provides useful services for working with IPFS Network. \\nIt's included in `robonomics_liability` launch file\\n\\n## ROS Parameters\\n\\n### ~lighthouse_contract\\n\\nThe name of a lighthouse you are working on. The type is `string`, defaults to `airalab.lighthouse.5.robonomics.eth`\\n\\n### ~ipfs_http_provider\\n\\nIPFS HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:5001`\\n\\n### ~ipfs_public_providers\\n\\nA public IPFS node to pin result files. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_file_providers\\n\\nA list of public nodes to pin result files. The type is `list of strings`, defaults to `[ipfs_public_providers]`\\n\\n### ~ipfs_swarm_connect_addresses\\n\\nIPFS nodes to connect to. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~ipfs_swarm_connect_to\\n\\nA list of IPFS nodes to connect to. The type is `list of strings`, defaults to `[ipfs_swarm_connect_addresses]`\\n\\n## Subscribed topics\"}},{\"node\":{\"id\":\"1c97dab403b722084f63508eb05f6cad\",\"title\":\"IPFS Common Messages\",\"path\":\"/docs/en/ipfs-common-messages/\",\"content\":\"\\n## ipfs_common/Filepath.msg\\n\\n| Field         | Type                  | Description           |\\n|------------   |-------------------    |--------------------   |\\n| filepath      | std_msgs/String       | A path to a file      |\\n\\n## ipfs_common/Multihash.msg\\n\\n| Field         | Type              | Description                               |\\n|-----------    |-----------------  |------------------------------------------ |\\n| multihash     | std_msgs/String   | A wrapper for model and objective fields  |\\n\\n## ipfs_common/IpfsDownloadFile.srv\\n\\n**Request**\\n\\n| Field         | Type                                                  | Description               |\\n|-------------- |---------------------------------------------------    |------------------------   |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of a file       |\\n| file          | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)       | Where to save the file    |\\n\\n**Response**\\n\\n| Field         | Type              | Description           |\\n|-----------    |-----------------  |---------------------  |\\n| success       | std_msgs/Bool     | Status of execution   |\\n| error_msg     | std_msgs/String   | Error message         |\\n\\n## ipfs_common/IpfsUploadFile.srv\\n\\n**Request**\\n\\n| Field     | Type                                              | Description                               |\\n|-------    |-------------------------------------------------  |---------------------------------------    |\\n| file      | [ipfs_common/Filepath](#ipfs_commonfilepathmsg)   | Path to a file to be uploaded to IPFS     |\\n\\n**Response**\\n\\n| Field         | Type                                                  | Description                   |\\n|-------------- |---------------------------------------------------    |----------------------------   |\\n| success       | std_msgs/Bool                                         | Status of execution           |\\n| error_msg     | std_msgs/String                                       | Error message                 |\\n| ipfs_address  | [ipfs_common/Multihash](#ipfs_commonmultihashmsg)     | IPFS hash of uploaded file    |\\n\"}},{\"node\":{\"id\":\"b4733a1540607e49d90436d8e511eb7b\",\"title\":\"IoT Sensors Connectivity\",\"path\":\"/docs/en/iot-sensors-connectivity/\",\"content\":\"\\nRobonomics Network allows you to communicate with any sensor you wish and get data from the sensor all around the world. This data can be transferred to different destinations.\\n\\nOn this page you'll find step-by-step instructions to connect an ESP board to the connectivity server provided by AiraLab.\\n\\n## Requirements\\n\\n* ESP8266/ESP32 like board with WiFi\\n\\n## 1. Get the software\\n\\n### On Windows\\n\\nInstall [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\\n\\nInstall Ubuntu via Windows Store:\\n\\n![Windows Store](../images/windows_store.jpg \\\"Windows Store\\\")\\n\\nand clone the [package](https://github.com/airalab/sensors-connectivity)\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\n```\\n\\nThe next step is to install python and dependencies:\\n\\n```\\nsudo apt update && sudo apt install python3-pip\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n### On Ubuntu\\n\\n```\\nsudo apt update && sudo apt install python3-pip git\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\npip3 install -r requirements.txt\\n```\\n\\n> You can ignore such warnings:\\n>\\n> ```\\n> The script ... is installed in '...' which is not on PATH.\\n> Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\\n> ```\\n\\n### On NixOS\\n\\n```\\ngit clone https://github.com/airalab/sensors-connectivity\\ncd sensors-connectivity\\nnix build -f release.nix\\nsource result/setup.bash\\n```\\n\"}},{\"node\":{\"id\":\"fff9d591d3f996937214bf3be77a45a1\",\"title\":\"IoT Firmware Upload\",\"path\":\"/docs/en/iot-firmware-upload/\",\"content\":\"\\nThere are few firmwares for ESP like boards:\\n\\n* [Ping](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/ping)\\n* [TCP](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/tcp)\\n* [Mobile GPS](https://github.com/airalab/sensors-connectivity/tree/master/boards/esp/mobile_gps)\\n\\nThere is a script to upload a firmware for each one, called `flash_firmware.py`. It's located in the root of the repository\\n\\n> **Requirements**\\n> In order to install all dependencies run in the root of the repository folder:\\n>\\n> ```\\n> pip install -r requirements.txt\\n> ```\\n>\\n> Python3 is required!\\n\\nUsually in order to upload a firmware to your board follow these steps:\\n\\n1. Assemble the board and connect it to PC\\n2. Edit a `config.yaml` in a corresponding folder (e.g. `boards/esp/tcp/config.yaml`)\\n3. Run `python flash_firmware.py -s PATH_TO_FOLDER -c PATH_TO_CONFIG` where `PATH_TO_FOLDER` is a path to the desired firmware (e.g. `boards/esp/ping`) and `PATH_TO_CONFIG` is a path to the configuration file (e.g. `boards/esp/ping/config.yaml`)\\n\\n\"}},{\"node\":{\"id\":\"52a7121211bf409d61c95b51c3b8949c\",\"title\":\"Interact with AIRA\",\"path\":\"/docs/en/interact-with-aira/\",\"content\":\"\\nAt this point you should be familiar with a [DApp](/docs/get-weather-on-fuji-mountain/) and how to launch [AIRA image](/docs/aira-installation-on-vb/).\\nNow you are ready to do more complicated stuff like installing a package and interacting with it via DApp.\\n\\n> **Important:**\\n> Make sure you have covered previous lessons before you continue.\\n\\n\\n> **Tip:**\\n> During the lesson you will type a few commands in terminal. AIRA image doesn't support clipboard, so to make life easier have a look at [Connect via SSH](/docs/aira-connecting-via-ssh/) and log in via SSH to the VM.\\n\\nWalkthrough video:\\n\\nhttps://www.youtube.com/embed/QM06l07_wuA\\n\\n## Package installation\\n\\nAfter you launched AIRA and logged in using your terminal do the following:\\n\\n```\\nsu liability && cd\\ngit clone https://github.com/vourhey/hello_aira\\ncd hello_aira\\nnix build -f release.nix\\nsource result/setup.bash\\nrosrun hello_aira hello_aira\\n```\\n\\nRun one by one commands above. After the last one you should see a link to DApp generated specifically for your instance.\\n\\n![Terminal with AIRA](../images/aira_hello_terminal.jpg \\\"Terminal with AIRA\\\")\\n\\nClick on the link, the DApp should be shown.\\n\\n## DApp \\n\\nConnect [MetaMask](http://metamask.io/) if prompted and click on the button\\n\\n![Request connection in Robonomics Dapp](../images/aira_hello_dapp.jpg \\\"Request connection in Robonomics Dapp\\\")\\n\\nSign the message as usual and wait for the result\\n\\n![Wait for Result of request](../images/aira_hello_dapp_2.jpg \\\"Wait for Result of request\\\")\\n\\nMeanwhile have a look at the terminal. You should see the greeting\\n\\n![AIRA greeting in terminal](../images/aira_hello_terminal_2.jpg \\\"AIRA greeting in terminal\\\")\\n\\nIn the end the greeting will appear in the DApp\\n\\n![Robonomics DApp Greeting for AIRA](../images/aira_hello_dapp_3.jpg \\\"Robonomics DApp Greeting for AIRA\\\")\\n\\n## Troubleshooting\\n\\n### You click \\\"Request current values\\\" but see no greeting\\n\\nProbably you have just launched AIRA and IPFS hasn't finished initialization. Wait a minute or so and try again.\\n\\n### I see response hash but the data doesn't appear\\n\\nAgain most probably the issue comes from IPFS connection. Click and the hash and you'll see the result. It's not necessary to download the file.\\n\\n## Home Task (optional)\\n\\nIf you are familiar with [Python](https://www.python.org/) change the shown text to something different and complete the lesson with your version of `hello_aira`\\n\\n- Make a fork of the [repository](https://github.com/vourhey/hello_aira)\\n- The output text is located [here](https://github.com/Vourhey/hello_aira/blob/master/scripts/hello_aira#L45)\\n\"}},{\"node\":{\"id\":\"9b9d8ae07c13763aae1dffc223e8fc97\",\"title\":\"How to launch the Robonomics collator\",\"path\":\"/docs/en/how-to-launch-the-robonomics-collator/\",\"content\":\"\\nNote: In the screencast and screenshots of this article, we used version 1.4.0 of Robonomics. You need to use the same commands, but replace the version of Robonomics with the current one.\\n\\nhttps://youtu.be/wUTDDLDbzTg\\n\\nCurrently the Robonomics network is maintained by developers, but anyone can support the project. Every additional full node of the blockchain helps it to be more sustainable and fault tolerant. Robonomics node binaries are available in [release](https://github.com/airalab/robonomics/releases) assets or it could be [built from source](/docs/how-to-build-collator-node/).\\n\\n## Requirements\\n\\n**Minimum hardware requirements** for collators:\\n+ 4-cores CPU\\n+ 200GB extendable NVMe space\\n+ 8GB RAM\\n\\n\\nBut we recommend that you launch a collator using the **standard hardware requirements** for [Polkadot validators](https://wiki.polkadot.network/docs/maintain-guides-how-to-validate-polkadot#standard-hardware):\\n+ CPU - Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz.\\n+ Storage - A NVMe solid state drive. Should be reasonably sized to deal with the blockchain growth. Currently the Kusama db uses around 90GB of space. We recommend 200-240GB for first months, but it will need to be re-evaluated every six months. Again: The ability to expand this disk space is required.\\n+ Memory - 64GB ECC\\n\\n\\nIn this article we use next specifications:\\n+ 4 VCPU\\n+ 240GB extendable volume for collator's databases\\n+ 8GB RAM\\n\\n\\n## Important information\\n1. We use some variables in these instructions, and you'll need to replace the values for your own in all the commands:\\n    + **%NODE_NAME%** is the node name. Example: *my-robonomics-kusama-collator*\\n    + **%BASE_PATH%** is the path to mounted volume. Example: */mnt/HC_Volume_16056435/*\\n    + **%POLKADOT_ACCOUNT_ADDRESS%** is the account address in the Polkadot ecosystem in SS58 format. Example: *4Gp3QpacQhp4ZReGhJ47pzExQiwoNPgqTWYqEQca9XAvrYsu*\\n\\n2. Note that you need use *--state-cache-size=0* in the collator's service launch. This parameter is important for the stability of the collator.\\nYou can see more info in the related [issue](https://github.com/airalab/robonomics/issues/234) on github.\\n\\n## Easily launch a Robonomics collator\\n\\nYou can simply launch a collator directly in the command line to check for errors.\\nAfter that we strongly recommend to launch the Robonomics collator as a service.\\n\\n```\\nroot@robokusama-collator-screencast:~# robonomics \\\\\\n  --parachain-id=2048 \\\\\\n  --name=\\\"%NODE_NAME%\\\" \\\\\\n  --validator \\\\\\n  --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n  --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n  --base-path=\\\"%BASE_PATH%\\\" \\\\\\n  --state-cache-size=0 \\\\\\n  -- \\\\\\n  --database=RocksDb \\\\\\n  --unsafe-pruning \\\\\\n  --pruning=1000\\n```\\n\\n\\n## Launch the Robonomics collator as a service\\n\\n1. Create the user for the service with home directory\\n    ```\\n    root@robokusama-collator-screencast:~# useradd -m robonomics\\n    ```\\n\\n2. Download, extract and move the Robonomics binary to the */usr/local/bin/* directory. You need to replace *$ROBONOMICS_VERSION* with the current version of Robonomics in the commands in this section. You can find the current version on the [Releases page of the Robonomics repository on github](https://github.com/airalab/robonomics/releases).\\n   ```\\n   root@robokusama-collator-screencast:~# wget https://github.com/airalab/robonomics/releases/download/v$ROBONOMICS_VERSION/robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# tar -xf robonomics-$ROBONOMICS_VERSION-x86_64-unknown-linux-gnu.tar.gz\\n   root@robokusama-collator-screencast:~# mv robonomics /usr/local/bin/\\n   ```\\n   ![Download Robonomics 1.4.0 binary](../images/how-to-launch-the-robonomics-collator/wget_binary.png)\\n\\n\\n3. Create the systemd service file named *robonomics.service*:\\n    ```\\n    root@robokusama-collator-screencast:~# nano /etc/systemd/system/robonomics.service\\n    ```\\n\\n    And add the following lines in the service file:\\n    ```\\n    [Unit]\\n    Description=robonomics\\n    After=network.target\\n    \\n    [Service]\\n    User=robonomics\\n    Group=robonomics\\n    Type=simple\\n    Restart=on-failure\\n\\n    ExecStart=/usr/local/bin/robonomics \\\\\\n      --parachain-id=2048 \\\\\\n      --name=\\\"%NODE_NAME%\\\" \\\\\\n      --validator \\\\\\n      --lighthouse-account=\\\"%POLKADOT_ACCOUNT_ADDRESS%\\\" \\\\\\n      --telemetry-url=\\\"wss://telemetry.parachain.robonomics.network/submit/ 0\\\" \\\\\\n      --base-path=\\\"%BASE_PATH%\\\" \\\\\\n      --state-cache-size=0 \\\\\\n      -- \\\\\\n      --database=RocksDb \\\\\\n      --unsafe-pruning \\\\\\n      --pruning=1000\\n\\n    [Install]\\n    WantedBy=multi-user.target\\n    ```\\n    ![Create Robonomics service file](../images/how-to-launch-the-robonomics-collator/nano_robonomics_service.png)\\n\\n\\n    ```\\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%\\n    ```\\n\\n\\n4. Save this file, then enable and start the service:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl enable robonomics.service root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n\\nTelemetry url: https://telemetry.parachain.robonomics.network/#/Robonomics\\n\\nCollators logs can be monitored with : `journalctl -u robonomics.service -f` \\n\\nNow the robonomics collator is launched it will sync with the Kusama Relay Chain, this can take up quite some time depending on your network speed and system specifications, so we recommend to download a Kusama snapshot and use it. \\n\\n\\n## Speeding up the sync process using a Kusama snapshot\\n\\nWe recommend to do this immediately after you've created and started the robonomics service. You can find more info about snapshots and usage instructions on the followin page: https://ksm-rocksdb.polkashots.io/\\n\\nInstructions:\\n\\n1. Stop the Robonomics service and remove the current Kusama database directory:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl stop robonomics.service\\n    root@robokusama-collator-screencast:~# rm -rf %BASE_PATH%/polkadot/chains/ksmcc3/db/\\n    ```\\n2. Download the actual snapshot and extract it:\\n    ```\\n    root@robokusama-collator-screencast:~# wget https://ksm-rocksdb.polkashots.io/snapshot -O kusama.RocksDb.tar.lz4\\n    root@robokusama-collator-screencast:~# lz4 -c -d kusama.RocksDb.tar.lz4 | tar -x -C %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n    ![Download Kusama snapshot](../images/how-to-launch-the-robonomics-collator/wget_kusama_snapshot.png)\\n\\n\\n    You can remove the downloaded archive after succesful unpacking:\\n    ```\\n    root@robokusama-collator-screencast:~# rm -v kusama.RocksDb.tar.lz4\\n    ```   \\n3. Setting the right ownership for the database folder:\\n    ``` \\n    root@robokusama-collator-screencast:~# chown -R robonomics:robonomics %BASE_PATH%/polkadot/chains/ksmcc3\\n    ```\\n4. Start the Robonomics service again:\\n    ```\\n    root@robokusama-collator-screencast:~# systemctl start robonomics.service\\n    ```\\n5. Check service logs:\\n    ```\\n    root@robokusama-collator-screencast:~# journalctl -u robonomics.service -f\\n    ```    \\n    ![Check service logs](../images/how-to-launch-the-robonomics-collator/finish_journalctl.png)\\n\"}},{\"node\":{\"id\":\"c5e6c7e5649ff9a596e5633c83e40717\",\"title\":\"How to build collator node from source\",\"path\":\"/docs/en/how-to-build-collator-node/\",\"content\":\"\\nhttps://youtu.be/wnAtD7w0Pxk\\n\\nEnsure you have Rust and the support software installed. The Rust installer will ask you about current installation options, you should choose the `1) Proceed with installation (default)` option.\\n\\n\\n```\\n  curl https://sh.rustup.rs -sSf | sh\\n  # on Windows download and run rustup-init.exe\\n  # from https://rustup.rs instead\\n  source $HOME/.cargo/env\\n```\\n![Install Rust](../images/how-to-build-collator-node/install_rust.jpg)\\n\\n\\nInstall the required nightly toolchain and wasm target.\\nNext commands actual for Robonomics v1.4.0:\\n\\n```\\n  rustup install nightly-2021-11-02\\n```\\n![Install nightly](../images/how-to-build-collator-node/install_nightly.jpg)\\n\\n\\n```\\n  rustup default nightly-2021-11-02\\n  rustup target add wasm32-unknown-unknown --toolchain nightly-2021-11-02\\n```\\nYou will also need to install the following packages:\\n\\n  1. Linux:\\n\\n  ```\\n    sudo apt install cmake git clang libclang-dev\\n  ```\\n  2. Mac:\\n\\n  ```\\n    brew install cmake pkg-config git llvm\\n  ```\\n  3. Windows (PowerShell):\\n\\n  ```\\n    # Install git https://git-scm.com/download/win\\n    # Install LLVM\\n    # Download and install the Pre Build Windows binaries\\n    # of LLVM  from http://releases.llvm.org/download.html\\n  ```\\nNow you can install the robonomics node from git source.\\n\\n```\\n  cargo install --force --git https://github.com/airalab/robonomics --tag v1.4.0 robonomics-node\\n```\\n![Start build Robonomics](../images/how-to-build-collator-node/start_build_robonomics.jpg)\\n![End build Robonomics](../images/how-to-build-collator-node/end_build_robonomics.jpg)\\n\\n\\nAfter this command the compiled robonomics binary will be in `~/.cargo/bin` directory.\\n\\nThe next step is how to launch the collator node. You can read about it in the [\\\"How to launch the Robonomics collator\\\"](/docs/how-to-launch-the-robonomics-collator) article.\"}},{\"node\":{\"id\":\"aad9241f0236305682256cd47626ae2c\",\"title\":\"how to update robonomics collator node version\",\"path\":\"/docs/en/how-to-update-robonomics-collator-node-version/\",\"content\":\"\\r\\nIt is recommended to have read the following articles prior to reading this post. [\\\"how-to-build-collator-node\\\"](https://github.com/airalab/robonomics-wiki/blob/master/docs/en/how-to-build-collator-node.md) & [\\\"how-to-launch-the-robonomics-collator\\\"](https://github.com/airalab/robonomics-wiki/blob/master/docs/en/how-to-launch-the-robonomics-collator.md).\\r\\n\\r\\nThis article contains the commands required to update a Robonomics collator node (running on Ubuntu), and also gives an example afterwards.\\r\\n\\r\\n# **Required Commands**\\r\\n\\r\\n*Before you begin, it is recommended that you are logged in as Root, if not, then I would recommend that you use:*\\r\\n\\r\\n``sudo su -``\\r\\n\\r\\n1. Stop the robonomics service\\r\\n\\r\\n``systemctl stop robonomics.service``\\r\\n\\r\\n2. Remove previous version of Robonomics (make sure you are in the correct directory)\\r\\n\\r\\n``rm -f robonomics.X.X.X-ubuntu-x86_64.tar.gz``\\r\\n\\r\\n3. Get the latest release version of Robonomics\\r\\n\\r\\n``wget https://github.com/airalab/robonomics/releases/vX.X.X/.....``\\r\\n\\r\\n4. tar -xf new file\\r\\n\\r\\n``tar -xf robonomics-X.X.X-x86_64-unknown-linux.gnu.tar.gz``\\r\\n\\r\\n5. Move the file\\r\\n\\r\\n``mv robonomics /usr/local/bin/``\\r\\n\\r\\n*(note, you need to move this file to the correct directory which you installed the Robonomics node)*\\r\\n\\r\\n6. Start Robonomics\\r\\n\\r\\n``systemctl start robonomics.service``\\r\\n\\r\\n# **Example when upgrading collator node to Robonomics v1.8.4**\\r\\n\\r\\n``sudo su -`` - log in to root environment\\r\\n\\r\\n``cd /home/admin`` - navigate to the correct directory (your directory may be different)\\r\\n\\r\\n``systemctl stop robonomics.service`` - stop Robonomics\\r\\n\\r\\n``rm -f robonomics-1.7.3-x86_64-unknown-linux-gnu.tar.gz`` - remove previous version\\r\\n\\r\\n``wget https://github.com/airalab/robonomics/releases/download/v1.8.4/robonomics-1.8.4-x86_64-unknown-linux-gnu.tar.gz`` - download latest release version (in this example v1.8.3)\\r\\n\\r\\n``tar -xf robonomics-1.8.4-x86_64-unknown-linux-gnu.tar.gz`` - extract files\\r\\n\\r\\n``mv robonomics /usr/local/bin/`` - move files to desired location\\r\\n\\r\\n``systemctl start robonomics.service`` start Robonomics service\\r\\n\\r\\nNote: releases of Robonomics can be found here: https://github.com/airalab/robonomics/releases/ \\r\\n\\r\\n\\r\\n\"}},{\"node\":{\"id\":\"1280be84d81217f32b1496a993e34164\",\"title\":\"Robonomics Smart Home\",\"path\":\"/docs/en/home-assistant-begin/\",\"content\":\"There are instructions on how to connect your smart home devices to the Robonomics network. You need Robonomics [accounts](/docs/create-account-in-dapp/) for each device, they will publish encrypted data in datalog. Also you need user account that will send commands to devices end encrypt/decrypt data.\\n\\nIn this video you can see the example of connecting temperature sensor:\\n\\nhttps://youtu.be/iB2Z8HtERgs\\n\\n# Requirements\\n\\n* Raspberry Pi 4 or 3\\n* SD card and SD adapter\\n* Temperature sensor - [Keen Home RS-THP-MP-1.0](https://www.zigbee2mqtt.io/devices/RS-THP-MP-1.0.html) (or another [supported device](https://www.zigbee2mqtt.io/information/supported_devices.html))\\n\\n### Method 1 (with SLS Gateway)\\n* [Robonomics SLS Gateway](https://easyeda.com/ludovich88/robonomics_sls_gateway_v01)\\n\\n### Method 2 (with zigbee2MQTT)\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\n### Method 3 (with Xiaomi Gateway)\\n* Xiaomi Gateway (one of [supported](https://www.home-assistant.io/integrations/xiaomi_miio#xiaomi-gateway))\\n* [Mi Home app](https://play.google.com/store/apps/details?id=com.xiaomi.smarthome&hl=ru&gl=US) or HomeKit app\\n\\nAlso you can connect some devices directly through Mi Home app (for example, Vacuum Cleaner).\\n\\n# Setup\\n\\n1. First you need to [setup Raspberry Pi](/docs/raspberry-setup/) (also you can [use prepared image](/docs/raspberry-image/)).\\n2. Then you need to connect devices to Home Assistant:\\n- [Connection with zigbee2MQTT](/docs/zigbee2-mqtt/)\\n- [Setup SLS Gateway](/docs/sls-setup) and [connect it to Home Assistant](/docs/sls-gateway-connect)\\n- [Connection through Xiaomi Gateway](/docs/xiaomi-gateway/)\\n- [Connect Vacuum Cleaner](/docs/vacuum-connect/)\\n3. And [connect them to Robonomics Network](/docs/add-smart-device-to-robonomics/).\\n\"}},{\"node\":{\"id\":\"ab2093f71a4c16ea6bc1e5fbdd3a6ec4\",\"title\":\"Passing dynamic parameters\",\"path\":\"/docs/en/hardware-passing-dynamic-parameters/\",\"content\":\"\\nIn [previous](/docs/connect-simple-cps/) example we discussed how to create a simple CPS with Arduino. Our first CPS is able to do only one task: to blink a led. We suggest you to get through the first lesson. Now let's expand the example and teach our board to blink blue or red led depending on objective parameter.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_with_args).\\n\\n\\n## Arduino\\n\\nThe only difference in Arduino source code is instead of subscribing to one topic now we subscribe to `/blink_red` and `/blink_blue` topics\\n\\n```c\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void blinkRedCb(const std_msgs::Empty& msg) {\\n    blink(13, 500);\\n    blink(13, 500);\\n    blink(13, 500);\\n  }\\n\\n  void blinkBlueCb(const std_msgs::Empty& msg) {\\n    blink(12, 500);\\n    blink(12, 500);\\n    blink(12, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> subRed(\\\"blink_red\\\", &blinkRedCb);\\n  ros::Subscriber<std_msgs::Empty> subBlue(\\\"blink_blue\\\", &blinkBlueCb);\\n\\n  void setup()\\n  {\\n    pinMode(13, OUTPUT);\\n    pinMode(12, OUTPUT);\\n\\n    nh.initNode();\\n    nh.subscribe(subRed);\\n    nh.subscribe(subBlue);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n<!-- Here is the diagram of all connections:\\n\\n.. image:: ../img/6.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\n\\n## ROS\\n\\nWe can pass arguments via objective which points to rosbag file. Have a look at `blink.py` script. The main difference is `blink()` method:\\n\\n```python\\ndef blink(self, data):\\n  if data.data == \\\"blue\\\":\\n      rospy.loginfo(\\\"Blinking blue...\\\")\\n      self.blink_blue.publish(Empty())\\n\\n  if data.data == \\\"red\\\":\\n      rospy.loginfo(\\\"Blinking red...\\\")\\n      self.blink_red.publish(Empty())\\n\\n  rospy.wait_for_service('/liability/finish')\\n  fin = rospy.ServiceProxy('/liability/finish', FinishLiability)\\n  fin(FinishLiabilityRequest(address=self.liability, success=True))\\n  rospy.loginfo(\\\"Finished\\\")\\n```\\n\\nNow `/blink` topic has a `String` type. You can find prepared rosbags in `rosbag` folder.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh/). Do not forget to add `COM1` port in settings. Run the following command:\\n\\n```\\n$ rosrun arduino_with_args blink.py\\n```\\n\\nAlso we need to add rosbag files to IPFS:\\n\\n```\\n$ ipfs add rosbag/blink_blue.bag\\n$ ipfs add rosbag/blink_red.bag\\n```\\n\\n**Before the next step you should approve XRT tokens on the Factory.**\\n\\nThe last step is to build Dapp and launch. Take a look at the previous [lesson](/docs/connect-simple-cps/). To make Arduino blink the blue led send blue demand and blue offer messages. For the red one send corresponding messages.\\n\\nThat's it! Now you are able to pass dynamic parameters to your cyber-physical system agent!\"}},{\"node\":{\"id\":\"71ce4de05ec97c5fa9ac243461be10aa\",\"title\":\"Connect an Air Pollution Sensor\",\"path\":\"/docs/en/hardware-connect-sensor/\",\"content\":\"\\nIn this lesson you are going to learn how to connect your sensor to the network and make it publish data. You will see how it is easy to become a member of a global sensor network!\\n\\nSource code is located [here](https://github.com/airalab/robonomics_tutorials/tree/master/sensor_city).\\n\\nIn this section we are not going to create a liability contract. Instead we will teach Arduino with sensors to publish the data by a request. All measurements will be published as a Result message.\\n\\n## Arduino\\n\\nLet's begin with an Arduino circuit. You need the following components:\\n\\n* Arduino Uno\\n* Optical Dust Sensor Sharp GP2Y1010AU0F\\n* Gas Sensor MQ-2\\n* Gas Sensor MQ-7\\n* Resistor 150 Ohm\\n* Capacitor 220 uF\\n* Wires\\n\\nConnect all parts as described below:\\n\\n<!-- .. image:: ../img/7.png\\n  :alt: Arduino schema\\n  :align: center -->\\n\\nA firmware for Arduino Uno is in `sensor_city/scetches` folder. In order to upload it to the board use [Arduino IDE](https://www.arduino.cc/en/Main/Software).\\n\\n<!-- .. image:: ../img/8.png\\n   :alt: Arduino IDE\\n   :align: center\\n -->\\n\\n## Aira\\n\\nThe following steps are performed in Aira client. You can download the latest image from [this page](https://github.com/airalab/aira/releases). It's convenient to [connect via SSH](/docs/aira-connecting-via-ssh/).\\n\\nAfter you have imported the image to VirtualBox, connect Arduino via USB to your PC and enable serial port forwarding. You should check `Enable Serial Port` and assign `/dev/ttyACM0` in `Path/Address`. Inside the virtual machine `/dev/ttyS0` refers to your external Arduino.\\n\\n<!-- .. image:: ../img/9.png\\n   :alt: Set a port\\n   :align: center -->\\n\\nFinally launch the image and run these command:\\n\\n```\\n$ roslaunch sensor_city publish_data.launch\\n```\\n\\n**Check out the source code to learn how it works under the hood!**\\n\\nNow Aira patiently waits for a signal to publish the measurements. Go to [Dapp](https://dev.aira.life/smart-city/#/) and click on `Broadcast signal`. You should see the data!\"}},{\"node\":{\"id\":\"1c1695f9d703a32d45c7a45bc01a23e7\",\"title\":\"Glossary\",\"path\":\"/docs/en/glossary/\",\"content\":\"\\n## Agent\\n\\nIn terms of Robonomics Network agent is a program module that uses IPFS or blockchain or both interfaces of the network and does some actual work.\\nUsually it's represented as a ROS package and it may connect (but not necessarily) a real cyber-physical system to the Robonomics Network.\\n\\n## Cyber-physical system\\n\\nIt is a combination of a physical mechanism that is usually called a robot and a program algorithm that controls the behavior of the mechanism.\\n\\n## Dapp\\n\\nIt is a short form for Decentralized application. Usually it is a single page web based application that helps to interact with an agent.\\n\\n## IPFS\\n\\nAccording to the official [documentation](https://docs.ipfs.io/introduction/) \\\"IPFS is a distributed system for storing and accessing files, websites, applications, and data\\\".\\nFor more detail how it works go to the official website.\\n\\n## Lighthouse\\n\\nA lighthouse is an autonomous workflow that allows us to distribute the running time of providers that serve a single broadcast channel.\\n\\nFor more information read [Robonomics Whitepaper](https://static.robonomics.network/docs/whitepaper/Robonomics-whitepaper-en.pdf) section 5.2.\\n\\n## Sidechain\\n\\nEthereum based blockchain network with Proof-of-Authority consensus owned by Airalab.\\n\\n\"}},{\"node\":{\"id\":\"ca118dfbaef7821221f7dc42a4727336\",\"title\":\"Getting Started\",\"path\":\"/docs/en/\",\"content\":\"\\n## What is Robonomics\\n\\nRobonomics platform provides tools for working with the robot economy network. Robonomics allow designers of smart cities and industry 4.0 zones to build trust among the [autonomous robots services](/docs/glossary#cyber-physical-system), provide [direct user access via dapp](/docs/glossary#dapp) for ordering products from autonomous factories and services of urban sensor networks. This in turn will allow us to put in place a decentralized system that globally monitors the activities of cyber physical systems.\\n\\nThe following chart describes what place Robonomics takes in the scenario:\\n\\n![Robonomics Chart](../images/robonomics_network_basic_scheme.jpg \\\"Robonomics Network scenario\\\")\\n\\nFind more in [Building dApps on Robonomics deck](https://gateway.pinata.cloud/ipfs/QmNNdLG3vuTsJtZtNByWaDTKRYPcBZSZcsJ1FY6rTYCixQ/Robonomics_keypoint_March_2021.pdf)\\n\\n## Robonomics Network quick start\\n**For newcomer's convenience core Robonomics developers came up with a [6 lessons learning curve](https://wiki.robonomics.network/docs/en/wschool2021-intro/)!**\\n\\nYou'll explore the serverless IoT architecture! Robonomics Web Services (RWS) is the basic infrastructural service for Robotics and IoT on top of Polkadot && IPFS.\\n\\nCourse graduates can launch a local relay chain and control a ROS-compatible device through cross-chain transaction.\\n\\n**[Join Robonomics Developers Discord](https://discord.gg/jTxqGeF5Qy) to connect with community and get technical support.**\\n\\n### Benefits for Robonomics Academy graduates\\n- Intership for best students   Become a Robonomics team member and contribute to the development of the chosen product.\\n- Active community && regular events   Become a part of the learner's community, discuss your use-cases with industry experts. Team-up and participate in hackathons!\\n- Certificate of completion   Add a certificate for completing the course on building DAPPs for IoT to your portfolio.\\n- Assistance in admission to the ITMO university. Whether you are a bachelor or master, you'll get assistance in your admission to the university.\\n- Funding && acceleration opportunities: 1)Apply for up to $50.000 Academia - support grant; 2)Participate in Robonomics builders acceleration program supported by Web3 Foundation; 3)Deploy your stand-alone DAPP on top of Robonomics; 4)Monetize it && get marketing support from Robonomics team.\\n\\n\\n## What the documentation contains\\n\\n### I'm a Dapp developer\\n\\n- [Robonomics-js on GitHub](https://github.com/airalab/robonomics-js) - simple Javascript SDK for Robonomics Network dApp developers.\\n- [dApp template](https://github.com/airalab/vue-dapp-robonomics-template) - uses Vue.js\\n- [Wiki documentation](/docs/robonomics-js/)\\n\\n### I'm a robotics engineer\\n\\nCheck out [cases](/docs/iot-sensors-connectivity/) section and start developing by [examples](/docs/agent-development-examples).\\n\\n\"}},{\"node\":{\"id\":\"d73aa38a7f017fe2315a5b2972ed5782\",\"title\":\"DEMO \\\"Get Weather on Fuji Mountain\\\"\",\"path\":\"/docs/en/get-weather-on-fuji-mountain/\",\"content\":\"\\n**Let's start from a quick example of what Robonomics is able to do within 5 minutes. Requirements: [Metamask extension](https://metamask.io/)**\\n\\nTo get the weather from sensor on Fuji Mountain, please, open the page of [Fuji Weather sensor](https://dapp.robonomics.network/#/fuji/airalab/QmbQT8cj9TJKfYVaidfShnrEX1g14yTC9bdG1XbcRX73wY/0x4D8a26e1f055c0b28D71cf1deA05f0f595a6975d/) in Robonomics dApp and follow instructions below.\\n\\nHere's a walkthrough video:\\n\\nhttps://www.youtube.com/embed/t098NlMELk4\\n\\n## 1. Open the Dapp\\n\\nIn case you don't have MetaMask extension you'll see the picture below. Go to the link provided above and install one.\\n\\n![\\\"Robonomics dApp if no MetaMask installed\\\"](../images/sensor-demo/sensor-demo-1.png \\\"Robonomics dApp if no MetaMask installed\\\")\\n\\n## 2. Allow connection to the extension\\n![\\\"Connection to Robonomics dApp via Metamask\\\"](../images/sensor-demo/sensor-demo-2.png \\\"Connection to Robonomics dApp via Metamask\\\")\\n\\n## 3. Press \\\"Request current values\\\"\\n![\\\"Request sensor's data in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-3.png \\\"Request sensor's data in Robonomics network via dApp\\\")\\n\\n## 4. Sign a message. No token or ether are needed\\n![\\\"Sign a message in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-4.png \\\"Sign a message in Robonomics network via dApp\\\")\\n\\n## 5. Wait until the agent collects the data and sends it back\\n![\\\"Wait for response of the agent in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-5.png \\\"Wait for response of the agent in Robonomics network via dApp\\\")\\n\\n## 6. Wait until the Dapp downloads the result file from IPFS\\n![\\\"Wait for IPFS file with results in Robonomics network via dApp\\\"](../images/sensor-demo/sensor-demo-6.png \\\"Wait for IPFS file with results in Robonomics network via dApp\\\")\\n\\n## 7. Look at the weather data on Fuji Mountain\\n![\\\"The results of sensor network in Robonomics via dApp\\\"](../images/sensor-demo/sensor-demo-7.png \\\"The results of sensor network in Robonomics via dApp\\\")\\n\\nJust now you have broadcasted a demand message and got a result from an autonomous agent! The result file is stored in IPFS, the result message is signed with the agent's private key.\\n\"}},{\"node\":{\"id\":\"d1e2120268293b7b38b196e0961c9841\",\"title\":\"How to Buy a Subscription\",\"path\":\"/docs/en/get-subscription/\",\"content\":\"\\nhttps://youtu.be/EsUiG_4ZGcw\\n\\nWe will use [Robonomics dev node](/docs/run-dev-node) to try the subscription, but in the production network everything works the same. \\n\\nIn `Developer/Chain state` you can see auctions for subscriptions (to get a subscription you need to win a fast auction). Choose `rws` and `auctionQueue` and press `+` button, you will see IDs of available auctions:\\n\\n![queue](../images/dev-node/queue.png)\\n\\nYou can see an information about any subscription with `rws` `auction` and ID of auction (the auction's ID in the picture is 0):\\n\\n![auction](../images/dev-node/auction.png)\\n\\nIn the information about the auction you can see `winner` field, at the moment it is `null` so nobody has this subscription and we can get it. For that go to `Developer/Extrinsic`, choose your account and `rws -> bid`. Also set auction ID (0) and the amount of units to bid (more than 1000000000 Wn):\\n\\n![bid](../images/dev-node/bid.png)\\n\\nSubmit the transaction and check the information about the auction with ID 0 (in `Chain state` choose `rws -> auction` and ID 0):\\n\\n![win](../images/dev-node/auc_win.png)\\n\\nNow in `winner` field you will see your account address, it means that this account has the subscription 0. An auction starts with the first bid and lasts a few blocks, so if somebody bids more tokens than you in the next few blocks one will be the winner and one will take the subscription.\\n\\nNow you can add devices. Devices are accounts that are able to use this subscription and send extrinsics with no fee. To test it lets create a new account with no tokens and add it to devices. \\n\\nTo add devices choose `rws -> setDevices` in `Developer/Extrinsic`. Then press `Add Item` button and choose recently created account with no tokens:\\n\\n![set_devices](../images/dev-node/set_devices.png)\\n\\nSubmit the transaction. Now you can check the list of devices in `Chain state` with `rws -> devices`. There you will see the address of your account without tokens. Choose the account that has bought the subscription and press `+`:\\n\\n![devices](../images/dev-node/devices.png)\\n\\nNow you can try to [send launch](/docs/subscription-launch) extrinsic using the subscription.\"}},{\"node\":{\"id\":\"3d839af62c929db90b9c1cf4369b14a2\",\"title\":\"Gaka-Chu setup and software Installation\",\"path\":\"/docs/en/gaka-chu/\",\"content\":\"\\nhttps://www.youtube.com/watch?v=GxlYxaykqTU\\n\\n**In this article we will go through some installation and launching steps to set up a robot-painter. Requirements:**\\n- KUKA KR6 R900 sixx with KRC4 and a SmartPad;\\n- Intel NUC with [ROS melodic](http://wiki.ros.org/melodic/Installation/Ubuntu) installed;\\n- Table, paint, brush, water.\\n\\n## Software installation on KRC4\\nEKI interface is required on both, KRC4 and NUC. Detailed information on how to set it up on KRC4 is presented [here](https://github.com/AlexeiOvcharov/kuka_experimental/tree/a915bf4e932990379c84164713e7ae11a24a2a13/kuka_eki_hw_interface/krl). Launch it on robot's controller.\\n\\n## Software installation on NUC\\nCreate a catkin workspace:\\n```\\nmkdir -p ~/catkin_ws/src\\ncd ~/catkin_ws/\\ncatkin build\\n```\\nDownload ROS packages. All the scripts are stored [here](https://github.com/airalab/robot_painter/tree/test_branch). Clone the repository:\\n```\\ncd src\\ngit clone --branch test_branch https://github.com/airalab/robot_painter\\ncd robot_painter\\nrm -rf scenes\\nmv * ../\\ncd ..\\nrmdir robot_painter\\n```\\nYou may need some header files and libraries to make it all work correctly. Download them:\\n```\\ncd ~\\ngit clone https://github.com/PaTara43/kuka_moveit_webots\\ncd kuka_moveit_webots\\nsudo mv -r headers/* usr/include/c++/7/\\nsudo mv libs/* usr/local/lib/\\ncd ~\\nsvn checkout https://github.com/PX4/Matrix/trunk/matrix\\nmv matrix -r /usr/include/c++/7/\\nsudo apt-get install ros-melodic-brics-actuator\\ncd ~/catkin_ws\\ncatkin build\\n```\\nAdd source command to `.bashrc` file:\\n```\\necho “source ~/catkin_ws/devel/setup.bash” >> ~/.bashrc\\nsource ~/.bashrc\\n```\\nUp to now. you should be able to launch the scripts. If something goes wrong, try some [troubleshooting](https://github.com/airalab/robot_painter/issues)\\n\\n## Filling in constants\\nFirst of all, the robot needs to know canvas location and orientation as well as the paint tin position. All of this is specified in `fake_painter_enviroment_tf/src/tf_broadcaster.cpp`. Let's take a look into it.\\n```\\n// Plane constants\\nconst double A = -0.0641;\\nconst double B = 0.0214;\\nconst double C = 0.9977;\\nconst double D = -0.2198;\\n\\n// Canvas transform\\nconst double px = 0.52;\\nconst double py = -0.24;\\nconst double qx = -0.011;\\nconst double qy = -0.032;\\nconst double qz = 0.0;\\nconst double qw = 0.999;\\n```\\nThese are the plane equation constants which specify canvas position in 3-D space. They are to be obtained during a calibration process described below. Next goes the paint.\\n```\\ncolorTransform.transform.translation.x = 0.5;\\ncolorTransform.transform.translation.y = 0.2;\\ncolorTransform.transform.translation.z = 0.258;\\n```\\nThese are paint tin coordinates. They also may be specified while calibrating. Canvas size is specified in\\n```\\ncanvas.width = 0.5;\\ncanvas.height = 0.4;\\n```\\nSeveral more important constants are stored in `local_task_planner/src/Drawing.cpp`:\\n```\\nconst double COLOR_BOTLE_HEIGHT = 0.06;\\nconst double COLOR_HEIGHT = 0.045;\\nconst double HEIGHT_OFFSET = COLOR_BOTLE_HEIGHT - COLOR_HEIGHT + 0.02;\\nconst double BRUSH_HEIGHT = 0.01;\\nconst double BRUSH_WIDTH = 0.01;\\n```\\nTheir names say it all, so fill them in according to the situation.\\n\\n## Calibrating Gaka-Chu\\nThe calibration process itself is pretty simple.\\n\\n1) Start EKI interface on the KRC4:\\n\\nLog in in 'AUT' mode, turn on drivers and launch the script `eki_hw_interface`\\n\\n2) Start EKI interface on the NUC\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\nIt should output endless logs.\\n\\n3) Start RViz\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\nYou should see the following:\\n\\n![KUKA in RViz](../images/kuka-real/kuka_rviz.png \\\"KUKA in RViz\\\")\\n\\nTry moving the end effector and clicking 'Plan and Execute'. The robot should move. On SmartPad go to **Display -> Actual position** and observe end effector's coordinate. Place a canvas horizontally to the robot base. Plug a brush into the brush holder and carefully move it till it barely touches the canvas. At this position, save end effector's coordinates. Repeat 12-15 times. Also, save the coordinates of the canvas center and paint tin.\\nWhen you have a set of coordinates, use [these](https://github.com/nakata5321/Matlab_scripts_gaka-chu) Matlab scripts to resolve the missing constants and quaternion. Paste them. Rebuild your workspace with\\n```\\ncd ~/catkin_workspace\\nrm -rf build logs devel\\ncatkin build\\n```\\n\\n## Testing Gaka-Chu calibration\\nWhen calibrated, Gaka-Chu needs to be tested by drawing the borders of canvas. To make him do so execute each in new terminal:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\nroslaunch kuka_moveit_config demo.launch\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\nrosrun local_task_planner draw_workspace\\n```\\nAfter this, you should see a canvas contour in RViz:\\n\\n![KUKA in RViz canvas](../images/kuka-real/kuka_rviz_canvas.png \\\"KUKA in RViz canvas\\\")\\n\\nIn terminal press \\\"S\\\" to perform testing. Robot's end effector should move right above the borders of the canvas and the brush should gently touch the canvas during the entire movement. If not so, try recalibrating. If the canvas model is rotated wrong, you can rotate it by changing quaternion in Matlab.\\n\\n## Making art\\nYou need 6 basic modules to make it all work:\\n- EKI interface;\\n- MOVEit + RViz;\\n- Environment frames broadcasting;\\n- Picture converter service;\\n- Trajectories drawing module;\\n- Starting trigger.\\n\\nLet's launch them one by one.\\n\\n### Eki interface\\nOn KRC4 launch `eki_hw_interface`, on NUC in a new terminal do:\\n```\\nroslaunch kuka_eki_hw_interface test_hardware_interface.launch\\n```\\n\\n### RViz and MOVEit\\nYou need a planner and a simulation. Launch them with\\n```\\nroslaunch kuka_moveit_config demo.launch\\n```\\n\\n### Environment\\nTell the robot where the paint tin and the canvas are. Note that it is not necessary to launch `draw workspace` node, the `tf_broadcaster` shares the canvas size. It just doesn't show it in RViz.\\n```\\nrosrun fake_painter_enviroment_tf tf_broadcaster\\n```\\n\\n### Pictures processor\\nAll incoming pictures need to be processed. Launch the service.\\n```\\nrosrun picture_preprocessing TextConverter.py\\n```\\nWhen it receives the call, it processes a picture with a HP filter and creates a rosbag file with trajectories.\\n\\n### Trajectories drawer\\nThe mainest script here is the trajectories drawer itself. It waits for the picture, calls TextConverter service and draws the painting.\\n```\\nrosrun local_task_planner trajectory_drawing\\n```\\n\\n## Send the robot a picture to draw\\nThe robot listens to a specific ROS-topic where you need to pass the path to a desired picture. The picture should be square (width equals height) and made of lines. Send the path:\\n```\\nrostopic pub /run std_msgs/String \\\"data: '<path_to_picture>'\\\"\\n```\\nAfter that. Two windows pop up showing the contours and the tracks. Close them and see Gaka-Chu drawing. Watch out for safety and alwasy be ready to press emergency stop button.\\nWhen Gaka-Chu finishes his art, you can send another path to picture and painter repeats the whole process.\\n\"}},{\"node\":{\"id\":\"1743989f5302eda3f85683b806b9ea10\",\"title\":\"Connect an Amazon FreeRTOS Device to Robonomics by MQTT\",\"path\":\"/docs/en/freertos-mqtt/\",\"content\":\"\\nHere's the demonstration of how a microcontroller running [Amazon Web Services FreeRTOS](https://aws.amazon.com/freertos/) may be connected to Robonomics Network via MQTT. Please check [this repository](http://github.com/khssnv/freertos_mqtt_robonomics_example) for the project source code.\\n\\nWe use [ESP32 DevKitC](https://devices.amazonaws.com/detail/a3G0L00000AANtjUAH/ESP32-WROOM-32-DevKitC/) with FreeRTOS distribution and MQTT implementation provided by [Espressif IoT Development Framework](https://github.com/espressif/esp-idf) while Espressif is a vendor of the microcontroller used.\\n\\nAlso there is a [PMS-3003](http://www.plantower.com/en/content/?107.html) sensor for demonstration purposes. Sensor measures presence of particulated matter in the air and one may use it to estimate air quality.\\n\\nAir quality is not a topic of the article, you may find more about it at WHO's website: [Ambient (outdoor) air pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health). A goal of the system is to publish sensor measurements to Airalab's Robonomics network.\\n\\n## Hardware setup\\n\\nWe connect PMS3003 TXD PIN5 to ESP32 DevKitC IO17 to transfer measurements by UART.\\nAlso both devices require power and common ground.\\n\\n![Wiring Diagram](../images/freertos-mqtt/wiring.png)\\n\\n## Data Flow\\n\\nIn order to deliver sensor measurements to Robonomics network, on a firmware level our goal is to get data from a sensor by embedded communication protocol it supports (UART in our case) and pass it to AIRA instance by MQTT / TCP.\\n\\n![Sending](../images/freertos-mqtt/send.svg)\\n\\nIn our example we use AIRA cloud deployment available by public IP address and domain name assigned.\\nOn AIRA instance we setup `mosquitto` MQTT broker and subscribe to `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` topic to get messages from MQTT.\\n\\nThen we pass messages to `robonomics io` writer by pipe.\\n\\n![Receiving](../images/freertos-mqtt/recv.svg)\\n\\nNow data available in Robonomics Network and we can be read it with `robonomics io` again.\\n\\n## Firmware\\n\\nWe use [ESP-MQTT sample application with TCP transport](https://github.com/espressif/esp-idf/tree/master/examples/protocols/mqtt/tcp) as a basis.\\n\\nWe only modify `main/app_main.c` for UART connection to the sensor, SNTP time synchronization and periodic MQTT publisher routine.\\n\\nIf you are trying to repeat the project, and it's your first ESP IDF based project, at first please follow [Espressif's ESP-IDF Programming guide](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/index.html#installation-step-by-step) introduction in order to familiarize with firmware operations like configuration, build and upload with `idf.py` tool.\\n\\n### Wi-Fi Configuration\\n\\nIn order to communicate with AIRA instance deployed in cloud, our microcontroller requires Internet connection.\\nWe use ESP32's Wi-Fi for it.\\nEspressif provides utilities to configure on-board Wi-Fi.\\nIn our example we use development environment with Ubuntu 20.04 GNU/Linux.\\nTo configure Wi-Fi we go to project folder and run SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nThen we set Wi-Fi access point SSID and password in `Example Connection Configuration` section.\\n\\n![Menuconfig Wi-Fi](../images/freertos-mqtt/menuconfig-wi-fi.png)\\n\\n### MQTT Endpoint Configuration\\n\\nThere are two things to configure for MQTT.\\nThe first is a MQTT broker address.\\nIt is configurable with SDK configuration tool.\\n\\n```console\\ncd freertos_mqtt_robonomics_example/firmware\\nidf.py menuconfig\\n```\\n\\nSet `Broker URL` in `Example Configuration` section.\\n\\n![Menuconfig MQTT](../images/freertos-mqtt/menuconfig-mqtt.png)\\n\\nThe second thing is a MQTT topic.\\nWe set it in the firmware with the project name prefix followed with our ESP32 MAC address.\\nIt gives us `/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4` for our particular microchip.\\n\\n## From MQTT to Robonomics\\n\\nAt first let's check we receive data by MQTT.\\nWe can subscribe to our Mosquitto MQTT broker topic device publish to.\\n\\n```console\\n$ nix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\"\\nts=1615651809, PM1=2, PM2.5=6, PM10=3\\n```\\n\\nHere we bring `mosquitto` package into our environment to use `mosquitto_sub` utility.\\nThen we subscribe to the topic set in the firmware.\\nWe got our measurements that means AIRA receives data by MQTT correctly.\\nNow let's pipe these messages to Robonomics Network.\\n\\n```console\\nnix-shell -p mosquitto --run \\\"mosquitto_sub -h localhost -t '/freertos_mqtt_robonomics_example/98:F4:AB:72:23:C4'\\\" | robonomics io write pubsub --bootnodes=/ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n```\\n\\nHere we use `robonomics` utility to publish messages in pubsub channel `/freertos_mqtt_robonomics_example`.\\nWe specify `bootnodes` to ensure at least one connection established.\\n\\nNow we are read these messages from the same pubsub channel.\\n\\n```console\\n$ robonomics io read pubsub --listen /ip4/127.0.0.1/tcp/34333 /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:51  Generated random peer id: 12D3KooWB2nym5E6c3aPpnPKK5wB9Z6n9eZzcXSpyUBozxhi6dam\\n2021-03-27 15:15:51  Subscribed to topic: _robonomics_pubsub_peer_discovery\\n2021-03-27 15:15:51  Subscribed to topic: /freertos_mqtt_robonomics_example\\n2021-03-27 15:15:56  New peer connected: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\")\\n2021-03-27 15:15:56  GRAFT: Mesh link added for peer: PeerId(\\\"12D3KooWRPLCioD2b9XLZTZJQELSAuQAyTrHUKzRktrQHtTSs6kS\\\") in topic: TopicHash { hash: \\\"_robonomics_pubsub_peer_discovery\\\" }\\nts=1616843855, PM1=3, PM2.5=4, PM10=3\\n```\\n\\n## Original Resources Used\\n\\n* ESP32 DevKitC pinout from GoJimmy's blog https://gojimmypi.blogspot.com/2017/03/jtag-debugging-for-esp32.html\\n* PSM3003 data structure and decoder from OpenAirProject https://github.com/openairproject/sensor-esp32\\n\\n**Thank you all!**\\n\"}},{\"node\":{\"id\":\"8d5cbb73dee00b6714f5533465ab2e39\",\"title\":\"Ethereum Common\",\"path\":\"/docs/en/ethereum-common/\",\"content\":\"\\nThe packages contains two launch files: `erc20.launch` and `signer.launch`. The last one is included in [Robonomics Liability](/docs/robonomics-liability).\\n\\nBelow is the description for `erc20` node which contains utils for convenient work with Ethereum accounts and XRT token.\\n\\n## ROS Parameters\\n\\n###  ~web3_http_provider\\n\\nWeb3 HTTP provider address. The type is `string`, defaults to `http://127.0.0.1:8545`\\n\\n### ~erc20_token\\n\\nERC20 token to work with. Type is `string`, defaults to `xrt.5.robonomics.eth`\\n\\n### ~factory_contract\\n\\nThe name of the liability factory. The type is `string`, defaults to `factory.5.robonomics.eth`\\n\\n### ~ens_contract\\n\\nThe checksumed address of ENS registry. The type is `string`, defaults to `\\\"\\\"`\\n\\n### ~keyfile\\n\\nPath to keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n### ~keyfile_password_file\\n\\nPath to a file with password for the keyfile. The type is `string`, defaults to `\\\"\\\"`. **Required parameter**\\n\\n## Published topics\\n\\n### /eth/event/transfer (ethereum_common/TransferEvent)\\n\\nThe event [ethereum_common/TransferEvent](/docs/ethereum-common-messages#ethereum_commontransfereventmsg) is emitted after the transfer of tokens was made\\n\\n### /eth/event/approval (ethereum_common/ApprovalEvent)\\n\\nThe event [ethereum_common/ApprovalEvent](/docs/ethereum-common-messages#ethereum_commonapprovaleventmsg) is emitted after the approval of tokens was made\\n\\n## Services\\n\\n### /eth/accounts (ethereum_common/Accounts)\\n\\nList of available Ethereum accounts. See [ethereum_common/Accounts](/docs/ethereum-common-messages#ethereum_commonaccountssrv)\\n\\n### /eth/account_eth_balance (ethereum_common/AccountBalance)\\n\\nReturns the balance of the given address in Wei. See [ethereum_common/AccountBalance](/docs/ethereum-common-messages#ethereum_commonaccountbalancesrv)\\n\\n### /eth/eth_balance (ethereum_common/Balance)\\n\\nReturns the balance of the default address. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/current_block (ethereum_common/BlockNumber)\\n\\nReturns current block number. See :ref:`Ethereum-common-BlockNumber.srv`\\n\\n### /eth/transfer (ethereum_common/Transfer)\\n\\nTransfers tokens from the default account to a given one. See :ref:`Ethereum-common-Transfer.srv`\\n\\n### /eth/transfer_from (ethereum_common/TransferFrom)\\n\\nTransfers tokens from a given account to another one. See :ref:`Ethereum-common-TransferFrom.srv`\\n\\n### /eth/approve (ethereum_common/Approve)\\n\\nApproves tokens from the default account to a given one. See :ref:`Ethereum-common-Approve.srv`\\n\\n### /eth/account_xrt_balance (ethereum_common/AccountBalance)\\n\\nReturns the XRT balance of a given account. See :ref:`Ethereum-common-AccountBalance.srv`\\n\\n### /eth/xrt_balance (ethereum_common/Balance)\\n\\nReturn the XRT balance of the default account. See :ref:`Ethereum-common-Balance.srv`\\n\\n### /eth/account_xrt_allowance (ethereum_common/AccountToAddressAllowance)\\n\\nReturns how much one account is allowed to spend from another account. See :ref:`Ethereum-common-AccountToAddressAllowance.srv`\\n\\n### /eth/xrt_allowance (ethereum_common/Allowance)\\n\\nReturns how much the Factory is allowed to spend from the default account. See :ref:`Ethereum-common-Allowance.srv`\"}},{\"node\":{\"id\":\"f74bdcea89d2c7bde07f3baad0b0bcd9\",\"title\":\"Ethereum Common Messages\",\"path\":\"/docs/en/ethereum-common-messages/\",\"content\":\"\\n## ethereum_common/Address.msg\\n\\n| Field   \\t| Type            \\t| Description                    \\t|\\n|---------\\t|-----------------\\t|--------------------------------\\t|\\n| address \\t| std_msgs/String \\t| Address in Ethereum blockchain \\t|\\n\\n## ethereum_common/UInt256.msg\\n\\n| Field   \\t| Type            \\t| Description                \\t|\\n|---------\\t|-----------------\\t|----------------------------\\t|\\n| uint256 \\t| std_msgs/String \\t| A wrapper for big integers \\t|\\n\\n## ethereum_common/TransferEvent.msg\\n\\n| Field      \\t| Type                                                  \\t| Description      \\t|\\n|------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_from  \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Sender address   \\t|\\n| args_to    \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Receiver address \\t|\\n| args_value \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/ApprovalEvent.msg\\n\\n| Field        \\t| Type                                                  \\t| Description      \\t|\\n|--------------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| args_owner   \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Owner address    \\t|\\n| args_spender \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Spender address  \\t|\\n| args_value   \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Amount of tokens \\t|\\n\\n## ethereum_common/AccountBalance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field   \\t| Type                                                  \\t| Description    \\t|\\n|---------\\t|-------------------------------------------------------\\t|----------------\\t|\\n| balance \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wei \\t|\\n\\n## ethereum_common/AccountToAddressAllowance.srv\\n\\n**Request**\\n\\n| Field   \\t| Type                                                  \\t| Description      \\t|\\n|---------\\t|-------------------------------------------------------\\t|------------------\\t|\\n| account \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n| to      \\t| [ethereum_common/Address](#ethereum_commonaddressmsg) \\t| Ethereum address \\t|\\n\\n**Response**\\n\\n| Field  \\t| Type                                                  \\t| Description   \\t|\\n|--------\\t|-------------------------------------------------------\\t|---------------\\t|\\n| amount \\t| [ethereum_common/UInt256](#ethereum_commonuint256msg) \\t| Balance in Wn \\t|\\n\\n## ethereum_common/Accounts.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------- |-------------------------------------------------------    |----------------------------   |\\n| accounts  | [ethereum_common/Address[]](#ethereum_commonaddressmsg)     | List of available accounts    |\\n\\n## ethereum_common/Allowance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                                       |\\n|--------   |-------------------------------------------------------    |-----------------------------------------------    |\\n| amount    | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | Amount of XRT the Factory is allowed to spend     |\\n\\n## ethereum_common/Approve.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description                   |\\n|---------  |-------------------------------------------------------    |-----------------------------  |\\n| spender   | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Who is allowed to spend       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | How much tokens are allowed   |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/Balance.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type                                                      | Description                       |\\n|---------  |-------------------------------------------------------    |--------------------------------   |\\n| balance   | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The balance of default account    |\\n\\n## ethereum_common/BlockNumber.srv\\n\\n**Request**\\n\\nRequest is empty\\n\\n**Response**\\n\\n| Field     | Type              | Description           |\\n|--------   |-----------------  |---------------------- |\\n| number    | std_msgs/Uint64   | Current block number  |\\n\\n## ethereum_common/Transfer.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Ethereum address      |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\\n## ethereum_common/TransferFrom.srv\\n\\n**Request**\\n\\n| Field     | Type                                                      | Description           |\\n|-------    |-------------------------------------------------------    |---------------------- |\\n| owner     | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Owner's address       |\\n| to        | [ethereum_common/Address](#ethereum_commonaddressmsg)     | Another account       |\\n| value     | [ethereum_common/UInt256](#ethereum_commonuint256msg)     | The amount of tokens  |\\n\\n**Response**\\n\\n| Field     | Type                  | Description       |\\n|--------   |--------------------   |------------------ |\\n| txhash    | std_msgs/Uint8[32]    | Transaction hash  |\\n\"}},{\"node\":{\"id\":\"e62b3364b04000dee581dd55448c6a57\",\"title\":\"How to edit WIKI\",\"path\":\"/docs/en/edit-wiki/\",\"content\":\"\\n**Robonomics WIKI is open source. Any corrections are welcome: fixing errors, typos, some unclear or outdated information, translation into any language. You'll need a [GitHub](https://github.com/) account.**\\n\\n## Edit existing doc\\n\\n1. Choose page\\n2. Click button \\\"Edit page\\\" marked with the Github logo on the page you want to edit\\n3. Clicking on the button will take you to the .md file.\\n4. Please, follow common rules for editing [Markdown files](https://en.wikipedia.org/wiki/Markdown), bearing in mind a few features of the WIKI stack:\\n\\n### Frontmatter\\nDocs in Robonomics WIKI contain frontmatter block. It must be at the top of the Markdown file, and must take the form of valid YAML set between triple-dashed lines. Between the triple-dashed lines, you can set or edit folowing options:\\n\\n```YAML\\n---\\ntitle: How to contribute # Title for the page, you do not need to duplicate it in text\\ncontributors: [positivecrash] # Main contributors (who actively curates this page). GitHub nickname required, without any additional symbols\\ntranslated: true # \\\"true\\\" if it has been translated in current language (see locale folder name of doc)\\n---\\n```\\n\\n### Images\\n1. Upload image in folder `/docs/images/url-of-your-doc`\\n* If image needs to be localized, insert all of them in one folder\\n* Use locale appendix in name of images if it's localized, e.g. `image_en.jpg`\\n* Make sure your image is web optimised and at the same time it looks good\\n2. Insert images standart way for Markdown files.\\n\\n### YouTube videos\\nYou can embed any YouTube video in doc by inserting share link as separate paragraph without any additional quotes or tags, e.g.: `https://youtu.be/kQaSwNYHJQ8`\\n\\n### Asciinema\\nRobonomics WIKI has support for Asciinema. To insert Asciinema, please, follow these instructions:\\n* Import component after frontmatter block `import Asciinema from '~/components/Asciinema.vue'`\\n* Insert as separate paragraph `<Asciinema vid=\\\"WCFcx8C6M8e52UKDNei1xZloU\\\"/>`, where is vid is ID of specific asciicast\\n\\n> You can get the widget script for a specific asciicast by clicking on “Embed” link on asciicast page.\\n> It looks like this:\\n> `<script src=\\\"https://asciinema.org/a/14.js\\\" id=\\\"asciicast-14\\\" async></script>`\\n[Asciinema docs](https://asciinema.org/docs/embedding)\\n\\nIn the example above vid is 14.\\n\\n## Add new doc\\n\\nIf you need to add new page in docs of Robonomics WIKI, please, follow these steps:\\n\\n1. Find the folder with the locale that matches the language of the article you are adding, e.g. `/docs/en/`\\n2. Create .md file, using in name latin characters and follow common rules for [url structure](https://developers.google.com/search/docs/advanced/guidelines/url-structure)\\n3. Edit file as described above\\n4. Duplicate file to other locale folders, even if you do not plan to translate them. Do not forget mark in frontmatter not translated pages as `translated: false`\\n5. Add doc in menu:\\n* Open file `/data/sidebar_docs.yaml`\\n* Decide where to place your doc\\n* If you want to create new section, provide title with locale appendix, using only locales your section is translated\\n* Add doc with link. The link must be only one, and must not contain locale characters. Correct is `/docs/url-of-your-doc`, not correct is `/docs/en/url-of-your-doc`\\n* Use valid YAML for `/data/sidebar_docs.yaml` and rely on the existing file structure\\n\\n## Submit Pull Request\\n\\n[Make pull request](https://docs.github.com/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request) for any content you changed including typos, translations, outdated information or broken links.\\n\\nDecisions about individual PRs made by Robonomics core team. Special grants in [XRT](https://robonomics.network/community#token) are also possible for extended contribution 🤖💙💛💚💎🍭🎉🔌\"}},{\"node\":{\"id\":\"3d8cb475528ddb05c0b144c3e62f4ad7\",\"title\":\"Digital Twins\",\"path\":\"/docs/en/digital-twins/\",\"content\":\"\\n## Requirements\\n- `robonomics` [executable][ln1]\\n- Be familiar with [parachain.robonomics][ln2]\\n\\n## Digital Twins Schema\\n\\nDigital twins have the following structure:\\n\\n| DT id \\t| Topic Name \\t| Source    \\t|\\n|-------\\t|------------\\t|-----------\\t|\\n| 0     \\t| 0x00...000 \\t| 4Gz...hQJ \\t|\\n| 1     \\t| 0x00...001 \\t| 4GVi...Bn \\t|\\n|       \\t| 0x00...002 \\t| 4Hm...vLS \\t|\\n|       \\t| 0x00...... \\t| 4HQ...RQY \\t|\\n|       \\t| 0xFF...FFF \\t| 4Hw...CyK \\t|\\n| 2     \\t| 0x00...000 \\t| 4HJ...k3o \\t|\\n\\n Where:\\n* **DT id** - is unsigned integer unique number.\\n* **Topic name** - is 0x prefixed `H256 hex` or `ascii data` with 32 bytes length. For example: `0x1234....FF` and  `hello.parachain.robonomics.world`.\\n* **Source** - is Account address.\\n\\n## Create Digital Twin\\nGo to ***Developer -> Extrinsics*** and choose `digitalTwin.create()` extrinsic.\\n![digital Twin create][im1]\\n\\n Submit transaction and go to ***Network -> Explorer*** and in the **recent events** you will see information about digital twin.\\n ![digital Twin create info][im2]\\n\\n## Add DT Topic\\n\\nYou can create multiple topics for one digital twin. for creating topic you need go to ***Developer -> Extrinsics*** and choose `digitalTwin.setSource(id,topic,source)` extrinsic. Fill in the fields and submit transaction.\\n![DT topic fields][im3]\\n\\nAgain go to **Network -> Explorer*** and in the **recent events** you will see information about created topic.\\n![info about topic][im4]\\n\\nYou can create several topics for one twin.\\n![topics][im5]\\n\\n## Chain State\\n\\nYou can find all information about existing *digital twins in* ***Developer -> Chain state*** such as:\\n- Total number of Digital twins - total()\\n- Information about owner of digital twin - owner(u32)\\n- Information about topics in digital twin - digitalTwin(u32)\\n![chain info][im6]\\n\\n\\n[ln1]: <https://github.com/airalab/robonomics/releases>\\n[ln2]: </docs/create-account-in-dapp>\\n[im1]: <../images/digital-twin/twin-create.jpg>\\n[im2]: <../images/digital-twin/create-log.jpg>\\n[im3]: <../images/digital-twin/fields.jpg>\\n[im4]: <../images/digital-twin/topic.jpg>\\n[im5]: <../images/digital-twin/topics.jpg>\\n[im6]: <../images/digital-twin/chain-state.jpg>\\n\"}},{\"node\":{\"id\":\"ba7e780dec2105ea2ef04fd61ee5e6c8\",\"title\":\"Cross-chain Message\",\"path\":\"/docs/en/cross-chain-messages/\",\"content\":\"\\nXCM (Cross-chain Message) allows sending messages between parachains. You can send launchXcm transaction to run/stop your robot or datalogXcm transaction to save data to blockchain.\\n\\nhttps://www.youtube.com/watch?v=a6XrqoaYhK8&feature=emb_logo\\n\\n## Create Account\\n\\nLets try to send message from Earth to Mars.\\nGo to [parachain.robonomics.network](https://parachain.robonomics.network/#/explorer) and choose `Airalab Rococo` testnet:\\n\\n![testnets](../images/cross-chain/testnet.jpg)\\n\\nIn `Network/Parachains` you will see two parachains with their id:\\n\\n![ids](../images/cross-chain/Parachains_id.jpg)\\n\\nThen go to Earth parachain and [create](https://wiki.robonomics.network/docs/create-account-in-dapp/) two accounts (for example `ROBOT` and `EMPLOYER`). In a new tab go to Mars parachain.\\n\\n## LaunchXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `EMPLOYER` account and launchXcm. Then write Mars parachain id (2000) and choose the `ROBOT` account:\\n\\n![launch](../images/cross-chain/launch.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nTo see your transaction in Mars parachain go to `Network/Explorer` and look at Recent Events.\\n\\n![recent_launch](../images/cross-chain/recent_launch.jpg)\\n\\n## DatalogXcm\\n\\nIn Earth parachain go to `Developer/Extrinsics` and choose your `ROBOT` account and datalogXcm. Write Mars parachain id (2000) and the message:\\n\\n![datalog](../images/cross-chain/datalog.jpg)\\n\\nNow press `Submit Transaction`.\\n\\nYou can see your transaction in Recent Events in Mars parachain:\\n\\n![recent_datalog](../images/cross-chain/recent_datalog.jpg)\\n\\n\\n\"}},{\"node\":{\"id\":\"a1f1e016f084066b5dcb33ea4ab3b7e1\",\"title\":\"Create digital identity run by Ethereum\",\"path\":\"/docs/en/create-digital-identity-run-by-ethereum/\",\"content\":\"\\nOne of the Robonomics services is [Digital Passport Registration](https://dapp.robonomics.network/#/passport/) for arbitrary data. The service allows you to create a digital identity saving the hashes of the data to the public blockchain and assigning a unique address.\\n\\nYou may find \\\"Digital passport registration\\\" service in [Robonomics DApp](https://dapp.robonomics.network/) in the \\\"Services\\\" section or just follow this [direct link](https://dapp.robonomics.network/#/passport/).\\n\\n\\n## Video walkthrough\\n\\nThe following video shows a progress of Robonomics Whitepaper registration:\\n\\nhttps://www.youtube.com/embed/E8R6VbZvf9w\\n\\n## Step-by-step in pictures\\n\\n### 1. Open the service\\n\\n![Digital passport registration applying form](../images/case_digital_passport_1.jpg \\\"Digital passport registration applying form\\\")\\n\\n### 2. Add necessary information and files\\n\\nPlease note, it is possible to add multiple images.\\n\\n![Filled Form](../images/case_digital_passport_2.jpg \\\"Filled Form\\\")\\n\\n### 3. Sign the demand\\n\\n![Sign the demand for digital passport creation](../images/case_digital_passport_3.jpg \\\"Sign the demand for digital passport creation\\\")\\n\\n\\n### 4. Approve tokens\\n\\nThe service charges a small fee. But first you must approve the required amount of tokens to be spent from your account.\\n\\n![Approve Tokens](../images/case_digital_passport_4.jpg \\\"Approve Tokens\\\")\\n\\n\\n### 5. Accept the offer and sign the message again\\n\\n![Send Order](../images/case_digital_passport_5.jpg \\\"Send Order\\\")\\n\\n### 6. Have a look at the created passport\\n\\n![The Digital Identity](../images/case_digital_passport_6.jpg \\\"The Digital Identity\\\") \\n\\nThe process of registration takes some time. In the end you will see a link to the created identity.\\n\"}},{\"node\":{\"id\":\"de3944de0e02f8e3752a0a0f8ebd24d2\",\"title\":\"Create Account for Robonomics Parachain\",\"path\":\"/docs/en/create-account-in-dapp/\",\"content\":\"\\n**In order to interact and operate with Robonomics Parachain, developers and users need to create an account on the Polkadot / Substrate Portal. The account performs basic functions for the network: your public network address(the public key), the access control to the address and funds (the private key), sending transactions to the network, showing your tokens and their amount, etc. Below are two main ways to create an account for Robonomics Parachain.**\\n\\n## 1. Using Polkadot{.js} Browser Extension\\n\\nThe Polkadot Extension provides a mechanism to generate the account and interact with all Polkadot / Kusama projects including Robonomics Parachain. This is not the safest way to manage your account, but it is the most convenient in terms of security / usability balance.\\n\\n## 1.1. Install Browser Extension\\n\\nThe browser extension is available for [FireFox](https://addons.mozilla.org/en-US/firefox/addon/polkadot-js-extension) and [Google Chrome](https://chrome.google.com/webstore/detail/polkadot%7Bjs%7D-extension/mopnmbcafieddcagagdcbnhejhlodfdd?hl=en) (plus Chromium-based browsers).\\n\\n![Browser Extension](../images/creating-an-account/1.1-polkadot-extension.png \\\"Browser Extension\\\")\\n\\n## 1.2. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. If this is the first time you entered the portal, it will request access to the browser extension, so allow access. \\n\\nOnce you've opened the app, take a look at the top left corner. The name of the network, its icon and the number of the last block are displayed there. Clicking on this area will open a list of all Polkadot / Kusama networks, including test networks and local nodes. You can switch between networks by selecting the required one and pressing the `Switch` button. **Make sure you are connected to Robonomics Parachain now**. \\n\\n![Robonomics Parachain app](../images/creating-an-account/1.2-robonomics-app.png \\\"Robonomics Parachain app\\\")\\n\\n## 1.3. Update Extension Metadata\\n\\nIt is very likely that the app will ask you to update the metadata for the extension to display the correct information about the chain you are connected to. Go to **Settings -> Metadata**, press `Update metadata` button and then, in the pop-up window, allow the extension to do it. \\n\\n![Updating metadata](../images/creating-an-account/1.3-metadata-update.png \\\"Updating metadata\\\")\\n\\n## 1.4. Create Account in Extension\\n\\nOpen the Polkadot{.js} browser extension. Click the big plus button or select `Create new account` from the small plus icon in the top right. You should see the following menu, with generated mnemonic seed in the form of twelve words and the address. \\n\\n![Account creation, step one](../images/creating-an-account/1.4-create-account-step-1.png \\\"Account creation, step one\\\")\\n\\nThe seed is your key to the account. Knowing the seed allows you (or anyone else who knows the seed) to get control on this account and even re-create it, if you forget the password. **It's very important to store it somewhere securely**, preferably on paper or other non-digital device, not in digital storage or on a computer. \\n\\nSave the seed and press `Next step`. You should see the following menu.\\n\\n![Account creation, step two](../images/creating-an-account/1.5-create-account-step-2.png \\\"Account creation, step two\\\")\\n\\n- *Network* allows you to choose which of the networks this account will be exclusively used for. You can use the same address on multiple networks, however, for privacy reasons, it is recommended that you create a new address for each network you use. \\nSelect the Robonomics network from the drop-down list. If you could not find the Robonomics network, then most likely you did not update the metadata, go back and do it.\\n\\n    - You will notice that the format of the address and the account icon will change — this is normal. Different network formats are merely other representations of the same public key. \\n\\n- *Name* is just account's name for your use only. It is not stored on the blockchain and will not be visible to other users. \\n\\n- *Password* is used to encrypt your account's information. You will need to re-enter it when signing transactions on the portal. Create one and remember it.\\n\\nAs a result, after creating an account, you will see it in the list of accounts in Polkadot{.js} extension. By clicking on three dots, you can rename the account, export it, remove it from the extension and change the network used for the account. \\n\\nAlso, the account will appear in the **Accounts -> Accounts** menu on the portal, where it will be noted that it was injected using the extension.\\n\\n![Successful account creation](../images/creating-an-account/1.6-account-injected.png \\\"Successful account creation\\\")\\n\\n\\n## 2. Directly on Robonomics Parachain App\\n\\nYou can use the user interface on the Polkadot / Substrate Portal to create an account, although this is not recommended as it is the less secure method for the account creation. It should be used when other methods are not applicable or for development and tests. \\n\\n## 2.1. Open Robonomics Parachain App\\n\\nGo to [Robonomics Parachain app](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) on Polkadot / Substrate Portal. **Check at the top left corner that you are connected to Robonomics Parachain**.  \\n\\nGo to **Accounts -> Accounts** and press `Add account` button. \\n\\n![Robonomics Parachain App](../images/creating-an-account/2.1-robonomics-app-main-view.png \\\"Robonomics Parachain App\\\")\\n\\n## 2.2. Create Account\\n\\nYou should see the following popup menu with account seed. \\n\\n![Generating account seed](../images/creating-an-account/2.2-robonomics-app-seed.png \\\"Generating account seed\\\")\\n\\nIt has two forms: *Mnemonic* (human-readable) and *Raw* (a sequence of digits and letters). Save the seed phrase securely and press `Next`.\\n\\nIn the next menu, you need to set the account name and password, similar to the extension instructions described above.\\n\\n![Generating account name and password](../images/creating-an-account/2.3-robonomics-app-name-pass.png \\\"Generating account name and password\\\")\\n\\nClicking on the `Next` button will take you to the last window. Click `Save` to finish account creation. It will also generate a backup JSON-files that you should safely store. You can later use this file to recover your account if you remember the password.\\n\\n![Successful account creation](../images/creating-an-account/2.4-robonomics-app-account-created.png \\\"Successful account creation\\\")\\n\\n## 3. Account Сreated Successfully \\n\\nNow you can fully operate with your fresh-created account. Send and receive tokens, messages, write datalog and more. Feel free to explore all the features of app. To copy your account's address simply click on its icon, address will be copied to clipboard. \\n\\nIf you would like to know more about Polkadot / Kusama accounts and additional ways to create them, more information can be found [here](https://wiki.polkadot.network/docs/learn-accounts) and [here](https://wiki.polkadot.network/docs/learn-account-generation).\\n\"}},{\"node\":{\"id\":\"789283347c200026f4ddc94febc1b3c6\",\"title\":\"How to contribute\",\"path\":\"/docs/en/contributing/\",\"content\":\"\\nRobonomics network is an open-source project built by core maintainers from Airalab and contributors. We want to make it easy for anyone to contribute. You may contribute to core, suggest changes, improve documentation or write a blog post. Please, read some rules and suggestions for contributing.\\n\\n## Main Airalab repositories \\n\\n- [aira](https://github.com/airalab/aira) - AIRA client for Robonomics network. \\n- [robonomics_comm](https://github.com/airalab/robonomics_comm) - Robonomics communication stack\\n- [robonomics_contracts](https://github.com/airalab/robonomics_contracts) - smart contracts of Robonomics network\\n\\n## Bugs and proposals for improvements\\n\\nIf you find a bug in AIRA client, Robonomics repositories, this documentation or would like to propose an improvement, please, open a new issue in the same repository, that you want to contribute.\\n\\n### Rules for reporting\\n\\nWhen opening a new issue, do not forget about a few basic rules for reporting:\\n\\n1. Choose exact repository, that you want to submit an issue.\\n\\n2. If you are reporting bug, make sure the bug was not already reported.\\n\\n3. Be sure to include title and clear description, as much relevant information as possible.\\n\\n4. Please prefix your issue with one of the following: `[BUG]`, `[PROPOSAL]`, `[QUESTION]`.\\n\\n\\n## Pull requests\\n\\nAny Airalab repository or this documentation may be subject to pull requests or changes by contributors where you believe you have something valuable to add or change. Please, do not forget about basic rules for contributors.\\n\\n### Rules for contributing\\n\\n1. Pull requests are preferred to issues, if you have some fixes, especially for small changes such as typos.\\n\\n2. Make sure the PR description clearly describes the problem and the solution. Include the relevant issue number if applicable.\\n\\n3. Please, do not fix whitespace, format code, or make a purely cosmetic patch.\\n\\n4. Please, attempt to adhere to the prevailing Markdown style, language, and layout.\\n\\n\\n\"}},{\"node\":{\"id\":\"b9f3cf58125758813be8bd42728cf903\",\"title\":\"Substrate Cumulus Parachain Testsuite for cross-chain messaging\",\"path\":\"/docs/en/connectivity-terminal-readme/\",\"content\":\"\\n# Sensors-Connectivity Terminal Readme\\n\\n## Connection\\n\\nTo connect to the server:\\n\\n```bash\\nssh <user>@<address>\\n```\\nWhere user and address are replaced with user, which connectivity service runs under, and address of the VM respectively.\\n\\n## Installation\\n\\nInstallation guide can be found on this [page](https://wiki.robonomics.network/docs/en/sensors-connectivity-on-aira/).\\n\\n\\n## Status checking \\n\\nAssuming you launch the code as a systemd service. Therefore, to check service status:\\n\\n```bash\\nsystemctl status connectivity.service\\n```\\nThere you will find all necessary information about the service, including path to the log files.\\n\\n## Logs\\n\\nGeneral path for log files is: ` ~/.ros/log/latest/connectivity-worker-1.log` where `connectivity-worker-1.log` is the last recordered file.\\n\\nFor watching logs in real time:\\n```bash\\ntail -f  <path>\\n```\\nWhere path should be replced with the log path. To look through the whole file simply open the log file in your favourite editor.\\n\\nIt can be useful to copy log files to your local machine:\\n\\n```bash\\nscp -rv <user>@<address>: <path-to-log-files> <path-in-your-local-machine>\\n```\"}},{\"node\":{\"id\":\"993217b532ab3f29860c89e6128507b0\",\"title\":\"Connect the simplest CPS\",\"path\":\"/docs/en/connect-simple-cps/\",\"content\":\"\\nIn this section we will build the simplest real cyber-physical system!\\n\\nWe will buy a \\\"wink\\\" from Arduino, e.g. make Arduino blink with its onboard led. The lesson is tested on Arduino Uno, but any other board with a led will do the job.\\n\\n> The source code of this lesson is [here](https://github.com/airalab/robonomics_tutorials/tree/master/arduino_blink).\\n\\n## Arduino\\n\\nThe firmware for the board is located in [arduino_blink/misc/arduino/arduino.ino](https://github.com/airalab/robonomics_tutorials/blob/master/arduino_blink/misc/arduino/arduino.ino). Use [Arduino IDE](https://www.arduino.cc/en/Main/Software) to load the code to your Arduino board.\\n\\nIn the code we subscribe for the ``/blink_led`` topic and set a callback. The type of the topic is ``Empty``, so the board waits until someone publishes to the topic and performs the LED blinking.\\n\\n```\\n  #include <ros.h>\\n  #include <std_msgs/Empty.h>\\n\\n  ros::NodeHandle  nh;\\n\\n  void blink(int led, int mil) {\\n\\n    digitalWrite(led, HIGH);\\n    delay(mil);\\n    digitalWrite(led, LOW);\\n    delay(mil);\\n\\n  }\\n\\n  void messageCb( const std_msgs::Empty& toggle_msg){\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n    blink(LED_BUILTIN, 500);\\n  }\\n\\n  ros::Subscriber<std_msgs::Empty> sub(\\\"blink_led\\\", &messageCb );\\n\\n  void setup()\\n  {\\n    pinMode(LED_BUILTIN, OUTPUT);\\n    nh.initNode();\\n    nh.subscribe(sub);\\n  }\\n\\n  void loop()\\n  {\\n    nh.spinOnce();\\n    delay(1);\\n  }\\n```\\n\\n\\n## AIRA client\\n\\n> You can download the latest release from [here](https://github.com/airalab/aira/releases).\\n\\nSet up the COM port forwarding. You should forward your `/dev/ttyUSB0` or `/dev/ttyACM0` port (depending on the system) to `COM1`. In the client `/dev/ttyS0` will represent the board. After this launch the virtual machine.\\n\\n## ROS\\n\\nWhen new liability is created it goes to `/liability/ready` topic. We have to remember the address and call `/liability/start` service to get the data from objective.\\n\\n```\\n  def newliability(l):\\n    self.liability = l.address\\n    rospy.loginfo(\\\"Got new liability {}\\\".format(self.liability))\\n\\n    prefix = \\\"/liability/eth_\\\" + self.liability\\n    rospy.Subscriber(prefix + '/blink', Empty, self.blink)\\n\\n    rospy.wait_for_service(\\\"/liability/start\\\")\\n    rospy.ServiceProxy('/liability/start', StartLiability)(StartLiabilityRequest(address=self.liability))\\n  rospy.Subscriber(\\\"/liability/ready\\\", Liability, newliability)\\n```\\n\\nA message in the `/blink` topic come from the objective field. Have a look at [Basic usage](/docs/aira-basic-usage) page.\\n\\n## AIRA\\n\\nConnect to AIRA client via SSH as described [here](/docs/aira-connecting-via-ssh). All tutorials are pre-installed. To launch the ros package run the following command:\\n\\n```\\n$ rosrun arduino_blink blink.py\\n```\\n\\nAlso we need to add a rosbag file to IPFS::\\n\\n```\\n$ ipfs add rosbag/blink.bag\\n```\\n\\n> Before the next step you should approve XRT tokens on the Factory.\\n\\nOn your host system build and launch an Dapp for the lesson:\\n\\n```\\n$ git clone https://github.com/airalab/robonomics_tutorials/\\n$ cd robonomics_tutorials/arduino_blink_dapp\\n$ npm i && npm run dev\\n```\\n\\nOpen [http://localhost:8000/](http://localhost:8000/) and press \\\"Demand\\\" then \\\"Offer\\\" buttons. Wait until a new liability is created and you should see the board blinking. Congratulations on the first agent!\\n\"}},{\"node\":{\"id\":\"dd1924ac9e7e8fee3662b1696b86a7c3\",\"title\":\"Connect Sensor To Robonomics Network\",\"path\":\"/docs/en/connect-sensor-to-robonomics/\",\"content\":\"\\n## Hardware\\n\\nUniversal board for air quality sensor, based on ESP8266 allows to use the following modules: NODEMCU v3, NODEMCU v2, WEMOS D1 MINI. The device is designed for 6 - 24 volt power supply, using DC-DC converter DC MINI560.\\n\\n![plata](../images/sensors-connectivity/plata.png)\\n\\nThis board allows you to connect PM sensors:\\n\\n- [SDS011](https://cdn-reichelt.de/documents/datenblatt/X200/SDS011-DATASHEET.pdf)\\n- PMS1003-6003\\n- [PMS7003/G7](http://www.plantower.com/en/content/?110.html)\\n- [SPS 30 PM Sensor](https://sensirion.com/products/catalog/SPS30/)\\n\\nI2C connectivity:\\n\\n- [BMP180](https://cdn-shop.adafruit.com/datasheets/BST-BMP180-DS000-09.pdf) - temperature and humidity\\n- [BME/P280](https://www.mouser.com/datasheet/2/783/BST-BME280-DS002-1509607.pdf) - temperature, humidity, atmospheric pressure\\n- [HTU21D](https://eu.mouser.com/ProductDetail/Measurement-Specialties/HTU21D?qs=tx5doIiTu8oixw1WN5Uy8A%3D%3D) - temperature and humidity\\n- SHT3x(I2C) - temperature and humidity\\n- [CCS811 VOC SENSOR](https://www.sciosense.com/wp-content/uploads/documents/Application-Note-Baseline-Save-and-Restore-on-CCS811.pdf) - volatile Organic Compounds, CO2 equivalent\\n- LCD1602/ 2004 / OLED SSD1306 / SH1106 - supported displays\\n\\nPossibility of connection via 1 Wire interface:\\n\\n- DTH22(AM2302) - temperature and humidity\\n- DS18B20 - temperature.\\n\\nThere is also a smaller MINI model with a trimmed down list of connectable devices. The source circuits for both models can be found at [full model](https://oshwlab.com/ludovich88/aira_sensor_rev0-1) and [MINI model](https://oshwlab.com/ludovich88/aira_sensor_d1_mini).\\n\\n> To obtain a ready-made board, contact the developers at vm@multi-agent.io.\\n\\nAfter receiving/assembling the sensor, all that remains is to flash and configure it.\\n\\n## Firmware\\n\\nOur firmware is based on the firmware from [Sensor.Community](https://github.com/opendata-stuttgart/sensors-software), with some sensors added and the data sending scheme changed. The source code can be found [at the link](https://github.com/LoSk-p/sensors-software/tree/master/airrohr-firmware). \\n\\nTo flash the sensor you can use `airrohr-flasher`. Download the executable for your operating system from [latest release](https://github.com/airalab/sensors-connectivity/releases).\\n\\n### For Linux\\n\\nFirst you need to add a user to the `dialout` group (for Ubuntu) to gain access to the USB port:\\n\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\n\\nAfter that, reboot the computer. Next, change the permissions of the file and run it:\\n\\n```bash\\nchmod +x airrohr-flasher-linux\\n./airrohr-flasher-linux\\n```\\n\\n### For Windows:\\nUnzip the flasher and double-click to run it. You will also need to install drivers for USB2serial (Windows 10 should start automatically):\\n\\n* Drivers for NodeMCU v3 (CH340): [Windows](http://www.wch.cn/downloads/file/5.html) ([2018/09/04 v3.4 mirror](https://d.inf.re/luftdaten/CH341SER.ZIP))\\n\\n### For MacOS.\\nDownload the flasher and run it. You will also need to install the drivers for USB2serial: \\n* Drivers for NodeMCU v3 (CH340): [macOS](http://www.wch.cn/downloads/file/178.html) ([2018/09/04 v1.4 mirror](https://d.inf.re/luftdaten/CH341SER_MAC.ZIP))\\n\\n---\\n\\nSelect the firmware (in English or Russian) and click `Upload`. Uploading the firmware will take some time.\\n\\n![flasher](../images/sensors-connectivity/7_flasher.jpg)\\n\\n## Setup\\n\\nAfter downloading the firmware, reboot the ESP (just disconnect and reconnect the USB).\\n\\nAfter a while after the reboot, ESP will create a Wi-Fi network called RobonomicsSensor-xxxxxxxxx. Connect to it from your phone or computer, then an authorization window will open (if it doesn't open in any browser go to 192.168.4.1). Select your Wi-Fi network from the list (or write it yourself if it's not on the list) and fill in the password field. Also write the coordinates of the place where the sensor will be installed in the field below:\\n\\n![guest](../images/sensors-connectivity/guest.jpg)\\n\\nClick `Save and restart`.\\n\\nThe board will connect to the specified Wi-Fi network and in a couple of minutes you will be able to see the data on [map](https://sensors.robonomics.network/#/):\\n\\n![map](../images/sensors-connectivity/14_map.jpg)\\n\\n## Advanced Setup\\n\\nFor a more detailed setup (you may need it to connect additional sensors or send data to your own server) you need to find the address of the sensor in your Wi-Fi network. To do this, you can use `airrohr-flasher` (your computer must be on the same network as the sensor is connected to). Start it and go to the `Discovery` tab, then press `Refresh`, wait a moment and your sensor address will appear.\\n\\n![addr](../images/sensors-connectivity/11_flaser2.jpg)\\n\\nDouble-click on this address (or type it into your browser), you will get to the sensor menu:\\n\\n![home](../images/sensors-connectivity/home.png)\\n\\nUnder the `Configuration` tab you can configure the sensors used:\\n\\n![sensors](../images/sensors-connectivity/sensors.png)\\n\\nAnd also set up sending to your own server. To do this, in the tab `APIs` uncheck `Robonomics` and check `Send to own API` and specify the server address and port (65 for sensors connectivity):\\n\\n![apis](../images/sensors-connectivity/apis_en.png)\\n\\nClick `Save and restart` to save the settings.\\n\\n\\n\"}},{\"node\":{\"id\":\"5d69df7948e0bf05939bcb1f3c3dc507\",\"title\":\"Connect Mars Curiosity rover under Robonomics parachain control\",\"path\":\"/docs/en/connect-mars-curiosity-rover-under-robonomics-parachain-control/\",\"content\":\"\\n**Let's see how Robonomics Parachain control allows to make Mars Curiosity rover move. Requirements:**\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller\\n```\\n- IPFS up to [0.6.0](https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz)\\n- [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases). This tutorial tested fine on v1.1)\\n\\nHere is the video showing successful launch:\\n\\nhttps://www.youtube.com/watch?v=6BSOyRbmac8\\n\\n### 1. Set up a simulation\\nDownload Curiosity rover package:\\n```shell\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src\\ngit clone https://bitbucket.org/theconstructcore/curiosity_mars_rover/src/master/\\ncd ..\\ncatkin build\\n```\\nWe need to adjust starting conditions to make our rover spawn smoothly:\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/worlds` and change line 14 of the file` mars_curiosity.world` to \\n`<pose>0 0 8 0 0 0</pose>`\\n\\n- Go to\\n\\n`src/master/curiosity_mars_rover_description/launch` and change line 4 of the file `mars_curiosity_world.launch` to \\n`<arg name=\\\"paused\\\" default=\\\"false\\\"/>`\\n\\nDon't forget to add source command to `~/.bashrc`\\n`source /home/$USER/robonomics_ws/devel/setup.bash`\\n\\n\\n- Reboot console and launch the simulation:\\n\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\n![Mars rover](../images/curiosity-demo/rover.jpg?raw=true \\\"Mars rover\\\")\\n\\nNote: if the image is dark, e.g. shadowed, change `Camera` to `Orthorgraphic` in Gazebo toolbar.\\nThe simulation can be closed for a while.\\n\\n------------\\n\\n### 2. Download Robonomics controller package\\nTo download a controller package for Rover type in terminal:\\n```shell\\ncd ~/robonomics_ws/src\\ngit clone https://github.com/PaTara43/robonomics_sample_controller\\ncd robonomics_sample_controller\\npip3 install -r requirements.txt\\npip3 install rospkg\\ncd ..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3 # The controller supports python3\\n```\\n\\n------------\\n\\n### 3. Manage accounts in DAPP\\nSince we are testing, let us create a local robonomics network with robonomics binary file:\\n```shell\\n./robonomics --dev --tmp\\n```\\n\\n![Running node](../images/curiosity-demo/robonomics.jpg?raw=true \\\"Running node\\\")\\n\\n\\nGo to [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/) and switch to local node \\n\\n![Local node](../images/curiosity-demo/local_node.jpg?raw=true \\\"Local node\\\")\\n\\n\\nGo to Accounts and create **CURIOSITY** and **EMPLOYER** accounts.\\n\\n**Important**! Copy each account's address (to copy address click on account's icon) and Curiosity's account **mnemonic seed** (obtained while creating the account)\\nTransfer some money (units) to these accounts. You can read more about accounts in Robonomics [here](https://wiki.robonomics.network/docs/en/create-account-in-dapp/)\\n\\n![Account creation](../images/curiosity-demo/account_creation.jpg?raw=true \\\"Account creation\\\")\\n\\n\\nAdd these addresses, seed and node address (defaults to `ws://127.0.0.1:9944` for developer node) in `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. No quotes.\\n\\n------------\\n\\n\\n### 4. Start Robonomics\\n\\nBefore going further, make sure that you have installed [IPFS Companion Extension](https://github.com/ipfs/ipfs-companion).\\n\\nIn a separate terminal launch IPFS:\\n```shell\\nifps init #you only need to do this once per IPFS installation\\nipfs daemon\\n```\\n\\nIn another separate terminal launch Curiosity simulation if it's not live:\\n```shell\\nroslaunch curiosity_mars_rover_description main_real_mars.launch\\n```\\nWait till it stays still\\n\\nIn another terminal launch the controller:\\n```shell\\nrosrun robonomics_sample_controller sample_controller.py\\n```\\n![Controller](../images/curiosity-demo/controller.jpg?raw=true \\\"Controller\\\")\\n\\n\\nNow you can send a transaction triggering the Rover to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/).\\nGo to `Developer->Extrinsics` and select Curiosity's employer account, `launch` extrinsic, Curiosity's account as a target account and `yes` as a parameter.\\nSubmit the extrinsic.\\n\\n![Extrinsic](../images/curiosity-demo/extrinsic.jpg?raw=true \\\"Extrinsic\\\")\\n\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter. The rover will move around and collect data for about a minute.\\nLater, when the job is done:\\n\\n![Job done](../images/curiosity-demo/job_done.jpg?raw=true \\\"Job done\\\")\\n\\n\\nOn the Robonomics portal go to `Developer -> Chain state` and obtain a `CURIOSITY` datalog using “+” button with selected `datalog -> RingBufferItem` as query: \\n\\n![Datalog](../images/curiosity-demo/datalog.jpg?raw=true \\\"Datalog\\\")\\n\\nNow the IPFS hash of the telemetry is saved in the blockchain. To see the data simply copy the hash and find it on a gateway:\\n\\n![Data in IPFS](../images/curiosity-demo/data_in_ipfs.jpg?raw=true \\\"Data in IPFS\\\")\\n\\n\\nThis telemetry is kept in a decentralized storage, and it's hash is stored in a blockchain!\\n\"}},{\"node\":{\"id\":\"e34bbe4a824ebcd1500720fa277e07e3\",\"title\":\"Connect any ROS-compatible robot under Robonomics parachain control. Part 2, IPFS\",\"path\":\"/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2/\",\"content\":\"\\n**In this article we will continue using Robonomics tools to make a drone be controlled by a parachain. This time we will add sending data to IPFS and hash storing in chain options. Below is the instruction and code snippets. Requirements:**\\n- [**Part 1 of this tutorial**](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1)\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- IPFS 0.4.22 (download from [here](https://dist.ipfs.io/go-ipfs/v0.4.22/go-ipfs_v0.4.22_linux-386.tar.gz) and install)\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n- Python dependencies:\\n```\\npip install cv_bridge ipfshttpclient\\n```\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=dliLb6GHgpo&feature=youtu.be\\n\\n\\n## 1. Add dependencies\\nIf we launch a simulation and look at the topic list (see previous tutorial), we will see, that there is one topic containing front camera data and using `sensor_msgs/Image` message type:\\n\\n![front_camera](../images/drone-demo/front_camera.jpg \\\"front_camera\\\")\\n\\nLet's try to take a picture every 1 second and after the flight publish these photos to IPFS. If you have completed the first tutorial, you don't need to download anything else. It's the `drone_sample_controller_pictures.py` script.\\n## 2. Manage accounts in DAPP\\nAs done in a previous tutorial, create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 3. Launch\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nIn another one launch ipfs daemon:\\n```\\nifps init # you only need to do this once\\nipfs daemon\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller_pictures.py\\n```\\nNow you can send a transaction triggering the drone to start flying and taking pictures. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying and taking pictures:\\n\\n![flying_picturing](../images/drone-demo/flying_picturing.jpg \\\"flying_picturing\\\")\\n\\nLater, when the job is done, on the Robonomics portal go to `Developer` -> `Chain state` and add a `DRONE` datalog using `“+”` button with selected `datalog` as state query. The IPFS hash of the telemetry has been saved in the blockchain. To see the data simply copy the hash and add it to the local [gateway](https://gateway.ipfs.io/ipfs/QmeYYwD4y4DgVVdAzhT7wW5vrvmbKPQj8wcV2pAzjbj886/docs/getting-started/) address `localhost:8080/ipfs/`:\\n\\n![Voila](../images/drone-demo/datalog.jpg \\\"Voila\\\")\\n\"}},{\"node\":{\"id\":\"05ee09699b614b818cafd943d61d8940\",\"title\":\"Connect ROS-compatibale Drone To Robonomics Parachain. Part 1. Launch by Transaction\",\"path\":\"/docs/en/connect-any-ros-compatible-robot-under-robonomics-parachain-control-1/\",\"content\":\"\\n**In this article we will show that with the help of Robonomics tools you can control any ROS-compatible device. We will find a random drone simulation package on the web and adjust it to run with Robonomics.**\\n**Requirements:**\\n- Ubuntu 18.04 LTS\\n- ROS Melodic + Gazebo + RViz (installation manual [here](http://wiki.ros.org/melodic/Installation))\\n- Robonomics node (binary file) (download latest release [here](https://github.com/airalab/robonomics/releases))\\n\\nThe entire process of coding this part of demo is presented in a video below.\\n\\nhttps://www.youtube.com/watch?v=fDpwhBasQ5o&feature=youtu.be\\n\\n## 1. Find a simulation\\nLet's surf the web. Google for `ROS drone simulator`. The first link will mostly likely show you the `tum_simulator` page on [http://wiki.ros.org/tum_simulator](http://wiki.ros.org/tum_simulator)\\n\\n![tum_simulator](../images/drone-demo/tum_simulator.jpg \\\"tum_simulator\\\")\\n\\nIt's pretty outdated, so we better find a fork for our system. Google for `tum_simulator Ubuntu 18 Gazebo 9 fork`. The first result is a GitHub [repo](https://github.com/tahsinkose/sjtu-drone) with an appropriate package. Dowload it\\n```\\nmkdir -p drone_simulator_ws/src\\ncd drone_simulator_ws/src\\ngit clone https://github.com/tahsinkose/sjtu-drone\\ncd ..\\ncatkin build\\n```\\nDon’t forget to add source command to `~/.bashrc`:\\n```\\necho \\\"source /home/$USER/drone_simulator_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource \\\"~/.bashrc\\\"\\n```\\nNow we can run the simulation to see what do we need to do to take the drone under parachain control.\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\n\\n## 2. Inspect ROS topics\\nWhen the simulation is runnung, in a new tab run the following command to see the list of topics used by the drone:\\n```\\nrostopic list\\n```\\nLet's take a look at `/cmd_vel`, `/drone/takeoff` and `/drone/land`:\\n```\\nrostopic info /cmd_vel\\nrostopic info /drone/takeoff\\nrostopic info /drone/land\\n```\\n\\n![topics_info](../images/drone-demo/topics_info.jpg \\\"topics_info\\\")\\n\\nAs may be seen, there should be messages of `Twist` and `Empty` types, they are parts of `std_msgs` and `geometry_msgs`, we'll use this in the controller. Shut the simulation for a while.\\n## 3. Download controller package\\nGlobally, the main difference from the casual ROS robot controller is a block of code, which checks all the transactions in the network using [Robonomics IO](https://wiki.robonomics.network/docs/rio-overview/). The package itself is available on GitHub. Download it and build the workspace:\\n```\\ncd ~/drone_simulator_ws/src\\ngit clone https://github.com/PaTara43/drone_simulator_controller\\ncd drone_simulator_controller/src\\nchmod +x *.py\\ncd ~/drone_simulator_ws/src\\ncatkin build\\n```\\n## 4. Manage accounts in DAPP\\nSince we are testing, let's create a local robonomics network node with robonomics binary file:\\n```\\n./robonomics --dev\\n```\\n**Important!** Before next launches it is necessary to remove a directory `db` with\\n\\n```\\nrm -rf /home/$USER/.local/share/robonomics/chains/dev/db\\n```\\nAfter a successful launch create accounts following [this](/docs/create-account-in-dapp) manual. **Do not forget to save each account's seed and address! You will need them for transactions**. Add these addresses, seeds and path to robonomics binary file to file `config.config` in `robonomics_ws/src/robonomics_sample_controller/src`. Transfer some money (units) to these accounts:\\n\\n![balances](../images/drone-demo/balances.jpg \\\"balances\\\")\\n## 5. Launching the drone under parachain control\\nUp to now the **only thing running** should be the robonomics local node. In a separate terminal launch drone simulation:\\n```\\nroslaunch sjtu_drone simple.launch\\n```\\nRun the script:\\n```\\nrosrun drone_simulator_controller drone_sample_controller.py\\n```\\n\\n![launched_drone](../images/drone-demo/launched_drone.jpg \\\"launched_drone\\\")\\n\\nNow you can send a transaction triggering the drone to start flying. To do so, you should use the Robonomics IO `write` subcommand of robonomics binary file:\\n```\\necho \\\"ON\\\" | ./robonomics io write launch -r <DRONE_ADDRESS> -s <EMPLOYER’S_KEY>\\n```\\nWhere `<DRONE_ADDRESS>`  and `<EMPLOYER’S_KEY>` are replaced with  previously saved strings accordingly.\\nYou should see the log `\\\"Taking Off\\\"` and the drone should start flying:\\n\\n![flying](../images/drone-demo/flying.jpg \\\"flying\\\")\\n\\nThat's how any ROS-compatible robot can be controlled by Robonomics parachain control. Proceed to [part 2](/docs/connect-any-ros-compatible-robot-under-robonomics-parachain-control-2) to learn more\\n\"}},{\"node\":{\"id\":\"b925fa1f52f5f979217b930315a898eb\",\"title\":\"Configuration Options Description\",\"path\":\"/docs/en/configuration-options-description/\",\"content\":\"\\nBasically, you can think of the package as a black box with one input (sensor data) and many outputs.\\nFor now only SDS011 sensor is supported, but if you are familiar with Python it'd be easy to add other sensors as well.\\n\\nHave a look at [configuration](https://github.com/airalab/sensors-connectivity/blob/master/config/default.json) file:\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"port\\\": \\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\": 300,\\n      \\\"geo\\\": \\\"\\\",\\n      \\\"public_key\\\": \\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\nAt the moment it's possible to publish data to [Luftdaten](https://luftdaten.info/), [Robonomics Network](https://robonomics.network/) and [Datalog](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer).\\nThe last one is experimental!\\n\\n> DO NOT edit `config/default.json` file. Instead make a copy\\n\\nPlay around with the configuration!\\n\\nExplanation of options:\\n\\n| Field                         | Description                                                                                                                                                                                                                                           |\\n|------------------------------    |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |\\n| `general/publish_interval`         | integer number from 1 and above. Tells how often send measurements. Keep in mind that if measurements from sensors come less often than this number connectivity sends last data      |\\n| `general/db_path`                  |   path to the database (.db) file    |\\n| `comstation/enable`                | true/false. Enabling/disabling the station      |\\n| `comstation/port`                  | valid path to com port, for example `/dev/ttyUSB0`. It is where a sensor is connected to      |\\n| `comstation/work_period`           | integer from 0 to 1800. For SDS011 sensor 0 means continuous work. Recommended period is 300 seconds     |\\n| `comstation/geo`                   | `lat,lon` a string with two floats separated by a comma. It represents latitude and longitude of a sensor     |\\n| `comstation/public_key`            | Ed25519 verifying key in hex format. If not provided connectivity generates a new one      |\\n| `httpstation/enable`                | true/false. Enabling/disabling the station   |\\n| `httpstation/port`                  | what port listen to      |\\n| `mqttstation/enable`                | true/false. Enabling/disabling the station   |\\n|`mqttstation/host`                   | the hostname or IP address of the remote broker |\\n|`mqttstation/port`                   | the network port of the server host to connect to |\\n| `luftdaten/enable`                 | true/false. Whether or not publish data to [Luftdaten](https://devices.sensor.community/). Don't forget to register the sensor's mac address on the site         |\\n| `robonomics/enable`                | true/false. Whether or not publish data to IPFS topic according to Robonomics communication protocol      |\\n| `robonomics/ipfs_proveder`         | an endpoint for IPFS daemon. By default it's `/ip4/127.0.0.1/tcp/5001/http` that means local daemon. The endpoint must by in multiaddr format. For example for [Infura.io](https://infura.io/) it would be `/dns/ipfs.infura.io/tcp/5001/https`       |\\n| `robonomics/ipfs_topic`            | IPFS topic's name. If you want to use [DApp](https://sensors.robonomics.network) provided by Robonomics team leave it untouched                 |\\n| `datalog/enable`                   | true/false. Enable/Disable saving log to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)    |\\n| `datalog/suri`                     | a private key from robonomics parachain account  |\\n| `datalog/dump_interval`            | specify a period of time for collecting log in seconds                                      |\\n| `datalog/temporal_username`        | set username to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `detalog/temporal_password`        | set password to upload files to [Temporal.Cloud](https://temporal.cloud/) (Optional)                  |\\n| `datalog/pinata_api`                | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) api key                      |\\n| `datalog/pinata_secret`            | your personal [pinata](https://docs.pinata.cloud#connecting-to-the-api) secret api key                |\\n| `dev/sentry`                       | for development purpose. If you have a [Sentry.io](https://sentry.io/) account you can put sentry's credentials in here   |\\n| `frontier/enable`                  | true/false. Whether or not publish telemetry to [Robonomics Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/explorer)   |\\n| `frontier/suri`                    | a private key from robonomics parachain account                                                       |\\n| `trackagro/enable`                 | true/false. Enabling/disabling the station from [TrackAgro](https://tmeteo.docs.apiary.io/#)          |\\n| `trackagro/token`                  | authorization token for [TrackAgro](https://tmeteo.docs.apiary.io/#)                                  |\\n\\n## Scenario #1: Connect SDS011 to serial port\\n\\nThe easiest and the most straightforward way to connect your sensor to the network is using the serial port\\n\\nConnect you SDS011 sensor to a USB port, let's assume it got `/dev/ttyUSB0` address\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":true,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #2: Connect SDS011 via HTTP\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n> Do not forget to open the port in system firewall\\n>\\n> On NixOS you can do:\\n> ```\\n> networking.firewall.allowedTCPPorts = [ 31313 ];\\n> ```\\n\\n## Scenario #3: Connect SDS011 via MQTT\\n\\n### Connectivity Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": false\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": false,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n## Scenario #4: Connect Multiple Sensors and Publish to Datalog\\n\\n### Configuration\\n\\n```json\\n{\\n   \\\"general\\\": {\\n      \\\"publish_interval\\\": 30,\\n      \\\"db_path\\\": \\\"\\\"\\n   },\\n   \\\"comstation\\\":{\\n      \\\"enable\\\":false,\\n      \\\"port\\\":\\\"/dev/ttyUSB0\\\",\\n      \\\"work_period\\\":300,\\n      \\\"geo\\\":\\\"59.944954,30.294534\\\",\\n      \\\"public_key\\\":\\\"\\\"\\n   },\\n   \\\"httpstation\\\": {\\n      \\\"enable\\\": true,\\n      \\\"port\\\": 8001\\n   },\\n   \\\"mqttstation\\\": {\\n      \\\"enable\\\": false,\\n      \\\"host\\\": \\\"localhost\\\",\\n      \\\"port\\\": 1883\\n   },\\n   \\\"luftdaten\\\": {\\n      \\\"enable\\\": true\\n   },\\n   \\\"robonomics\\\": {\\n      \\\"enable\\\": true,\\n      \\\"ipfs_provider\\\": \\\"/ip4/127.0.0.1/tcp/5001/http\\\",\\n      \\\"ipfs_topic\\\": \\\"airalab.lighthouse.5.robonomics.eth\\\"\\n   },\\n   \\\"datalog\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\",\\n      \\\"dump_interval\\\": 60,\\n      \\\"temporal_username\\\": \\\"\\\",\\n      \\\"temporal_password\\\": \\\"\\\",\\n      \\\"pinata_api\\\": \\\"\\\",\\n      \\\"pinata_secret\\\": \\\"\\\"\\n   },\\n   \\\"dev\\\": {\\n      \\\"sentry\\\": \\\"\\\"\\n   },\\n   \\\"frontier\\\": {\\n      \\\"enable\\\": true,\\n      \\\"suri\\\": \\\"\\\"\\n   },\\n   \\\"trackagro\\\": {\\n      \\\"enable\\\": false,\\n      \\\"token\\\": \\\"\\\"\\n   }\\n}\\n```\\n\\n\\n\"}},{\"node\":{\"id\":\"1e80f2902469c07db9a76d4634eb9973\",\"title\":\"Community\",\"path\":\"/docs/en/community/\",\"content\":\"\\n**Here you can learn how to get involved in the Robonomics Network Community.**\\n\\nThere are many ways to contribute to Robonomics Network: you can contribute directly based on your skills and professional background, you can attend an event, join the conversation online or watch for our latest news and release.\\n\\n## For Developers\\n\\n- [Robonomics' code base and new releases on GitHub](https://github.com/airalab)\\n- [Ask your technical question on Riot](https://riot.im/app/#/room/#robonomics:matrix.org)\\n\\n## For Researchers & Academics\\n\\n- [Read Robonomics White Paper and our scientific articles](https://robonomics.network/community/#science)\\n\\nIf you have a background in mathematics, cryptography, or economics you might be interested for collaboration with us, write us to [research@aira.life](mailto:research@aira.life)\\n\\n## For All, even non-technical\\n\\n- [Get familiar with Robonomics services and statistics in dApp - open in browser with Metamask](https://dapp.robonomics.network)\\n- [Read our blog](https://blog.aira.life)\\n- [Stay tuned by following us on Twitter](https://twitter.com/AIRA_Robonomics)\\n\\nIf you are not a developer or a researcher, you can start with other suggestions for getting involeved in Robonomics Network Community. If you want to organize a meetup in your city, write content about Robonomics, translate Robonomics content into your native language, write to [community@aira.life](mailto:community@aira.life)\\n\"}},{\"node\":{\"id\":\"fae8b8f40024c96860b9c0c96d6cff2e\",\"title\":\"Changing Exodus Bridge Receiving Address\",\"path\":\"/docs/en/changing-exodus-receiving-address/\",\"content\":\"\\r\\nThis article will provide guidance on how you can change your Robonomics parachain receiving address in the event that you have input the wrong receiving address in the [Exodus bridge dapp](https://dapp.robonomics.network/#/exodus)\\r\\n\\r\\nPlease be aware that the process of changing the receiving address is not something that will be able to be carried out indefinitely, in fact the intervention of the development team is only possible during the early stages of the Robonomics parachain development, and eventually it will not be possible for the development team to conduct this kind of operation. **Please always ensure that you input the correct parachain address (i.e. one you have the seed phrase for) into the Exodus bridging application**.\\r\\n\\r\\n*Please be informed that the currently, if you input the wrong Robonomics parachain account address into the Exodus bridge dapp, then the process will be carried out as follows:*\\r\\n\\r\\n1. Complete the process as described in this article (i.e. signing the message & raising a GitHub issue).\\r\\n2. Bridged $XRT will be sent to the account originally input into the Exodus bridge dapp (i.e. the incorrect account).\\r\\n3. If no transactions are made on the incorrect account for 1 month, then the Robonomics team will transfer the $XRT tokens to the new address stipulated in the message (which you will sign as per the instructions below).\\r\\n\\r\\nOf course, the utmost priority for the Robonomics team is to ensure only valid changes of address are executed, as such you need to sign a message **from the Ethereum account which you originally deposited the $XRT tokens into the Exodus dapp**. We recommend that you utilize a site such as [MyCrypto](https://app.mycrypto.com/sign-message) to create this message (the following images will show how to conduct this process on MyCrypto).\\r\\n\\r\\nSelect the icon which corresponds to your web3 wallet, in our case we will choose MetaMask.\\r\\n\\r\\n![MyCrypto.com-Landing-Page](https://i.imgur.com/fyJyBG0.png)\\r\\n\\r\\nNow, click on the \\\"Connect to MetaMask\\\" button as shown above, and select the correct account (the account which you previously **sent $XRT tokens from**).\\r\\n\\r\\n![Page-after-selecing-metamask](https://i.imgur.com/1rd6izf.png)\\r\\n\\r\\nNow, we get the option to input a message, you shall follow the below template when inputting the message into this section, otherwise the process will not work. **These addresses relate to the Robonomics parachain addresses**.\\r\\n\\r\\n>Wrong target address: **WRONG_ADDRESS**. Right target address: **RIGHT_ADDRESS**\\r\\n\\r\\nSo, your message will look something like the message below (please make sure you input your own address, and not the one shown below). The message should all be on 1 line, don't use any line breaks (i.e. pressing enter). Afterwards, press the \\\"Sign Message\\\" button located under the message text.\\r\\n\\r\\n![example-of-how-the-message-should-look](https://i.imgur.com/jb1YqLs.png)\\r\\n\\r\\nNow you should get a notification on your web 3 wallet, click \\\"Sign\\\".\\r\\n\\r\\n![Example-metamask-notification](https://i.imgur.com/GTHEYTs.png)\\r\\n\\r\\nOnce signed, wait a few moments and then the MyCrypto page should change, and a signature shall appear.\\r\\n\\r\\n![signature-generated-from-signed-message](https://i.imgur.com/JemAEPm.png)\\r\\n\\r\\nNext, you need to head on over to the [Robonomics GitHub page](https://github.com/airalab/robonomics/issues/new), and open a new issue. The issue should have the title \\\"Robonomics exodus: a request to change the target address\\\", and the body / comment of the issue shall be the signature generated by MyCrypto. Afterwards, click \\\"Submit new issue\\\", and the Robonomics team will handle your issue and leave a reply to your issue regarding the status of your request.\\r\\n\\r\\n![example-of-GitHub-issue](https://i.imgur.com/6ZHSFRw.png)\"}},{\"node\":{\"id\":\"4a404f3329c644a7cf5dfcb0319728f0\",\"title\":\"Offsetting Service\",\"path\":\"/docs/en/carbon-footprint-service/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/Ha9wN6bjh64\\n\\nService to offset CO2 footprint by burning tokens in Statemine network. \\nProduced CO2 calculates as follows: data from device in Wh multiply by  coeffcients depends on the region. 1 ton of C02 is covered by consuption of 1 token. [Here](/docs/carbon-footprint-sensor) is the unstructions for connecting device.\\n\\n## Scenario\\n\\n1. Register a new deivce in Digital Twin in Robonomics network \\n2. Once in an interval getting last data from all device and multiply by the coefficient depending on the region\\n3. Sum data and convert them to CO2 tons\\n4. Subtract the total number of burning tokens from current data \\n5. Burn integer number of tokens in Statemine network \\n6. Saved total number of burning tokens in local DB and Datalog \\n\\n\\n## Installing\\n\\nClone the repository and edit config file.\\n\\n```\\ngir clone https://github.com/tubleronchik/service-robonomics-carbon-footprint.git\\ncd service-robonomics-carbon-footprint\\ncp config/config_template.yaml config/config.yaml \\n```\\n\\n## Configuration description\\n\\nDo not edit `config/config_template.yaml`!\\n\\n```\\nrobonomics:\\n  seed: <seed for account in Robonomics Network where Digital Twin will be created>\\nstatemine:\\n  seed: <seed for admin account with green tokens in Statemine Netowrk>\\n  endpoint: <statemine endpoint>\\n  token_id: <id of the token which will be burned>\\n  ss58_format: <format of address in Polkadot (for Statemine Network is 2)>\\n\\nservice:\\n  interval: <how often data from devices will be collected>\\n```\\nCoefficients for non-renewable energy have been taken from [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=File:Renewable_energy_2020_infographic_18-01-2022.jpg) and stored in `utils/coefficients.py`. \\n\\n## Launch\\n\\n```\\ndocker-compose up\\n```\"}},{\"node\":{\"id\":\"8a119803c4619510a9e317df7fce16e4\",\"title\":\"Connect sensor\",\"path\":\"/docs/en/carbon-footprint-sensor/\",\"content\":\"\\nExample of work is in the video:\\n\\nhttps://youtu.be/jsaFCVAx2sA\\n\\n## Requirements\\n\\n* [Aqara Smart Plug](https://aqara.ru/product/aqara-smart-plug/?yclid=462434430312045270)\\n* Raspberry Pi\\n* Zigbee adapter [JetHome USB JetStick Z2](https://jhome.ru/catalog/parts/PCBA/293/) (or one of [supported](https://www.zigbee2mqtt.io/information/supported_adapters.html))\\n\\nService is running on Raspberry Pi and contact the smart plug via zigbee protocol.\\n\\n## Zigbee stick\\n\\nIf you have JetHome USB JetStick Z2 it already has necessary firmware so you don't need to flash it. But if you have another adapter firstly you need to flash it with zigbee2MQTT software. You can find instructions for you device [here](https://www.zigbee2mqtt.io/information/supported_adapters.html).\\n\\nConnect the adapter and verify the adapter address (it also may be `/dev/ttyUSB1`):\\n```bash\\n$ ls -l /dev/ttyUSB0\\ncrw-rw---- 1 root dialout 166, 0 May 16 19:15 /dev/ttyUSB0 \\n```\\n\\nYou might need to get access to the USB port first. Add your user to `dialout` group (it works for ubuntu, but the name of the group may be different on other OS).\\nFor ubuntu:\\n```bash\\nsudo usermod -a -G dialout $USER\\n```\\nFor arch:\\n```bash\\nsudo usermod -a -G uucp $USER\\n```\\nThen logout and login or restart the computer.\\n\\n## Installation\\n\\nClone the repository:\\n\\n```\\ngit clone https://github.com/makyul/robonomics-carbon-footprint.git\\ncd robonomics-carbon-footprint\\n```\\n\\n## Configuration\\n\\nGo to `data/configuration.yaml` and set `permit_join: true`:\\n\\n```\\n# Home Assistant integration (MQTT discovery)\\nhomeassistant: false\\n\\n# allow new devices to join\\npermit_join: true\\n\\n# MQTT settings\\nmqtt:\\n  # MQTT base topic for zigbee2mqtt MQTT messages\\n  base_topic: zigbee2mqtt\\n  # MQTT server URL\\n  server: 'mqtt://172.17.0.1'\\n  # MQTT server authentication, uncomment if required:\\n  # user: my_user\\n  # password: my_password\\n\\n# Serial settings\\nserial:\\n  # Location of CC2531 USB sniffer\\n  port: /dev/ttyUSB0\\n```\\nAlso you might want to fill fields `server` and `port` with corresponding information. In `server` field use the IP of the `docker0` bridge to establish the connection: \\n\\n```bash\\n$ ip a                                                 127\\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\\n\\n...\\n\\n5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \\n    link/ether 02:42:0d:ff:5f:a3 brd ff:ff:ff:ff:ff:ff\\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::42:dff:feff:5fa3/64 scope link \\n       valid_lft forever preferred_lft forever\\n```\\nHere your address is `172.17.0.1`.\\n\\nThen create file config/config.yaml with following information and set your location (you can look up to https://countrycode.org/ for 3-letters ISO-code):\\n\\n```\\nlocation: RUS\\nservice_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\ntwin_id: 5\\nsending_timeout: 3600\\nbroker_address: \\\"172.17.0.1\\\"\\nbroker_port: 1883\\n```\\n\\n## Connect Plug\\n\\nFirst run:\\n\\n```\\ndocker-compose up     \\n```\\n\\nTo switch to the pairing mode on plug long press the power button for a few seconds until the light starts flashing blue rapidly. \\n\\nIn logs you should see now your plug started publishing to mqtt. \\n\\n\\n## After pairing\\n\\nIf you don't wont to let other devices to pair with your stick, now you should go to `data/configuration.yaml` and set `permit_join: false`. Restart service (use 'Ctrl+C' and \\n\\n```bash\\ndocker-compose up     \\n```\\nonce again to submit changes).\\n\\n## Running\\nAt first start the account for the plug will be created. \\n> If you already have an account you should add its seed to `config.config.yaml` file in `device_seed` section:\\n>\\n> ```\\n> location: RUS\\n> service_address: 4GdHeLbmio2noKCQM5mfxswXfPoW2PcbpYKKkM4NQiqSqJMd\\n> twin_id: 5\\n> sending_timeout: 3600\\n> broker_address: \\\"172.17.0.1\\\"\\n> broker_port: 1883\\n> device_seed: <device_seed>\\n>```\\n\\nAfter creating account you will see the address in logs (seed will be added to `config/config.yaml`):\\n```\\nplug               | Generated account with address: 4GuP82BMAgrbtU8GhnKhgzP827sJEaBXeMX38pZZKPSpcWeT\\n```\\nYou need to transfer some tokens to this account for transaction fees, you can do it on [Robonomics Portal](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/accounts). \\n\\nService will see that you have enough tokens, in logs you will see:\\n```\\nplug               | Balance is OK\\n```\\nService will see mqtt messages from the plug and safe power usage. Every hour (you can change timeout in `config/config.yaml` in `sending_timeout` section, timeout is on seconds) it will create datalog with the following information:\\n```\\n{'geo': 'RUS', 'power_usage': 1.021237391233444, 'timestamp': 1644494860.5860083}\\n```\\n\"}},{\"node\":{\"id\":\"7ce7403be7eef85384c10e1616d88aa6\",\"title\":\"Say \\\"Hello Baxter!\\\" with robonomics\",\"path\":\"/docs/en/baxter2/\",\"content\":\"Example of how it works:\\n\\nhttps://youtu.be/2Dvuv0ZE2Bw\\n\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```sh\\nsudo apt-get install ros-melodic-qt-build ros-melodic-driver-common ros-melodic-gazebo-ros-control ros-melodic-gazebo-ros-pkgs ros-melodic-ros-control ros-melodic-control-toolbox ros-melodic-realtime-tools ros-melodic-ros-controllers ros-melodic-xacro python-wstool ros-melodic-tf-conversions ros-melodic-kdl-parser python-wstool python-catkin-tools qt4-default\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```sh\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node (binary file) (download latest [release][db4] here)\\n - Create __Baxter__ and __Employer__ accounts  on **Robonomics Portal**  \\n (you can find tutorial [\\\"Create an Account on Robonomics Portal\\\"][db8] here).\\n - IPFS browser extension (not necessary)\\n\\n## 0. install CV Bridge extension for python3\\n\\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n## 1. Download simulation and controller packages\\nWe will need to create 2 workspaces - one for main Baxter's packages and other for main control programme.\\nFirst workspace. It's main control programme. It will run under python3.\\n\\n```sh\\ncd ~\\nmkdir -p robonomics_ws/src\\ncd robonomics_ws/src/\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\npip3 install -r requirements.txt\\n```\\nSecond workspace. There will be all Baxter's packages. Simulation is very old, so it could run only under python2.\\n```shell\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src/\\nwstool init .\\nwstool merge https://raw.githubusercontent.com/RethinkRobotics/baxter_simulator/master/baxter_simulator.rosinstall\\nwstool update\\n```\\nThese packages were created for ROS indigo. We have to change some files to run them on ROS melodic.\\nWe will use **patch** files.\\n```sh\\npatch ./baxter_simulator/baxter_sim_io/include/baxter_sim_io/qnode.hpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/qnode_patch\\npatch ./baxter_simulator/baxter_sim_kinematics/src/arm_kinematics.cpp ~/robonomics_ws/src/Baxter_simulation_controller/patch/arm_patch\\npatch ./baxter_interface/src/baxter_interface/robot_enable.py ~/robonomics_ws/src/Baxter_simulation_controller/patch/interface_patch\\n```\\nAnd let's build  all our packages:  \\nFirst build Baxter's packages\\n```sh\\ncd ../\\ncatkin build\\n```\\nThen return to first workspace and build it too:\\n```sh\\ncd ~/Baxter_simulation_controller/\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\necho \\\"source /home/$USER/robonomics_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```  \\n\\n\\n## 2. Start simulation\\n### Let's start our simulation:\\nAt first go to `robot_ws` and copy and edit baxter.sh\\n```sh\\ncd ~/robot_ws/\\ncp src/baxter/baxter.sh .\\n```\\nFind your local ip address with command:\\n```\\nip a\\n```\\n![ip_a][im14]\\n\\nEdit the following values in `baxter.sh` :\\n```\\nnano baxter.sh\\n```\\n\\n- your_ip - put your local ip address. See `ip a`\\n- ros_version - for example \\\"melodic\\\"\\n\\n![baxtersh][im15]\\n\\nRun the baxter shell script with sim specified:\\n```sh\\n./baxter.sh sim\\nroslaunch baxter_gazebo baxter_world.launch\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp\\n```\\n![robonomics][im3]\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts.\\n\\nYou can find The manual \\\"Create an Account on Robonomics Portal\\\" [here][db8]\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\n\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n![create account2][im16]\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robonomics_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same portal [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nWhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL:  \\n#### gateway.ipfs.io/ipfs/< put your hash here>\\n\\n\\n\\nThat's all!\\n\\n![result1][im12]\\n![result2][im13]\\n\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/ip_a.png>\\n[im15]: <../images/baxter_demo/baxter_sh.jpg>\\n[im16]: <../images/baxter_demo/create_account2.jpg>\\n[db8]: <https://wiki.robonomics.network/docs/create-account-in-dapp/>\"}},{\"node\":{\"id\":\"d9860973577427c52e0252080d6e5de0\",\"title\":\"Control Baxter robot with robonomics\",\"path\":\"/docs/en/baxter/\",\"content\":\"\\nExample of how it works:\\n\\nhttps://www.youtube.com/watch?v=JivTDhDJLHo\\n\\n## Requirements:\\n\\n - ROS Melodic + Gazebo (installation manual [here][db2])  \\n - extra packages:\\n```shell\\nsudo apt-get install ros-melodic-gazebo-ros-control ros-melodic-effort-controllers ros-melodic-joint-state-controller python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-melodic-cv-bridge\\n```\\n- IPFS up to 0.6.0 (download from [here][db3] and install)\\n- python packages:\\n```shell\\nsudo apt-get -y install python3-pip\\npip3 install --upgrade pip\\n```\\n - Robonomics node download latest [release][db4] here (last tested release v1.1)\\n - IPFS browser extension (not necessary)\\n## 0. install CV Bridge extension for python3\\n \\n - Create catkin workspace\\n```shell\\nmkdir -p catkin_workspace/src\\ncd catkin_workspace\\ncatkin init\\n```\\n\\n - Instruct catkin to set cmake variables. Use your current version of `python`. For me, it is `python3.6`:\\n```sh\\ncatkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.6m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\\ncatkin config --install\\n```\\n\\n - Clone cv_bridge src:\\n```shell\\ngit clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv\\n```\\n\\n - Find version of cv_bridge in your repository:\\n```shell\\napt-cache show ros-melodic-cv-bridge | grep Version\\n    Version: 1.12.8-0xenial-20180416-143935-0800\\n```\\n\\n - Checkout right version in git repo. In our case it is 1.12.8:\\n```shell\\ncd src/vision_opencv/\\ngit checkout 1.12.8\\ncd ../../\\n```\\n\\n - Build:\\n```shell\\ncatkin build cv_bridge\\n```\\n\\n - Extend environment with new package:\\n\\n```shell\\nsource install/setup.bash --extend\\n``` \\n - Test:\\n```shell\\n$ python3\\n\\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0] on linux\\nType \\\"help\\\", \\\"copyright\\\", \\\"credits\\\" or \\\"license\\\" for more information.\\n>>> from cv_bridge.boost.cv_bridge_boost import getCvType\\n>>>\\n```\\n\\n\\n## 1. Download simulation and controller packages\\nDownload packages:\\n```sh\\ncd ~\\nmkdir -p robot_ws/src\\ncd robot_ws/src\\ngit clone https://github.com/nakata5321/Baxter_simulation_controller.git\\ncd Baxter_simulation_controller\\ngit checkout old_version\\npip3 install -r requirements.txt\\ncd ../..\\ncatkin build -DPYTHON_EXECUTABLE=/usr/bin/python3\\n```\\nDon't forget to add source command:\\n```sh\\necho \\\"source /home/$USER/robot_ws/devel/setup.bash\\\" >> ~/.bashrc\\nsource ~/.bashrc\\n```\\n\\n## 2. Start simulation\\nLet's start gazebo world and put our baxter in it:\\n```sh\\nroslaunch gazebo_ros empty_world.launch\\n```\\n![empty world][im1]\\n\\nOpen one more window in terminal:\\n```sh\\nrosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\\n```\\nYou can put some models in front of our baxter. It will be more interesting.\\n\\n![baxter][im2]\\n\\n## 3.Manage accounts in DAPP\\n\\nSince we are testing, let us create a local robonomics network with robonomics binary file. Go to folder with robonomics file and run:\\n```sh\\n./robonomics --dev --tmp --rpc-cors all\\n```\\n![robonomics][im3]\\n\\n\\nGo to [Robonomics Parachain portal][db5] and switch to local node\\n\\n![local node][im4]\\n\\nGo to Accounts and create __Baxter__ and __Employer__ accounts (__Robot__ is not necessary)\\n\\n__Important!__ Copy each account's **Mnemonic** and **address** (to copy address click on account's icon). **Mnemonic** is the private key for account.\\nTransfer some money (units) to these accounts:\\n\\n![create account][im5]\\n\\n![create account2][im14]\\n\\n![accounts][im6]\\n\\nAdd Baxter's **Mnemonic** and **address** to `config.yaml` in `robot_ws/src/Baxter_simulation_controller/config/`\\n\\n## 4.Start simulation\\n\\nIn new window run:\\n```sh\\nifps init #you only need to do this once\\nipfs daemon\\n```\\nOpen separate terminal and start *controller package*:\\n```sh\\nrosrun robot_controller robot_control.py\\n```\\n![waiting][im7]\\n\\nNow you can send a transaction triggering the Baxter to start moving and collecting data. To do so, you can use the same [Robonomics Parachain portal][db5]. Go to **Developer->Extrinsics** and select Baxter's employer account, `launch` extrinsic, Baxter's account as a target account and `yes` as a parameter. Submit the extrinsic.\\n\\n\\n![rob_message][im8]\\n\\nThe robot should start moving. It won't accept commands from other accounts neither commands with `no` parameter.\\nYou should see the following:\\n\\n![working][im9]\\n\\nwhen the work is over go to the Robonomics Portal to `Developer > Chain state`. Choose *datalog.datalogItem(AccountId,u64)* in **state query**.If you want to show all datalog's, then turn off `include option` add view Baxter's datalog message using \\\"+\\\" button.\\n\\n![datalog][im10]\\n\\nNow the IPFS hash of the telemetry and photos is saved in the blockchain. To see the data simply copy the hash and insert it in the search bar with URL: gateway.ipfs.io/ipfs/< put your hash here >\\n\\n![ipfs][im11]\\n\\nClick  __View on Gateway__ and that's all!\\n\\n![result1][im12]\\n\\n![result2][im13]\\n\\n[db2]: <http://wiki.ros.org/melodic/Installation>\\n[db3]: <https://dist.ipfs.io/go-ipfs/v0.6.0/go-ipfs_v0.6.0_linux-386.tar.gz>\\n[db4]: <https://github.com/airalab/robonomics/releases>\\n[im1]: <../images/baxter_demo/empty_world.jpg>\\n[im2]: <../images/baxter_demo/baxter_simulation.jpg>\\n[im3]: <../images/baxter_demo/robonomics.jpg>\\n[db5]: <https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.rpc.robonomics.network%2F#/>\\n[im4]: <../images/baxter_demo/local_node.jpg>\\n[im5]: <../images/baxter_demo/create_account.jpg>\\n[im6]: <../images/baxter_demo/accounts.jpg>\\n[im7]: <../images/baxter_demo/waiting.jpg>\\n[db6]: <https://wiki.robonomics.network/docs/rio-overview/>\\n[im8]: <../images/baxter_demo/rob_message.jpg>\\n[im9]: <../images/baxter_demo/working.jpg>\\n[im10]: <../images/baxter_demo/datalog.jpg>\\n[im11]: <../images/baxter_demo/ipfs.jpg>\\n[im12]: <../images/baxter_demo/result1.jpg>\\n[im13]: <../images/baxter_demo/result2.jpg>\\n[im14]: <../images/baxter_demo/create_account2.jpg>\"}},{\"node\":{\"id\":\"cd746379fa5a86f0030a2f8f1fc33d86\",\"title\":\"AIRA Overview\",\"path\":\"/docs/en/aira-overview/\",\"content\":\"\\n## Introduction\\n\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It implements the standard of economic interaction between human-robot and robot-robot. AIRA makes it possible to connect a variety of different robots under decentralized computer's control (currently supported Ethereum and Polkadot/Substrate).\\n\\nBasically it is the client for Robonomics Network developed by [Airalab](https://aira.life).\\n\\nAIRA is NixOS based operating system and officially supports the following architectures: x86, Raspberry Pi 3 B+ and Raspberry Pi 4.\\n\\nThe most simple way to get familiar with AIRA is to try installing AIRA as a [virtual machine](/docs/aira-installation-on-vb/).\\n\\nAIRA comes with a few preinstalled and configured services to help you focus on [agent](/docs/glossary#agent) development.\\n\\nMeanwhile it's highly customizable, but it's recommended to understand [NixOS](http://nixos.org/) and [Nix](https://nixos.org/nix/) language.\\n\\n## What's included? \\n\\nThe following services are included in the default distribution:\\n\\n* [Robonomics communication stack](https://github.com/airalab/robonomics_comm)\\n* [IPFS](https://ipfs.io/)\\n* OpenSSH\\n* [cjdns](https://github.com/cjdelisle/cjdns)\\n* [Yggdrasil-go](https://yggdrasil-network.github.io/)\\n\\nBesides at the first launch AIRA [generates](/docs/aira-installation-on-vb#launch-the-machine) for you new Ethereum address and IPNS identifier.\\n\\nIt's possible to use AIRA as a virtual machine or install as a main operating system. Also you can install only the services you need.\\n\"}},{\"node\":{\"id\":\"f181f28f3ec5920cdb3001ccef3fd75d\",\"title\":\"AIRA Installation\",\"path\":\"/docs/en/aira-installation/\",\"content\":\"\\n- [**How to launch AIRA on VirtualBox**](/docs/aira-installation-on-vb/)\\n\\n- **The installation on Raspberry Pi** is as simple as writing an image of AIRA on SD card using `dd` or [Etcher](https://www.balena.io/etcher/), for example.\\n\\n\\n\"}},{\"node\":{\"id\":\"10b1bb8045334d3bde42d2cdfc70e341\",\"title\":\"AIRA Installation on VirtualBox\",\"path\":\"/docs/en/aira-installation-on-vb/\",\"content\":\"\\nAIRA stands for \\\"Autonomous Intelligent Robot Agent\\\". It is the client for Robonomics Network developed by [Airalab](https://aira.life). It is an operating system based on [NixOS](https://nixos.org/). With AIRA you can  turn any cyber-physical system in an economic agent, where robots operate as a services for the reasonable payments. [More theory about AIRA here](/docs/aira-overview).\\n\\nIt's possible to install AIRA on a x86_64 PC. Also there are images for Raspberry Pi 3 and 4 supported by the team.\\n\\nThe best way to try AIRA is to start from installing it as a virtual machine on [VirtualBox](https://www.virtualbox.org/).\\n\\n## Requirements\\n\\n* VirtualBox\\n* [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads#VirtualBox6.1.2OracleVMVirtualBoxExtensionPack)\\n* 2Gb of RAM for the machine\\n* 40Gb of free disk space\\n\\n## Obtain the image\\n\\nAIRA has [stable](https://aira.life/channels/aira-stable/) and [unstable](https://aira.life/channels/aira-unstable/) channels.\\n\\nTo get stable image download the file with `.ova` extension.\\n\\tThe link for stable image is [here](https://releases.aira.life/channels/aira/stable/862-aira-stable/nixos-20.03pre-git-x86_64-linux.ova)\\n\\nDon't forget to compare checksum of the downloaded image with the last column `SHA-256 hash` on the [download page](https://aira.life/channels/aira-stable/). It must be equal to the output of the following command (it is an example, please check the name of downloaded by you .ova file first):\\n\\n```\\nsha256sum nixos-20.03pre-git-x86_64-linux.ova\\n```\\n\\nYou may wish to check out the walkthrough video:\\n\\nhttps://www.youtube.com/embed/cDcaypYPBhI\\n\\n## Troubleshooting\\n\\nIf you have fresh installed VirtualBox, you need to install the [extension](https://www.virtualbox.org/wiki/Downloads) pack or disable USB 2.0 controller.\\n\\nAlso VirtualBox may show a warning about `Display settings`. Consider switching `Graphics Controller` in settings of the VM to `VMSVGA`.\\n\\n## Import to VirtualBox\\n\\nOpen VirtualBox and press `Ctrl+I` or go to `File > Import Applicance...`\\n\\n![AIRA import VB image](../images/aira-installation/aira_import_vb_image.jpg \\\"AIRA import VB image\\\")\\n\\nAt this moment the next step is not necessary but it will help you to connect to the VM via SSH easily.\\n\\nFirst add `Host-Only` adapter in VirtualBox menu `File > Host Network Manager...` or by pressing `Ctrl+H`\\n\\n![Host Only](../images/aira-installation/host_only_adapter.jpg \\\"Host Only\\\")\\n\\nThen go to the image's settings, Network and add the second network adapter\\n\\n![Second adapter](../images/aira-installation/add_second_adapter.jpg \\\"Second adapter\\\")\\n\\nFor more details look at the standalone [lesson](/docs/aira-connecting-via-ssh/).\\n\\nOptionally you can increase the amount of video memory and switch `Graphics Controller` to `VMSVGA`.\\n\\n## Launch the machine\\n\\nFinally press Start and you'll see AIRA welcoming you with generated Ethereum address and IPFS identifier\\n\\n![AIRA image ready, Welcome screen](../images/aira-installation/aira_image_ready.jpg \\\"AIRA image ready, Welcome screen\\\")\\n\\nAt the very first initialization AIRA generates new Ethereum address and IPNS identifier for you.\\n\\n\"}},{\"node\":{\"id\":\"e822ab468fea96f049f1777e70537497\",\"title\":\"Frequently Asked Questions about AIRA\",\"path\":\"/docs/en/aira-faq/\",\"content\":\"\\n## How to see logs from main services?\\n\\nIPFS in real time:\\n\\n    journalctl -u ipfs -f\\n\\nand Liability::\\n\\n    journalctl -u liability -f\\n\\n## How to check the quantity of IPFS peers?\\n\\n    ipfs pubsub peers \\n\\n## IPFS can't connect to the daemon, what should I do?\\n\\nTry to specify `--api` option\\n\\n    ipfs swarm peers --api=/ip4/127.0.0.1/tcp/5001/\\n\\n## How to change ethereum address of AIRA?\\n\\nDelete `keyfile` and `keyfile-psk` in `/var/lib/liability` and restart the service\\n\\n```\\nsystemctl restart liability\\n```\\n\\n## IPFS daemon doesn't start\\n\\nThe error mostly occurs on single-board computers like Raspberry Pi or LattePanda after unexpected electricity lost.\\n\\nUsually the file `/var/lib/ipfs/api` is corrupted and one may see error:\\n\\n```\\nError: Failed to parse '/var/lib/ipfs/api' file.\\n  error: failed to parse multiaddr \\\"\\\": empty multiaddr\\nIf you're sure go-ipfs isn't running, you can just delete it.\\nOtherwise check:\\n  ps aux | grep ipfs\\n```\\n\\nYou can delete `/var/lib/ipfs/api` file and restart the service\\n\\n\"}},{\"node\":{\"id\":\"c516ac9b4e9b1c44b1df63ac5effd436\",\"title\":\"Connecting AIRA via SSH\",\"path\":\"/docs/en/aira-connecting-via-ssh/\",\"content\":\"\\nIt is more convenient to work with virtual machine via ssh connection. In this section we will configure VM.\\n\\n> **It's required to have your ssh public key on Github. In case you don't have one, please follow the [link](https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/)**\\n\\nBelow is the walkthrough video:\\n\\nhttps://www.youtube.com/embed/R6waDG5iwm0\\n\\n## Add Host Adapter\\n\\nGo to `File` -> `Host Network Manager...` or press `Ctrl+H`\\n\\n![VirtualBox Network Manager](../images/virtualbox_network_manager.png \\\"VirtualBox Network Manager\\\")\\n\\nClick `Create` button.\\n\\n## Add the Second Adapter to the VM\\n\\nSelect imported VM and click `Settings`. Go to `Network` tab and enable the second adapter\\n\\n![Add Second Adapter](../images/add_second_adapter_to_vm.png \\\"Add Second Adapter\\\")\\n\\n## Populate Authorized Keys\\n\\nLaunch the VM and run the following command replacing `<username>` with your Github user name:\\n\\n```\\nmkdir .ssh\\nchmod 700 .ssh\\ncurl -sSL https://github.com/<username>.keys >> .ssh/authorized_keys\\n```\\n\\nFind out the VM's IP address by running:\\n\\n```\\nip a\\n```\\n\\nYou should look for an address which starts with `192.168.xx.xx`\\n\\n## Log in via SSH\\n\\nNow open your terminal and log in via SSH as usual using the address from the previous step:\\n\\n```\\nssh root@192.168.xx.xx\\n```\\n\"}},{\"node\":{\"id\":\"57dfc372142c3201a7d8f9427ea22d4f\",\"title\":\"Basic usage of AIRA\",\"path\":\"/docs/en/aira-basic-usage/\",\"content\":\"\\nTo get familiar with AIRA, let's see what is under the hood.\\n\\nOnce you launch the client several ros nodes will already be on the run. Here's a list of robonomics communication stack nodes:\\n\\n```bash\\n$ rosnode list\\n/eth/erc20_token\\n/eth/eth_node\\n/graph/aira_graph\\n/liability/executor\\n/liability/infochan/eth/signer\\n/liability/infochan/ipfs_channel\\n/liability/persistence\\n/liability/listener\\n/rosout\\n```\\n\\n- `/eth/erc20_token`, `/eth/eth_node` - proved services for Ethereum blockchain and ERC20 tokens\\n- `/graph/aira_graph` - service node for exploring other AIRA instances\\n- `/liability/executor` - gets rosbag file from IPFS and plays it\\n- `/liability/infochan/ipfs_channel` - is responsible for offer, demand and result messages. It catches messages from the channel and sends signed messages back\\n- `/liability/infochan/eth/signer` - offers services for signing offer, demand and result messages\\n- `/liability/listener` - watches for a new liability contracts. When the event is received the node calls executor node\\n- `/liability/persistence` - helps to store incoming liabilities and restart them after shutdown\\n\\nAnd here's a list of robonomics stack topics.\\n\\n```bash\\n$ rostopic list\\n/eth/event/approval\\n/eth/event/transfer\\n/graph/greetings\\n/liability/complete\\n/liability/finalized\\n/liability/incoming\\n/liability/infochan/eth/sending/demand\\n/liability/infochan/eth/sending/offer\\n/liability/infochan/eth/sending/result\\n/liability/infochan/eth/signing/demand\\n/liability/infochan/eth/signing/offer\\n/liability/infochan/eth/signing/result\\n/liability/infochan/incoming/demand\\n/liability/infochan/incoming/offer\\n/liability/infochan/incoming/result\\n/liability/persistence/add\\n/liability/persistence/del\\n/liability/persistence/update_timestamp\\n/liability/ready\\n/liability/result\\n/rosout\\n/rosout_agg\\n```\\n\\nThe most important topics for us are:\\n\\n- `/liability/incoming` - when a new liability is created, this topic publishes Ethereum address of the contract\\n- `/liability/result` - this topic is for publishing results. But don't publish a result directly to this topic! Use a service instead\\n- `/liability/infochan/incoming/*` - a CPS gets information about offer, demand or result from corresponding topics\\n- `/liability/infochan/eth/signing/*` - a CPS sends offer, demand or result messages to corresponding topics\\n\\nFor the details check out the [API page](/docs/robonomics-liability/).\\n\\nLet's start with greetings - say hello to AIRA!\\n\\nYou should just launch a pre-installed package `hello_aira`:\\n\\n```\\n$ rosrun hello_aira hello_aira\\n```\\n\\nWe've launched our agent. It will wait for a demand message. Now it's time to send the message. Go to [dapp](https://airalab.github.io/robonomics_tutorials/) and press Order.\\nNow go back to the console and see the result!\"}},{\"node\":{\"id\":\"d32c76ebc4a70fe87b9d61fae18909cd\",\"title\":\"Agent development examples\",\"path\":\"/docs/en/agent-development-examples/\",\"content\":\"\\nUseful pieces of code and a few scenarios. All source code is [here](https://github.com/vourhey/robonomics_tutorials).\\n\\n1. [Broadcast Demand](https://github.com/Vourhey/robonomics_tutorials/tree/master/01_broadcast_demand/)\\n2. [Broadcast Offer](https://github.com/Vourhey/robonomics_tutorials/tree/master/02_broadcast_offer/)\\n3. [Trader](https://github.com/Vourhey/robonomics_tutorials/tree/master/03_trader/)\\n4. [Trader with ACL](https://github.com/Vourhey/robonomics_tutorials/tree/master/04_trader_with_acl/)\\n5. [Open Sensor Data](https://github.com/Vourhey/robonomics_tutorials/tree/master/05_open_sensor_data/)\\n\\n\"}},{\"node\":{\"id\":\"962df0ddf916fde494d62ea1e699af57\",\"title\":\"Adding funds to your account on Robonomics Portal\",\"path\":\"/docs/en/adding-funds-to-account-in-dapp/\",\"content\":\"\\n**After successfully creating your accounts on Robonomics portal, it is time to add funds to them so that you would able to initiate transactions.**\\n\\n## 1. Navigate to Accounts section on Robonomics portal \\n\\n![Accounts](../images/creating-an-account/portal-top-left.jpg \\\"Accounts\\\")\\n\\n## 2. Choose the account you want to transfer funds from\\n\\nIn the development mode, there exist several accounts, with 10000 Units worth of funds each, that can be used to transfer funds to other accounts created in the development network. These accounts are indicated by wrench signs <img alt=\\\"wrench sign\\\" src=\\\"../images/adding-funds/wrench.png\\\" width=\\\"20\\\" /> next to them.\\n\\n![Accounts-for-sending](../images/adding-funds/accounts-for-sending.svg \\\"Accounts-for-sending\\\")\\n\\n- Click on the \\\"send\\\" button of the account you want to transfer funds from, for example BOB\\n\\n## 3. Choose the account you want to transfer funds into\\nAfter clicking on the \\\"send\\\" button, you would be prompted with the \\\"send funds window\\\". In the prompted window:\\n\\n- From the list of available accounts, choose the account you want to send funds into.\\n- Enter the number of Units you want to send.\\n- Press \\\"make transfer\\\"\\n\\n![Transfer-Funds](../images/adding-funds/send-funds.png \\\"Transfer-Funds\\\")\\n\\n## 4. Authorize the transaction\\n\\nAfter pressing \\\"make transfer\\\" in the previous stage, you would be prompted with \\\"authorize transaction window\\\".<br/>\\nReview the details of the transaction and finally click on \\\"sign and submit\\\" button.\\n\\n![sign-transaction](../images/adding-funds/sign-transaction.png \\\"sign-transaction\\\")\\nIn this example, we transferred 500 units of funds from \\\"BOB\\\" to \\\"EMPLOYER\\\". You can see that EMPLOYER's account, which initially did not have any funds, has 500 Units of fund now.\\n\\n![funds-added](../images/adding-funds/funds-added.svg \\\"funds-added\\\")\\n\\n**Make sure that you have enough funds in the accounts you want to use in the playground.**\"}},{\"node\":{\"id\":\"170ca1f4621e9a6a853b0d85d2375601\",\"title\":\"Add Device to Robonomics\",\"path\":\"/docs/en/add-smart-device-to-robonomics/\",\"content\":\"For each device you need separate [Robonomics accounts](/docs/create-account-in-dapp/). After you've added your devices, you need to add them in a `config.config` file with their seeds. Firstly in `Configuration/Entities` tab in your Home Assistant find entity ids of your devices:\\n\\n![entity_id](../images/home-assistant/entity_id.png)\\n\\nOpen the configuration file:\\n```bash\\nnano /srv/homeassistant/python_scripts/config.config\\n```\\nAnd add there information of your devices in the following format:\\n\\n```\\n[device_name]\\nIDS = ['entity_id1', 'entity_id2']\\nSEED = word word word\\n```\\nWhere `device_name` is the name of your device (you can choose any name), `IDS` are entity ids of the data from the device (it may be one or more ids) and `SEED` is a mnemonic or raw seed from robonomics account to this device.\\n\\nAfter you fill the configuration file you need to get access token from Home Assistant. For that open your `profile` in the lower left corner:\\n\\n![profile](../images/home-assistant/profile.png)\\n\\nIn the end of the page find `Long-Lived Access Tokens` and press `create token`. Save it somewhere, you will not be able to see it again.\\n\\n![token](../images/home-assistant/token.png)\\n\\nNow run `create_config.py` script with your token:\\n\\n```bash\\ncd /srv/homeassistant\\nsource bin/activate\\npython3 python_scripts/create_config.py --token <access_token>\\n```\\nAnd restart Home Assistant:\\n```bash\\nsystemctl restart home-assistant@homeassistant.service\\n```\\n\\nYou can add the data from sensors to your homepage like in `Home Assistant setup` in the description to [Method 1](/docs/zigbee2-mqtt/).\\n\\nYou can see the data in [subscan](https://robonomics.subscan.io/), find your account and you will see datalog transactions. Data looks like this:\\n\\n![datalog_data](../images/home-assistant/datalog_data.png)\\n\\nYou can decrypt it with script `decrypt.py`, run it with the data from datalog:\\n```bash\\ncd /srv/homeassistant/\\nsource bin/activate\\npython3 python_scripts/decrypt.py <data>\\n```\"}}]}};/* harmony default export */ __webpack_exports__[\"default\"] = (function(_ref){var options=_ref.options;if(options.__staticData){options.__staticData.data=data;return;}options.__staticData=vue__WEBPACK_IMPORTED_MODULE_0__[\"default\"].observable({data:data});options.computed=computed({$static:function $static(){return options.__staticData.data;}},options.computed);});\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/babel-loader/lib??ref--14-0!./node_modules/gridsome/lib/plugins/vue-components/lib/loaders/static-query.js!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "uifM":
/*!************************************************************************************************************************************************************************************************************************************************************!*\
  !*** ./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options!./src/components/Search.vue?vue&type=script&lang=js& ***!
  \************************************************************************************************************************************************************************************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var core_js_modules_es_regexp_exec_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! core-js/modules/es.regexp.exec.js */ \"rB9j\");\n/* harmony import */ var core_js_modules_es_regexp_exec_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_regexp_exec_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var core_js_modules_es_string_search_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! core-js/modules/es.string.search.js */ \"hByQ\");\n/* harmony import */ var core_js_modules_es_string_search_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_string_search_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var core_js_modules_es_array_filter_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! core-js/modules/es.array.filter.js */ \"TeQF\");\n/* harmony import */ var core_js_modules_es_array_filter_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_array_filter_js__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var core_js_modules_es_object_to_string_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! core-js/modules/es.object.to-string.js */ \"07d7\");\n/* harmony import */ var core_js_modules_es_object_to_string_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_object_to_string_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var core_js_modules_es_array_includes_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! core-js/modules/es.array.includes.js */ \"yq1k\");\n/* harmony import */ var core_js_modules_es_array_includes_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_array_includes_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var core_js_modules_es_string_includes_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! core-js/modules/es.string.includes.js */ \"JTJg\");\n/* harmony import */ var core_js_modules_es_string_includes_js__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_string_includes_js__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var core_js_modules_es_string_trim_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! core-js/modules/es.string.trim.js */ \"SYor\");\n/* harmony import */ var core_js_modules_es_string_trim_js__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(core_js_modules_es_string_trim_js__WEBPACK_IMPORTED_MODULE_6__);\n\n\n\n\n\n\n\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n/* harmony default export */ __webpack_exports__[\"default\"] = ({\n  data: function data() {\n    return {\n      isActive: false,\n      isFocused: false,\n      search: ''\n    };\n  },\n  computed: {\n    toggleClasses: function toggleClasses() {\n      return {\n        'active': this.isActive\n      };\n    },\n    searchResults: function searchResults() {\n      var _this = this;\n\n      if (this.search.length > 2) {\n        return this.$static.allDocPage.edges.filter(function (post) {\n          return (post.node.title.toLowerCase().includes(_this.search.toLowerCase().trim()) || post.node.content.toLowerCase().includes(_this.search.toLowerCase().trim())) & post.node.path.includes('/' + _this.$store.state.locale + '/') & post.node.path != _this.$route.matched[0].path + '/';\n        });\n      } else return '';\n    }\n  },\n  methods: {\n    focusIn: function focusIn() {\n      this.isActive = true;\n    },\n    focusOut: function focusOut() {\n      this.isActive = false;\n    } // SearchLinksFocus() {\n    //   document.querySelector('.search-container nav a:first-child').focus()\n    // }\n\n  },\n  watch: {\n    \"$route.path\": function $routePath() {\n      this.isActive = false;\n    }\n  }\n});\n\n//# sourceURL=webpack:///./src/components/Search.vue?./node_modules/cache-loader/dist/cjs.js??ref--1-0!./node_modules/babel-loader/lib??ref--1-1!./node_modules/cache-loader/dist/cjs.js??ref--0-0!./node_modules/vue-loader/lib??vue-loader-options");

/***/ }),

/***/ "wQbG":
/*!***********************************!*\
  !*** ./src/components/Search.vue ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Search.vue?vue&type=template&id=2d5d749c& */ \"Lr+N\");\n/* harmony import */ var _Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Search.vue?vue&type=script&lang=js& */ \"BO/4\");\n/* empty/unused harmony star reexport *//* harmony import */ var _Search_vue_vue_type_style_index_0_lang_scss_scope_true___WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Search.vue?vue&type=style&index=0&lang=scss&scope=true& */ \"ZbFX\");\n/* harmony import */ var _node_modules_vue_loader_lib_runtime_componentNormalizer_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../node_modules/vue-loader/lib/runtime/componentNormalizer.js */ \"KHd+\");\n/* harmony import */ var _Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Search.vue?vue&type=custom&index=0&blockType=static-query */ \"A2fM\");\n\n\n\n\n\n\n/* normalize component */\n\nvar component = Object(_node_modules_vue_loader_lib_runtime_componentNormalizer_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(\n  _Search_vue_vue_type_script_lang_js___WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  _Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__[\"render\"],\n  _Search_vue_vue_type_template_id_2d5d749c___WEBPACK_IMPORTED_MODULE_0__[\"staticRenderFns\"],\n  false,\n  null,\n  null,\n  null\n  \n)\n\n/* custom blocks */\n\nif (typeof _Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__[\"default\"] === 'function') Object(_Search_vue_vue_type_custom_index_0_blockType_static_query__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(component)\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (component.exports);\n\n//# sourceURL=webpack:///./src/components/Search.vue?");

/***/ })

}]);